{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 1 - Machine Learning II \n",
    "Prof: Carlos Padilha\n",
    "\n",
    "#### Alunos:  \n",
    "\n",
    "Roberto A. Coutinho  \n",
    "Thais Galho\n",
    "\n",
    "\n",
    "## Sistemas com Multi-classificadores ou Ensembles\n",
    "\n",
    "#### Este trabalho visa avaliar o entendimento em relaçãao á construção de sistemas com multi-classificadores ou ensembles. Para tal, os alunos deverão fazer o seguinte:\n",
    "\n",
    "\n",
    "* Implementar o algoritmo AdaBoost (nos mesmos moldes que fizemos com o algoritmo Bagging).\n",
    "    – Podem escolher qualquer tipo de classificador (MLP, SVM, etc).\n",
    "* Processar os dados presente no arquivo sonar.all-data.\n",
    "* Realizar treinamento e teste usando validação cruzada com 10 folds.\n",
    "* Avaliar os resultados em termos de acurácia, recall e precisão.\n",
    "\n",
    "Obs: O trabalho pode ser feito em dupla e deve ser enviado por email (carlos.engcomp@gmail.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modelos\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# K-fold CrossValidation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# K-fold CrossValidation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9  ...      51      52      53      54      55      56      57      58  \\\n",
       "0  0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090   \n",
       "1  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
       "2  0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
       "3  0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
       "4  0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
       "\n",
       "       59  60  \n",
       "0  0.0032   R  \n",
       "1  0.0044   R  \n",
       "2  0.0078   R  \n",
       "3  0.0117   R  \n",
       "4  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_data = pd.read_csv('sonar.all-data.csv', header=None)\n",
    "imported_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 208)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separação entre dados e labels\n",
    "\n",
    "labels = imported_data.iloc[:,-1]\n",
    "data = imported_data.iloc[:,:-1]\n",
    "len(data), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def getAccuracy(testset, predictions):\n",
    "    correct = 0\n",
    "    for id_test, test in enumerate(testset):\n",
    "        if test == predictions[id_test]:\n",
    "            correct += 1\n",
    "    return (correct / float(len(testset))) * 100.0\n",
    "\n",
    "def printCM(Y_test, predictions):\n",
    "    cm = confusion_matrix(Y_test, predictions)\n",
    "    print ('Confusion Matrix : ')\n",
    "    print (cm)\n",
    "    print\n",
    "    tn = float(cm[0][0])\n",
    "    fp = float(cm[0][1])\n",
    "    fn = float(cm[1][0])\n",
    "    tp = float(cm[1][1])\n",
    "\n",
    "    actual_yes = fn+tp\n",
    "    actual_no = tn+fp\n",
    "    predicted_yes = fp+tp\n",
    "    predicted_no = tn+fn\n",
    "\n",
    "    total = float(len(imported_data))\n",
    "    print ('Total : '+ str(total))\n",
    "\n",
    "    acc = str(getAccuracy(Y_test, predictions))\n",
    "    print ('Acurácia : ' + acc)\n",
    "\n",
    "    misclassification_rate = round((fp+fn)/total,3) # Overall, how often is it wrong?\n",
    "    print ('Misclassification rate : ' +str(misclassification_rate))\n",
    "\n",
    "    true_positive = round(tp/actual_yes,3) # When it's actually yes, how often does it predict yes?\n",
    "    print ('True positives : ' +str(true_positive))\n",
    "\n",
    "    false_positive = round(fp/actual_no,3) # When it's actually no, how often does it predict yes?\n",
    "    print ('False positives : ' +str(false_positive))\n",
    "\n",
    "    specificity = round(tn/actual_no,3) # When it's actually no, how often does it predict no?\n",
    "    print ('Specificity : ' +str(specificity))\n",
    "\n",
    "    precision = round(tp/predicted_yes,3) # When it predicts yes, how often is it correct?\n",
    "    print ('Precision : ' +str(precision))\n",
    "\n",
    "    prevalence = round(actual_yes/total,3) # How often does the yes condition actually occur in our sample?\n",
    "    print ('Prevalence : ' +str(prevalence))\n",
    "\n",
    "    #f1 = round(2 * ((precision * true_positive) / (precision + true_positive)),3)\n",
    "    #print ('F1 Score : ' +str(f1))\n",
    "    \n",
    "    return acc, precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Treinamento</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 156)\n",
      "(52, 52)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# utiliza 25% do dataset para teste\n",
    "trainData, testData, trainLabels, testLabels = train_test_split(data, labels, \n",
    "                                                    train_size=0.75, \n",
    "                                                    test_size=0.25, \n",
    "                                                    stratify=labels)\n",
    "\n",
    "print(len(trainData), len(trainLabels))\n",
    "print(len(testData), len(testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializando vetor de pesos....\n",
      "[0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026]\n",
      "\n",
      "Iniciando treinamento com 10 K-folds\n",
      "\n",
      "################################################\n",
      "K-fold : 1\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.22142857142857197\n",
      "Alpha : 0.012573606777439943\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[62 12]\n",
      " [19 47]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 77.8571428571\n",
      "Misclassification rate : 0.149\n",
      "True positives : 0.712\n",
      "False positives : 0.162\n",
      "Specificity : 0.838\n",
      "Precision : 0.797\n",
      "Prevalence : 0.317\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 2]\n",
      " [1 6]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 81.25\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.857\n",
      "False positives : 0.222\n",
      "Specificity : 0.778\n",
      "Precision : 0.75\n",
      "Prevalence : 0.034\n",
      "\n",
      "New weights : \n",
      "[0.00633016 0.00649137 0.00649137 0.00633016 0.00633016 0.00633016\n",
      " 0.00633016 0.00633016 0.00633016 0.00633016 0.00633016 0.00633016\n",
      " 0.00649137 0.00633016 0.00649137 0.00633016 0.00633016 0.00633016\n",
      " 0.00633016 0.00633016 0.00633016 0.00633016 0.00633016 0.00633016\n",
      " 0.00649137 0.00649137 0.00633016 0.00633016 0.00649137 0.00633016\n",
      " 0.00633016 0.00633016 0.00633016 0.00633016 0.00633016 0.00633016\n",
      " 0.00633016 0.00649137 0.00633016 0.00633016 0.00633016 0.00633016\n",
      " 0.00633016 0.00649137 0.00633016 0.00633016 0.00633016 0.00633016\n",
      " 0.00649137 0.00633016 0.00633016 0.00633016 0.00633016 0.00633016\n",
      " 0.00633016 0.00633016 0.00633016 0.00649137 0.00633016 0.00633016\n",
      " 0.00633016 0.00633016 0.00633016 0.00633016 0.00633016 0.00649137\n",
      " 0.00633016 0.00633016 0.00649137 0.00633016 0.00633016 0.00633016\n",
      " 0.00633016 0.00633016 0.00633016 0.00633016 0.00649137 0.00633016\n",
      " 0.00633016 0.00633016 0.00633016 0.00633016 0.00649137 0.00633016\n",
      " 0.00633016 0.00649137 0.00649137 0.00633016 0.00649137 0.00633016\n",
      " 0.00633016 0.00633016 0.00633016 0.00633016 0.00633016 0.00633016\n",
      " 0.00633016 0.00649137 0.00633016 0.00633016 0.00633016 0.00649137\n",
      " 0.00649137 0.00633016 0.00633016 0.00649137 0.00649137 0.00633016\n",
      " 0.00649137 0.00633016 0.00649137 0.00633016 0.00633016 0.00633016\n",
      " 0.00633016 0.00649137 0.00633016 0.00633016 0.00649137 0.00633016\n",
      " 0.00649137 0.00633016 0.00633016 0.00633016 0.00633016 0.00633016\n",
      " 0.00633016 0.00633016 0.00633016 0.00633016 0.00633016 0.00633016\n",
      " 0.00633016 0.00633016 0.00633016 0.00633016 0.00649137 0.00649137\n",
      " 0.00633016 0.00649137 0.00633016 0.00649137 0.00633016 0.00633016\n",
      " 0.00633016 0.00633016 0.00633016 0.00633016 0.00649137 0.00633016\n",
      " 0.00649137 0.00633016 0.00633016 0.00633016 0.00633016 0.00633016]\n",
      "\n",
      "################################################\n",
      "K-fold : 2\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2139885533927723\n",
      "Alpha : 0.01301048830664234\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[60 12]\n",
      " [18 50]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 78.5714285714\n",
      "Misclassification rate : 0.144\n",
      "True positives : 0.735\n",
      "False positives : 0.167\n",
      "Specificity : 0.833\n",
      "Precision : 0.806\n",
      "Prevalence : 0.327\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 2]\n",
      " [2 3]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 75.0\n",
      "Misclassification rate : 0.019\n",
      "True positives : 0.6\n",
      "False positives : 0.182\n",
      "Specificity : 0.818\n",
      "Precision : 0.6\n",
      "Prevalence : 0.024\n",
      "\n",
      "New weights : \n",
      "[0.00624834 0.00657637 0.00640746 0.00624834 0.00624834 0.00624834\n",
      " 0.00624834 0.00624834 0.00641306 0.00624834 0.00641306 0.00624834\n",
      " 0.00640746 0.00624834 0.00640746 0.00624834 0.00624834 0.00624834\n",
      " 0.00624834 0.00624834 0.00624834 0.00624834 0.00624834 0.00624834\n",
      " 0.00657637 0.00657637 0.00624834 0.00624834 0.00657637 0.00624834\n",
      " 0.00624834 0.00624834 0.00624834 0.00624834 0.00624834 0.00624834\n",
      " 0.00624834 0.00657637 0.00624834 0.00624834 0.00624834 0.00624834\n",
      " 0.00624834 0.00657637 0.00624834 0.00624834 0.00624834 0.00624834\n",
      " 0.00657637 0.00624834 0.00624834 0.00624834 0.00624834 0.00624834\n",
      " 0.00624834 0.00624834 0.00624834 0.00657637 0.00624834 0.00624834\n",
      " 0.00624834 0.00624834 0.00624834 0.00624834 0.00624834 0.00657637\n",
      " 0.00624834 0.00624834 0.00657637 0.00624834 0.00624834 0.00624834\n",
      " 0.00624834 0.00624834 0.00624834 0.00624834 0.00657637 0.00624834\n",
      " 0.00624834 0.00624834 0.00624834 0.00624834 0.00657637 0.00624834\n",
      " 0.00624834 0.00657637 0.00657637 0.00624834 0.00657637 0.00624834\n",
      " 0.00624834 0.00624834 0.00624834 0.00624834 0.00624834 0.00624834\n",
      " 0.00624834 0.00657637 0.00624834 0.00624834 0.00624834 0.00657637\n",
      " 0.00657637 0.00624834 0.00624834 0.00657637 0.00657637 0.00624834\n",
      " 0.00657637 0.00624834 0.00657637 0.00624834 0.00624834 0.00624834\n",
      " 0.00624834 0.00657637 0.00624834 0.00624834 0.00657637 0.00624834\n",
      " 0.00657637 0.00624834 0.00624834 0.00624834 0.00624834 0.00624834\n",
      " 0.00624834 0.00624834 0.00624834 0.00624834 0.00624834 0.00624834\n",
      " 0.00624834 0.00624834 0.00624834 0.00624834 0.00657637 0.00657637\n",
      " 0.00624834 0.00657637 0.00624834 0.00657637 0.00641306 0.00624834\n",
      " 0.00624834 0.00624834 0.00624834 0.00624834 0.00640746 0.00624834\n",
      " 0.00640746 0.00624834 0.00641306 0.00624834 0.00641306 0.00624834]\n",
      "\n",
      "################################################\n",
      "K-fold : 3\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.22158971883236103\n",
      "Alpha : 0.012564261802262002\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[64 13]\n",
      " [18 45]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 77.8571428571\n",
      "Misclassification rate : 0.149\n",
      "True positives : 0.714\n",
      "False positives : 0.169\n",
      "Specificity : 0.831\n",
      "Precision : 0.776\n",
      "Prevalence : 0.303\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[5 1]\n",
      " [3 7]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 75.0\n",
      "Misclassification rate : 0.019\n",
      "True positives : 0.7\n",
      "False positives : 0.167\n",
      "Specificity : 0.833\n",
      "Precision : 0.875\n",
      "Prevalence : 0.048\n",
      "\n",
      "New weights : \n",
      "[0.00617032 0.00665952 0.00632746 0.00617032 0.00617032 0.00617032\n",
      " 0.00617032 0.00617032 0.00649414 0.00617032 0.00649414 0.00617032\n",
      " 0.00632746 0.00617032 0.00632746 0.00617032 0.00617032 0.00632734\n",
      " 0.00632734 0.00617032 0.00617032 0.00617032 0.00617032 0.00617032\n",
      " 0.00649426 0.00649426 0.00617032 0.00617032 0.00665952 0.00617032\n",
      " 0.00632734 0.00617032 0.00617032 0.00617032 0.00617032 0.00617032\n",
      " 0.00617032 0.00665952 0.00617032 0.00617032 0.00617032 0.00617032\n",
      " 0.00617032 0.00665952 0.00617032 0.00617032 0.00617032 0.00617032\n",
      " 0.00665952 0.00617032 0.00617032 0.00617032 0.00617032 0.00617032\n",
      " 0.00617032 0.00617032 0.00617032 0.00665952 0.00617032 0.00617032\n",
      " 0.00617032 0.00617032 0.00617032 0.00617032 0.00617032 0.00665952\n",
      " 0.00617032 0.00617032 0.00665952 0.00617032 0.00617032 0.00617032\n",
      " 0.00617032 0.00617032 0.00617032 0.00617032 0.00665952 0.00617032\n",
      " 0.00617032 0.00617032 0.00617032 0.00617032 0.00665952 0.00617032\n",
      " 0.00617032 0.00665952 0.00665952 0.00617032 0.00665952 0.00617032\n",
      " 0.00617032 0.00617032 0.00617032 0.00617032 0.00617032 0.00617032\n",
      " 0.00617032 0.00665952 0.00617032 0.00617032 0.00617032 0.00665952\n",
      " 0.00665952 0.00617032 0.00617032 0.00665952 0.00665952 0.00617032\n",
      " 0.00665952 0.00617032 0.00665952 0.00617032 0.00617032 0.00617032\n",
      " 0.00617032 0.00665952 0.00617032 0.00617032 0.00665952 0.00617032\n",
      " 0.00665952 0.00617032 0.00617032 0.00617032 0.00617032 0.00617032\n",
      " 0.00617032 0.00617032 0.00617032 0.00617032 0.00617032 0.00617032\n",
      " 0.00617032 0.00617032 0.00617032 0.00617032 0.00665952 0.00665952\n",
      " 0.00617032 0.00665952 0.00617032 0.00649426 0.00633299 0.00632734\n",
      " 0.00617032 0.00617032 0.00617032 0.00617032 0.00648847 0.00632734\n",
      " 0.00632746 0.00617032 0.00649414 0.00617032 0.00633299 0.00617032]\n",
      "\n",
      "################################################\n",
      "K-fold : 4\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.22945789507707223\n",
      "Alpha : 0.012113747505480275\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[65 13]\n",
      " [19 43]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 77.1428571429\n",
      "Misclassification rate : 0.154\n",
      "True positives : 0.694\n",
      "False positives : 0.167\n",
      "Specificity : 0.833\n",
      "Precision : 0.768\n",
      "Prevalence : 0.298\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[ 4  1]\n",
      " [ 1 10]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 87.5\n",
      "Misclassification rate : 0.01\n",
      "True positives : 0.909\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.909\n",
      "Prevalence : 0.053\n",
      "\n",
      "New weights : \n",
      "[0.00609603 0.00674068 0.00625127 0.00609603 0.00609603 0.00609603\n",
      " 0.00609603 0.00609603 0.00657329 0.00609603 0.00657329 0.00609603\n",
      " 0.00625127 0.00609603 0.00625127 0.00609603 0.00609603 0.00640445\n",
      " 0.00640445 0.00609603 0.00609603 0.00609603 0.00609603 0.00609603\n",
      " 0.00641607 0.00641607 0.00609603 0.00609603 0.00674068 0.00609603\n",
      " 0.00640445 0.00609603 0.00609603 0.00609603 0.00609603 0.00609603\n",
      " 0.00609603 0.00657934 0.00609603 0.00609603 0.00624552 0.00624552\n",
      " 0.00609603 0.00657934 0.00624552 0.00609603 0.00609603 0.00609603\n",
      " 0.00674068 0.00609603 0.00609603 0.00609603 0.00609603 0.00609603\n",
      " 0.00609603 0.00609603 0.00609603 0.00674068 0.00609603 0.00609603\n",
      " 0.00609603 0.00609603 0.00609603 0.00609603 0.00609603 0.00674068\n",
      " 0.00609603 0.00609603 0.00674068 0.00609603 0.00609603 0.00609603\n",
      " 0.00609603 0.00609603 0.00609603 0.00609603 0.00674068 0.00609603\n",
      " 0.00609603 0.00609603 0.00609603 0.00609603 0.00674068 0.00609603\n",
      " 0.00609603 0.00674068 0.00674068 0.00609603 0.00674068 0.00609603\n",
      " 0.00609603 0.00609603 0.00609603 0.00609603 0.00609603 0.00609603\n",
      " 0.00609603 0.00674068 0.00609603 0.00609603 0.00609603 0.00674068\n",
      " 0.00674068 0.00609603 0.00609603 0.00674068 0.00674068 0.00609603\n",
      " 0.00674068 0.00609603 0.00674068 0.00609603 0.00609603 0.00609603\n",
      " 0.00609603 0.00674068 0.00609603 0.00609603 0.00674068 0.00609603\n",
      " 0.00674068 0.00609603 0.00609603 0.00609603 0.00609603 0.00609603\n",
      " 0.00609603 0.00609603 0.00609603 0.00609603 0.00609603 0.00609603\n",
      " 0.00609603 0.00609603 0.00609603 0.00609603 0.00674068 0.00674068\n",
      " 0.00609603 0.00674068 0.00609603 0.00641607 0.00625673 0.00625115\n",
      " 0.00609603 0.00624552 0.00609603 0.00609603 0.00641034 0.00625115\n",
      " 0.00625127 0.00624552 0.00641595 0.00609603 0.00625673 0.00609603]\n",
      "\n",
      "################################################\n",
      "K-fold : 5\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.230803554990049\n",
      "Alpha : 0.012037794546135346\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[64 14]\n",
      " [18 44]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 77.1428571429\n",
      "Misclassification rate : 0.154\n",
      "True positives : 0.71\n",
      "False positives : 0.179\n",
      "Specificity : 0.821\n",
      "Precision : 0.759\n",
      "Prevalence : 0.298\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[5 0]\n",
      " [2 9]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 87.5\n",
      "Misclassification rate : 0.01\n",
      "True positives : 0.818\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 1.0\n",
      "Prevalence : 0.053\n",
      "\n",
      "New weights : \n",
      "[0.00602308 0.00682232 0.00617647 0.00602308 0.00602308 0.00602308\n",
      " 0.00602308 0.00602308 0.00665289 0.00602308 0.00665289 0.00602308\n",
      " 0.00617647 0.00602308 0.00617647 0.00602308 0.00602308 0.00648201\n",
      " 0.00648201 0.00602308 0.00602308 0.00602308 0.00602308 0.00602308\n",
      " 0.00633929 0.00633929 0.00602308 0.00602308 0.00682232 0.00602308\n",
      " 0.00648201 0.00602308 0.00602308 0.00602308 0.00602308 0.00602308\n",
      " 0.00602308 0.00650061 0.00602308 0.00602308 0.00632116 0.00632116\n",
      " 0.00602308 0.00650061 0.00632116 0.00602308 0.00602308 0.00602308\n",
      " 0.00666003 0.00602308 0.00602308 0.00602308 0.00602308 0.00616985\n",
      " 0.00602308 0.00602308 0.00602308 0.00666003 0.00602308 0.00616985\n",
      " 0.00602308 0.00602308 0.00602308 0.00602308 0.00602308 0.00682232\n",
      " 0.00602308 0.00602308 0.00682232 0.00602308 0.00602308 0.00602308\n",
      " 0.00602308 0.00602308 0.00602308 0.00602308 0.00682232 0.00602308\n",
      " 0.00602308 0.00602308 0.00602308 0.00602308 0.00682232 0.00602308\n",
      " 0.00602308 0.00682232 0.00682232 0.00602308 0.00682232 0.00602308\n",
      " 0.00602308 0.00602308 0.00602308 0.00602308 0.00602308 0.00602308\n",
      " 0.00602308 0.00682232 0.00602308 0.00602308 0.00602308 0.00682232\n",
      " 0.00682232 0.00602308 0.00602308 0.00682232 0.00682232 0.00602308\n",
      " 0.00682232 0.00602308 0.00682232 0.00602308 0.00602308 0.00602308\n",
      " 0.00602308 0.00682232 0.00602308 0.00602308 0.00682232 0.00602308\n",
      " 0.00682232 0.00602308 0.00602308 0.00602308 0.00602308 0.00602308\n",
      " 0.00602308 0.00602308 0.00602308 0.00602308 0.00602308 0.00602308\n",
      " 0.00602308 0.00602308 0.00602308 0.00602308 0.00682232 0.00682232\n",
      " 0.00602308 0.00682232 0.00616985 0.00633929 0.00618187 0.00617635\n",
      " 0.00602308 0.00617079 0.00602308 0.00602308 0.00633364 0.00632686\n",
      " 0.00617647 0.00617079 0.00633918 0.00602308 0.00618187 0.00602308]\n",
      "\n",
      "################################################\n",
      "K-fold : 6\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.22564470900933334\n",
      "Alpha : 0.01233069122332267\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[58 14]\n",
      " [17 51]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 77.8571428571\n",
      "Misclassification rate : 0.149\n",
      "True positives : 0.75\n",
      "False positives : 0.194\n",
      "Specificity : 0.806\n",
      "Precision : 0.785\n",
      "Prevalence : 0.327\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[11  0]\n",
      " [ 3  2]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 81.25\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.4\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 1.0\n",
      "Prevalence : 0.024\n",
      "\n",
      "New weights : \n",
      "[0.00594927 0.00690696 0.00610078 0.00594927 0.00594927 0.00594927\n",
      " 0.00594927 0.00594927 0.00673544 0.00594927 0.00673544 0.00594927\n",
      " 0.00610078 0.00594927 0.00610078 0.00594927 0.00594927 0.00656243\n",
      " 0.00656243 0.00594927 0.00594927 0.00594927 0.00594927 0.00594927\n",
      " 0.00626161 0.00626161 0.00594927 0.00594927 0.00690696 0.00594927\n",
      " 0.00656243 0.00594927 0.00594927 0.00594927 0.00594927 0.00594927\n",
      " 0.00594927 0.00642095 0.00594927 0.00594927 0.00639959 0.00639959\n",
      " 0.00594927 0.00642095 0.00639959 0.00594927 0.00594927 0.00594927\n",
      " 0.00657841 0.00594927 0.00594927 0.00594927 0.00594927 0.0062464\n",
      " 0.00594927 0.00594927 0.00594927 0.00657841 0.00594927 0.0062464\n",
      " 0.00594927 0.00594927 0.00594927 0.00594927 0.00609781 0.00673871\n",
      " 0.00594927 0.00594927 0.00673871 0.00594927 0.00594927 0.00594927\n",
      " 0.00594927 0.00609781 0.00594927 0.00594927 0.00673871 0.00594927\n",
      " 0.00594927 0.00594927 0.00594927 0.00594927 0.00690696 0.00594927\n",
      " 0.00594927 0.00690696 0.00690696 0.00594927 0.00690696 0.00594927\n",
      " 0.00594927 0.00594927 0.00594927 0.00594927 0.00594927 0.00594927\n",
      " 0.00594927 0.00690696 0.00594927 0.00594927 0.00594927 0.00690696\n",
      " 0.00690696 0.00594927 0.00594927 0.00690696 0.00690696 0.00594927\n",
      " 0.00690696 0.00594927 0.00690696 0.00594927 0.00594927 0.00594927\n",
      " 0.00594927 0.00690696 0.00594927 0.00594927 0.00690696 0.00594927\n",
      " 0.00690696 0.00594927 0.00594927 0.00594927 0.00594927 0.00594927\n",
      " 0.00594927 0.00594927 0.00594927 0.00594927 0.00594927 0.00594927\n",
      " 0.00594927 0.00594927 0.00594927 0.00594927 0.00690696 0.00690696\n",
      " 0.00594927 0.00690696 0.00609424 0.00641795 0.00610611 0.00610066\n",
      " 0.00609781 0.00609517 0.00594927 0.00594927 0.00625602 0.00624932\n",
      " 0.00610078 0.00609517 0.00641783 0.00594927 0.00610611 0.00594927]\n",
      "\n",
      "################################################\n",
      "K-fold : 7\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.21799402458250122\n",
      "Alpha : 0.012773947294735544\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[62 11]\n",
      " [19 49]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 78.7234042553\n",
      "Misclassification rate : 0.144\n",
      "True positives : 0.721\n",
      "False positives : 0.151\n",
      "Specificity : 0.849\n",
      "Precision : 0.817\n",
      "Prevalence : 0.327\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[6 4]\n",
      " [1 4]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 66.6666666667\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.8\n",
      "False positives : 0.4\n",
      "Specificity : 0.6\n",
      "Precision : 0.5\n",
      "Prevalence : 0.024\n",
      "\n",
      "New weights : \n",
      "[0.00587376 0.00699576 0.00602334 0.00587376 0.00587376 0.00587376\n",
      " 0.00587376 0.00587376 0.00682203 0.00587376 0.00682203 0.00587376\n",
      " 0.00602334 0.00587376 0.00602334 0.00587376 0.00587376 0.0066468\n",
      " 0.0066468  0.00587376 0.00587376 0.00587376 0.00587376 0.00587376\n",
      " 0.00618213 0.00618213 0.00587376 0.00587376 0.00699576 0.00587376\n",
      " 0.0066468  0.00587376 0.00587376 0.00587376 0.00587376 0.00587376\n",
      " 0.00587376 0.00633945 0.00587376 0.00587376 0.00648186 0.00648186\n",
      " 0.00587376 0.00633945 0.00648186 0.00587376 0.00587376 0.00587376\n",
      " 0.00649491 0.00587376 0.00587376 0.00587376 0.00587376 0.00632671\n",
      " 0.00587376 0.00587376 0.00587376 0.00649491 0.00587376 0.00632671\n",
      " 0.00587376 0.00587376 0.00587376 0.00587376 0.00617621 0.00665318\n",
      " 0.00587376 0.00587376 0.00665318 0.00587376 0.00587376 0.00587376\n",
      " 0.00587376 0.00617621 0.00587376 0.00587376 0.00665318 0.00587376\n",
      " 0.00587376 0.00587376 0.00587376 0.00602575 0.00681929 0.00587376\n",
      " 0.00602575 0.00681929 0.00681929 0.00587376 0.00681929 0.00587376\n",
      " 0.00587376 0.00587376 0.00602575 0.00587376 0.00587376 0.00587376\n",
      " 0.00587376 0.00681929 0.00602575 0.00587376 0.00587376 0.00681929\n",
      " 0.00699576 0.00602575 0.00587376 0.00681929 0.00699576 0.00602575\n",
      " 0.00681929 0.00602575 0.00681929 0.00602575 0.00587376 0.00587376\n",
      " 0.00587376 0.00681929 0.00602575 0.00587376 0.00681929 0.00602575\n",
      " 0.00681929 0.00602575 0.00587376 0.00587376 0.00587376 0.00587376\n",
      " 0.00587376 0.00587376 0.00587376 0.00587376 0.00587376 0.00587376\n",
      " 0.00587376 0.00587376 0.00587376 0.00587376 0.00681929 0.00699576\n",
      " 0.00602575 0.00681929 0.00617259 0.00633649 0.00602861 0.00617909\n",
      " 0.00602041 0.00617353 0.00602575 0.00602575 0.00617662 0.00632966\n",
      " 0.00602334 0.0060178  0.00633637 0.00587376 0.00602861 0.00587376]\n",
      "\n",
      "################################################\n",
      "K-fold : 8\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.20684791107115463\n",
      "Alpha : 0.013440311984684266\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[62 13]\n",
      " [15 51]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 80.1418439716\n",
      "Misclassification rate : 0.135\n",
      "True positives : 0.773\n",
      "False positives : 0.173\n",
      "Specificity : 0.827\n",
      "Precision : 0.797\n",
      "Prevalence : 0.317\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 1]\n",
      " [5 2]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 60.0\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.286\n",
      "False positives : 0.125\n",
      "Specificity : 0.875\n",
      "Precision : 0.667\n",
      "Prevalence : 0.034\n",
      "\n",
      "New weights : \n",
      "[0.00579534 0.00709042 0.00594293 0.00579534 0.00579534 0.00579534\n",
      " 0.00579534 0.00579534 0.00691434 0.00579534 0.00691434 0.00579534\n",
      " 0.00594293 0.00579534 0.00594293 0.00579534 0.00579534 0.00673674\n",
      " 0.00673674 0.00579534 0.00579534 0.00579534 0.00579534 0.00579534\n",
      " 0.0060996  0.0060996  0.00579534 0.00579534 0.00709042 0.00579534\n",
      " 0.00673674 0.00579534 0.00579534 0.00579534 0.00579534 0.00579534\n",
      " 0.00579534 0.00625481 0.00579534 0.00579534 0.00656956 0.00656956\n",
      " 0.00579534 0.00625481 0.00656956 0.00579534 0.00579534 0.00579534\n",
      " 0.0064082  0.00579534 0.00579534 0.00579534 0.00579534 0.00641231\n",
      " 0.00579534 0.00579534 0.00579534 0.0064082  0.00579534 0.00641231\n",
      " 0.00579534 0.00579534 0.00579534 0.00579534 0.00625978 0.00656435\n",
      " 0.00579534 0.00579534 0.00656435 0.00579534 0.00579534 0.00579534\n",
      " 0.00579534 0.00625978 0.00579534 0.00579534 0.00656435 0.00579534\n",
      " 0.00579534 0.00579534 0.00579534 0.00610729 0.00672825 0.00579534\n",
      " 0.00610729 0.00672825 0.00672825 0.00579534 0.00672825 0.00579534\n",
      " 0.00579534 0.00579534 0.00610729 0.00579534 0.00579534 0.00579534\n",
      " 0.00579534 0.00672825 0.00610729 0.00579534 0.00579534 0.00691157\n",
      " 0.00709042 0.00594531 0.00595324 0.00672825 0.00690236 0.00594531\n",
      " 0.00672825 0.00594531 0.00672825 0.00610729 0.00579534 0.00579534\n",
      " 0.00579534 0.00672825 0.00610729 0.00579534 0.00672825 0.00610729\n",
      " 0.00672825 0.00610729 0.00579534 0.00579534 0.00579534 0.00579534\n",
      " 0.00579534 0.00579534 0.00579534 0.00579534 0.00579534 0.00579534\n",
      " 0.00579534 0.00579534 0.00579534 0.00579534 0.00672825 0.00709042\n",
      " 0.00610729 0.00672825 0.00625611 0.00625189 0.00594812 0.0062627\n",
      " 0.00594004 0.00609111 0.00594531 0.00610729 0.00626019 0.00624516\n",
      " 0.00594293 0.00609923 0.0064221  0.00579534 0.00611018 0.00579534]\n",
      "\n",
      "################################################\n",
      "K-fold : 9\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.22394492640387767\n",
      "Alpha : 0.012428233314368486\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[63 13]\n",
      " [17 48]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 78.7234042553\n",
      "Misclassification rate : 0.144\n",
      "True positives : 0.738\n",
      "False positives : 0.171\n",
      "Specificity : 0.829\n",
      "Precision : 0.787\n",
      "Prevalence : 0.313\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[6 1]\n",
      " [3 5]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 73.3333333333\n",
      "Misclassification rate : 0.019\n",
      "True positives : 0.625\n",
      "False positives : 0.143\n",
      "Specificity : 0.857\n",
      "Precision : 0.833\n",
      "Prevalence : 0.038\n",
      "\n",
      "New weights : \n",
      "[0.00572376 0.00717909 0.00586952 0.00572376 0.00572376 0.00572376\n",
      " 0.00572376 0.00572376 0.0070008  0.00572376 0.0070008  0.00572376\n",
      " 0.00586952 0.00572376 0.00586952 0.00572376 0.00572376 0.00682099\n",
      " 0.00682099 0.00572376 0.00572376 0.00572376 0.00572376 0.00572376\n",
      " 0.00602426 0.00602426 0.00572376 0.00572376 0.00717909 0.00572376\n",
      " 0.00682099 0.00572376 0.00572376 0.00572376 0.00572376 0.00572376\n",
      " 0.00572376 0.00617756 0.00572376 0.00572376 0.00665172 0.00665172\n",
      " 0.00572376 0.00617756 0.00665172 0.00572376 0.00572376 0.00572376\n",
      " 0.00632905 0.00572376 0.00572376 0.00572376 0.00572376 0.0064925\n",
      " 0.00572376 0.00572376 0.00572376 0.00632905 0.00572376 0.0064925\n",
      " 0.00572376 0.00572376 0.00572376 0.00572376 0.00633806 0.00648328\n",
      " 0.00572376 0.00572376 0.00648328 0.00572376 0.00572376 0.00572376\n",
      " 0.00572376 0.00633806 0.00572376 0.00572376 0.00648328 0.00572376\n",
      " 0.00572376 0.00572376 0.00572376 0.00618367 0.00664515 0.00572376\n",
      " 0.00618367 0.00664515 0.00664515 0.00572376 0.00664515 0.00572376\n",
      " 0.00572376 0.00572376 0.00618367 0.00572376 0.00572376 0.00572376\n",
      " 0.00572376 0.00664515 0.00618367 0.00572376 0.00572376 0.006998\n",
      " 0.00717909 0.00587188 0.00602769 0.00664515 0.00681711 0.00587188\n",
      " 0.00664515 0.00587188 0.00664515 0.00603186 0.00572376 0.00586782\n",
      " 0.00572376 0.00664515 0.00603186 0.00586782 0.0068124  0.00603186\n",
      " 0.00664515 0.00618367 0.00586782 0.00572376 0.00586782 0.00572376\n",
      " 0.00572376 0.00572376 0.00572376 0.00572376 0.00572376 0.00572376\n",
      " 0.00572376 0.00572376 0.00572376 0.00572376 0.00664515 0.00717909\n",
      " 0.00618367 0.00664515 0.00633435 0.00633008 0.00587465 0.00618535\n",
      " 0.00586667 0.00601587 0.00601966 0.00603186 0.00618287 0.00632326\n",
      " 0.00586952 0.00617551 0.00634278 0.00572376 0.00603471 0.00572376]\n",
      "\n",
      "################################################\n",
      "K-fold : 10\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.23494261207682457\n",
      "Alpha : 0.01180609567512831\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[61 11]\n",
      " [20 49]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 78.0141843972\n",
      "Misclassification rate : 0.149\n",
      "True positives : 0.71\n",
      "False positives : 0.153\n",
      "Specificity : 0.847\n",
      "Precision : 0.817\n",
      "Prevalence : 0.332\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 3]\n",
      " [0 4]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 80.0\n",
      "Misclassification rate : 0.014\n",
      "True positives : 1.0\n",
      "False positives : 0.273\n",
      "Specificity : 0.727\n",
      "Precision : 0.571\n",
      "Prevalence : 0.019\n",
      "\n",
      "New weights : \n",
      "[0.00565658 0.00726435 0.00580063 0.00565658 0.00565658 0.00565658\n",
      " 0.00565658 0.00565658 0.00708395 0.00565658 0.00708395 0.00565658\n",
      " 0.00580063 0.00565658 0.00580063 0.00565658 0.00565658 0.00690199\n",
      " 0.00690199 0.00565658 0.00565658 0.00565658 0.00565658 0.00565658\n",
      " 0.00595355 0.00595355 0.00565658 0.00565658 0.00726435 0.00565658\n",
      " 0.00690199 0.00565658 0.00565658 0.00565658 0.00565658 0.00565658\n",
      " 0.00565658 0.00610505 0.00565658 0.00565658 0.00673072 0.00673072\n",
      " 0.00565658 0.00610505 0.00673072 0.00565658 0.00565658 0.00565658\n",
      " 0.00625477 0.00565658 0.00565658 0.00565658 0.00565658 0.00656961\n",
      " 0.00565658 0.00565658 0.00565658 0.00625477 0.00565658 0.00656961\n",
      " 0.00565658 0.00565658 0.00565658 0.00565658 0.00641333 0.00640718\n",
      " 0.00565658 0.00565658 0.00640718 0.00565658 0.00565658 0.00565658\n",
      " 0.00565658 0.00641333 0.00565658 0.00565658 0.00640718 0.00565658\n",
      " 0.00565658 0.00565658 0.00565658 0.0062571  0.00656716 0.00565658\n",
      " 0.0062571  0.00656716 0.00656716 0.00565658 0.00656716 0.00565658\n",
      " 0.00565658 0.00565658 0.0062571  0.00565658 0.00565658 0.00565658\n",
      " 0.00565658 0.00656716 0.0062571  0.00565658 0.00565658 0.00708111\n",
      " 0.00726435 0.00580296 0.00609927 0.00656716 0.0067371  0.00580296\n",
      " 0.00656716 0.00580296 0.00656716 0.00596106 0.00565658 0.0059375\n",
      " 0.00565658 0.00656716 0.00596106 0.0059375  0.0068933  0.00596106\n",
      " 0.00656716 0.0062571  0.0059375  0.00565658 0.0059375  0.00565658\n",
      " 0.00579174 0.00565658 0.00565658 0.00565658 0.00565658 0.00579174\n",
      " 0.00565658 0.00565658 0.00579174 0.00565658 0.00672407 0.00709483\n",
      " 0.00611109 0.00656716 0.00626    0.00625578 0.00580571 0.00611275\n",
      " 0.00579782 0.00594527 0.00594901 0.00596106 0.0061103  0.00624904\n",
      " 0.00580063 0.00610303 0.00641811 0.00579174 0.00596388 0.00579174]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "print(\"Inicializando vetor de pesos....\")\n",
    "\n",
    "# Initialize weights\n",
    "w = np.ones(n_train) / n_train\n",
    "print(w)\n",
    "\n",
    "n_train, n_test = len(trainData), len(testData)\n",
    "#pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)]\n",
    "    \n",
    "# Fit um classificador\n",
    "clf_tree = DecisionTreeClassifier(max_depth = 1, random_state = 1)\n",
    "\n",
    "# Define quantos folds\n",
    "kf = KFold(n_splits=10)\n",
    "alpha = 0.01\n",
    "\n",
    "print\n",
    "print(\"Iniciando treinamento com 10 K-folds\" )\n",
    "print\n",
    "    \n",
    "kfold = 0    \n",
    "for train_index, test_index in kf.split(trainData):\n",
    "    print(\"################################################\")\n",
    "    print(\"K-fold : \"+str(kfold+1))    \n",
    "    print(\"################################################\")\n",
    "    #print(train_index, test_index)\n",
    "    print\n",
    "    \n",
    "    # Obten os subdados de treinamento e teste no n fold\n",
    "    #---------------------------------------------------------------------\n",
    "    X_train, X_test = trainData.iloc[train_index,:], trainData.iloc[test_index,:]\n",
    "    #print(len(X_train), len(X_test))\n",
    "\n",
    "    y_train, y_test = trainLabels.iloc[train_index], trainLabels.iloc[test_index]\n",
    "    #print(len(y_train), len(y_test))\n",
    "\n",
    "    # Obten os sub-pesos de treinamento e teste no n fold\n",
    "    #---------------------------------------------------------------------\n",
    "    trainWeights = w[train_index]\n",
    "    testWeights = w[test_index]\n",
    "    \n",
    "    # Treina o modelo de classificação\n",
    "    #---------------------------------------------------------------------\n",
    "    print(\"Treinando o modelo....\")\n",
    "    \n",
    "    # Treina o classificador com os pesos de treinamento\n",
    "    clf_tree.fit(X_train, y_train, sample_weight=trainWeights)\n",
    "\n",
    "    # Classifica o treino\n",
    "    pred_train_i = clf_tree.predict(X_train)\n",
    "    #print(pred_train_i)\n",
    "\n",
    "    # Classifica o teste\n",
    "    pred_test_i = clf_tree.predict(X_test)\n",
    "    #print(pred_test_i)        \n",
    "\n",
    "    kfold += 1 \n",
    "    print\n",
    "\n",
    "    \n",
    "    print\n",
    "    print(\"...:::: Avaliação ::::....  \")\n",
    "    print\n",
    "    \n",
    "    # Obtem o index dos erros da classificação de treino e teste\n",
    "    #---------------------------------------------------------------------\n",
    "    miss = [int(x) for x in (pred_train_i != y_train)]\n",
    "    #print(\"Training Miss : \"+str(miss))\n",
    "    missTest = [int(x) for x in (pred_test_i != y_test)]\n",
    "    #print(\"Testing Miss : \"+str(missTest))\n",
    "\n",
    "    \n",
    "    # Equivale os valores entre 1/-1 para atualização dos pesos\n",
    "    #---------------------------------------------------------------------\n",
    "    miss2 = [x if x==1 else -1 for x in miss]\n",
    "    #print(\"Training Miss2 : \"+str(miss2))\n",
    "    miss2Test = [x if x==1 else -1 for x in missTest]\n",
    "    #print(\"Testing Miss2 : \"+str(miss2Test))\n",
    "    \n",
    "    # Calcula o erro\n",
    "    #---------------------------------------------------------------------\n",
    "    err_m = np.dot(trainWeights,miss) / sum(trainWeights)\n",
    "    print(\"Error : \"+str(err_m))\n",
    "\n",
    "    # Calcula o Alpha \n",
    "    #---------------------------------------------------------------------\n",
    "    alpha_m = alpha * np.log( (1 - err_m) / float(err_m))\n",
    "    print(\"Alpha : \"+str(alpha_m))\n",
    "\n",
    "    # Mostra a Matriz de Confusão para treino e teste\n",
    "    #---------------------------------------------------------------------\n",
    "    print\n",
    "    print(\":: Treinamento :: \")\n",
    "    print\n",
    "    train_acc_score, train_precision_score = printCM(y_train, pred_train_i)\n",
    "    \n",
    "    print\n",
    "    print(\":: Teste ::\")\n",
    "    print\n",
    "    test_acc_score, test_precision_score = printCM(y_test, pred_test_i)\n",
    "    print\n",
    "    \n",
    "    \n",
    "    # Atualiza os valores dos pesos\n",
    "    #---------------------------------------------------------------------\n",
    "    w = np.multiply(w, np.exp([float(x) * alpha_m for x in np.concatenate((miss2, miss2Test), axis=0)]))\n",
    "    print(\"New weights : \")\n",
    "    print(w)\n",
    "    \n",
    "    \n",
    "    scores.append([kfold, train_acc_score, train_precision_score])\n",
    "\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, '77.8571428571', 0.797],\n",
       " [2, '78.5714285714', 0.806],\n",
       " [3, '77.8571428571', 0.776],\n",
       " [4, '77.1428571429', 0.768],\n",
       " [5, '77.1428571429', 0.759],\n",
       " [6, '77.8571428571', 0.785],\n",
       " [7, '78.7234042553', 0.817],\n",
       " [8, '80.1418439716', 0.797],\n",
       " [9, '78.7234042553', 0.787],\n",
       " [10, '78.0141843972', 0.817]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, '77.8571428571', 0.797], [2, '78.5714285714', 0.806], [3, '77.8571428571', 0.776], [4, '77.1428571429', 0.768], [5, '77.1428571429', 0.759], [6, '77.8571428571', 0.785], [7, '78.7234042553', 0.817], [8, '80.1418439716', 0.797], [9, '78.7234042553', 0.787], [10, '78.0141843972', 0.817]]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
