{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 1 - Machine Learning II \n",
    "Prof: Carlos Padilha\n",
    "\n",
    "#### Alunos:  \n",
    "\n",
    "Roberto A. Coutinho  \n",
    "Thais Galho\n",
    "\n",
    "\n",
    "## Sistemas com Multi-classificadores ou Ensembles\n",
    "\n",
    "#### Este trabalho visa avaliar o entendimento em relaçãao á construção de sistemas com multi-classificadores ou ensembles. Para tal, os alunos deverão fazer o seguinte:\n",
    "\n",
    "\n",
    "* Implementar o algoritmo AdaBoost (nos mesmos moldes que fizemos com o algoritmo Bagging).\n",
    "    – Podem escolher qualquer tipo de classificador (MLP, SVM, etc).\n",
    "* Processar os dados presente no arquivo sonar.all-data.\n",
    "* Realizar treinamento e teste usando validação cruzada com 10 folds.\n",
    "* Avaliar os resultados em termos de acurácia, recall e precisão.\n",
    "\n",
    "Obs: O trabalho pode ser feito em dupla e deve ser enviado por email (carlos.engcomp@gmail.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modelos\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# K-fold CrossValidation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# K-fold CrossValidation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9  ...      51      52      53      54      55      56      57      58  \\\n",
       "0  0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090   \n",
       "1  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
       "2  0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
       "3  0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
       "4  0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
       "\n",
       "       59  60  \n",
       "0  0.0032   R  \n",
       "1  0.0044   R  \n",
       "2  0.0078   R  \n",
       "3  0.0117   R  \n",
       "4  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_data = pd.read_csv('sonar.all-data.csv', header=None)\n",
    "imported_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 208)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separação entre dados e labels\n",
    "\n",
    "labels = imported_data.iloc[:,-1]\n",
    "data = imported_data.iloc[:,:-1]\n",
    "len(data), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Treinamento</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 156)\n",
      "(52, 52)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# utiliza 25% do dataset para teste\n",
    "trainData, testData, trainLabels, testLabels = train_test_split(data, labels, \n",
    "                                                    train_size=0.75, \n",
    "                                                    test_size=0.25, \n",
    "                                                    stratify=labels)\n",
    "\n",
    "print(len(trainData), len(trainLabels))\n",
    "print(len(testData), len(testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 156, 156)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainData), len(w), len(trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializando vetor de pesos....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "       0.00641026])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializando vetor de pesos....\n",
      "[0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026\n",
      " 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026 0.00641026]\n",
      "\n",
      "Iniciando treinamento com 10 K-folds\n",
      "\n",
      "################################################\n",
      "K-fold : 1\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 2]\n",
      " [1 6]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 81.25\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.857\n",
      "False positives : 0.222\n",
      "Specificity : 0.778\n",
      "Prevalence : 0.034\n",
      "\n",
      "Training Miss : [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
      "Testing Miss : [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "Training Miss2 : [-1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1]\n",
      "Testing Miss2 : [-1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1]\n",
      "Error : 0.22142857142857197\n",
      "Alpha : 0.6286803388719971\n",
      "New weights : \n",
      "[0.00341856 0.01202009 0.01202009 0.00341856 0.00341856 0.00341856\n",
      " 0.00341856 0.00341856 0.00341856 0.00341856 0.00341856 0.00341856\n",
      " 0.01202009 0.00341856 0.01202009 0.00341856 0.00341856 0.00341856\n",
      " 0.00341856 0.00341856 0.00341856 0.00341856 0.00341856 0.00341856\n",
      " 0.01202009 0.01202009 0.00341856 0.00341856 0.01202009 0.00341856\n",
      " 0.00341856 0.00341856 0.00341856 0.00341856 0.00341856 0.00341856\n",
      " 0.00341856 0.01202009 0.00341856 0.00341856 0.00341856 0.00341856\n",
      " 0.00341856 0.01202009 0.00341856 0.00341856 0.00341856 0.00341856\n",
      " 0.01202009 0.00341856 0.00341856 0.00341856 0.00341856 0.00341856\n",
      " 0.00341856 0.00341856 0.00341856 0.01202009 0.00341856 0.00341856\n",
      " 0.00341856 0.00341856 0.00341856 0.00341856 0.00341856 0.01202009\n",
      " 0.00341856 0.00341856 0.01202009 0.00341856 0.00341856 0.00341856\n",
      " 0.00341856 0.00341856 0.00341856 0.00341856 0.01202009 0.00341856\n",
      " 0.00341856 0.00341856 0.00341856 0.00341856 0.01202009 0.00341856\n",
      " 0.00341856 0.01202009 0.01202009 0.00341856 0.01202009 0.00341856\n",
      " 0.00341856 0.00341856 0.00341856 0.00341856 0.00341856 0.00341856\n",
      " 0.00341856 0.01202009 0.00341856 0.00341856 0.00341856 0.01202009\n",
      " 0.01202009 0.00341856 0.00341856 0.01202009 0.01202009 0.00341856\n",
      " 0.01202009 0.00341856 0.01202009 0.00341856 0.00341856 0.00341856\n",
      " 0.00341856 0.01202009 0.00341856 0.00341856 0.01202009 0.00341856\n",
      " 0.01202009 0.00341856 0.00341856 0.00341856 0.00341856 0.00341856\n",
      " 0.00341856 0.00341856 0.00341856 0.00341856 0.00341856 0.00341856\n",
      " 0.00341856 0.00341856 0.00341856 0.00341856 0.01202009 0.01202009\n",
      " 0.00341856 0.01202009 0.00341856 0.01202009 0.00341856 0.00341856\n",
      " 0.00341856 0.00341856 0.00341856 0.00341856 0.01202009 0.00341856\n",
      " 0.01202009 0.00341856 0.00341856 0.00341856 0.00341856 0.00341856]\n",
      "\n",
      "################################################\n",
      "K-fold : 2\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 2]\n",
      " [2 3]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 75.0\n",
      "Misclassification rate : 0.019\n",
      "True positives : 0.6\n",
      "False positives : 0.182\n",
      "Specificity : 0.818\n",
      "Prevalence : 0.024\n",
      "\n",
      "Training Miss : [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
      "Testing Miss : [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "Training Miss2 : [-1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1]\n",
      "Testing Miss2 : [-1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1]\n",
      "Error : 0.19532406037289154\n",
      "Alpha : 0.7078898048059993\n",
      "New weights : \n",
      "[0.00168426 0.02439723 0.00592209 0.00168426 0.00168426 0.00168426\n",
      " 0.00168426 0.00168426 0.00693866 0.00168426 0.00693866 0.00168426\n",
      " 0.00592209 0.00168426 0.00592209 0.00168426 0.00168426 0.00168426\n",
      " 0.00168426 0.00168426 0.00168426 0.00168426 0.00168426 0.00168426\n",
      " 0.02439723 0.02439723 0.00168426 0.00168426 0.02439723 0.00168426\n",
      " 0.00168426 0.00168426 0.00168426 0.00168426 0.00168426 0.00168426\n",
      " 0.00168426 0.02439723 0.00168426 0.00168426 0.00168426 0.00168426\n",
      " 0.00168426 0.02439723 0.00168426 0.00168426 0.00168426 0.00168426\n",
      " 0.02439723 0.00168426 0.00168426 0.00168426 0.00168426 0.00168426\n",
      " 0.00168426 0.00168426 0.00168426 0.02439723 0.00168426 0.00168426\n",
      " 0.00168426 0.00168426 0.00168426 0.00168426 0.00168426 0.02439723\n",
      " 0.00168426 0.00168426 0.02439723 0.00168426 0.00168426 0.00168426\n",
      " 0.00168426 0.00168426 0.00168426 0.00168426 0.02439723 0.00168426\n",
      " 0.00168426 0.00168426 0.00168426 0.00168426 0.02439723 0.00168426\n",
      " 0.00168426 0.02439723 0.02439723 0.00168426 0.02439723 0.00168426\n",
      " 0.00168426 0.00168426 0.00168426 0.00168426 0.00168426 0.00168426\n",
      " 0.00168426 0.02439723 0.00168426 0.00168426 0.00168426 0.02439723\n",
      " 0.02439723 0.00168426 0.00168426 0.02439723 0.02439723 0.00168426\n",
      " 0.02439723 0.00168426 0.02439723 0.00168426 0.00168426 0.00168426\n",
      " 0.00168426 0.02439723 0.00168426 0.00168426 0.02439723 0.00168426\n",
      " 0.02439723 0.00168426 0.00168426 0.00168426 0.00168426 0.00168426\n",
      " 0.00168426 0.00168426 0.00168426 0.00168426 0.00168426 0.00168426\n",
      " 0.00168426 0.00168426 0.00168426 0.00168426 0.02439723 0.02439723\n",
      " 0.00168426 0.02439723 0.00168426 0.02439723 0.00693866 0.00168426\n",
      " 0.00168426 0.00168426 0.00168426 0.00168426 0.00592209 0.00168426\n",
      " 0.00592209 0.00168426 0.00693866 0.00168426 0.00693866 0.00168426]\n",
      "\n",
      "################################################\n",
      "K-fold : 3\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 2]\n",
      " [5 5]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 56.25\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.5\n",
      "False positives : 0.333\n",
      "Specificity : 0.667\n",
      "Prevalence : 0.048\n",
      "\n",
      "Training Miss : [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1]\n",
      "Testing Miss : [1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]\n",
      "Training Miss2 : [-1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1]\n",
      "Testing Miss2 : [1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1]\n",
      "Error : 0.19453246679550054\n",
      "Alpha : 0.7104119109450562\n",
      "New weights : \n",
      "[0.00082772 0.04964419 0.00291036 0.00082772 0.00082772 0.00082772\n",
      " 0.00082772 0.00082772 0.00340995 0.00082772 0.01411899 0.00082772\n",
      " 0.00291036 0.00342719 0.00291036 0.00082772 0.00082772 0.00342719\n",
      " 0.00082772 0.00082772 0.00082772 0.00082772 0.00082772 0.00082772\n",
      " 0.01198981 0.01198981 0.00082772 0.00082772 0.04964419 0.00082772\n",
      " 0.00082772 0.00342719 0.00082772 0.00082772 0.00082772 0.00082772\n",
      " 0.00082772 0.04964419 0.00082772 0.00082772 0.00082772 0.00082772\n",
      " 0.00342719 0.01198981 0.00082772 0.00082772 0.00082772 0.00082772\n",
      " 0.04964419 0.00082772 0.00082772 0.00342719 0.00082772 0.00082772\n",
      " 0.00342719 0.00082772 0.00082772 0.04964419 0.00082772 0.00342719\n",
      " 0.00082772 0.00082772 0.00342719 0.00082772 0.00342719 0.01198981\n",
      " 0.00082772 0.00082772 0.04964419 0.00082772 0.00082772 0.00082772\n",
      " 0.00082772 0.00082772 0.00082772 0.00342719 0.04964419 0.00082772\n",
      " 0.00082772 0.00342719 0.00082772 0.00082772 0.01198981 0.00082772\n",
      " 0.00082772 0.04964419 0.01198981 0.00082772 0.01198981 0.00342719\n",
      " 0.00082772 0.00082772 0.00082772 0.00082772 0.00082772 0.00082772\n",
      " 0.00082772 0.04964419 0.00082772 0.00082772 0.00082772 0.04964419\n",
      " 0.04964419 0.00082772 0.00082772 0.04964419 0.04964419 0.00082772\n",
      " 0.01198981 0.00082772 0.04964419 0.00082772 0.00082772 0.00082772\n",
      " 0.00082772 0.04964419 0.00082772 0.00082772 0.04964419 0.00082772\n",
      " 0.01198981 0.00082772 0.00082772 0.00082772 0.00342719 0.00082772\n",
      " 0.00082772 0.00082772 0.00082772 0.00082772 0.00082772 0.00082772\n",
      " 0.00082772 0.00082772 0.00082772 0.00342719 0.01198981 0.04964419\n",
      " 0.00082772 0.04964419 0.00342719 0.01198981 0.00340995 0.00082772\n",
      " 0.00342719 0.00342719 0.00082772 0.00082772 0.01205045 0.00342719\n",
      " 0.00291036 0.00342719 0.01411899 0.00082772 0.00340995 0.00082772]\n",
      "\n",
      "################################################\n",
      "K-fold : 4\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Confusion Matrix : \n",
      "[[0 5]\n",
      " [3 8]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 50.0\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.727\n",
      "False positives : 1.0\n",
      "Specificity : 0.0\n",
      "Prevalence : 0.053\n",
      "\n",
      "Training Miss : [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1]\n",
      "Testing Miss : [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "Training Miss2 : [-1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, -1, -1, -1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, 1, -1, -1, 1, -1, 1]\n",
      "Testing Miss2 : [-1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, 1]\n",
      "Error : 0.17914406982835052\n",
      "Alpha : 0.7610786358254714\n",
      "New weights : \n",
      "[0.00038668 0.02319189 0.00135961 0.00038668 0.0017718  0.00038668\n",
      " 0.00038668 0.00038668 0.001593   0.00038668 0.03022288 0.00038668\n",
      " 0.00135961 0.00733619 0.00622988 0.0017718  0.0017718  0.00160105\n",
      " 0.0017718  0.0017718  0.0017718  0.0017718  0.00038668 0.0017718\n",
      " 0.0256652  0.00560119 0.0017718  0.0017718  0.02319189 0.0017718\n",
      " 0.0017718  0.00733619 0.00038668 0.0017718  0.0017718  0.00038668\n",
      " 0.00038668 0.02319189 0.00038668 0.00038668 0.00038668 0.00038668\n",
      " 0.00160105 0.00560119 0.00038668 0.0017718  0.00038668 0.00038668\n",
      " 0.02319189 0.00038668 0.00038668 0.00733619 0.00038668 0.00038668\n",
      " 0.00160105 0.00038668 0.00038668 0.02319189 0.00038668 0.00160105\n",
      " 0.0017718  0.00038668 0.00733619 0.00038668 0.00733619 0.00560119\n",
      " 0.0017718  0.0017718  0.02319189 0.00038668 0.0017718  0.0017718\n",
      " 0.0017718  0.0017718  0.0017718  0.00160105 0.02319189 0.0017718\n",
      " 0.0017718  0.00733619 0.00038668 0.00038668 0.0256652  0.0017718\n",
      " 0.00038668 0.02319189 0.00560119 0.00038668 0.0256652  0.00160105\n",
      " 0.00038668 0.0017718  0.0017718  0.0017718  0.00038668 0.00038668\n",
      " 0.0017718  0.02319189 0.0017718  0.00038668 0.0017718  0.10626755\n",
      " 0.02319189 0.0017718  0.0017718  0.02319189 0.10626755 0.0017718\n",
      " 0.00560119 0.0017718  0.10626755 0.0017718  0.00038668 0.0017718\n",
      " 0.00038668 0.02319189 0.00038668 0.00038668 0.02319189 0.0017718\n",
      " 0.00560119 0.00038668 0.0017718  0.00038668 0.00160105 0.00038668\n",
      " 0.0017718  0.0017718  0.0017718  0.00038668 0.0017718  0.00038668\n",
      " 0.00038668 0.00038668 0.0017718  0.00160105 0.00560119 0.10626755\n",
      " 0.00038668 0.10626755 0.00160105 0.00560119 0.001593   0.00038668\n",
      " 0.00733619 0.00733619 0.0017718  0.0017718  0.00562951 0.00160105\n",
      " 0.00135961 0.00160105 0.03022288 0.0017718  0.00729928 0.0017718 ]\n",
      "\n",
      "################################################\n",
      "K-fold : 5\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Confusion Matrix : \n",
      "[[1 4]\n",
      " [3 8]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 56.25\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.727\n",
      "False positives : 0.8\n",
      "Specificity : 0.2\n",
      "Prevalence : 0.053\n",
      "\n",
      "Training Miss : [1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0]\n",
      "Testing Miss : [1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "Training Miss2 : [1, -1, -1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, -1, -1, -1]\n",
      "Testing Miss2 : [1, -1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, -1, 1, -1]\n",
      "Error : 0.1332343976260881\n",
      "Alpha : 0.9363293101036579\n",
      "New weights : \n",
      "[9.86263115e-04 9.09271352e-03 5.33055330e-04 1.51602892e-04\n",
      " 6.94659517e-04 1.51602892e-04 9.86263115e-04 9.86263115e-04\n",
      " 6.24557975e-04 9.86263115e-04 1.18493140e-02 1.51602892e-04\n",
      " 5.33055330e-04 1.87116998e-02 2.44251249e-03 4.51915560e-03\n",
      " 6.94659517e-04 4.08365211e-03 6.94659517e-04 4.51915560e-03\n",
      " 4.51915560e-03 6.94659517e-04 1.51602892e-04 6.94659517e-04\n",
      " 1.00624113e-02 2.19602643e-03 4.51915560e-03 6.94659517e-04\n",
      " 5.91532776e-02 6.94659517e-04 4.51915560e-03 2.87625864e-03\n",
      " 9.86263115e-04 4.51915560e-03 6.94659517e-04 1.51602892e-04\n",
      " 1.51602892e-04 9.09271352e-03 1.51602892e-04 1.51602892e-04\n",
      " 1.51602892e-04 1.51602892e-04 6.27716337e-04 2.19602643e-03\n",
      " 1.51602892e-04 4.51915560e-03 1.51602892e-04 1.51602892e-04\n",
      " 9.09271352e-03 1.51602892e-04 1.51602892e-04 1.87116998e-02\n",
      " 1.51602892e-04 1.51602892e-04 6.27716337e-04 1.51602892e-04\n",
      " 1.51602892e-04 9.09271352e-03 1.51602892e-04 4.08365211e-03\n",
      " 6.94659517e-04 1.51602892e-04 2.87625864e-03 1.51602892e-04\n",
      " 1.87116998e-02 1.42864020e-02 4.51915560e-03 4.51915560e-03\n",
      " 9.09271352e-03 9.86263115e-04 4.51915560e-03 6.94659517e-04\n",
      " 6.94659517e-04 6.94659517e-04 6.94659517e-04 6.27716337e-04\n",
      " 9.09271352e-03 6.94659517e-04 6.94659517e-04 1.87116998e-02\n",
      " 9.86263115e-04 1.51602892e-04 6.54617139e-02 4.51915560e-03\n",
      " 1.51602892e-04 9.09271352e-03 2.19602643e-03 9.86263115e-04\n",
      " 6.54617139e-02 6.27716337e-04 1.51602892e-04 6.94659517e-04\n",
      " 4.51915560e-03 4.51915560e-03 1.51602892e-04 1.51602892e-04\n",
      " 4.51915560e-03 9.09271352e-03 6.94659517e-04 1.51602892e-04\n",
      " 4.51915560e-03 4.16637169e-02 9.09271352e-03 4.51915560e-03\n",
      " 4.51915560e-03 5.91532776e-02 4.16637169e-02 6.94659517e-04\n",
      " 2.19602643e-03 4.51915560e-03 2.71046196e-01 4.51915560e-03\n",
      " 1.51602892e-04 6.94659517e-04 9.86263115e-04 9.09271352e-03\n",
      " 1.51602892e-04 1.51602892e-04 5.91532776e-02 6.94659517e-04\n",
      " 2.19602643e-03 1.51602892e-04 6.94659517e-04 1.51602892e-04\n",
      " 6.27716337e-04 1.51602892e-04 6.94659517e-04 6.94659517e-04\n",
      " 6.94659517e-04 1.51602892e-04 4.51915560e-03 9.86263115e-04\n",
      " 1.51602892e-04 9.86263115e-04 4.51915560e-03 4.08365211e-03\n",
      " 2.19602643e-03 4.16637169e-02 1.51602892e-04 4.16637169e-02\n",
      " 4.08365211e-03 2.19602643e-03 4.06310517e-03 1.51602892e-04\n",
      " 2.87625864e-03 1.87116998e-02 6.94659517e-04 6.94659517e-04\n",
      " 1.43586477e-02 6.27716337e-04 3.46782837e-03 6.27716337e-04\n",
      " 7.70865329e-02 6.94659517e-04 1.86175516e-02 6.94659517e-04]\n",
      "\n",
      "################################################\n",
      "K-fold : 6\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 8]\n",
      " [1 4]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 43.75\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.8\n",
      "False positives : 0.727\n",
      "Specificity : 0.273\n",
      "Prevalence : 0.024\n",
      "\n",
      "Training Miss : [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
      "Testing Miss : [0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0]\n",
      "Training Miss2 : [1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1]\n",
      "Testing Miss2 : [-1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1]\n",
      "Error : 0.12267812830037546\n",
      "Alpha : 0.9836549285762219\n",
      "New weights : \n",
      "[2.63747711e-03 2.43158478e-02 1.42550320e-03 5.66906686e-05\n",
      " 2.59762277e-04 5.66906686e-05 3.68805071e-04 3.68805071e-04\n",
      " 2.33548375e-04 3.68805071e-04 4.43095460e-03 4.05418343e-04\n",
      " 1.99331706e-04 5.00390607e-02 6.53179734e-03 1.68990149e-03\n",
      " 1.85766713e-03 1.52704850e-03 1.85766713e-03 1.68990149e-03\n",
      " 1.68990149e-03 2.59762277e-04 5.66906686e-05 1.85766713e-03\n",
      " 3.76275688e-03 5.87264123e-03 1.20851822e-02 1.85766713e-03\n",
      " 2.21198871e-02 2.59762277e-04 1.20851822e-02 1.07555353e-03\n",
      " 2.63747711e-03 1.68990149e-03 2.59762277e-04 4.05418343e-04\n",
      " 5.66906686e-05 3.40014627e-03 5.66906686e-05 5.66906686e-05\n",
      " 4.05418343e-04 5.66906686e-05 1.67864685e-03 8.21186223e-04\n",
      " 5.66906686e-05 1.20851822e-02 5.66906686e-05 4.05418343e-04\n",
      " 3.40014627e-03 5.66906686e-05 5.66906686e-05 6.99708796e-03\n",
      " 4.05418343e-04 5.66906686e-05 2.34729419e-04 5.66906686e-05\n",
      " 5.66906686e-05 3.40014627e-03 5.66906686e-05 1.52704850e-03\n",
      " 1.85766713e-03 5.66906686e-05 1.07555353e-03 5.66906686e-05\n",
      " 6.99708796e-03 5.34228386e-03 1.20851822e-02 1.20851822e-02\n",
      " 2.43158478e-02 3.68805071e-04 1.68990149e-03 1.85766713e-03\n",
      " 2.59762277e-04 2.59762277e-04 1.85766713e-03 2.34729419e-04\n",
      " 2.43158478e-02 2.59762277e-04 2.59762277e-04 6.99708796e-03\n",
      " 2.63747711e-03 5.66906686e-05 1.75058531e-01 1.20851822e-02\n",
      " 4.05418343e-04 3.40014627e-03 5.87264123e-03 3.68805071e-04\n",
      " 1.75058531e-01 2.34729419e-04 5.66906686e-05 2.59762277e-04\n",
      " 1.20851822e-02 1.20851822e-02 5.66906686e-05 5.66906686e-05\n",
      " 1.68990149e-03 3.40014627e-03 1.85766713e-03 5.66906686e-05\n",
      " 1.20851822e-02 1.55798081e-02 3.40014627e-03 1.20851822e-02\n",
      " 1.20851822e-02 2.21198871e-02 1.55798081e-02 1.85766713e-03\n",
      " 8.21186223e-04 1.20851822e-02 7.24835115e-01 1.20851822e-02\n",
      " 4.05418343e-04 1.85766713e-03 2.63747711e-03 2.43158478e-02\n",
      " 4.05418343e-04 4.05418343e-04 2.21198871e-02 2.59762277e-04\n",
      " 8.21186223e-04 5.66906686e-05 1.85766713e-03 5.66906686e-05\n",
      " 2.34729419e-04 4.05418343e-04 2.59762277e-04 2.59762277e-04\n",
      " 1.85766713e-03 5.66906686e-05 1.20851822e-02 3.68805071e-04\n",
      " 5.66906686e-05 3.68805071e-04 1.20851822e-02 1.52704850e-03\n",
      " 8.21186223e-04 1.11417631e-01 5.66906686e-05 1.55798081e-02\n",
      " 1.52704850e-03 8.21186223e-04 1.08656065e-02 4.05418343e-04\n",
      " 7.69172667e-03 5.00390607e-02 1.85766713e-03 2.59762277e-04\n",
      " 5.36929955e-03 1.67864685e-03 1.29676622e-03 1.67864685e-03\n",
      " 2.88258821e-02 1.85766713e-03 4.97872885e-02 2.59762277e-04]\n",
      "\n",
      "################################################\n",
      "K-fold : 7\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 2]\n",
      " [1 4]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 80.0\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.8\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Prevalence : 0.024\n",
      "\n",
      "Training Miss : [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]\n",
      "Testing Miss : [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "Training Miss2 : [-1, -1, -1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1]\n",
      "Testing Miss2 : [-1, -1, -1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1]\n",
      "Error : 0.11613825371114084\n",
      "Alpha : 1.014759665521101\n",
      "New weights : \n",
      "[9.56057859e-04 8.81424042e-03 5.16729998e-04 2.05497743e-05\n",
      " 7.16606273e-04 2.05497743e-05 1.33687980e-04 1.01742266e-03\n",
      " 6.44289975e-04 1.33687980e-04 1.22236758e-02 1.46959908e-04\n",
      " 5.49896437e-04 1.81386360e-02 2.36770820e-03 6.12571609e-04\n",
      " 5.12474689e-03 5.53539104e-04 6.73384901e-04 4.66193175e-03\n",
      " 4.66193175e-03 9.41611078e-05 2.05497743e-05 6.73384901e-04\n",
      " 1.03803186e-02 1.62008572e-02 4.38075212e-03 6.73384901e-04\n",
      " 8.01822765e-03 7.16606273e-04 3.33393959e-02 3.89876901e-04\n",
      " 9.56057859e-04 4.66193175e-03 9.41611078e-05 1.46959908e-04\n",
      " 2.05497743e-05 1.23251745e-03 1.56392565e-04 1.56392565e-04\n",
      " 1.46959908e-04 2.05497743e-05 4.63088358e-03 2.26540669e-03\n",
      " 1.56392565e-04 4.38075212e-03 2.05497743e-05 1.46959908e-04\n",
      " 1.23251745e-03 2.05497743e-05 2.05497743e-05 1.93028687e-02\n",
      " 1.46959908e-04 2.05497743e-05 8.50869588e-05 2.05497743e-05\n",
      " 1.56392565e-04 9.37998456e-03 1.56392565e-04 4.21266915e-03\n",
      " 5.12474689e-03 1.56392565e-04 3.89876901e-04 2.05497743e-05\n",
      " 2.53637118e-03 1.47377601e-02 4.38075212e-03 3.33393959e-02\n",
      " 8.81424042e-03 1.33687980e-04 6.12571609e-04 6.73384901e-04\n",
      " 7.16606273e-04 7.16606273e-04 5.12474689e-03 8.50869588e-05\n",
      " 8.81424042e-03 9.41611078e-05 9.41611078e-05 2.53637118e-03\n",
      " 7.27600891e-03 2.05497743e-05 6.34568859e-02 3.33393959e-02\n",
      " 1.46959908e-04 9.37998456e-03 2.12877101e-03 1.33687980e-04\n",
      " 6.34568859e-02 8.50869588e-05 2.05497743e-05 9.41611078e-05\n",
      " 4.38075212e-03 4.38075212e-03 2.05497743e-05 2.05497743e-05\n",
      " 6.12571609e-04 9.37998456e-03 6.73384901e-04 2.05497743e-05\n",
      " 4.38075212e-03 5.64751744e-03 9.37998456e-03 4.38075212e-03\n",
      " 4.38075212e-03 8.01822765e-03 5.64751744e-03 5.12474689e-03\n",
      " 2.26540669e-03 3.33393959e-02 2.62745146e-01 4.38075212e-03\n",
      " 1.46959908e-04 6.73384901e-04 9.56057859e-04 6.70801367e-02\n",
      " 1.46959908e-04 1.46959908e-04 8.01822765e-03 9.41611078e-05\n",
      " 2.97671415e-04 2.05497743e-05 6.73384901e-04 2.05497743e-05\n",
      " 6.47548121e-04 1.11842771e-03 9.41611078e-05 9.41611078e-05\n",
      " 5.12474689e-03 2.05497743e-05 4.38075212e-03 1.33687980e-04\n",
      " 2.05497743e-05 1.01742266e-03 4.38075212e-03 5.53539104e-04\n",
      " 2.97671415e-04 4.03877255e-02 2.05497743e-05 5.64751744e-03\n",
      " 4.21266915e-03 2.97671415e-04 3.93866867e-03 1.46959908e-04\n",
      " 2.12191687e-02 1.81386360e-02 6.73384901e-04 7.16606273e-04\n",
      " 1.48122883e-02 6.08491921e-04 4.70064187e-04 6.08491921e-04\n",
      " 1.04490807e-02 6.73384901e-04 1.80473712e-02 9.41611078e-05]\n",
      "\n",
      "################################################\n",
      "K-fold : 8\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 1]\n",
      " [5 2]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 60.0\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.286\n",
      "False positives : 0.125\n",
      "Specificity : 0.875\n",
      "Prevalence : 0.034\n",
      "\n",
      "Training Miss : [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
      "Testing Miss : [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0]\n",
      "Training Miss2 : [-1, 1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1]\n",
      "Testing Miss2 : [-1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1]\n",
      "Error : 0.1136102160008299\n",
      "Alpha : 1.027191679413255\n",
      "New weights : \n",
      "[3.42279192e-04 2.46200296e-02 1.84995003e-04 7.35704440e-06\n",
      " 2.00163222e-03 7.35704440e-06 4.78617620e-05 3.64248464e-04\n",
      " 1.79963757e-03 4.78617620e-05 3.41433006e-02 5.26132576e-05\n",
      " 1.96868951e-04 6.49383048e-03 8.47665485e-04 2.19307350e-04\n",
      " 1.83471555e-03 1.54615128e-03 1.88090583e-03 1.66902266e-03\n",
      " 1.66902266e-03 3.37107086e-05 7.35704440e-06 2.41079175e-04\n",
      " 3.71626781e-03 5.80008442e-03 1.22363632e-02 2.41079175e-04\n",
      " 2.87061338e-03 2.00163222e-03 9.31239533e-02 1.39580203e-04\n",
      " 2.67047093e-03 1.66902266e-03 3.37107086e-05 5.26132576e-05\n",
      " 7.35704440e-06 4.41254756e-04 5.59902522e-05 5.59902522e-05\n",
      " 4.10489969e-04 5.73998469e-05 1.65790707e-03 8.11040422e-04\n",
      " 5.59902522e-05 1.56835727e-03 7.35704440e-06 5.26132576e-05\n",
      " 4.41254756e-04 7.35704440e-06 7.35704440e-06 6.91063855e-03\n",
      " 5.26132576e-05 5.73998469e-05 3.04620638e-05 7.35704440e-06\n",
      " 5.59902522e-05 3.35813728e-03 5.59902522e-05 1.50818173e-03\n",
      " 1.83471555e-03 5.59902522e-05 1.39580203e-04 7.35704440e-06\n",
      " 7.08461882e-03 5.27627964e-03 1.56835727e-03 1.19358691e-02\n",
      " 3.15559467e-03 4.78617620e-05 2.19307350e-04 2.41079175e-04\n",
      " 2.56552900e-04 2.00163222e-03 1.83471555e-03 3.04620638e-05\n",
      " 3.15559467e-03 3.37107086e-05 3.37107086e-05 9.08048681e-04\n",
      " 2.60489093e-03 5.73998469e-05 2.27182606e-02 1.19358691e-02\n",
      " 4.10489969e-04 3.35813728e-03 7.62123351e-04 4.78617620e-05\n",
      " 2.27182606e-02 3.04620638e-05 7.35704440e-06 3.37107086e-05\n",
      " 1.22363632e-02 1.56835727e-03 7.35704440e-06 7.35704440e-06\n",
      " 2.19307350e-04 3.35813728e-03 1.88090583e-03 7.35704440e-06\n",
      " 1.22363632e-02 1.57747055e-02 2.62002721e-02 1.56835727e-03\n",
      " 1.22363632e-02 2.87061338e-03 2.02187314e-03 1.83471555e-03\n",
      " 8.11040422e-04 1.19358691e-02 9.40656418e-02 1.22363632e-02\n",
      " 5.26132576e-05 2.41079175e-04 3.42279192e-04 2.40154241e-02\n",
      " 4.10489969e-04 5.26132576e-05 2.87061338e-03 2.63011802e-04\n",
      " 1.06569629e-04 5.73998469e-05 2.41079175e-04 7.35704440e-06\n",
      " 2.31829324e-04 4.00409376e-04 3.37107086e-05 3.37107086e-05\n",
      " 1.83471555e-03 7.35704440e-06 1.56835727e-03 4.78617620e-05\n",
      " 7.35704440e-06 3.64248464e-04 1.56835727e-03 1.98173066e-04\n",
      " 1.06569629e-04 1.12811422e-01 5.73998469e-05 2.02187314e-03\n",
      " 1.17668720e-02 1.06569629e-04 1.41008655e-03 4.10489969e-04\n",
      " 7.59669496e-03 6.49383048e-03 2.41079175e-04 2.00163222e-03\n",
      " 4.13738404e-02 2.17846777e-04 1.68288131e-04 1.69964607e-03\n",
      " 2.91864827e-02 2.41079175e-04 5.04101082e-02 3.37107086e-05]\n",
      "\n",
      "################################################\n",
      "K-fold : 9\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Confusion Matrix : \n",
      "[[6 1]\n",
      " [5 3]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 60.0\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.375\n",
      "False positives : 0.143\n",
      "Specificity : 0.857\n",
      "Prevalence : 0.038\n",
      "\n",
      "Training Miss : [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0]\n",
      "Testing Miss : [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1]\n",
      "Training Miss2 : [-1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1]\n",
      "Testing Miss2 : [1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, -1, 1, 1]\n",
      "Error : 0.16941777218454104\n",
      "Alpha : 0.7948796224540963\n",
      "New weights : \n",
      "[1.54585468e-04 5.45130403e-02 8.35503287e-05 3.32270315e-06\n",
      " 9.04008367e-04 3.32270315e-06 2.16160755e-05 1.64507573e-04\n",
      " 8.12780393e-04 2.16160755e-05 1.54203300e-02 1.16494930e-04\n",
      " 8.89130266e-05 2.93284501e-03 3.82835909e-04 9.90470061e-05\n",
      " 8.28622857e-04 3.42344865e-03 8.49484030e-04 7.53790047e-04\n",
      " 7.53790047e-04 1.52249560e-05 3.32270315e-06 1.08879937e-04\n",
      " 1.67839884e-03 2.61952460e-03 5.52637720e-03 1.08879937e-04\n",
      " 6.35603878e-03 9.04008367e-04 4.20580924e-02 3.09054919e-04\n",
      " 5.91288848e-03 7.53790047e-04 1.52249560e-05 2.37620201e-05\n",
      " 1.62897797e-05 9.77015003e-04 2.52871911e-05 2.52871911e-05\n",
      " 9.08896399e-04 1.27093274e-04 7.48769853e-04 1.79578498e-03\n",
      " 1.23972186e-04 7.08325974e-04 3.32270315e-06 2.37620201e-05\n",
      " 1.99286356e-04 3.32270315e-06 1.62897797e-05 3.12109038e-03\n",
      " 2.37620201e-05 1.27093274e-04 1.37577524e-05 3.32270315e-06\n",
      " 2.52871911e-05 7.43550173e-03 1.23972186e-04 6.81148557e-04\n",
      " 8.28622857e-04 2.52871911e-05 6.30393887e-05 1.62897797e-05\n",
      " 1.56865819e-02 2.38295571e-03 7.08325974e-04 5.39066339e-03\n",
      " 1.42517889e-03 2.16160755e-05 4.85584729e-04 1.08879937e-04\n",
      " 1.15868422e-04 4.43196291e-03 8.28622857e-04 6.74483231e-05\n",
      " 1.42517889e-03 1.52249560e-05 1.52249560e-05 4.10107109e-04\n",
      " 5.76768293e-03 2.59238142e-05 1.02603752e-02 5.39066339e-03\n",
      " 9.08896399e-04 1.51665434e-03 3.44202036e-04 2.16160755e-05\n",
      " 1.02603752e-02 1.37577524e-05 3.32270315e-06 1.52249560e-05\n",
      " 2.70934426e-02 7.08325974e-04 3.32270315e-06 1.62897797e-05\n",
      " 9.90470061e-05 1.51665434e-03 8.49484030e-04 3.32270315e-06\n",
      " 5.52637720e-03 7.12441854e-03 1.18329756e-02 7.08325974e-04\n",
      " 5.52637720e-03 6.35603878e-03 9.13149885e-04 8.28622857e-04\n",
      " 3.66294726e-04 5.39066339e-03 4.24833924e-02 5.52637720e-03\n",
      " 2.37620201e-05 5.33791348e-04 1.54585468e-04 1.08462204e-02\n",
      " 1.85391883e-04 1.16494930e-04 6.35603878e-03 1.18785493e-04\n",
      " 4.81306381e-05 1.27093274e-04 5.33791348e-04 3.32270315e-06\n",
      " 1.04702376e-04 1.80839128e-04 1.52249560e-05 1.52249560e-05\n",
      " 8.28622857e-04 3.32270315e-06 7.08325974e-04 2.16160755e-05\n",
      " 3.32270315e-06 1.64507573e-04 7.08325974e-04 8.95020112e-05\n",
      " 2.35963749e-04 5.09496542e-02 1.27093274e-04 4.47677983e-03\n",
      " 5.31433830e-03 2.35963749e-04 6.36845282e-04 1.85391883e-04\n",
      " 3.43093788e-03 2.93284501e-03 5.33791348e-04 9.04008367e-04\n",
      " 1.86858992e-02 4.82350765e-04 7.60049107e-05 7.67620670e-04\n",
      " 6.46239640e-02 1.08879937e-04 1.11616773e-01 7.46413894e-05]\n",
      "\n",
      "################################################\n",
      "K-fold : 10\n",
      "################################################\n",
      "\n",
      "Treinando o modelo....\n",
      "\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Confusion Matrix : \n",
      "[[2 9]\n",
      " [0 4]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 40.0\n",
      "Misclassification rate : 0.043\n",
      "True positives : 1.0\n",
      "False positives : 0.818\n",
      "Specificity : 0.182\n",
      "Prevalence : 0.019\n",
      "\n",
      "Training Miss : [1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0]\n",
      "Testing Miss : [0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1]\n",
      "Training Miss2 : [1, -1, 1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, -1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1, -1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, -1, 1, -1, -1, 1, -1, -1]\n",
      "Testing Miss2 : [-1, 1, 1, -1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1]\n",
      "Error : 0.1570325193511358\n",
      "Alpha : 0.8402377339950238\n",
      "New weights : \n",
      "[3.58161809e-04 2.35282590e-02 1.93579237e-04 1.43410494e-06\n",
      " 3.90177156e-04 1.43410494e-06 9.32966903e-06 7.10027687e-05\n",
      " 1.88314530e-03 5.00826684e-05 3.57276358e-02 5.02801327e-05\n",
      " 3.83755650e-05 6.79516058e-03 8.86999301e-04 2.29483764e-04\n",
      " 1.91985098e-03 1.47758750e-03 3.66644021e-04 1.74646952e-03\n",
      " 3.25341742e-04 3.52749704e-05 1.43410494e-06 4.69934415e-05\n",
      " 3.88871201e-03 1.13060752e-03 2.38522808e-03 2.52265856e-04\n",
      " 2.74331657e-03 3.90177156e-04 1.81526051e-02 7.16054819e-04\n",
      " 1.36996761e-02 3.25341742e-04 3.52749704e-05 1.02558757e-05\n",
      " 7.03079766e-06 4.21687397e-04 1.09141515e-05 1.09141515e-05\n",
      " 2.10583817e-03 5.48544615e-05 3.23174986e-04 7.75074988e-04\n",
      " 5.35073751e-05 1.64113300e-03 7.69842982e-06 5.50546454e-05\n",
      " 8.60135661e-05 1.43410494e-06 7.03079766e-06 1.34708727e-03\n",
      " 1.02558757e-05 2.94464659e-04 3.18755803e-05 1.43410494e-06\n",
      " 1.09141515e-05 3.20922131e-03 5.35073751e-05 2.93989100e-04\n",
      " 1.91985098e-03 5.85883411e-05 2.72082984e-05 7.03079766e-06\n",
      " 6.77045274e-03 1.02850252e-03 3.05719089e-04 1.24897235e-02\n",
      " 6.15118472e-04 5.00826684e-05 2.09582207e-04 4.69934415e-05\n",
      " 5.00097268e-05 1.91287022e-03 1.91985098e-03 2.91112293e-05\n",
      " 3.30202222e-03 6.57121135e-06 3.52749704e-05 9.50184429e-04\n",
      " 2.48937754e-03 1.11889231e-05 4.42845904e-03 2.32665292e-03\n",
      " 3.92286869e-04 3.51396331e-03 1.48560319e-04 9.32966903e-06\n",
      " 2.37724452e-02 3.18755803e-05 7.69842982e-06 3.52749704e-05\n",
      " 1.16937440e-02 3.05719089e-04 1.43410494e-06 3.77420793e-05\n",
      " 2.29483764e-04 6.54599999e-04 1.96818460e-03 7.69842982e-06\n",
      " 2.38522808e-03 1.65066916e-02 5.10720578e-03 1.64113300e-03\n",
      " 1.28041613e-02 2.74331657e-03 3.94122707e-04 1.91985098e-03\n",
      " 1.58095699e-04 2.32665292e-03 1.83361679e-02 2.38522808e-03\n",
      " 1.02558757e-05 2.30388564e-04 3.58161809e-04 4.68131446e-03\n",
      " 4.29537739e-04 2.69909169e-04 2.74331657e-03 2.75216213e-04\n",
      " 2.07735638e-05 5.48544615e-05 2.30388564e-04 7.69842982e-06\n",
      " 4.51903728e-05 4.18989381e-04 3.52749704e-05 3.52749704e-05\n",
      " 1.91985098e-03 1.43410494e-06 3.05719089e-04 9.32966903e-06\n",
      " 1.43410494e-06 3.81150511e-04 3.05719089e-04 2.07368796e-04\n",
      " 1.01843819e-04 2.19902734e-02 2.94464659e-04 1.93221356e-03\n",
      " 2.29371041e-03 1.01843819e-04 1.47551812e-03 4.29537739e-04\n",
      " 1.48081990e-03 6.79516058e-03 2.30388564e-04 3.90177156e-04\n",
      " 8.06498177e-03 1.11756704e-03 1.76097124e-04 1.77851393e-03\n",
      " 1.49728408e-01 2.52265856e-04 4.81746815e-02 1.72937958e-04]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "print(\"Inicializando vetor de pesos....\")\n",
    "\n",
    "# Initialize weights\n",
    "w = np.ones(n_train) / n_train\n",
    "print(w)\n",
    "\n",
    "n_train, n_test = len(trainData), len(testData)\n",
    "#pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)]\n",
    "    \n",
    "# Fit a simple decision tree first\n",
    "clf_tree = DecisionTreeClassifier(max_depth = 1, random_state = 1)\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "print\n",
    "print(\"Iniciando treinamento com 10 K-folds\" )\n",
    "print\n",
    "    \n",
    "kfold = 0    \n",
    "for train_index, test_index in kf.split(trainData):\n",
    "    print(\"################################################\")\n",
    "    print(\"K-fold : \"+str(kfold+1))    \n",
    "    print(\"################################################\")\n",
    "    #print(train_index, test_index)\n",
    "    print\n",
    "    \n",
    "    X_train, X_test = trainData.iloc[train_index,:], trainData.iloc[test_index,:]\n",
    "    #print(len(X_train), len(X_test))\n",
    "\n",
    "    y_train, y_test = trainLabels.iloc[train_index], trainLabels.iloc[test_index]\n",
    "    #print(len(y_train), len(y_test))\n",
    "\n",
    "\n",
    "    trainWeights = w[train_index]\n",
    "    testWeights = w[test_index]\n",
    "    \n",
    "    print(\"Treinando o modelo....\")\n",
    "    # Fit a classifier with the specific weights\n",
    "    clf_tree.fit(X_train, y_train, sample_weight=trainWeights)\n",
    "\n",
    "    pred_train_i = clf_tree.predict(X_train)\n",
    "    #print(pred_train_i)\n",
    "\n",
    "    pred_test_i = clf_tree.predict(X_test)\n",
    "    #print(pred_test_i)        \n",
    "\n",
    "    \n",
    "\n",
    "    scores.append([i, y_test])\n",
    "\n",
    "    kfold += 1 \n",
    "    print\n",
    "\n",
    "    \n",
    "    print\n",
    "    print(\"...:::: Avaliação ::::....  \")\n",
    "    print\n",
    "    \n",
    "    # Print Confusion Matrix\n",
    "    printCM(y_test, pred_test_i)\n",
    "    print\n",
    "    # Indicator function\n",
    "    miss = [int(x) for x in (pred_train_i != y_train)]\n",
    "    print(\"Training Miss : \"+str(miss))\n",
    "    missTest = [int(x) for x in (pred_test_i != y_test)]\n",
    "    print(\"Testing Miss : \"+str(missTest))\n",
    "\n",
    "    \n",
    "    # Equivalent with 1/-1 to update weights\n",
    "    miss2 = [x if x==1 else -1 for x in miss]\n",
    "    miss2Test = [x if x==1 else -1 for x in missTest]\n",
    "    \n",
    "    print(\"Training Miss2 : \"+str(miss2))\n",
    "    print(\"Testing Miss2 : \"+str(miss2Test))\n",
    "    \n",
    "    # Error\n",
    "    err_m = np.dot(trainWeights,miss) / sum(trainWeights)\n",
    "    print(\"Error : \"+str(err_m))\n",
    "\n",
    "    # Alpha\n",
    "    alpha_m = 0.5 * np.log( (1 - err_m) / float(err_m))\n",
    "    print(\"Alpha : \"+str(alpha_m))\n",
    "\n",
    "\n",
    "    # New weights\n",
    "    w = np.multiply(w, np.exp([float(x) * alpha_m for x in np.concatenate((miss2, miss2Test), axis=0)]))\n",
    "    print(\"New weights : \")\n",
    "    print(w)\n",
    "\n",
    "    print\n",
    "    \n",
    "    # Add to prediction\n",
    "    #pred_train = [sum(x) for x in zip(pred_train, [x * alpha_m for x in pred_train_i])]\n",
    "    #pred_test = [sum(x) for x in zip(pred_test, [x * alpha_m for x in pred_test_i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################################\n",
      "Iteração : 1\n",
      "#############################################################\n",
      "Iniciando treinamento com 10 K-folds\n",
      "\n",
      "K-fold : 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of weights=156 does not match number of samples=104",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-50350726b57f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Fit a classifier with the specific weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mclf_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mpred_train_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/roberto/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/roberto/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 raise ValueError(\"Number of weights=%d does not match \"\n\u001b[1;32m    261\u001b[0m                                  \u001b[0;34m\"number of samples=%d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                                  (len(sample_weight), n_samples))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of weights=156 does not match number of samples=104"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "n_iterations = 10\n",
    "\n",
    "# Initialize weights\n",
    "w = np.ones(n_train) / n_train\n",
    "\n",
    "n_train, n_test = len(trainData), len(testData)\n",
    "pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)]\n",
    "\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    \n",
    "    print(\"#############################################################\")\n",
    "    print(\"Iteração : \"+str(i+1))\n",
    "    print(\"#############################################################\")\n",
    "    \n",
    "    # Fit a simple decision tree first\n",
    "    clf_tree = DecisionTreeClassifier(max_depth = 1, random_state = 1)\n",
    "    \n",
    "    kf = KFold(n_splits=3)\n",
    "    \n",
    "    print(\"Iniciando treinamento com 10 K-folds\" )\n",
    "    print\n",
    "    \n",
    "    kfold = 0    \n",
    "    for train_index, test_index in kf.split(trainData):\n",
    "        print(\"K-fold : \"+str(kfold+1))    \n",
    "        #print(train_index, test_index)\n",
    "    \n",
    "        X_train, X_test = trainData.iloc[train_index,:], trainData.iloc[test_index,:]\n",
    "        #print(len(X_train), len(X_test))\n",
    "        \n",
    "        y_train, y_test = trainLabels.iloc[train_index], trainLabels.iloc[test_index]\n",
    "        #print(len(y_train), len(y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Fit a classifier with the specific weights\n",
    "        clf_tree.fit(X_train, y_train, =w)\n",
    "\n",
    "        pred_train_i = clf_tree.predict(X_train)\n",
    "        #print(pred_train_i)\n",
    "\n",
    "        pred_test_i = clf_tree.predict(X_test)\n",
    "        #print(pred_test_i)        \n",
    "        \n",
    "        # Print Confusion Matrix\n",
    "        printCM(y_test, pred_test_i)\n",
    "        \n",
    "        scores.append([i, y_test])\n",
    "        \n",
    "        kfold += 1 \n",
    "        print\n",
    "\n",
    "    \n",
    "    print\n",
    "    print(\".:: Avaliação ::.  \")\n",
    "    print\n",
    "    # Indicator function\n",
    "    miss = [int(x) for x in (pred_train_i != y_train)]\n",
    "    print(\"Miss : \"+str(miss))\n",
    "\n",
    "    # Equivalent with 1/-1 to update weights\n",
    "    miss2 = [x if x==1 else -1 for x in miss]\n",
    "\n",
    "    # Error\n",
    "    err_m = np.dot(w,miss) / sum(w)\n",
    "    print(\"Error : \"+str(err_m))\n",
    "\n",
    "    # Alpha\n",
    "    alpha_m = 0.2 * np.log( (1 - err_m) / float(err_m))\n",
    "    print(\"Alpha : \"+str(alpha_m))\n",
    "\n",
    "\n",
    "    # New weights\n",
    "    w = np.multiply(w, np.exp([float(x) * alpha_m for x in miss2]))\n",
    "    #print(\"New weights : \")\n",
    "    #print(w)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    # Add to prediction\n",
    "    #pred_train = [sum(x) for x in zip(pred_train, [x * alpha_m for x in pred_train_i])]\n",
    "    #pred_test = [sum(x) for x in zip(pred_test, [x * alpha_m for x in pred_test_i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 133    M\n",
      "7      R\n",
      "117    M\n",
      "37     R\n",
      "169    M\n",
      "58     R\n",
      "77     R\n",
      "75     R\n",
      "107    M\n",
      "98     M\n",
      "110    M\n",
      "14     R\n",
      "24     R\n",
      "162    M\n",
      "114    M\n",
      "103    M\n",
      "163    M\n",
      "83     R\n",
      "120    M\n",
      "173    M\n",
      "11     R\n",
      "112    M\n",
      "57     R\n",
      "199    M\n",
      "170    M\n",
      "72     R\n",
      "191    M\n",
      "180    M\n",
      "49     R\n",
      "168    M\n",
      "178    M\n",
      "127    M\n",
      "147    M\n",
      "6      R\n",
      "200    M\n",
      "31     R\n",
      "48     R\n",
      "67     R\n",
      "44     R\n",
      "38     R\n",
      "109    M\n",
      "5      R\n",
      "0      R\n",
      "92     R\n",
      "43     R\n",
      "161    M\n",
      "130    M\n",
      "119    M\n",
      "25     R\n",
      "10     R\n",
      "52     R\n",
      "79     R\n",
      "Name: 60, dtype: object], [0, 183    M\n",
      "150    M\n",
      "116    M\n",
      "95     R\n",
      "64     R\n",
      "3      R\n",
      "13     R\n",
      "86     R\n",
      "164    M\n",
      "174    M\n",
      "96     R\n",
      "65     R\n",
      "82     R\n",
      "32     R\n",
      "8      R\n",
      "152    M\n",
      "70     R\n",
      "100    M\n",
      "94     R\n",
      "69     R\n",
      "76     R\n",
      "16     R\n",
      "99     M\n",
      "30     R\n",
      "156    M\n",
      "23     R\n",
      "132    M\n",
      "55     R\n",
      "33     R\n",
      "87     R\n",
      "188    M\n",
      "204    M\n",
      "1      R\n",
      "186    M\n",
      "189    M\n",
      "50     R\n",
      "176    M\n",
      "207    M\n",
      "128    M\n",
      "141    M\n",
      "93     R\n",
      "195    M\n",
      "201    M\n",
      "131    M\n",
      "143    M\n",
      "41     R\n",
      "140    M\n",
      "206    M\n",
      "118    M\n",
      "106    M\n",
      "88     R\n",
      "104    M\n",
      "Name: 60, dtype: object], [0, 97     M\n",
      "34     R\n",
      "51     R\n",
      "115    M\n",
      "192    M\n",
      "193    M\n",
      "63     R\n",
      "18     R\n",
      "36     R\n",
      "91     R\n",
      "148    M\n",
      "184    M\n",
      "182    M\n",
      "153    M\n",
      "2      R\n",
      "159    M\n",
      "202    M\n",
      "81     R\n",
      "21     R\n",
      "177    M\n",
      "89     R\n",
      "181    M\n",
      "166    M\n",
      "187    M\n",
      "137    M\n",
      "196    M\n",
      "12     R\n",
      "29     R\n",
      "71     R\n",
      "123    M\n",
      "80     R\n",
      "129    M\n",
      "90     R\n",
      "56     R\n",
      "122    M\n",
      "22     R\n",
      "27     R\n",
      "26     R\n",
      "126    M\n",
      "105    M\n",
      "198    M\n",
      "125    M\n",
      "190    M\n",
      "61     R\n",
      "40     R\n",
      "101    M\n",
      "145    M\n",
      "135    M\n",
      "111    M\n",
      "155    M\n",
      "42     R\n",
      "108    M\n",
      "Name: 60, dtype: object], [1, 133    M\n",
      "7      R\n",
      "117    M\n",
      "37     R\n",
      "169    M\n",
      "58     R\n",
      "77     R\n",
      "75     R\n",
      "107    M\n",
      "98     M\n",
      "110    M\n",
      "14     R\n",
      "24     R\n",
      "162    M\n",
      "114    M\n",
      "103    M\n",
      "163    M\n",
      "83     R\n",
      "120    M\n",
      "173    M\n",
      "11     R\n",
      "112    M\n",
      "57     R\n",
      "199    M\n",
      "170    M\n",
      "72     R\n",
      "191    M\n",
      "180    M\n",
      "49     R\n",
      "168    M\n",
      "178    M\n",
      "127    M\n",
      "147    M\n",
      "6      R\n",
      "200    M\n",
      "31     R\n",
      "48     R\n",
      "67     R\n",
      "44     R\n",
      "38     R\n",
      "109    M\n",
      "5      R\n",
      "0      R\n",
      "92     R\n",
      "43     R\n",
      "161    M\n",
      "130    M\n",
      "119    M\n",
      "25     R\n",
      "10     R\n",
      "52     R\n",
      "79     R\n",
      "Name: 60, dtype: object], [1, 183    M\n",
      "150    M\n",
      "116    M\n",
      "95     R\n",
      "64     R\n",
      "3      R\n",
      "13     R\n",
      "86     R\n",
      "164    M\n",
      "174    M\n",
      "96     R\n",
      "65     R\n",
      "82     R\n",
      "32     R\n",
      "8      R\n",
      "152    M\n",
      "70     R\n",
      "100    M\n",
      "94     R\n",
      "69     R\n",
      "76     R\n",
      "16     R\n",
      "99     M\n",
      "30     R\n",
      "156    M\n",
      "23     R\n",
      "132    M\n",
      "55     R\n",
      "33     R\n",
      "87     R\n",
      "188    M\n",
      "204    M\n",
      "1      R\n",
      "186    M\n",
      "189    M\n",
      "50     R\n",
      "176    M\n",
      "207    M\n",
      "128    M\n",
      "141    M\n",
      "93     R\n",
      "195    M\n",
      "201    M\n",
      "131    M\n",
      "143    M\n",
      "41     R\n",
      "140    M\n",
      "206    M\n",
      "118    M\n",
      "106    M\n",
      "88     R\n",
      "104    M\n",
      "Name: 60, dtype: object], [1, 97     M\n",
      "34     R\n",
      "51     R\n",
      "115    M\n",
      "192    M\n",
      "193    M\n",
      "63     R\n",
      "18     R\n",
      "36     R\n",
      "91     R\n",
      "148    M\n",
      "184    M\n",
      "182    M\n",
      "153    M\n",
      "2      R\n",
      "159    M\n",
      "202    M\n",
      "81     R\n",
      "21     R\n",
      "177    M\n",
      "89     R\n",
      "181    M\n",
      "166    M\n",
      "187    M\n",
      "137    M\n",
      "196    M\n",
      "12     R\n",
      "29     R\n",
      "71     R\n",
      "123    M\n",
      "80     R\n",
      "129    M\n",
      "90     R\n",
      "56     R\n",
      "122    M\n",
      "22     R\n",
      "27     R\n",
      "26     R\n",
      "126    M\n",
      "105    M\n",
      "198    M\n",
      "125    M\n",
      "190    M\n",
      "61     R\n",
      "40     R\n",
      "101    M\n",
      "145    M\n",
      "135    M\n",
      "111    M\n",
      "155    M\n",
      "42     R\n",
      "108    M\n",
      "Name: 60, dtype: object], [2, 133    M\n",
      "7      R\n",
      "117    M\n",
      "37     R\n",
      "169    M\n",
      "58     R\n",
      "77     R\n",
      "75     R\n",
      "107    M\n",
      "98     M\n",
      "110    M\n",
      "14     R\n",
      "24     R\n",
      "162    M\n",
      "114    M\n",
      "103    M\n",
      "163    M\n",
      "83     R\n",
      "120    M\n",
      "173    M\n",
      "11     R\n",
      "112    M\n",
      "57     R\n",
      "199    M\n",
      "170    M\n",
      "72     R\n",
      "191    M\n",
      "180    M\n",
      "49     R\n",
      "168    M\n",
      "178    M\n",
      "127    M\n",
      "147    M\n",
      "6      R\n",
      "200    M\n",
      "31     R\n",
      "48     R\n",
      "67     R\n",
      "44     R\n",
      "38     R\n",
      "109    M\n",
      "5      R\n",
      "0      R\n",
      "92     R\n",
      "43     R\n",
      "161    M\n",
      "130    M\n",
      "119    M\n",
      "25     R\n",
      "10     R\n",
      "52     R\n",
      "79     R\n",
      "Name: 60, dtype: object], [2, 183    M\n",
      "150    M\n",
      "116    M\n",
      "95     R\n",
      "64     R\n",
      "3      R\n",
      "13     R\n",
      "86     R\n",
      "164    M\n",
      "174    M\n",
      "96     R\n",
      "65     R\n",
      "82     R\n",
      "32     R\n",
      "8      R\n",
      "152    M\n",
      "70     R\n",
      "100    M\n",
      "94     R\n",
      "69     R\n",
      "76     R\n",
      "16     R\n",
      "99     M\n",
      "30     R\n",
      "156    M\n",
      "23     R\n",
      "132    M\n",
      "55     R\n",
      "33     R\n",
      "87     R\n",
      "188    M\n",
      "204    M\n",
      "1      R\n",
      "186    M\n",
      "189    M\n",
      "50     R\n",
      "176    M\n",
      "207    M\n",
      "128    M\n",
      "141    M\n",
      "93     R\n",
      "195    M\n",
      "201    M\n",
      "131    M\n",
      "143    M\n",
      "41     R\n",
      "140    M\n",
      "206    M\n",
      "118    M\n",
      "106    M\n",
      "88     R\n",
      "104    M\n",
      "Name: 60, dtype: object], [2, 97     M\n",
      "34     R\n",
      "51     R\n",
      "115    M\n",
      "192    M\n",
      "193    M\n",
      "63     R\n",
      "18     R\n",
      "36     R\n",
      "91     R\n",
      "148    M\n",
      "184    M\n",
      "182    M\n",
      "153    M\n",
      "2      R\n",
      "159    M\n",
      "202    M\n",
      "81     R\n",
      "21     R\n",
      "177    M\n",
      "89     R\n",
      "181    M\n",
      "166    M\n",
      "187    M\n",
      "137    M\n",
      "196    M\n",
      "12     R\n",
      "29     R\n",
      "71     R\n",
      "123    M\n",
      "80     R\n",
      "129    M\n",
      "90     R\n",
      "56     R\n",
      "122    M\n",
      "22     R\n",
      "27     R\n",
      "26     R\n",
      "126    M\n",
      "105    M\n",
      "198    M\n",
      "125    M\n",
      "190    M\n",
      "61     R\n",
      "40     R\n",
      "101    M\n",
      "145    M\n",
      "135    M\n",
      "111    M\n",
      "155    M\n",
      "42     R\n",
      "108    M\n",
      "Name: 60, dtype: object], [3, 133    M\n",
      "7      R\n",
      "117    M\n",
      "37     R\n",
      "169    M\n",
      "58     R\n",
      "77     R\n",
      "75     R\n",
      "107    M\n",
      "98     M\n",
      "110    M\n",
      "14     R\n",
      "24     R\n",
      "162    M\n",
      "114    M\n",
      "103    M\n",
      "163    M\n",
      "83     R\n",
      "120    M\n",
      "173    M\n",
      "11     R\n",
      "112    M\n",
      "57     R\n",
      "199    M\n",
      "170    M\n",
      "72     R\n",
      "191    M\n",
      "180    M\n",
      "49     R\n",
      "168    M\n",
      "178    M\n",
      "127    M\n",
      "147    M\n",
      "6      R\n",
      "200    M\n",
      "31     R\n",
      "48     R\n",
      "67     R\n",
      "44     R\n",
      "38     R\n",
      "109    M\n",
      "5      R\n",
      "0      R\n",
      "92     R\n",
      "43     R\n",
      "161    M\n",
      "130    M\n",
      "119    M\n",
      "25     R\n",
      "10     R\n",
      "52     R\n",
      "79     R\n",
      "Name: 60, dtype: object], [3, 183    M\n",
      "150    M\n",
      "116    M\n",
      "95     R\n",
      "64     R\n",
      "3      R\n",
      "13     R\n",
      "86     R\n",
      "164    M\n",
      "174    M\n",
      "96     R\n",
      "65     R\n",
      "82     R\n",
      "32     R\n",
      "8      R\n",
      "152    M\n",
      "70     R\n",
      "100    M\n",
      "94     R\n",
      "69     R\n",
      "76     R\n",
      "16     R\n",
      "99     M\n",
      "30     R\n",
      "156    M\n",
      "23     R\n",
      "132    M\n",
      "55     R\n",
      "33     R\n",
      "87     R\n",
      "188    M\n",
      "204    M\n",
      "1      R\n",
      "186    M\n",
      "189    M\n",
      "50     R\n",
      "176    M\n",
      "207    M\n",
      "128    M\n",
      "141    M\n",
      "93     R\n",
      "195    M\n",
      "201    M\n",
      "131    M\n",
      "143    M\n",
      "41     R\n",
      "140    M\n",
      "206    M\n",
      "118    M\n",
      "106    M\n",
      "88     R\n",
      "104    M\n",
      "Name: 60, dtype: object], [3, 97     M\n",
      "34     R\n",
      "51     R\n",
      "115    M\n",
      "192    M\n",
      "193    M\n",
      "63     R\n",
      "18     R\n",
      "36     R\n",
      "91     R\n",
      "148    M\n",
      "184    M\n",
      "182    M\n",
      "153    M\n",
      "2      R\n",
      "159    M\n",
      "202    M\n",
      "81     R\n",
      "21     R\n",
      "177    M\n",
      "89     R\n",
      "181    M\n",
      "166    M\n",
      "187    M\n",
      "137    M\n",
      "196    M\n",
      "12     R\n",
      "29     R\n",
      "71     R\n",
      "123    M\n",
      "80     R\n",
      "129    M\n",
      "90     R\n",
      "56     R\n",
      "122    M\n",
      "22     R\n",
      "27     R\n",
      "26     R\n",
      "126    M\n",
      "105    M\n",
      "198    M\n",
      "125    M\n",
      "190    M\n",
      "61     R\n",
      "40     R\n",
      "101    M\n",
      "145    M\n",
      "135    M\n",
      "111    M\n",
      "155    M\n",
      "42     R\n",
      "108    M\n",
      "Name: 60, dtype: object], [4, 133    M\n",
      "7      R\n",
      "117    M\n",
      "37     R\n",
      "169    M\n",
      "58     R\n",
      "77     R\n",
      "75     R\n",
      "107    M\n",
      "98     M\n",
      "110    M\n",
      "14     R\n",
      "24     R\n",
      "162    M\n",
      "114    M\n",
      "103    M\n",
      "163    M\n",
      "83     R\n",
      "120    M\n",
      "173    M\n",
      "11     R\n",
      "112    M\n",
      "57     R\n",
      "199    M\n",
      "170    M\n",
      "72     R\n",
      "191    M\n",
      "180    M\n",
      "49     R\n",
      "168    M\n",
      "178    M\n",
      "127    M\n",
      "147    M\n",
      "6      R\n",
      "200    M\n",
      "31     R\n",
      "48     R\n",
      "67     R\n",
      "44     R\n",
      "38     R\n",
      "109    M\n",
      "5      R\n",
      "0      R\n",
      "92     R\n",
      "43     R\n",
      "161    M\n",
      "130    M\n",
      "119    M\n",
      "25     R\n",
      "10     R\n",
      "52     R\n",
      "79     R\n",
      "Name: 60, dtype: object], [4, 183    M\n",
      "150    M\n",
      "116    M\n",
      "95     R\n",
      "64     R\n",
      "3      R\n",
      "13     R\n",
      "86     R\n",
      "164    M\n",
      "174    M\n",
      "96     R\n",
      "65     R\n",
      "82     R\n",
      "32     R\n",
      "8      R\n",
      "152    M\n",
      "70     R\n",
      "100    M\n",
      "94     R\n",
      "69     R\n",
      "76     R\n",
      "16     R\n",
      "99     M\n",
      "30     R\n",
      "156    M\n",
      "23     R\n",
      "132    M\n",
      "55     R\n",
      "33     R\n",
      "87     R\n",
      "188    M\n",
      "204    M\n",
      "1      R\n",
      "186    M\n",
      "189    M\n",
      "50     R\n",
      "176    M\n",
      "207    M\n",
      "128    M\n",
      "141    M\n",
      "93     R\n",
      "195    M\n",
      "201    M\n",
      "131    M\n",
      "143    M\n",
      "41     R\n",
      "140    M\n",
      "206    M\n",
      "118    M\n",
      "106    M\n",
      "88     R\n",
      "104    M\n",
      "Name: 60, dtype: object], [4, 97     M\n",
      "34     R\n",
      "51     R\n",
      "115    M\n",
      "192    M\n",
      "193    M\n",
      "63     R\n",
      "18     R\n",
      "36     R\n",
      "91     R\n",
      "148    M\n",
      "184    M\n",
      "182    M\n",
      "153    M\n",
      "2      R\n",
      "159    M\n",
      "202    M\n",
      "81     R\n",
      "21     R\n",
      "177    M\n",
      "89     R\n",
      "181    M\n",
      "166    M\n",
      "187    M\n",
      "137    M\n",
      "196    M\n",
      "12     R\n",
      "29     R\n",
      "71     R\n",
      "123    M\n",
      "80     R\n",
      "129    M\n",
      "90     R\n",
      "56     R\n",
      "122    M\n",
      "22     R\n",
      "27     R\n",
      "26     R\n",
      "126    M\n",
      "105    M\n",
      "198    M\n",
      "125    M\n",
      "190    M\n",
      "61     R\n",
      "40     R\n",
      "101    M\n",
      "145    M\n",
      "135    M\n",
      "111    M\n",
      "155    M\n",
      "42     R\n",
      "108    M\n",
      "Name: 60, dtype: object], [5, 133    M\n",
      "7      R\n",
      "117    M\n",
      "37     R\n",
      "169    M\n",
      "58     R\n",
      "77     R\n",
      "75     R\n",
      "107    M\n",
      "98     M\n",
      "110    M\n",
      "14     R\n",
      "24     R\n",
      "162    M\n",
      "114    M\n",
      "103    M\n",
      "163    M\n",
      "83     R\n",
      "120    M\n",
      "173    M\n",
      "11     R\n",
      "112    M\n",
      "57     R\n",
      "199    M\n",
      "170    M\n",
      "72     R\n",
      "191    M\n",
      "180    M\n",
      "49     R\n",
      "168    M\n",
      "178    M\n",
      "127    M\n",
      "147    M\n",
      "6      R\n",
      "200    M\n",
      "31     R\n",
      "48     R\n",
      "67     R\n",
      "44     R\n",
      "38     R\n",
      "109    M\n",
      "5      R\n",
      "0      R\n",
      "92     R\n",
      "43     R\n",
      "161    M\n",
      "130    M\n",
      "119    M\n",
      "25     R\n",
      "10     R\n",
      "52     R\n",
      "79     R\n",
      "Name: 60, dtype: object], [5, 183    M\n",
      "150    M\n",
      "116    M\n",
      "95     R\n",
      "64     R\n",
      "3      R\n",
      "13     R\n",
      "86     R\n",
      "164    M\n",
      "174    M\n",
      "96     R\n",
      "65     R\n",
      "82     R\n",
      "32     R\n",
      "8      R\n",
      "152    M\n",
      "70     R\n",
      "100    M\n",
      "94     R\n",
      "69     R\n",
      "76     R\n",
      "16     R\n",
      "99     M\n",
      "30     R\n",
      "156    M\n",
      "23     R\n",
      "132    M\n",
      "55     R\n",
      "33     R\n",
      "87     R\n",
      "188    M\n",
      "204    M\n",
      "1      R\n",
      "186    M\n",
      "189    M\n",
      "50     R\n",
      "176    M\n",
      "207    M\n",
      "128    M\n",
      "141    M\n",
      "93     R\n",
      "195    M\n",
      "201    M\n",
      "131    M\n",
      "143    M\n",
      "41     R\n",
      "140    M\n",
      "206    M\n",
      "118    M\n",
      "106    M\n",
      "88     R\n",
      "104    M\n",
      "Name: 60, dtype: object], [5, 97     M\n",
      "34     R\n",
      "51     R\n",
      "115    M\n",
      "192    M\n",
      "193    M\n",
      "63     R\n",
      "18     R\n",
      "36     R\n",
      "91     R\n",
      "148    M\n",
      "184    M\n",
      "182    M\n",
      "153    M\n",
      "2      R\n",
      "159    M\n",
      "202    M\n",
      "81     R\n",
      "21     R\n",
      "177    M\n",
      "89     R\n",
      "181    M\n",
      "166    M\n",
      "187    M\n",
      "137    M\n",
      "196    M\n",
      "12     R\n",
      "29     R\n",
      "71     R\n",
      "123    M\n",
      "80     R\n",
      "129    M\n",
      "90     R\n",
      "56     R\n",
      "122    M\n",
      "22     R\n",
      "27     R\n",
      "26     R\n",
      "126    M\n",
      "105    M\n",
      "198    M\n",
      "125    M\n",
      "190    M\n",
      "61     R\n",
      "40     R\n",
      "101    M\n",
      "145    M\n",
      "135    M\n",
      "111    M\n",
      "155    M\n",
      "42     R\n",
      "108    M\n",
      "Name: 60, dtype: object], [6, 133    M\n",
      "7      R\n",
      "117    M\n",
      "37     R\n",
      "169    M\n",
      "58     R\n",
      "77     R\n",
      "75     R\n",
      "107    M\n",
      "98     M\n",
      "110    M\n",
      "14     R\n",
      "24     R\n",
      "162    M\n",
      "114    M\n",
      "103    M\n",
      "163    M\n",
      "83     R\n",
      "120    M\n",
      "173    M\n",
      "11     R\n",
      "112    M\n",
      "57     R\n",
      "199    M\n",
      "170    M\n",
      "72     R\n",
      "191    M\n",
      "180    M\n",
      "49     R\n",
      "168    M\n",
      "178    M\n",
      "127    M\n",
      "147    M\n",
      "6      R\n",
      "200    M\n",
      "31     R\n",
      "48     R\n",
      "67     R\n",
      "44     R\n",
      "38     R\n",
      "109    M\n",
      "5      R\n",
      "0      R\n",
      "92     R\n",
      "43     R\n",
      "161    M\n",
      "130    M\n",
      "119    M\n",
      "25     R\n",
      "10     R\n",
      "52     R\n",
      "79     R\n",
      "Name: 60, dtype: object], [6, 183    M\n",
      "150    M\n",
      "116    M\n",
      "95     R\n",
      "64     R\n",
      "3      R\n",
      "13     R\n",
      "86     R\n",
      "164    M\n",
      "174    M\n",
      "96     R\n",
      "65     R\n",
      "82     R\n",
      "32     R\n",
      "8      R\n",
      "152    M\n",
      "70     R\n",
      "100    M\n",
      "94     R\n",
      "69     R\n",
      "76     R\n",
      "16     R\n",
      "99     M\n",
      "30     R\n",
      "156    M\n",
      "23     R\n",
      "132    M\n",
      "55     R\n",
      "33     R\n",
      "87     R\n",
      "188    M\n",
      "204    M\n",
      "1      R\n",
      "186    M\n",
      "189    M\n",
      "50     R\n",
      "176    M\n",
      "207    M\n",
      "128    M\n",
      "141    M\n",
      "93     R\n",
      "195    M\n",
      "201    M\n",
      "131    M\n",
      "143    M\n",
      "41     R\n",
      "140    M\n",
      "206    M\n",
      "118    M\n",
      "106    M\n",
      "88     R\n",
      "104    M\n",
      "Name: 60, dtype: object], [6, 97     M\n",
      "34     R\n",
      "51     R\n",
      "115    M\n",
      "192    M\n",
      "193    M\n",
      "63     R\n",
      "18     R\n",
      "36     R\n",
      "91     R\n",
      "148    M\n",
      "184    M\n",
      "182    M\n",
      "153    M\n",
      "2      R\n",
      "159    M\n",
      "202    M\n",
      "81     R\n",
      "21     R\n",
      "177    M\n",
      "89     R\n",
      "181    M\n",
      "166    M\n",
      "187    M\n",
      "137    M\n",
      "196    M\n",
      "12     R\n",
      "29     R\n",
      "71     R\n",
      "123    M\n",
      "80     R\n",
      "129    M\n",
      "90     R\n",
      "56     R\n",
      "122    M\n",
      "22     R\n",
      "27     R\n",
      "26     R\n",
      "126    M\n",
      "105    M\n",
      "198    M\n",
      "125    M\n",
      "190    M\n",
      "61     R\n",
      "40     R\n",
      "101    M\n",
      "145    M\n",
      "135    M\n",
      "111    M\n",
      "155    M\n",
      "42     R\n",
      "108    M\n",
      "Name: 60, dtype: object], [7, 133    M\n",
      "7      R\n",
      "117    M\n",
      "37     R\n",
      "169    M\n",
      "58     R\n",
      "77     R\n",
      "75     R\n",
      "107    M\n",
      "98     M\n",
      "110    M\n",
      "14     R\n",
      "24     R\n",
      "162    M\n",
      "114    M\n",
      "103    M\n",
      "163    M\n",
      "83     R\n",
      "120    M\n",
      "173    M\n",
      "11     R\n",
      "112    M\n",
      "57     R\n",
      "199    M\n",
      "170    M\n",
      "72     R\n",
      "191    M\n",
      "180    M\n",
      "49     R\n",
      "168    M\n",
      "178    M\n",
      "127    M\n",
      "147    M\n",
      "6      R\n",
      "200    M\n",
      "31     R\n",
      "48     R\n",
      "67     R\n",
      "44     R\n",
      "38     R\n",
      "109    M\n",
      "5      R\n",
      "0      R\n",
      "92     R\n",
      "43     R\n",
      "161    M\n",
      "130    M\n",
      "119    M\n",
      "25     R\n",
      "10     R\n",
      "52     R\n",
      "79     R\n",
      "Name: 60, dtype: object], [7, 183    M\n",
      "150    M\n",
      "116    M\n",
      "95     R\n",
      "64     R\n",
      "3      R\n",
      "13     R\n",
      "86     R\n",
      "164    M\n",
      "174    M\n",
      "96     R\n",
      "65     R\n",
      "82     R\n",
      "32     R\n",
      "8      R\n",
      "152    M\n",
      "70     R\n",
      "100    M\n",
      "94     R\n",
      "69     R\n",
      "76     R\n",
      "16     R\n",
      "99     M\n",
      "30     R\n",
      "156    M\n",
      "23     R\n",
      "132    M\n",
      "55     R\n",
      "33     R\n",
      "87     R\n",
      "188    M\n",
      "204    M\n",
      "1      R\n",
      "186    M\n",
      "189    M\n",
      "50     R\n",
      "176    M\n",
      "207    M\n",
      "128    M\n",
      "141    M\n",
      "93     R\n",
      "195    M\n",
      "201    M\n",
      "131    M\n",
      "143    M\n",
      "41     R\n",
      "140    M\n",
      "206    M\n",
      "118    M\n",
      "106    M\n",
      "88     R\n",
      "104    M\n",
      "Name: 60, dtype: object], [7, 97     M\n",
      "34     R\n",
      "51     R\n",
      "115    M\n",
      "192    M\n",
      "193    M\n",
      "63     R\n",
      "18     R\n",
      "36     R\n",
      "91     R\n",
      "148    M\n",
      "184    M\n",
      "182    M\n",
      "153    M\n",
      "2      R\n",
      "159    M\n",
      "202    M\n",
      "81     R\n",
      "21     R\n",
      "177    M\n",
      "89     R\n",
      "181    M\n",
      "166    M\n",
      "187    M\n",
      "137    M\n",
      "196    M\n",
      "12     R\n",
      "29     R\n",
      "71     R\n",
      "123    M\n",
      "80     R\n",
      "129    M\n",
      "90     R\n",
      "56     R\n",
      "122    M\n",
      "22     R\n",
      "27     R\n",
      "26     R\n",
      "126    M\n",
      "105    M\n",
      "198    M\n",
      "125    M\n",
      "190    M\n",
      "61     R\n",
      "40     R\n",
      "101    M\n",
      "145    M\n",
      "135    M\n",
      "111    M\n",
      "155    M\n",
      "42     R\n",
      "108    M\n",
      "Name: 60, dtype: object], [8, 133    M\n",
      "7      R\n",
      "117    M\n",
      "37     R\n",
      "169    M\n",
      "58     R\n",
      "77     R\n",
      "75     R\n",
      "107    M\n",
      "98     M\n",
      "110    M\n",
      "14     R\n",
      "24     R\n",
      "162    M\n",
      "114    M\n",
      "103    M\n",
      "163    M\n",
      "83     R\n",
      "120    M\n",
      "173    M\n",
      "11     R\n",
      "112    M\n",
      "57     R\n",
      "199    M\n",
      "170    M\n",
      "72     R\n",
      "191    M\n",
      "180    M\n",
      "49     R\n",
      "168    M\n",
      "178    M\n",
      "127    M\n",
      "147    M\n",
      "6      R\n",
      "200    M\n",
      "31     R\n",
      "48     R\n",
      "67     R\n",
      "44     R\n",
      "38     R\n",
      "109    M\n",
      "5      R\n",
      "0      R\n",
      "92     R\n",
      "43     R\n",
      "161    M\n",
      "130    M\n",
      "119    M\n",
      "25     R\n",
      "10     R\n",
      "52     R\n",
      "79     R\n",
      "Name: 60, dtype: object], [8, 183    M\n",
      "150    M\n",
      "116    M\n",
      "95     R\n",
      "64     R\n",
      "3      R\n",
      "13     R\n",
      "86     R\n",
      "164    M\n",
      "174    M\n",
      "96     R\n",
      "65     R\n",
      "82     R\n",
      "32     R\n",
      "8      R\n",
      "152    M\n",
      "70     R\n",
      "100    M\n",
      "94     R\n",
      "69     R\n",
      "76     R\n",
      "16     R\n",
      "99     M\n",
      "30     R\n",
      "156    M\n",
      "23     R\n",
      "132    M\n",
      "55     R\n",
      "33     R\n",
      "87     R\n",
      "188    M\n",
      "204    M\n",
      "1      R\n",
      "186    M\n",
      "189    M\n",
      "50     R\n",
      "176    M\n",
      "207    M\n",
      "128    M\n",
      "141    M\n",
      "93     R\n",
      "195    M\n",
      "201    M\n",
      "131    M\n",
      "143    M\n",
      "41     R\n",
      "140    M\n",
      "206    M\n",
      "118    M\n",
      "106    M\n",
      "88     R\n",
      "104    M\n",
      "Name: 60, dtype: object], [8, 97     M\n",
      "34     R\n",
      "51     R\n",
      "115    M\n",
      "192    M\n",
      "193    M\n",
      "63     R\n",
      "18     R\n",
      "36     R\n",
      "91     R\n",
      "148    M\n",
      "184    M\n",
      "182    M\n",
      "153    M\n",
      "2      R\n",
      "159    M\n",
      "202    M\n",
      "81     R\n",
      "21     R\n",
      "177    M\n",
      "89     R\n",
      "181    M\n",
      "166    M\n",
      "187    M\n",
      "137    M\n",
      "196    M\n",
      "12     R\n",
      "29     R\n",
      "71     R\n",
      "123    M\n",
      "80     R\n",
      "129    M\n",
      "90     R\n",
      "56     R\n",
      "122    M\n",
      "22     R\n",
      "27     R\n",
      "26     R\n",
      "126    M\n",
      "105    M\n",
      "198    M\n",
      "125    M\n",
      "190    M\n",
      "61     R\n",
      "40     R\n",
      "101    M\n",
      "145    M\n",
      "135    M\n",
      "111    M\n",
      "155    M\n",
      "42     R\n",
      "108    M\n",
      "Name: 60, dtype: object], [9, 133    M\n",
      "7      R\n",
      "117    M\n",
      "37     R\n",
      "169    M\n",
      "58     R\n",
      "77     R\n",
      "75     R\n",
      "107    M\n",
      "98     M\n",
      "110    M\n",
      "14     R\n",
      "24     R\n",
      "162    M\n",
      "114    M\n",
      "103    M\n",
      "163    M\n",
      "83     R\n",
      "120    M\n",
      "173    M\n",
      "11     R\n",
      "112    M\n",
      "57     R\n",
      "199    M\n",
      "170    M\n",
      "72     R\n",
      "191    M\n",
      "180    M\n",
      "49     R\n",
      "168    M\n",
      "178    M\n",
      "127    M\n",
      "147    M\n",
      "6      R\n",
      "200    M\n",
      "31     R\n",
      "48     R\n",
      "67     R\n",
      "44     R\n",
      "38     R\n",
      "109    M\n",
      "5      R\n",
      "0      R\n",
      "92     R\n",
      "43     R\n",
      "161    M\n",
      "130    M\n",
      "119    M\n",
      "25     R\n",
      "10     R\n",
      "52     R\n",
      "79     R\n",
      "Name: 60, dtype: object], [9, 183    M\n",
      "150    M\n",
      "116    M\n",
      "95     R\n",
      "64     R\n",
      "3      R\n",
      "13     R\n",
      "86     R\n",
      "164    M\n",
      "174    M\n",
      "96     R\n",
      "65     R\n",
      "82     R\n",
      "32     R\n",
      "8      R\n",
      "152    M\n",
      "70     R\n",
      "100    M\n",
      "94     R\n",
      "69     R\n",
      "76     R\n",
      "16     R\n",
      "99     M\n",
      "30     R\n",
      "156    M\n",
      "23     R\n",
      "132    M\n",
      "55     R\n",
      "33     R\n",
      "87     R\n",
      "188    M\n",
      "204    M\n",
      "1      R\n",
      "186    M\n",
      "189    M\n",
      "50     R\n",
      "176    M\n",
      "207    M\n",
      "128    M\n",
      "141    M\n",
      "93     R\n",
      "195    M\n",
      "201    M\n",
      "131    M\n",
      "143    M\n",
      "41     R\n",
      "140    M\n",
      "206    M\n",
      "118    M\n",
      "106    M\n",
      "88     R\n",
      "104    M\n",
      "Name: 60, dtype: object], [9, 97     M\n",
      "34     R\n",
      "51     R\n",
      "115    M\n",
      "192    M\n",
      "193    M\n",
      "63     R\n",
      "18     R\n",
      "36     R\n",
      "91     R\n",
      "148    M\n",
      "184    M\n",
      "182    M\n",
      "153    M\n",
      "2      R\n",
      "159    M\n",
      "202    M\n",
      "81     R\n",
      "21     R\n",
      "177    M\n",
      "89     R\n",
      "181    M\n",
      "166    M\n",
      "187    M\n",
      "137    M\n",
      "196    M\n",
      "12     R\n",
      "29     R\n",
      "71     R\n",
      "123    M\n",
      "80     R\n",
      "129    M\n",
      "90     R\n",
      "56     R\n",
      "122    M\n",
      "22     R\n",
      "27     R\n",
      "26     R\n",
      "126    M\n",
      "105    M\n",
      "198    M\n",
      "125    M\n",
      "190    M\n",
      "61     R\n",
      "40     R\n",
      "101    M\n",
      "145    M\n",
      "135    M\n",
      "111    M\n",
      "155    M\n",
      "42     R\n",
      "108    M\n",
      "Name: 60, dtype: object]]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testset, predictions):\n",
    "    correct = 0\n",
    "    for id_test, test in enumerate(testset):\n",
    "        if test == predictions[id_test]:\n",
    "            correct += 1\n",
    "    return (correct / float(len(testset))) * 100.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def printCM(Y_test, predictions):\n",
    "    cm = confusion_matrix(Y_test, predictions)\n",
    "    print ('Confusion Matrix : ')\n",
    "    print (cm)\n",
    "    print\n",
    "    tn = float(cm[0][0])\n",
    "    fp = float(cm[0][1])\n",
    "    fn = float(cm[1][0])\n",
    "    tp = float(cm[1][1])\n",
    "\n",
    "    actual_yes = fn+tp\n",
    "    actual_no = tn+fp\n",
    "    predicted_yes = fp+tp\n",
    "    predicted_no = tn+fn\n",
    "\n",
    "    total = float(len(imported_data))\n",
    "    print ('Total : '+ str(total))\n",
    "\n",
    "    print ('Acurácia : ' + str(getAccuracy(Y_test, predictions)))\n",
    "\n",
    "    misclassification_rate = round((fp+fn)/total,3) # Overall, how often is it wrong?\n",
    "    print ('Misclassification rate : ' +str(misclassification_rate))\n",
    "\n",
    "    true_positive = round(tp/actual_yes,3) # When it's actually yes, how often does it predict yes?\n",
    "    print ('True positives : ' +str(true_positive))\n",
    "\n",
    "    false_positive = round(fp/actual_no,3) # When it's actually no, how often does it predict yes?\n",
    "    print ('False positives : ' +str(false_positive))\n",
    "\n",
    "    specificity = round(tn/actual_no,3) # When it's actually no, how often does it predict no?\n",
    "    print ('Specificity : ' +str(specificity))\n",
    "\n",
    "    #precision = round(tp/predicted_yes,3) # When it predicts yes, how often is it correct?\n",
    "    #print ('Precision : ' +str(precision))\n",
    "\n",
    "    prevalence = round(actual_yes/total,3) # How often does the yes condition actually occur in our sample?\n",
    "    print ('Prevalence : ' +str(prevalence))\n",
    "\n",
    "    #f1 = round(2 * ((precision * true_positive) / (precision + true_positive)),3)\n",
    "    #print ('F1 Score : ' +str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-bcfc512dd5bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha_m\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_train_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "zip(pred_train, [x * alpha_m for x in pred_train_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
