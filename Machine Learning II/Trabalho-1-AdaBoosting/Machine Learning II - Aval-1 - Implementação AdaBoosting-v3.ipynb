{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 1 - Machine Learning II \n",
    "Prof: Carlos Padilha\n",
    "\n",
    "#### Alunos:  \n",
    "\n",
    "Roberto A. Coutinho  \n",
    "Thais Galho\n",
    "\n",
    "\n",
    "## Sistemas com Multi-classificadores ou Ensembles\n",
    "\n",
    "#### Este trabalho visa avaliar o entendimento em relaçãao á construção de sistemas com multi-classificadores ou ensembles. Para tal, os alunos deverão fazer o seguinte:\n",
    "\n",
    "\n",
    "* Implementar o algoritmo AdaBoost (nos mesmos moldes que fizemos com o algoritmo Bagging).\n",
    "    – Podem escolher qualquer tipo de classificador (MLP, SVM, etc).\n",
    "* Processar os dados presente no arquivo sonar.all-data.\n",
    "* Realizar treinamento e teste usando validação cruzada com 10 folds.\n",
    "* Avaliar os resultados em termos de acurácia, recall e precisão.\n",
    "\n",
    "Obs: O trabalho pode ser feito em dupla e deve ser enviado por email (carlos.engcomp@gmail.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modelos\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# K-fold CrossValidation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.0709</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.1918</td>\n",
       "      <td>0.3362</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1088</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.1948</td>\n",
       "      <td>0.4262</td>\n",
       "      <td>0.6828</td>\n",
       "      <td>0.5761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.1606</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.3061</td>\n",
       "      <td>0.2936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.1117</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.0997</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.2227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>0.1693</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.1583</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0477</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.1664</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.0804</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.1117</td>\n",
       "      <td>0.2984</td>\n",
       "      <td>0.3473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0578</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.0873</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.1563</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.2002</td>\n",
       "      <td>0.2876</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.1997</td>\n",
       "      <td>0.2604</td>\n",
       "      <td>0.3225</td>\n",
       "      <td>0.2247</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.2287</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.0740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0724</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.2103</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.2524</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.1163</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.2417</td>\n",
       "      <td>0.2661</td>\n",
       "      <td>0.4346</td>\n",
       "      <td>0.5378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.1972</td>\n",
       "      <td>0.1873</td>\n",
       "      <td>0.1806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.1627</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>0.2696</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.1048</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.0780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1058</td>\n",
       "      <td>0.1023</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.1795</td>\n",
       "      <td>0.1909</td>\n",
       "      <td>0.1692</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.1725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0654</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>0.2482</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.0989</td>\n",
       "      <td>0.2460</td>\n",
       "      <td>0.3422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.1493</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.1977</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.0759</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.1883</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.0554</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.2707</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>0.4117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.1161</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.1738</td>\n",
       "      <td>0.1351</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>0.3887</td>\n",
       "      <td>0.7106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0507</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.3823</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>0.3429</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.1515</td>\n",
       "      <td>0.2134</td>\n",
       "      <td>0.2613</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.2718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.0989</td>\n",
       "      <td>0.1093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.1164</td>\n",
       "      <td>0.1398</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.2795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.2770</td>\n",
       "      <td>0.2555</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.4110</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.5920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1384</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.0962</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1409</td>\n",
       "      <td>0.1916</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6       7       8   \\\n",
       "0   0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "1   0.0635  0.0709  0.0453  0.0333  0.0185  0.1260  0.1015  0.1918  0.3362   \n",
       "2   0.1088  0.1278  0.0926  0.1234  0.1276  0.1731  0.1948  0.4262  0.6828   \n",
       "3   0.0107  0.0453  0.0289  0.0713  0.1075  0.1019  0.1606  0.2119  0.3061   \n",
       "4   0.0228  0.0106  0.0130  0.0842  0.1117  0.1506  0.1776  0.0997  0.1428   \n",
       "5   0.0707  0.1252  0.1447  0.1644  0.1693  0.0844  0.0715  0.0947  0.1583   \n",
       "6   0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "7   0.0442  0.0477  0.0049  0.0581  0.0278  0.0678  0.1664  0.1490  0.0974   \n",
       "8   0.0336  0.0294  0.0476  0.0539  0.0794  0.0804  0.1136  0.1228  0.1235   \n",
       "9   0.0294  0.0123  0.0117  0.0113  0.0497  0.0998  0.1326  0.1117  0.2984   \n",
       "10  0.0197  0.0394  0.0384  0.0076  0.0251  0.0629  0.0747  0.0578  0.1357   \n",
       "11  0.0125  0.0152  0.0218  0.0175  0.0362  0.0696  0.0873  0.0616  0.1252   \n",
       "12  0.0211  0.0128  0.0015  0.0450  0.0711  0.1563  0.1518  0.1206  0.1666   \n",
       "13  0.0235  0.0291  0.0749  0.0519  0.0227  0.0834  0.0677  0.2002  0.2876   \n",
       "14  0.0530  0.0885  0.1997  0.2604  0.3225  0.2247  0.0617  0.2287  0.0950   \n",
       "15  0.0201  0.0178  0.0274  0.0232  0.0724  0.0833  0.1232  0.1298  0.2085   \n",
       "16  0.0269  0.0383  0.0505  0.0707  0.1313  0.2103  0.2263  0.2524  0.3595   \n",
       "17  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "18  0.1150  0.1163  0.0866  0.0358  0.0232  0.1267  0.2417  0.2661  0.4346   \n",
       "19  0.0188  0.0370  0.0953  0.0824  0.0249  0.0488  0.1424  0.1972  0.1873   \n",
       "20  0.0299  0.0688  0.0992  0.1021  0.0800  0.0629  0.0130  0.0813  0.1761   \n",
       "21  0.0100  0.0194  0.0155  0.0489  0.0839  0.1009  0.1627  0.2071  0.2696   \n",
       "22  0.0164  0.0627  0.0738  0.0608  0.0233  0.1048  0.1338  0.0644  0.1522   \n",
       "23  0.0115  0.0150  0.0136  0.0076  0.0211  0.1058  0.1023  0.0440  0.0931   \n",
       "24  0.0094  0.0333  0.0306  0.0376  0.1296  0.1795  0.1909  0.1692  0.1870   \n",
       "25  0.0654  0.0649  0.0737  0.1132  0.2482  0.1257  0.1797  0.0989  0.2460   \n",
       "26  0.0454  0.0472  0.0697  0.1021  0.1397  0.1493  0.1487  0.0771  0.1171   \n",
       "27  0.0050  0.0017  0.0270  0.0450  0.0958  0.0830  0.0879  0.1220  0.1977   \n",
       "28  0.0333  0.0221  0.0270  0.0481  0.0679  0.0981  0.0843  0.1172  0.0759   \n",
       "29  0.0119  0.0582  0.0623  0.0600  0.1397  0.1883  0.1422  0.1447  0.0487   \n",
       "30  0.0201  0.0423  0.0554  0.0783  0.0620  0.0871  0.1201  0.2707  0.1206   \n",
       "31  0.0340  0.0625  0.0381  0.0257  0.0441  0.1027  0.1287  0.1850  0.2647   \n",
       "32  0.0353  0.0713  0.0326  0.0272  0.0370  0.0792  0.1083  0.0687  0.0298   \n",
       "33  0.0368  0.0403  0.0317  0.0293  0.0820  0.1342  0.1161  0.0663  0.0155   \n",
       "34  0.0231  0.0351  0.0030  0.0304  0.0339  0.0860  0.1738  0.1351  0.1063   \n",
       "35  0.0430  0.0902  0.0833  0.0813  0.0165  0.0277  0.0569  0.2057  0.3887   \n",
       "36  0.0253  0.0808  0.0507  0.0244  0.1724  0.3823  0.3729  0.3583  0.3429   \n",
       "37  0.0311  0.0491  0.0692  0.0831  0.0079  0.0200  0.0981  0.1016  0.2025   \n",
       "38  0.0388  0.0324  0.0688  0.0898  0.1267  0.1515  0.2134  0.2613  0.2832   \n",
       "39  0.0208  0.0186  0.0131  0.0211  0.0610  0.0613  0.0612  0.0506  0.0989   \n",
       "40  0.0217  0.0340  0.0392  0.0236  0.1081  0.1164  0.1398  0.1009  0.1147   \n",
       "41  0.0308  0.0339  0.0202  0.0889  0.1570  0.1750  0.0920  0.1353  0.1593   \n",
       "42  0.0731  0.1249  0.1665  0.1496  0.1443  0.2770  0.2555  0.1712  0.0466   \n",
       "43  0.0126  0.0149  0.0641  0.1732  0.2565  0.2559  0.2947  0.4110  0.4983   \n",
       "44  0.0526  0.0563  0.1219  0.1206  0.0246  0.1022  0.0539  0.0439  0.2291   \n",
       "45  0.0260  0.0192  0.0254  0.0061  0.0352  0.0701  0.1263  0.1080  0.1523   \n",
       "46  0.0239  0.0189  0.0466  0.0440  0.0657  0.0742  0.1380  0.1099  0.1384   \n",
       "47  0.0164  0.0173  0.0347  0.0070  0.0187  0.0671  0.1056  0.0697  0.0962   \n",
       "48  0.0363  0.0478  0.0298  0.0210  0.1409  0.1916  0.1349  0.1613  0.1703   \n",
       "49  0.0109  0.0093  0.0121  0.0378  0.0679  0.0863  0.1004  0.0664  0.0941   \n",
       "\n",
       "        9  ...      51      52      53      54      55      56      57  \\\n",
       "0   0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "1   0.3900 ...  0.0048  0.0025  0.0087  0.0072  0.0095  0.0086  0.0085   \n",
       "2   0.5761 ...  0.0455  0.0213  0.0082  0.0124  0.0167  0.0103  0.0205   \n",
       "3   0.2936 ...  0.0164  0.0120  0.0113  0.0021  0.0097  0.0072  0.0060   \n",
       "4   0.2227 ...  0.0098  0.0178  0.0077  0.0074  0.0095  0.0055  0.0045   \n",
       "5   0.1247 ...  0.0156  0.0197  0.0135  0.0127  0.0138  0.0133  0.0131   \n",
       "6   0.2154 ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "7   0.1268 ...  0.0204  0.0216  0.0135  0.0055  0.0073  0.0080  0.0105   \n",
       "8   0.0842 ...  0.0150  0.0111  0.0032  0.0035  0.0169  0.0137  0.0015   \n",
       "9   0.3473 ...  0.0056  0.0104  0.0079  0.0014  0.0054  0.0015  0.0006   \n",
       "10  0.1695 ...  0.0134  0.0097  0.0042  0.0058  0.0072  0.0041  0.0045   \n",
       "11  0.1302 ...  0.0041  0.0074  0.0030  0.0050  0.0048  0.0017  0.0041   \n",
       "12  0.1345 ...  0.0117  0.0023  0.0047  0.0049  0.0031  0.0024  0.0039   \n",
       "13  0.3674 ...  0.0083  0.0037  0.0095  0.0105  0.0030  0.0132  0.0068   \n",
       "14  0.0740 ...  0.0244  0.0199  0.0257  0.0082  0.0151  0.0171  0.0146   \n",
       "15  0.2720 ...  0.0131  0.0049  0.0104  0.0102  0.0092  0.0083  0.0020   \n",
       "16  0.5915 ...  0.0167  0.0199  0.0145  0.0081  0.0045  0.0043  0.0027   \n",
       "17  0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "18  0.5378 ...  0.0099  0.0065  0.0085  0.0166  0.0110  0.0190  0.0141   \n",
       "19  0.1806 ...  0.0093  0.0033  0.0113  0.0030  0.0057  0.0090  0.0057   \n",
       "20  0.0998 ...  0.0459  0.0277  0.0172  0.0087  0.0046  0.0203  0.0130   \n",
       "21  0.2990 ...  0.0130  0.0073  0.0077  0.0075  0.0060  0.0080  0.0019   \n",
       "22  0.0780 ...  0.0258  0.0143  0.0226  0.0187  0.0185  0.0110  0.0094   \n",
       "23  0.0734 ...  0.0091  0.0016  0.0084  0.0064  0.0026  0.0029  0.0037   \n",
       "24  0.1725 ...  0.0153  0.0112  0.0241  0.0164  0.0055  0.0078  0.0055   \n",
       "25  0.3422 ...  0.0210  0.0361  0.0239  0.0447  0.0394  0.0355  0.0440   \n",
       "26  0.1675 ...  0.0120  0.0042  0.0238  0.0129  0.0084  0.0218  0.0321   \n",
       "27  0.2282 ...  0.0165  0.0056  0.0010  0.0027  0.0062  0.0024  0.0063   \n",
       "28  0.0920 ...  0.0022  0.0032  0.0060  0.0054  0.0063  0.0143  0.0132   \n",
       "29  0.0864 ...  0.0025  0.0103  0.0074  0.0123  0.0069  0.0076  0.0073   \n",
       "30  0.0279 ...  0.0191  0.0182  0.0160  0.0290  0.0090  0.0242  0.0224   \n",
       "31  0.4117 ...  0.0141  0.0019  0.0067  0.0099  0.0042  0.0057  0.0051   \n",
       "32  0.0880 ...  0.0163  0.0242  0.0043  0.0202  0.0108  0.0037  0.0096   \n",
       "33  0.0506 ...  0.0091  0.0160  0.0160  0.0081  0.0070  0.0135  0.0067   \n",
       "34  0.0347 ...  0.0106  0.0097  0.0022  0.0052  0.0072  0.0056  0.0038   \n",
       "35  0.7106 ...  0.0176  0.0197  0.0210  0.0141  0.0049  0.0027  0.0162   \n",
       "36  0.2197 ...  0.0178  0.0073  0.0079  0.0038  0.0116  0.0033  0.0039   \n",
       "37  0.0767 ...  0.0087  0.0032  0.0130  0.0188  0.0101  0.0229  0.0182   \n",
       "38  0.2718 ...  0.0255  0.0071  0.0263  0.0079  0.0111  0.0107  0.0068   \n",
       "39  0.1093 ...  0.0074  0.0063  0.0081  0.0087  0.0044  0.0028  0.0019   \n",
       "40  0.1777 ...  0.0031  0.0103  0.0078  0.0077  0.0094  0.0031  0.0030   \n",
       "41  0.2795 ...  0.0167  0.0127  0.0138  0.0090  0.0051  0.0029  0.0122   \n",
       "42  0.1114 ...  0.0444  0.0230  0.0290  0.0141  0.0161  0.0177  0.0194   \n",
       "43  0.5920 ...  0.0092  0.0035  0.0098  0.0121  0.0006  0.0181  0.0094   \n",
       "44  0.1632 ...  0.0339  0.0149  0.0335  0.0376  0.0174  0.0132  0.0103   \n",
       "45  0.1630 ...  0.0118  0.0120  0.0051  0.0070  0.0015  0.0035  0.0008   \n",
       "46  0.1376 ...  0.0091  0.0151  0.0080  0.0018  0.0078  0.0045  0.0026   \n",
       "47  0.0251 ...  0.0090  0.0223  0.0179  0.0084  0.0068  0.0032  0.0035   \n",
       "48  0.1444 ...  0.0115  0.0190  0.0055  0.0096  0.0050  0.0066  0.0114   \n",
       "49  0.1036 ...  0.0077  0.0023  0.0117  0.0053  0.0077  0.0076  0.0056   \n",
       "\n",
       "        58      59  60  \n",
       "0   0.0040  0.0117   1  \n",
       "1   0.0040  0.0051   0  \n",
       "2   0.0178  0.0187   0  \n",
       "3   0.0017  0.0036   0  \n",
       "4   0.0063  0.0039   0  \n",
       "5   0.0154  0.0218   0  \n",
       "6   0.0062  0.0067   0  \n",
       "7   0.0059  0.0105   1  \n",
       "8   0.0069  0.0051   1  \n",
       "9   0.0081  0.0043   0  \n",
       "10  0.0047  0.0054   0  \n",
       "11  0.0086  0.0058   1  \n",
       "12  0.0051  0.0015   0  \n",
       "13  0.0108  0.0090   1  \n",
       "14  0.0134  0.0056   0  \n",
       "15  0.0048  0.0036   0  \n",
       "16  0.0055  0.0057   0  \n",
       "17  0.0090  0.0032   1  \n",
       "18  0.0068  0.0086   0  \n",
       "19  0.0068  0.0024   1  \n",
       "20  0.0115  0.0015   0  \n",
       "21  0.0053  0.0019   1  \n",
       "22  0.0078  0.0112   0  \n",
       "23  0.0070  0.0041   1  \n",
       "24  0.0091  0.0067   0  \n",
       "25  0.0243  0.0098   0  \n",
       "26  0.0154  0.0053   0  \n",
       "27  0.0017  0.0028   0  \n",
       "28  0.0051  0.0041   1  \n",
       "29  0.0030  0.0138   1  \n",
       "30  0.0190  0.0096   0  \n",
       "31  0.0033  0.0058   0  \n",
       "32  0.0093  0.0053   1  \n",
       "33  0.0078  0.0068   1  \n",
       "34  0.0043  0.0030   1  \n",
       "35  0.0059  0.0021   0  \n",
       "36  0.0081  0.0053   1  \n",
       "37  0.0046  0.0038   1  \n",
       "38  0.0097  0.0067   0  \n",
       "39  0.0049  0.0023   1  \n",
       "40  0.0013  0.0069   1  \n",
       "41  0.0056  0.0020   1  \n",
       "42  0.0207  0.0057   0  \n",
       "43  0.0116  0.0063   1  \n",
       "44  0.0364  0.0208   0  \n",
       "45  0.0044  0.0077   1  \n",
       "46  0.0036  0.0024   1  \n",
       "47  0.0056  0.0040   1  \n",
       "48  0.0073  0.0033   0  \n",
       "49  0.0055  0.0039   1  \n",
       "\n",
       "[50 rows x 61 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_data = pd.read_csv('sonar.all-data.csv', header=None)\n",
    "\n",
    "imported_data.iloc[:,-1] = imported_data.iloc[:,-1].astype('category')\n",
    "categories = imported_data.select_dtypes(['category']).columns\n",
    "imported_data[categories] = imported_data[categories].apply(lambda x:x.cat.codes) \n",
    "\n",
    "imported_data = imported_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "imported_data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 208)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# Separação entre dados e labels\n",
    "\n",
    "labels = imported_data.iloc[:,-1]\n",
    "\n",
    "data = imported_data.iloc[:,:-1]\n",
    "len(data), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "def printCM(Y_test, predictions):\n",
    "    cm = confusion_matrix(Y_test, predictions)\n",
    "    acc_score = accuracy_score(Y_test, predictions)\n",
    "    prec_score = precision_score(Y_test, predictions, average='weighted')\n",
    "    \n",
    "    print ('Confusion Matrix : ')\n",
    "    print (cm)\n",
    "    print\n",
    "    \n",
    "    tn = float(cm[0][0])\n",
    "    fp = float(cm[0][1])\n",
    "    fn = float(cm[1][0])\n",
    "    tp = float(cm[1][1])\n",
    "\n",
    "    actual_yes = fn+tp\n",
    "    actual_no = tn+fp\n",
    "    predicted_yes = fp+tp\n",
    "    predicted_no = tn+fn\n",
    "\n",
    "    total = float(len(imported_data))\n",
    "    print ('Total : '+ str(total))\n",
    "\n",
    "    print ('Acurácia : ' + str(acc_score))\n",
    "\n",
    "    misclassification_rate = round((fp+fn)/total,3) # Overall, how often is it wrong?\n",
    "    print ('Misclassification rate : ' +str(misclassification_rate))\n",
    "\n",
    "    true_positive = round(tp/actual_yes,3) # When it's actually yes, how often does it predict yes?\n",
    "    print ('True positives : ' +str(true_positive))\n",
    "\n",
    "    false_positive = round(fp/actual_no,3) # When it's actually no, how often does it predict yes?\n",
    "    print ('False positives : ' +str(false_positive))\n",
    "\n",
    "    specificity = round(tn/actual_no,3) # When it's actually no, how often does it predict no?\n",
    "    print ('Specificity : ' +str(specificity))\n",
    "\n",
    "    #precision = round(tp/predicted_yes,3) # When it predicts yes, how often is it correct?\n",
    "    print ('Precision : ' +str(prec_score))\n",
    "\n",
    "    prevalence = round(actual_yes/total,3) # How often does the yes condition actually occur in our sample?\n",
    "    print ('Prevalence : ' +str(prevalence))\n",
    "    \n",
    "    recall = round(tp / (tp + fn), 3)\n",
    "    print ('Recall : ' +str(recall))\n",
    "\n",
    "    #f1 = round(2 * ((precision * true_positive) / (precision + true_positive)),3)\n",
    "    #print ('F1 Score : ' +str(f1))\n",
    "    \n",
    "    return acc_score, prec_score, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_rate(pred, Y):\n",
    "    return sum(pred != Y) / float(len(Y))\n",
    "\n",
    "def print_error_rate(err):\n",
    "    print('Error rate: Training: %.4f - Test: %.4f' % err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Separação entre treino e teste</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 166\n",
      "42 42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# utiliza 25% do dataset para teste\n",
    "trainData, validationData, trainLabels, validationLabels = train_test_split(data, labels, \n",
    "                                                    train_size=0.8, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=labels,\n",
    "                                                    random_state=43)\n",
    "\n",
    "print(len(trainData), len(trainLabels))\n",
    "print(len(validationData), len(validationLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....Iniciando treinamento com 10 K-folds....\n",
      "\n",
      "################################################\n",
      "K-fold : 1\n",
      "################################################\n",
      "[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34\n",
      "  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52\n",
      "  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.23489932885906067\n",
      "Alpha : 0.5904251934525402\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[67 12]\n",
      " [23 47]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7651006711409396\n",
      "Misclassification rate : 0.168\n",
      "True positives : 0.671\n",
      "False positives : 0.152\n",
      "Specificity : 0.848\n",
      "Precision : 0.7689518320504556\n",
      "Prevalence : 0.337\n",
      "Recall : 0.671\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 3]\n",
      " [2 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7058823529411765\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.714\n",
      "False positives : 0.3\n",
      "Specificity : 0.7\n",
      "Precision : 0.7148692810457516\n",
      "Prevalence : 0.034\n",
      "Recall : 0.714\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00371874 0.01211245 0.01211245 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.01211245 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874 0.01211245\n",
      " 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.01211245 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.01211245 0.00371874 0.01211245 0.01211245 0.01211245 0.00371874\n",
      " 0.01211245 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.01211245 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.00371874 0.01211245 0.00371874 0.00371874\n",
      " 0.01211245 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.00371874 0.01211245 0.00371874 0.00371874\n",
      " 0.01211245 0.00371874 0.01211245 0.01211245 0.00371874 0.01211245\n",
      " 0.00371874 0.00371874 0.01211245 0.01211245 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.00371874 0.00371874 0.01211245 0.01211245\n",
      " 0.00371874 0.00371874 0.01211245 0.00371874 0.01211245 0.00371874\n",
      " 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.01211245 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874 0.01211245\n",
      " 0.01211245 0.00371874 0.00371874 0.01211245 0.00371874 0.01211245\n",
      " 0.00371874 0.00371874 0.01211245 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874 0.01211245\n",
      " 0.00371874 0.01211245 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.01211245 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.01211245 0.00371874 0.00371874 0.00371874 0.01211245\n",
      " 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.33032581453634086\n",
      "Alpha : 0.3533559097970419\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[27 52]\n",
      " [ 3 67]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6308724832214765\n",
      "Misclassification rate : 0.264\n",
      "True positives : 0.957\n",
      "False positives : 0.658\n",
      "Specificity : 0.342\n",
      "Precision : 0.7416896960126333\n",
      "Prevalence : 0.337\n",
      "Recall : 0.957\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 7]\n",
      " [2 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.47058823529411764\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.714\n",
      "False positives : 0.7\n",
      "Specificity : 0.3\n",
      "Precision : 0.5245098039215687\n",
      "Prevalence : 0.034\n",
      "Recall : 0.714\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00261177 0.00850691 0.01724617 0.00529488 0.00529488 0.00261177\n",
      " 0.00261177 0.00529488 0.00850691 0.00261177 0.00529488 0.00529488\n",
      " 0.00261177 0.00261177 0.00529488 0.00529488 0.00261177 0.00850691\n",
      " 0.00529488 0.00261177 0.00261177 0.00261177 0.00261177 0.00261177\n",
      " 0.00529488 0.00850691 0.00261177 0.00261177 0.00529488 0.00261177\n",
      " 0.00850691 0.00261177 0.00850691 0.00850691 0.01724617 0.00261177\n",
      " 0.00850691 0.00261177 0.00529488 0.00529488 0.00261177 0.00261177\n",
      " 0.00850691 0.00529488 0.00261177 0.00261177 0.00529488 0.00261177\n",
      " 0.00529488 0.00261177 0.00261177 0.01724617 0.00261177 0.00261177\n",
      " 0.01724617 0.00261177 0.00261177 0.00529488 0.00529488 0.00529488\n",
      " 0.00529488 0.00261177 0.00529488 0.00850691 0.00261177 0.00529488\n",
      " 0.00850691 0.00261177 0.01724617 0.00850691 0.00529488 0.00850691\n",
      " 0.00261177 0.00261177 0.00850691 0.00850691 0.00261177 0.00529488\n",
      " 0.00261177 0.00261177 0.00261177 0.00529488 0.00850691 0.01724617\n",
      " 0.00529488 0.00529488 0.00850691 0.00529488 0.00850691 0.00261177\n",
      " 0.00261177 0.00261177 0.00529488 0.00529488 0.00261177 0.00529488\n",
      " 0.00850691 0.00261177 0.00261177 0.00529488 0.00529488 0.00529488\n",
      " 0.00261177 0.00529488 0.00529488 0.00261177 0.00261177 0.01724617\n",
      " 0.00850691 0.00529488 0.00261177 0.00850691 0.00261177 0.00850691\n",
      " 0.00261177 0.00529488 0.01724617 0.00529488 0.00261177 0.00529488\n",
      " 0.00261177 0.00261177 0.00261177 0.00529488 0.00529488 0.00850691\n",
      " 0.00261177 0.01724617 0.00529488 0.00261177 0.00261177 0.00261177\n",
      " 0.00529488 0.00261177 0.00850691 0.00261177 0.00261177 0.00261177\n",
      " 0.00261177 0.00850691 0.00261177 0.00529488 0.00261177 0.00850691\n",
      " 0.00261177 0.00261177 0.00529488 0.00261177 0.00529488]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.26916391988405547\n",
      "Alpha : 0.4994343161925587\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[64 15]\n",
      " [36 34]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6577181208053692\n",
      "Misclassification rate : 0.245\n",
      "True positives : 0.486\n",
      "False positives : 0.19\n",
      "Specificity : 0.81\n",
      "Precision : 0.6653116011505273\n",
      "Prevalence : 0.337\n",
      "Recall : 0.486\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 3]\n",
      " [3 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.571\n",
      "False positives : 0.3\n",
      "Specificity : 0.7\n",
      "Precision : 0.6470588235294118\n",
      "Prevalence : 0.034\n",
      "Recall : 0.571\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00158501 0.00516262 0.01046625 0.00321332 0.00321332 0.00158501\n",
      " 0.00158501 0.00321332 0.01401758 0.00158501 0.00321332 0.00321332\n",
      " 0.00430364 0.00430364 0.00321332 0.00321332 0.00430364 0.01401758\n",
      " 0.00321332 0.00430364 0.00158501 0.00158501 0.00158501 0.00158501\n",
      " 0.00872484 0.00516262 0.00158501 0.00158501 0.00321332 0.00158501\n",
      " 0.00516262 0.00430364 0.01401758 0.00516262 0.01046625 0.00430364\n",
      " 0.01401758 0.00158501 0.00321332 0.00321332 0.00430364 0.00430364\n",
      " 0.00516262 0.00321332 0.00158501 0.00158501 0.00321332 0.00430364\n",
      " 0.00321332 0.00430364 0.00430364 0.01046625 0.00158501 0.00158501\n",
      " 0.01046625 0.00430364 0.00430364 0.00321332 0.00321332 0.00321332\n",
      " 0.00321332 0.00430364 0.00321332 0.00516262 0.00430364 0.00321332\n",
      " 0.00516262 0.00430364 0.01046625 0.00516262 0.00321332 0.01401758\n",
      " 0.00430364 0.00158501 0.01401758 0.00516262 0.00430364 0.00321332\n",
      " 0.00158501 0.00430364 0.00430364 0.00321332 0.00516262 0.01046625\n",
      " 0.00321332 0.00321332 0.00516262 0.00321332 0.00516262 0.00158501\n",
      " 0.00158501 0.00158501 0.00872484 0.00321332 0.00430364 0.00321332\n",
      " 0.01401758 0.00430364 0.00430364 0.00872484 0.00321332 0.00321332\n",
      " 0.00430364 0.00321332 0.00321332 0.00158501 0.00430364 0.01046625\n",
      " 0.00516262 0.00321332 0.00158501 0.01401758 0.00430364 0.01401758\n",
      " 0.00158501 0.00321332 0.01046625 0.00321332 0.00158501 0.00321332\n",
      " 0.00430364 0.00430364 0.00158501 0.00321332 0.00321332 0.01401758\n",
      " 0.00430364 0.01046625 0.00321332 0.00158501 0.00158501 0.00158501\n",
      " 0.00872484 0.00158501 0.01401758 0.00158501 0.00430364 0.00430364\n",
      " 0.00158501 0.00516262 0.00158501 0.00321332 0.00430364 0.01401758\n",
      " 0.00430364 0.00430364 0.00321332 0.00430364 0.00321332]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.32960639871747777\n",
      "Alpha : 0.3549828965322788\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[73  6]\n",
      " [53 17]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6040268456375839\n",
      "Misclassification rate : 0.284\n",
      "True positives : 0.243\n",
      "False positives : 0.076\n",
      "Specificity : 0.924\n",
      "Precision : 0.6544226288900932\n",
      "Prevalence : 0.337\n",
      "Recall : 0.243\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[10  0]\n",
      " [ 6  1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.143\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 0.7794117647058824\n",
      "Prevalence : 0.034\n",
      "Recall : 0.143\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00111139 0.0073627  0.00733878 0.00225313 0.00225313 0.00226048\n",
      " 0.00226048 0.0045827  0.00982893 0.00226048 0.00225313 0.00225313\n",
      " 0.00301765 0.00613767 0.00225313 0.00225313 0.00613767 0.01999127\n",
      " 0.00225313 0.00301765 0.00226048 0.00226048 0.00226048 0.00226048\n",
      " 0.00611773 0.0073627  0.00226048 0.00226048 0.0045827  0.00226048\n",
      " 0.00361995 0.00613767 0.00982893 0.0073627  0.00733878 0.00613767\n",
      " 0.00982893 0.00111139 0.00225313 0.00225313 0.00613767 0.00301765\n",
      " 0.00361995 0.0045827  0.00111139 0.00226048 0.0045827  0.00613767\n",
      " 0.00225313 0.00301765 0.00301765 0.00733878 0.00111139 0.00226048\n",
      " 0.00733878 0.00613767 0.00301765 0.00225313 0.00225313 0.00225313\n",
      " 0.00225313 0.00301765 0.00225313 0.00361995 0.00613767 0.00225313\n",
      " 0.0073627  0.00301765 0.00733878 0.00361995 0.00225313 0.00982893\n",
      " 0.00613767 0.00111139 0.00982893 0.0073627  0.00301765 0.00225313\n",
      " 0.00111139 0.00613767 0.00301765 0.00225313 0.00361995 0.00733878\n",
      " 0.00225313 0.00225313 0.00361995 0.00225313 0.0073627  0.00111139\n",
      " 0.00226048 0.00226048 0.01244298 0.00225313 0.00613767 0.00225313\n",
      " 0.01999127 0.00613767 0.00301765 0.00611773 0.00225313 0.0045827\n",
      " 0.00301765 0.00225313 0.00225313 0.00226048 0.00613767 0.00733878\n",
      " 0.0073627  0.00225313 0.00111139 0.00982893 0.00613767 0.00982893\n",
      " 0.00226048 0.00225313 0.00733878 0.00225313 0.00226048 0.00225313\n",
      " 0.00301765 0.00301765 0.00226048 0.00225313 0.0045827  0.00982893\n",
      " 0.00613767 0.00733878 0.00225313 0.00111139 0.00111139 0.00111139\n",
      " 0.01244298 0.00226048 0.01999127 0.00226048 0.00301765 0.00613767\n",
      " 0.00226048 0.00361995 0.00111139 0.00225313 0.00613767 0.00982893\n",
      " 0.00301765 0.00613767 0.00225313 0.00613767 0.0045827 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2688210741082501\n",
      "Alpha : 0.5003060960922129\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[36 43]\n",
      " [10 60]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6442953020134228\n",
      "Misclassification rate : 0.255\n",
      "True positives : 0.857\n",
      "False positives : 0.544\n",
      "Specificity : 0.456\n",
      "Precision : 0.6886093019171003\n",
      "Prevalence : 0.337\n",
      "Recall : 0.857\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 6]\n",
      " [2 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5294117647058824\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.714\n",
      "False positives : 0.6\n",
      "Specificity : 0.4\n",
      "Precision : 0.5793226381461675\n",
      "Prevalence : 0.034\n",
      "Recall : 0.714\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00183293 0.00446434 0.00444983 0.00371593 0.00136618 0.00137063\n",
      " 0.00137063 0.0027787  0.00595972 0.00137063 0.00136618 0.00371593\n",
      " 0.00497679 0.00372155 0.00371593 0.00136618 0.00372155 0.0121216\n",
      " 0.00371593 0.00497679 0.00137063 0.00137063 0.00137063 0.00137063\n",
      " 0.00370946 0.00446434 0.00137063 0.00137063 0.0027787  0.00137063\n",
      " 0.00219494 0.00372155 0.00595972 0.00446434 0.00444983 0.00372155\n",
      " 0.00595972 0.00183293 0.00371593 0.00136618 0.00372155 0.00182974\n",
      " 0.00597012 0.0027787  0.00183293 0.00372804 0.00755791 0.00372155\n",
      " 0.00371593 0.00182974 0.00497679 0.00444983 0.00067389 0.00137063\n",
      " 0.00444983 0.00372155 0.00182974 0.00371593 0.00371593 0.00371593\n",
      " 0.00136618 0.00182974 0.00371593 0.00219494 0.00372155 0.00136618\n",
      " 0.00446434 0.00182974 0.01210331 0.00597012 0.00136618 0.01621012\n",
      " 0.0101224  0.00183293 0.00595972 0.00446434 0.00182974 0.00371593\n",
      " 0.00067389 0.00372155 0.00182974 0.00371593 0.00219494 0.00444983\n",
      " 0.00371593 0.00136618 0.00597012 0.00136618 0.01214276 0.00067389\n",
      " 0.00137063 0.00372804 0.00754474 0.00136618 0.00372155 0.00136618\n",
      " 0.0121216  0.00372155 0.00182974 0.00370946 0.00371593 0.00755791\n",
      " 0.00497679 0.00371593 0.00371593 0.00137063 0.00372155 0.01210331\n",
      " 0.00446434 0.00371593 0.00183293 0.01621012 0.00372155 0.00595972\n",
      " 0.00137063 0.00136618 0.00444983 0.00371593 0.00137063 0.00371593\n",
      " 0.00497679 0.00182974 0.00137063 0.00371593 0.0027787  0.01621012\n",
      " 0.00372155 0.01210331 0.00371593 0.00183293 0.00067389 0.00183293\n",
      " 0.00754474 0.00137063 0.0121216  0.00137063 0.00182974 0.00372155\n",
      " 0.00137063 0.00597012 0.00183293 0.00371593 0.00372155 0.01621012\n",
      " 0.00182974 0.00372155 0.00371593 0.00372155 0.0027787 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2909425261559668\n",
      "Alpha : 0.445405421725079\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[56 23]\n",
      " [21 49]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7046979865771812\n",
      "Misclassification rate : 0.212\n",
      "True positives : 0.7\n",
      "False positives : 0.291\n",
      "Specificity : 0.709\n",
      "Precision : 0.7053250627076131\n",
      "Prevalence : 0.337\n",
      "Recall : 0.7\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 3]\n",
      " [4 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5882352941176471\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.429\n",
      "False positives : 0.3\n",
      "Specificity : 0.7\n",
      "Precision : 0.5802139037433155\n",
      "Prevalence : 0.034\n",
      "Recall : 0.429\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00117411 0.00696938 0.00694674 0.00580102 0.00087512 0.00087798\n",
      " 0.00087798 0.00177993 0.00930386 0.00087798 0.00213277 0.00580102\n",
      " 0.00318796 0.00238389 0.00238029 0.00213277 0.00238389 0.00776467\n",
      " 0.00238029 0.00318796 0.00213972 0.00213972 0.00087798 0.00087798\n",
      " 0.00237615 0.0028597  0.00087798 0.00087798 0.00177993 0.00087798\n",
      " 0.001406   0.00238389 0.00930386 0.0028597  0.00285041 0.00238389\n",
      " 0.00930386 0.00117411 0.00238029 0.00213277 0.00238389 0.00117207\n",
      " 0.00932009 0.00433789 0.00286143 0.00581993 0.01179882 0.00580979\n",
      " 0.00238029 0.00117207 0.00776938 0.00285041 0.00043167 0.00087798\n",
      " 0.00285041 0.00238389 0.00117207 0.00238029 0.00238029 0.00238029\n",
      " 0.00213277 0.00285645 0.00580102 0.00342657 0.00238389 0.00087512\n",
      " 0.00696938 0.00117207 0.00775295 0.00382425 0.00213277 0.01038363\n",
      " 0.01580232 0.00117411 0.00930386 0.0028597  0.00117207 0.00238029\n",
      " 0.00043167 0.00238389 0.00117207 0.00238029 0.001406   0.00694674\n",
      " 0.00238029 0.00213277 0.00932009 0.00213277 0.00777822 0.00043167\n",
      " 0.00087798 0.00581993 0.01177827 0.00087512 0.00238389 0.00087512\n",
      " 0.00776467 0.00238389 0.00117207 0.00237615 0.00580102 0.01179882\n",
      " 0.00318796 0.00238029 0.00238029 0.00213972 0.00238389 0.00775295\n",
      " 0.0028597  0.00238029 0.00117411 0.01038363 0.00238389 0.00381759\n",
      " 0.00087798 0.00087512 0.00285041 0.00238029 0.00087798 0.00238029\n",
      " 0.00776938 0.00285645 0.00213972 0.00238029 0.00433789 0.01038363\n",
      " 0.00580979 0.01889476 0.00238029 0.00117411 0.00043167 0.00117411\n",
      " 0.00483289 0.00213972 0.00776467 0.00087798 0.00117207 0.00238389\n",
      " 0.00087798 0.00382425 0.00117411 0.00580102 0.00238389 0.01038363\n",
      " 0.00117207 0.00238389 0.00238029 0.00238389 0.00177993]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.290505664233224\n",
      "Alpha : 0.446464719414937\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[40 39]\n",
      " [19 51]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.610738255033557\n",
      "Misclassification rate : 0.279\n",
      "True positives : 0.729\n",
      "False positives : 0.494\n",
      "Specificity : 0.506\n",
      "Precision : 0.6256777765138588\n",
      "Prevalence : 0.337\n",
      "Recall : 0.729\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[5 5]\n",
      " [4 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.47058823529411764\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.429\n",
      "False positives : 0.5\n",
      "Specificity : 0.5\n",
      "Precision : 0.4812091503267974\n",
      "Prevalence : 0.034\n",
      "Recall : 0.429\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0007513  0.01089159 0.00444512 0.00371199 0.00055998 0.00056181\n",
      " 0.00137208 0.00278164 0.00595341 0.00056181 0.00333305 0.00371199\n",
      " 0.00498207 0.00152542 0.00152312 0.00136473 0.00372549 0.00496851\n",
      " 0.00152312 0.00498207 0.00136918 0.00334391 0.00137208 0.00137208\n",
      " 0.00152046 0.00182988 0.00056181 0.00137208 0.00278164 0.00137208\n",
      " 0.00219727 0.00372549 0.00595341 0.00182988 0.00182394 0.00152542\n",
      " 0.00595341 0.00183487 0.00152312 0.00333305 0.00152542 0.00183168\n",
      " 0.01456523 0.00277576 0.00183099 0.00909525 0.00754991 0.00371761\n",
      " 0.00371987 0.00183168 0.00497152 0.00182394 0.0006746  0.00056181\n",
      " 0.00445455 0.00152542 0.00183168 0.00371987 0.00152312 0.00152312\n",
      " 0.00136473 0.00446399 0.00371199 0.00219262 0.00372549 0.00136763\n",
      " 0.01089159 0.00183168 0.01211614 0.00597645 0.00136473 0.00664434\n",
      " 0.01011169 0.00183487 0.00595341 0.00182988 0.00074999 0.00152312\n",
      " 0.0006746  0.00152542 0.00183168 0.00371987 0.00089968 0.00444512\n",
      " 0.00152312 0.00136473 0.01456523 0.00333305 0.00497718 0.0006746\n",
      " 0.00137208 0.00372409 0.00753675 0.00055998 0.00152542 0.00136763\n",
      " 0.00496851 0.00152542 0.00183168 0.00371339 0.00371199 0.01843894\n",
      " 0.00498207 0.00371987 0.00152312 0.00136918 0.00152542 0.00496101\n",
      " 0.00182988 0.00371987 0.00183487 0.00664434 0.00152542 0.00244282\n",
      " 0.00137208 0.00055998 0.00182394 0.00152312 0.00056181 0.00371987\n",
      " 0.00497152 0.00446399 0.00136918 0.00152312 0.00677915 0.00664434\n",
      " 0.00371761 0.0120905  0.00152312 0.00183487 0.0006746  0.0007513\n",
      " 0.0030925  0.00136918 0.00496851 0.00056181 0.00074999 0.00152542\n",
      " 0.00056181 0.00244708 0.00183487 0.00371199 0.00152542 0.0162273\n",
      " 0.00183168 0.00152542 0.00152312 0.00152542 0.00113896]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3063719047258378\n",
      "Alpha : 0.40856809609670286\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[75  4]\n",
      " [51 19]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6308724832214765\n",
      "Misclassification rate : 0.264\n",
      "True positives : 0.271\n",
      "False positives : 0.051\n",
      "Specificity : 0.949\n",
      "Precision : 0.7036905804049078\n",
      "Prevalence : 0.337\n",
      "Recall : 0.271\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 2]\n",
      " [7 0]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.47058823529411764\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.0\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.3137254901960784\n",
      "Prevalence : 0.034\n",
      "Recall : 0.0\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00049931 0.00723856 0.00295423 0.002467   0.00037216 0.00084533\n",
      " 0.00206452 0.00184868 0.00895787 0.00084533 0.00221515 0.002467\n",
      " 0.00331109 0.00229524 0.00101226 0.000907   0.00247596 0.00747592\n",
      " 0.00229177 0.00331109 0.00206015 0.00222237 0.00206452 0.00206452\n",
      " 0.0010105  0.00275335 0.00084533 0.00206452 0.00184868 0.00206452\n",
      " 0.00146031 0.00247596 0.00895787 0.00275335 0.00121219 0.00229524\n",
      " 0.00395664 0.00121946 0.00101226 0.00221515 0.00229524 0.00121734\n",
      " 0.00968007 0.00417657 0.00121688 0.01368528 0.00501768 0.00559374\n",
      " 0.00247223 0.00121734 0.00330408 0.00121219 0.00044834 0.00084533\n",
      " 0.0029605  0.0010138  0.00121734 0.00247223 0.00101226 0.00101226\n",
      " 0.000907   0.00296677 0.002467   0.00145722 0.00247596 0.00090893\n",
      " 0.00723856 0.00121734 0.0080524  0.00397195 0.000907   0.00999749\n",
      " 0.01521467 0.00121946 0.00395664 0.00121614 0.00049844 0.00101226\n",
      " 0.00044834 0.00229524 0.00121734 0.00247223 0.00135372 0.00295423\n",
      " 0.00101226 0.000907   0.00968007 0.00221515 0.00748897 0.00044834\n",
      " 0.00206452 0.0056035  0.01134026 0.00037216 0.00229524 0.00090893\n",
      " 0.00747592 0.0010138  0.00121734 0.00246792 0.002467   0.01225454\n",
      " 0.00331109 0.00247223 0.00229177 0.00206015 0.00229524 0.00329709\n",
      " 0.00275335 0.00559714 0.00121946 0.00999749 0.00229524 0.00367562\n",
      " 0.00206452 0.00037216 0.00121219 0.00229177 0.00037338 0.00247223\n",
      " 0.00330408 0.00296677 0.00206015 0.00101226 0.00450543 0.00999749\n",
      " 0.00559374 0.00803536 0.00101226 0.00121946 0.00044834 0.00049931\n",
      " 0.00205528 0.00206015 0.00747592 0.00084533 0.00049844 0.00229524\n",
      " 0.00084533 0.00368203 0.00121946 0.002467   0.00229524 0.01078468\n",
      " 0.00275606 0.00229524 0.00101226 0.00229524 0.00075695]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2715534734507066\n",
      "Alpha : 0.4933775726061191\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[29 50]\n",
      " [ 8 62]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.610738255033557\n",
      "Misclassification rate : 0.279\n",
      "True positives : 0.886\n",
      "False positives : 0.633\n",
      "Specificity : 0.367\n",
      "Precision : 0.6756303283148921\n",
      "Prevalence : 0.337\n",
      "Recall : 0.886\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[2 8]\n",
      " [0 7]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5294117647058824\n",
      "Misclassification rate : 0.038\n",
      "True positives : 1.0\n",
      "False positives : 0.8\n",
      "Specificity : 0.2\n",
      "Precision : 0.780392156862745\n",
      "Prevalence : 0.034\n",
      "Recall : 1.0\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00081779 0.00441958 0.00483856 0.00150625 0.00060954 0.00138451\n",
      " 0.00338135 0.00302784 0.00546932 0.00051612 0.00362805 0.00404054\n",
      " 0.00202162 0.00140138 0.00061805 0.00148552 0.00151173 0.0045645\n",
      " 0.00139927 0.00542303 0.00125785 0.00135689 0.00126051 0.00126051\n",
      " 0.00165504 0.00450955 0.00051612 0.00126051 0.00302784 0.00338135\n",
      " 0.00239175 0.00151173 0.00546932 0.00168109 0.00198537 0.00140138\n",
      " 0.00241577 0.00199728 0.00165793 0.00135248 0.00140138 0.00074326\n",
      " 0.00591027 0.00255005 0.00199305 0.00835569 0.00821815 0.00341532\n",
      " 0.00150945 0.00074326 0.00541155 0.00198537 0.00073431 0.00051612\n",
      " 0.00484882 0.00061898 0.0019938  0.00150945 0.00165793 0.00061805\n",
      " 0.00148552 0.0018114  0.00404054 0.00088972 0.00151173 0.00148867\n",
      " 0.00441958 0.0019938  0.00491648 0.00650542 0.00148552 0.00610407\n",
      " 0.00928948 0.00074455 0.00241577 0.00074253 0.00081637 0.00061805\n",
      " 0.00027374 0.00375923 0.00074326 0.00150945 0.00082653 0.00483856\n",
      " 0.00165793 0.00148552 0.00591027 0.00362805 0.00457247 0.00073431\n",
      " 0.00126051 0.00342128 0.00692392 0.00022723 0.00140138 0.00148867\n",
      " 0.01224435 0.00166043 0.0019938  0.00404206 0.00404054 0.02007096\n",
      " 0.00202162 0.00150945 0.00139927 0.00125785 0.00140138 0.0054001\n",
      " 0.00168109 0.00341739 0.00074455 0.00610407 0.00140138 0.00224419\n",
      " 0.00126051 0.00022723 0.00198537 0.00139927 0.00022797 0.00150945\n",
      " 0.00201734 0.0048591  0.00125785 0.00165793 0.00737917 0.00610407\n",
      " 0.00341532 0.01316062 0.00165793 0.00074455 0.00073431 0.00081779\n",
      " 0.00125487 0.00337419 0.0045645  0.00051612 0.00030433 0.00140138\n",
      " 0.00051612 0.0022481  0.00074455 0.00150625 0.00140138 0.0065847\n",
      " 0.00168274 0.00140138 0.00165793 0.00140138 0.00123976]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.26684629567876683\n",
      "Alpha : 0.5053412754989961\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[49 30]\n",
      " [22 48]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6510067114093959\n",
      "Misclassification rate : 0.25\n",
      "True positives : 0.686\n",
      "False positives : 0.38\n",
      "Specificity : 0.62\n",
      "Precision : 0.6550204687079628\n",
      "Prevalence : 0.337\n",
      "Recall : 0.686\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[6 4]\n",
      " [2 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.714\n",
      "False positives : 0.4\n",
      "Specificity : 0.6\n",
      "Precision : 0.6699346405228759\n",
      "Prevalence : 0.034\n",
      "Recall : 0.714\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00049338 0.00266633 0.0029191  0.00090872 0.00036774 0.00083527\n",
      " 0.00203997 0.0018267  0.00329964 0.00031138 0.0021888  0.00243766\n",
      " 0.00335094 0.00084545 0.00102445 0.00089622 0.00250576 0.00275376\n",
      " 0.00084418 0.00327171 0.00075886 0.00224911 0.00076047 0.00076047\n",
      " 0.00099848 0.00272061 0.00031138 0.00076047 0.0018267  0.00203997\n",
      " 0.00396444 0.00091202 0.00329964 0.00278649 0.00119777 0.00232286\n",
      " 0.00145743 0.00331059 0.0027481  0.00224181 0.00084545 0.00123199\n",
      " 0.00979658 0.00153844 0.00120241 0.00504099 0.004958   0.00206046\n",
      " 0.00250198 0.00044841 0.00326479 0.00119777 0.00121715 0.00031138\n",
      " 0.00292529 0.001026   0.00330482 0.00250198 0.00100023 0.00037287\n",
      " 0.00089622 0.00109281 0.0066974  0.00147475 0.00091202 0.00089812\n",
      " 0.00266633 0.00120286 0.00814931 0.01078307 0.00089622 0.00368258\n",
      " 0.00560434 0.00123414 0.00145743 0.00044797 0.00135318 0.00102445\n",
      " 0.00016515 0.00226794 0.00123199 0.00250198 0.00049864 0.0029191\n",
      " 0.0027481  0.00089622 0.00979658 0.0021888  0.00275857 0.00044301\n",
      " 0.00076047 0.00567094 0.0041772  0.00037664 0.00084545 0.00246755\n",
      " 0.00738701 0.00100174 0.00120286 0.00243857 0.00243766 0.0121088\n",
      " 0.00335094 0.00250198 0.00084418 0.00208495 0.00232286 0.00325788\n",
      " 0.0010142  0.00206171 0.00123414 0.01011781 0.00232286 0.00135392\n",
      " 0.00076047 0.00013709 0.00329085 0.00084418 0.00013753 0.00250198\n",
      " 0.00121706 0.00293149 0.00075886 0.00100023 0.00445185 0.01011781\n",
      " 0.00566106 0.0079398  0.00100023 0.00044919 0.00121715 0.00135554\n",
      " 0.00075706 0.00203565 0.0075659  0.00031138 0.0001836  0.00232286\n",
      " 0.00031138 0.00372635 0.00123414 0.00249669 0.00084545 0.00397255\n",
      " 0.00278923 0.00232286 0.00100023 0.00232286 0.00074795]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 2\n",
      "################################################\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  34\n",
      "  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52\n",
      "  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165] [17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33]\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.24832214765100702\n",
      "Alpha : 0.5537904793254342\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[68 11]\n",
      " [26 44]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7516778523489933\n",
      "Misclassification rate : 0.178\n",
      "True positives : 0.629\n",
      "False positives : 0.139\n",
      "Specificity : 0.861\n",
      "Precision : 0.7593888333571327\n",
      "Prevalence : 0.337\n",
      "Recall : 0.629\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 1]\n",
      " [2 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8235294117647058\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.714\n",
      "False positives : 0.1\n",
      "Specificity : 0.9\n",
      "Precision : 0.8244206773618539\n",
      "Prevalence : 0.034\n",
      "Recall : 0.714\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0038575  0.0038575  0.01167675 0.0038575  0.0038575  0.01167675\n",
      " 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.0038575  0.0038575  0.01167675 0.01167675 0.0038575  0.01167675\n",
      " 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.0038575  0.01167675 0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.01167675 0.0038575  0.01167675 0.01167675 0.01167675 0.0038575\n",
      " 0.01167675 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.01167675 0.0038575  0.0038575  0.01167675 0.0038575  0.0038575\n",
      " 0.0038575  0.0038575  0.0038575  0.01167675 0.0038575  0.0038575\n",
      " 0.01167675 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.0038575  0.0038575  0.0038575  0.01167675 0.0038575  0.0038575\n",
      " 0.01167675 0.0038575  0.0038575  0.01167675 0.0038575  0.01167675\n",
      " 0.01167675 0.0038575  0.01167675 0.01167675 0.0038575  0.0038575\n",
      " 0.0038575  0.01167675 0.0038575  0.0038575  0.01167675 0.01167675\n",
      " 0.0038575  0.0038575  0.01167675 0.0038575  0.01167675 0.0038575\n",
      " 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.01167675 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575  0.01167675\n",
      " 0.01167675 0.0038575  0.0038575  0.01167675 0.0038575  0.01167675\n",
      " 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575  0.01167675\n",
      " 0.0038575  0.01167675 0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.0038575  0.0038575  0.01167675 0.0038575  0.0038575  0.0038575\n",
      " 0.0038575  0.01167675 0.0038575  0.0038575  0.0038575  0.01167675\n",
      " 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3223938223938217\n",
      "Alpha : 0.371396205524557\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[28 51]\n",
      " [ 5 65]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6241610738255033\n",
      "Misclassification rate : 0.269\n",
      "True positives : 0.929\n",
      "False positives : 0.646\n",
      "Specificity : 0.354\n",
      "Precision : 0.7131170534317953\n",
      "Prevalence : 0.337\n",
      "Recall : 0.929\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[2 8]\n",
      " [0 7]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5294117647058824\n",
      "Misclassification rate : 0.038\n",
      "True positives : 1.0\n",
      "False positives : 0.8\n",
      "Specificity : 0.2\n",
      "Precision : 0.780392156862745\n",
      "Prevalence : 0.034\n",
      "Recall : 1.0\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00266079 0.00559243 0.01692845 0.00266079 0.00559243 0.00805428\n",
      " 0.00559243 0.00266079 0.00559243 0.00266079 0.00266079 0.00559243\n",
      " 0.00559243 0.00559243 0.00805428 0.01692845 0.00266079 0.00805428\n",
      " 0.00559243 0.00266079 0.00266079 0.00266079 0.00266079 0.00266079\n",
      " 0.00559243 0.00805428 0.00266079 0.00266079 0.00559243 0.00266079\n",
      " 0.00805428 0.00266079 0.00805428 0.00805428 0.01692845 0.00266079\n",
      " 0.00805428 0.00266079 0.00559243 0.00559243 0.00266079 0.00266079\n",
      " 0.00805428 0.00559243 0.00266079 0.00805428 0.00559243 0.00266079\n",
      " 0.00559243 0.00266079 0.00266079 0.01692845 0.00266079 0.00266079\n",
      " 0.01692845 0.00266079 0.00266079 0.00559243 0.00559243 0.00559243\n",
      " 0.00559243 0.00266079 0.00559243 0.00805428 0.00266079 0.00559243\n",
      " 0.00805428 0.00266079 0.00559243 0.00805428 0.00559243 0.00805428\n",
      " 0.00805428 0.00266079 0.00805428 0.00805428 0.00266079 0.00559243\n",
      " 0.00266079 0.00805428 0.00266079 0.00559243 0.00805428 0.01692845\n",
      " 0.00559243 0.00559243 0.00805428 0.00559243 0.00805428 0.00266079\n",
      " 0.00266079 0.00266079 0.00559243 0.00559243 0.00266079 0.00559243\n",
      " 0.00805428 0.00266079 0.00266079 0.00559243 0.00559243 0.00559243\n",
      " 0.00266079 0.00559243 0.00559243 0.00266079 0.00266079 0.01692845\n",
      " 0.00805428 0.00559243 0.00266079 0.00805428 0.00266079 0.00805428\n",
      " 0.00266079 0.00559243 0.00559243 0.00559243 0.00266079 0.00559243\n",
      " 0.00266079 0.00266079 0.00266079 0.00559243 0.00559243 0.00805428\n",
      " 0.00266079 0.01692845 0.00559243 0.00266079 0.00266079 0.00266079\n",
      " 0.00559243 0.00266079 0.00805428 0.00266079 0.00266079 0.00266079\n",
      " 0.00266079 0.00805428 0.00266079 0.00559243 0.00266079 0.00805428\n",
      " 0.00266079 0.00266079 0.00559243 0.00266079 0.00559243]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3003352269819334\n",
      "Alpha : 0.4228510252855715\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[75  4]\n",
      " [45 25]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6711409395973155\n",
      "Misclassification rate : 0.236\n",
      "True positives : 0.357\n",
      "False positives : 0.051\n",
      "Specificity : 0.949\n",
      "Precision : 0.7363746817866235\n",
      "Prevalence : 0.337\n",
      "Recall : 0.357\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 3]\n",
      " [3 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.571\n",
      "False positives : 0.3\n",
      "Specificity : 0.7\n",
      "Precision : 0.6470588235294118\n",
      "Prevalence : 0.034\n",
      "Recall : 0.571\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00406118 0.00853577 0.01109112 0.00174328 0.00853577 0.0122933\n",
      " 0.00366403 0.00174328 0.00853577 0.00174328 0.00174328 0.00366403\n",
      " 0.00366403 0.00366403 0.00527697 0.01109112 0.00174328 0.00527697\n",
      " 0.00366403 0.00174328 0.00406118 0.00406118 0.00406118 0.00174328\n",
      " 0.00366403 0.00527697 0.00174328 0.00174328 0.00366403 0.00174328\n",
      " 0.00527697 0.00174328 0.0122933  0.0122933  0.01109112 0.00406118\n",
      " 0.0122933  0.00174328 0.00366403 0.00366403 0.00406118 0.00406118\n",
      " 0.0122933  0.00853577 0.00406118 0.0122933  0.00366403 0.00406118\n",
      " 0.00366403 0.00174328 0.00174328 0.01109112 0.00174328 0.00174328\n",
      " 0.01109112 0.00406118 0.00174328 0.00366403 0.00366403 0.00366403\n",
      " 0.00853577 0.00174328 0.00366403 0.0122933  0.00406118 0.00366403\n",
      " 0.0122933  0.00174328 0.00366403 0.00527697 0.00853577 0.00527697\n",
      " 0.0122933  0.00174328 0.0122933  0.00527697 0.00174328 0.00366403\n",
      " 0.00174328 0.0122933  0.00174328 0.00366403 0.00527697 0.01109112\n",
      " 0.00366403 0.00366403 0.0122933  0.00366403 0.0122933  0.00174328\n",
      " 0.00174328 0.00406118 0.00853577 0.00366403 0.00174328 0.00366403\n",
      " 0.00527697 0.00406118 0.00174328 0.00366403 0.00366403 0.00366403\n",
      " 0.00174328 0.00366403 0.00366403 0.00406118 0.00174328 0.01109112\n",
      " 0.00527697 0.00366403 0.00174328 0.0122933  0.00406118 0.00527697\n",
      " 0.00174328 0.00366403 0.00366403 0.00366403 0.00406118 0.00366403\n",
      " 0.00174328 0.00174328 0.00406118 0.00366403 0.00366403 0.0122933\n",
      " 0.00406118 0.01109112 0.00366403 0.00174328 0.00174328 0.00174328\n",
      " 0.00366403 0.00406118 0.0122933  0.00174328 0.00406118 0.00406118\n",
      " 0.00406118 0.0122933  0.00174328 0.00366403 0.00406118 0.00527697\n",
      " 0.00406118 0.00406118 0.00366403 0.00174328 0.00366403]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.30010861594741883\n",
      "Alpha : 0.42339034753798355\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[31 48]\n",
      " [ 9 61]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6174496644295302\n",
      "Misclassification rate : 0.274\n",
      "True positives : 0.871\n",
      "False positives : 0.608\n",
      "Specificity : 0.392\n",
      "Precision : 0.6738208854134597\n",
      "Prevalence : 0.337\n",
      "Recall : 0.871\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[2 8]\n",
      " [2 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.4117647058823529\n",
      "Misclassification rate : 0.048\n",
      "True positives : 0.714\n",
      "False positives : 0.8\n",
      "Specificity : 0.2\n",
      "Precision : 0.45248868778280543\n",
      "Prevalence : 0.034\n",
      "Recall : 0.714\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00265935 0.00558942 0.01693758 0.00266222 0.00558942 0.00804993\n",
      " 0.00239929 0.00266222 0.00558942 0.00266222 0.00114154 0.00559545\n",
      " 0.00559545 0.00559545 0.00345548 0.00726272 0.00114154 0.00345548\n",
      " 0.00239929 0.00114154 0.00265935 0.00265935 0.00265935 0.00114154\n",
      " 0.00239929 0.00345548 0.00114154 0.00114154 0.00559545 0.00114154\n",
      " 0.00805862 0.00114154 0.00804993 0.01877347 0.00726272 0.00265935\n",
      " 0.00804993 0.00266222 0.00559545 0.00559545 0.00265935 0.00620195\n",
      " 0.00804993 0.00558942 0.00620195 0.00804993 0.00239929 0.00265935\n",
      " 0.00559545 0.00266222 0.00266222 0.00726272 0.00266222 0.00114154\n",
      " 0.01693758 0.00265935 0.00114154 0.00559545 0.00239929 0.00239929\n",
      " 0.00558942 0.00266222 0.00559545 0.00804993 0.00620195 0.00559545\n",
      " 0.00804993 0.00114154 0.00559545 0.00805862 0.00558942 0.00345548\n",
      " 0.00804993 0.00114154 0.00804993 0.00345548 0.00266222 0.00559545\n",
      " 0.00114154 0.00804993 0.00266222 0.00559545 0.00345548 0.00726272\n",
      " 0.00559545 0.00239929 0.00804993 0.00239929 0.00804993 0.00266222\n",
      " 0.00114154 0.00265935 0.00558942 0.00559545 0.00114154 0.00559545\n",
      " 0.00345548 0.00265935 0.00114154 0.00239929 0.00559545 0.00239929\n",
      " 0.00266222 0.00559545 0.00559545 0.00265935 0.00114154 0.00726272\n",
      " 0.00345548 0.00559545 0.00266222 0.01877347 0.00265935 0.00345548\n",
      " 0.00114154 0.00239929 0.00559545 0.00559545 0.00265935 0.00559545\n",
      " 0.00266222 0.00266222 0.00265935 0.00239929 0.00559545 0.00804993\n",
      " 0.00620195 0.00726272 0.00559545 0.00114154 0.00266222 0.00266222\n",
      " 0.00239929 0.00265935 0.00804993 0.00114154 0.00265935 0.00265935\n",
      " 0.00265935 0.01877347 0.00266222 0.00239929 0.00265935 0.00805862\n",
      " 0.00620195 0.00620195 0.00239929 0.00114154 0.00239929]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.31439917452435057\n",
      "Alpha : 0.3898160681546236\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[74  5]\n",
      " [53 17]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.610738255033557\n",
      "Misclassification rate : 0.279\n",
      "True positives : 0.243\n",
      "False positives : 0.063\n",
      "Specificity : 0.937\n",
      "Precision : 0.6719624506973235\n",
      "Prevalence : 0.337\n",
      "Recall : 0.243\n",
      "\n",
      ":: Teste ::\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[9 1]\n",
      " [6 1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5882352941176471\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.143\n",
      "False positives : 0.1\n",
      "Specificity : 0.9\n",
      "Precision : 0.5588235294117647\n",
      "Prevalence : 0.034\n",
      "Recall : 0.143\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00392709 0.00378505 0.01146982 0.00180281 0.00825395 0.00545127\n",
      " 0.00162476 0.00180281 0.00825395 0.00180281 0.00168573 0.00378914\n",
      " 0.00378914 0.00378914 0.00510274 0.00491818 0.00168573 0.00510274\n",
      " 0.00162476 0.00077303 0.00392709 0.00392709 0.00392709 0.00168573\n",
      " 0.00162476 0.00510274 0.00168573 0.00168573 0.00826285 0.00168573\n",
      " 0.00545715 0.00168573 0.00545127 0.02772295 0.00491818 0.00392709\n",
      " 0.00545127 0.00180281 0.00378914 0.00378914 0.00392709 0.00419984\n",
      " 0.00545127 0.00825395 0.00419984 0.01188741 0.00354306 0.00392709\n",
      " 0.00378914 0.00180281 0.00180281 0.00491818 0.00180281 0.00168573\n",
      " 0.01146982 0.00392709 0.00077303 0.00378914 0.00162476 0.00162476\n",
      " 0.00378505 0.00180281 0.00378914 0.00545127 0.00915848 0.00378914\n",
      " 0.01188741 0.00077303 0.00378914 0.00545715 0.00378505 0.00233999\n",
      " 0.01188741 0.00077303 0.00545127 0.00510274 0.00180281 0.00378914\n",
      " 0.00077303 0.01188741 0.00180281 0.00378914 0.00233999 0.00491818\n",
      " 0.00378914 0.00162476 0.00545127 0.00162476 0.01188741 0.00180281\n",
      " 0.00168573 0.00392709 0.00825395 0.00378914 0.00168573 0.00378914\n",
      " 0.00510274 0.00392709 0.00077303 0.00162476 0.00378914 0.00354306\n",
      " 0.00180281 0.00378914 0.00378914 0.00392709 0.00168573 0.00491818\n",
      " 0.00510274 0.00378914 0.00180281 0.01271304 0.00392709 0.00233999\n",
      " 0.00168573 0.00162476 0.00378914 0.00378914 0.00392709 0.00378914\n",
      " 0.00180281 0.00180281 0.00392709 0.00162476 0.00826285 0.00545127\n",
      " 0.00915848 0.00491818 0.00378914 0.00077303 0.00180281 0.00180281\n",
      " 0.00354306 0.00392709 0.01188741 0.00168573 0.00180086 0.00392709\n",
      " 0.00392709 0.01271304 0.00180281 0.00162476 0.00392709 0.00545715\n",
      " 0.00419984 0.00915848 0.00162476 0.00168573 0.00354306]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3529680664260112\n",
      "Alpha : 0.30300903009904895\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[62 17]\n",
      " [36 34]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6442953020134228\n",
      "Misclassification rate : 0.255\n",
      "True positives : 0.486\n",
      "False positives : 0.215\n",
      "Specificity : 0.785\n",
      "Precision : 0.6486326074053782\n",
      "Prevalence : 0.337\n",
      "Recall : 0.486\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 1]\n",
      " [3 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7647058823529411\n",
      "Misclassification rate : 0.019\n",
      "True positives : 0.571\n",
      "False positives : 0.1\n",
      "Specificity : 0.9\n",
      "Precision : 0.7705882352941177\n",
      "Prevalence : 0.034\n",
      "Recall : 0.571\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00290052 0.00279561 0.01552929 0.00244087 0.0060963  0.00402626\n",
      " 0.00120003 0.00133154 0.0060963  0.00244087 0.00228235 0.00279863\n",
      " 0.00279863 0.00279863 0.00690874 0.00363253 0.00228235 0.00690874\n",
      " 0.00120003 0.00104663 0.00290052 0.00290052 0.00290052 0.00124507\n",
      " 0.0021998  0.00376885 0.00124507 0.00124507 0.00610288 0.00124507\n",
      " 0.00403061 0.00228235 0.00738061 0.02047596 0.00363253 0.00531699\n",
      " 0.00738061 0.00133154 0.00279863 0.00279863 0.00531699 0.00568628\n",
      " 0.00402626 0.0060963  0.00310197 0.00877995 0.00261687 0.00531699\n",
      " 0.00279863 0.00244087 0.00244087 0.00363253 0.00133154 0.00124507\n",
      " 0.00847152 0.00531699 0.00104663 0.00279863 0.00120003 0.00120003\n",
      " 0.00279561 0.00244087 0.00279863 0.00402626 0.0123999  0.00279863\n",
      " 0.00877995 0.00104663 0.00279863 0.00403061 0.00279561 0.00316817\n",
      " 0.01609468 0.00057096 0.00738061 0.00376885 0.00244087 0.00279863\n",
      " 0.00057096 0.01609468 0.00244087 0.00279863 0.0017283  0.00363253\n",
      " 0.00279863 0.00120003 0.00402626 0.00120003 0.00877995 0.00133154\n",
      " 0.00124507 0.00290052 0.01117524 0.00279863 0.00228235 0.00279863\n",
      " 0.00690874 0.00531699 0.00104663 0.0021998  0.00279863 0.00261687\n",
      " 0.00244087 0.00279863 0.00279863 0.00290052 0.00228235 0.00363253\n",
      " 0.00376885 0.00279863 0.00133154 0.01721253 0.00531699 0.00316817\n",
      " 0.00124507 0.00120003 0.00279863 0.00279863 0.00290052 0.00279863\n",
      " 0.00244087 0.00244087 0.00290052 0.00120003 0.00610288 0.00738061\n",
      " 0.0123999  0.00363253 0.00279863 0.00057096 0.00133154 0.00133154\n",
      " 0.00479704 0.00290052 0.01609468 0.00124507 0.00243824 0.00531699\n",
      " 0.00290052 0.00938976 0.00133154 0.00120003 0.00531699 0.00738858\n",
      " 0.00568628 0.0123999  0.00120003 0.00228235 0.00261687]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3123303322509476\n",
      "Alpha : 0.3946236018052254\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[57 22]\n",
      " [21 49]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7114093959731543\n",
      "Misclassification rate : 0.207\n",
      "True positives : 0.7\n",
      "False positives : 0.278\n",
      "Specificity : 0.722\n",
      "Precision : 0.7116820697026764\n",
      "Prevalence : 0.337\n",
      "Recall : 0.7\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[5 5]\n",
      " [2 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5882352941176471\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.714\n",
      "False positives : 0.5\n",
      "Specificity : 0.5\n",
      "Precision : 0.6260504201680672\n",
      "Prevalence : 0.034\n",
      "Recall : 0.714\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00430387 0.0041482  0.01046571 0.00164498 0.00904585 0.00597427\n",
      " 0.00080874 0.00197577 0.00904585 0.00164498 0.00153815 0.00188609\n",
      " 0.00188609 0.00188609 0.00465603 0.00539004 0.00153815 0.00465603\n",
      " 0.00080874 0.00070536 0.00195476 0.00430387 0.00195476 0.00083909\n",
      " 0.00148252 0.00253995 0.00083909 0.00083909 0.00411294 0.00083909\n",
      " 0.00271636 0.00153815 0.01095154 0.01379944 0.00244808 0.0035833\n",
      " 0.01095154 0.00089737 0.00188609 0.00415267 0.0035833  0.00383218\n",
      " 0.00597427 0.00904585 0.00460279 0.01302792 0.00388298 0.00788949\n",
      " 0.00188609 0.00164498 0.00362183 0.00244808 0.00089737 0.00083909\n",
      " 0.00570924 0.0035833  0.00070536 0.00188609 0.00080874 0.00080874\n",
      " 0.0041482  0.00362183 0.00415267 0.00597427 0.00835671 0.00188609\n",
      " 0.00591711 0.00070536 0.00188609 0.00271636 0.0041482  0.00213514\n",
      " 0.0238817  0.00038479 0.01095154 0.00253995 0.00164498 0.00188609\n",
      " 0.00038479 0.01084675 0.00164498 0.00188609 0.00116476 0.00539004\n",
      " 0.00188609 0.00178064 0.00597427 0.00178064 0.00591711 0.00089737\n",
      " 0.00083909 0.00430387 0.0165821  0.00188609 0.00153815 0.00188609\n",
      " 0.00465603 0.0035833  0.00070536 0.00148252 0.00415267 0.00388298\n",
      " 0.00164498 0.00188609 0.00188609 0.00430387 0.00153815 0.00539004\n",
      " 0.00253995 0.00188609 0.00089737 0.0116001  0.0035833  0.00213514\n",
      " 0.00083909 0.00080874 0.00188609 0.00188609 0.00195476 0.00188609\n",
      " 0.00362183 0.00362183 0.00430387 0.00080874 0.00905561 0.00497404\n",
      " 0.0183993  0.00539004 0.00188609 0.00038479 0.00089737 0.00089737\n",
      " 0.00323288 0.00430387 0.01084675 0.00083909 0.00164321 0.0035833\n",
      " 0.00195476 0.00632807 0.00089737 0.00178064 0.0035833  0.00497941\n",
      " 0.00383218 0.00835671 0.00080874 0.00153815 0.0017636 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.29673599061966477\n",
      "Alpha : 0.4314447725379947\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[39 40]\n",
      " [23 47]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5771812080536913\n",
      "Misclassification rate : 0.303\n",
      "True positives : 0.671\n",
      "False positives : 0.506\n",
      "Specificity : 0.494\n",
      "Precision : 0.5873130224236226\n",
      "Prevalence : 0.337\n",
      "Recall : 0.671\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[6 4]\n",
      " [3 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5882352941176471\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.571\n",
      "False positives : 0.4\n",
      "Specificity : 0.6\n",
      "Precision : 0.5980392156862745\n",
      "Prevalence : 0.034\n",
      "Recall : 0.571\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00279566 0.00269454 0.00679821 0.00253242 0.00587591 0.00388071\n",
      " 0.00124504 0.00304166 0.01392591 0.00106853 0.00236796 0.00122515\n",
      " 0.00122515 0.00122515 0.00302442 0.00350121 0.00099914 0.00302442\n",
      " 0.00052533 0.00108588 0.00126975 0.00279566 0.00300931 0.00054505\n",
      " 0.00228231 0.00164988 0.00054505 0.00129176 0.00633179 0.00129176\n",
      " 0.00418179 0.00099914 0.00711379 0.0089637  0.0015902  0.0023276\n",
      " 0.00711379 0.0005829  0.00122515 0.00269745 0.0023276  0.00589956\n",
      " 0.00388071 0.00587591 0.00298983 0.00846254 0.00252227 0.00512478\n",
      " 0.0029036  0.00253242 0.00235263 0.00376878 0.00138148 0.00054505\n",
      " 0.00370855 0.00551642 0.00108588 0.0029036  0.00124504 0.00052533\n",
      " 0.00269454 0.00235263 0.00639296 0.00919727 0.01286499 0.0029036\n",
      " 0.00384357 0.00108588 0.00122515 0.00418179 0.00638607 0.00138692\n",
      " 0.01551284 0.00059237 0.00711379 0.00164988 0.00253242 0.00122515\n",
      " 0.00059237 0.00704572 0.00106853 0.00122515 0.00075659 0.00350121\n",
      " 0.0029036  0.00115665 0.00919727 0.00115665 0.00384357 0.00138148\n",
      " 0.00129176 0.00279566 0.01077124 0.00122515 0.00099914 0.0029036\n",
      " 0.00302442 0.00551642 0.00108588 0.00228231 0.00639296 0.00597778\n",
      " 0.00253242 0.00122515 0.00122515 0.00279566 0.00099914 0.00350121\n",
      " 0.00164988 0.00122515 0.00138148 0.00753508 0.00551642 0.003287\n",
      " 0.00129176 0.00052533 0.0029036  0.00122515 0.00300931 0.00122515\n",
      " 0.00235263 0.00557573 0.00279566 0.00052533 0.00588225 0.00323099\n",
      " 0.02832535 0.00829786 0.00122515 0.00059237 0.00138148 0.00138148\n",
      " 0.00497696 0.00662572 0.00704572 0.00054505 0.00106738 0.0023276\n",
      " 0.00300931 0.00411053 0.00138148 0.00274126 0.00551642 0.00323448\n",
      " 0.00589956 0.00542827 0.00124504 0.00099914 0.00271503]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.29795883890641567\n",
      "Alpha : 0.4285183419265614\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[65 14]\n",
      " [26 44]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7315436241610739\n",
      "Misclassification rate : 0.192\n",
      "True positives : 0.629\n",
      "False positives : 0.177\n",
      "Specificity : 0.823\n",
      "Precision : 0.7351142262042516\n",
      "Prevalence : 0.337\n",
      "Recall : 0.629\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 2]\n",
      " [1 6]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8235294117647058\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.857\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.8316993464052288\n",
      "Prevalence : 0.034\n",
      "Recall : 0.857\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00429129 0.00413608 0.00442886 0.00164981 0.003828   0.00252818\n",
      " 0.00081111 0.00198156 0.02137601 0.00069612 0.00154266 0.00079815\n",
      " 0.00079815 0.00079815 0.00197033 0.00537429 0.00065091 0.00464243\n",
      " 0.00034224 0.00166681 0.00194905 0.00429129 0.00461924 0.00035508\n",
      " 0.00148686 0.00253253 0.00035508 0.00084155 0.00412499 0.00084155\n",
      " 0.00641897 0.00065091 0.01091954 0.01375912 0.00244093 0.00151637\n",
      " 0.01091954 0.00037975 0.00188058 0.00175732 0.00357283 0.00384341\n",
      " 0.00252818 0.003828   0.0019478  0.00551312 0.00164319 0.00333866\n",
      " 0.00189162 0.00164981 0.00153268 0.00245526 0.0009     0.00035508\n",
      " 0.00569256 0.0035938  0.00070743 0.00189162 0.00081111 0.00034224\n",
      " 0.00175542 0.00153268 0.00416484 0.00599178 0.0083812  0.00189162\n",
      " 0.00589981 0.00166681 0.00079815 0.00272432 0.00416035 0.0021289\n",
      " 0.02381192 0.00038591 0.01091954 0.00253253 0.00164981 0.00079815\n",
      " 0.00038591 0.0045901  0.00069612 0.00079815 0.0004929  0.00228094\n",
      " 0.00189162 0.00075353 0.00599178 0.00075353 0.00589981 0.0009\n",
      " 0.00084155 0.0018213  0.00701718 0.00079815 0.00153366 0.00189162\n",
      " 0.00464243 0.0035938  0.00070743 0.0035033  0.00416484 0.00389436\n",
      " 0.00164981 0.00079815 0.00079815 0.0018213  0.00065091 0.00537429\n",
      " 0.00253253 0.00079815 0.0009     0.01156621 0.0035938  0.00504549\n",
      " 0.00084155 0.00034224 0.00189162 0.00079815 0.00196049 0.00079815\n",
      " 0.00153268 0.00363244 0.0018213  0.00080638 0.00383213 0.00495951\n",
      " 0.01845322 0.00540584 0.00079815 0.00038591 0.00212055 0.0009\n",
      " 0.00324236 0.00431648 0.01081505 0.00035508 0.00163841 0.00151637\n",
      " 0.00196049 0.00630958 0.0009     0.00178586 0.0035938  0.00496486\n",
      " 0.00384341 0.00353637 0.00081111 0.00065091 0.00416751]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.25660291917041383\n",
      "Alpha : 0.5318502513047951\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[43 36]\n",
      " [17 53]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6442953020134228\n",
      "Misclassification rate : 0.255\n",
      "True positives : 0.757\n",
      "False positives : 0.456\n",
      "Specificity : 0.544\n",
      "Precision : 0.6597453686247895\n",
      "Prevalence : 0.337\n",
      "Recall : 0.757\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 6]\n",
      " [1 6]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5882352941176471\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.857\n",
      "False positives : 0.6\n",
      "Specificity : 0.4\n",
      "Precision : 0.6764705882352942\n",
      "Prevalence : 0.034\n",
      "Recall : 0.857\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0025212  0.00703993 0.00260203 0.00096929 0.00224902 0.00430316\n",
      " 0.00047654 0.00337278 0.01255877 0.00118485 0.00090634 0.00135852\n",
      " 0.00135852 0.00135852 0.00335365 0.00914746 0.00038242 0.0027275\n",
      " 0.00020107 0.00097928 0.0011451  0.0025212  0.0078623  0.00020862\n",
      " 0.00253076 0.00431057 0.00020862 0.00049443 0.0024235  0.00049443\n",
      " 0.00377125 0.00038242 0.00641542 0.00808371 0.00143409 0.00089089\n",
      " 0.00641542 0.00064636 0.00320089 0.0029911  0.0020991  0.00225807\n",
      " 0.00430316 0.00651556 0.0033153  0.00938377 0.0009654  0.00196152\n",
      " 0.00111136 0.00096929 0.00260873 0.00144251 0.00052877 0.00020862\n",
      " 0.00968918 0.00211142 0.00120409 0.00321968 0.00047654 0.00058252\n",
      " 0.00103134 0.00260873 0.00708889 0.01019848 0.0049241  0.00321968\n",
      " 0.00346624 0.00097928 0.00135852 0.00160059 0.00708125 0.00125076\n",
      " 0.0139899  0.00022673 0.00641542 0.00431057 0.00096929 0.00135852\n",
      " 0.00022673 0.00269676 0.00118485 0.00046893 0.00028959 0.00388235\n",
      " 0.00111136 0.00128256 0.00352027 0.00128256 0.00346624 0.00153187\n",
      " 0.00049443 0.0031     0.01194379 0.00135852 0.00090105 0.00111136\n",
      " 0.0027275  0.00211142 0.00041562 0.00205825 0.00244692 0.00662851\n",
      " 0.00096929 0.00046893 0.00135852 0.0031     0.00038242 0.00315749\n",
      " 0.0014879  0.00046893 0.00052877 0.00679534 0.00211142 0.00296431\n",
      " 0.00049443 0.00058252 0.00111136 0.00046893 0.00115182 0.00046893\n",
      " 0.00260873 0.00213412 0.00107004 0.00137252 0.00225144 0.0029138\n",
      " 0.01084158 0.00920116 0.00046893 0.00022673 0.00124586 0.00153187\n",
      " 0.00190494 0.002536   0.00635403 0.00020862 0.0027887  0.00089089\n",
      " 0.0033369  0.00370699 0.00052877 0.00104922 0.00211142 0.00291694\n",
      " 0.00654178 0.00601919 0.00047654 0.0011079  0.00244849]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 3\n",
      "################################################\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  51  52\n",
      "  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165] [34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50]\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.22147651006711436\n",
      "Alpha : 0.6285413148199415\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[67 17]\n",
      " [16 49]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7785234899328859\n",
      "Misclassification rate : 0.159\n",
      "True positives : 0.754\n",
      "False positives : 0.202\n",
      "Specificity : 0.798\n",
      "Precision : 0.778958420625761\n",
      "Prevalence : 0.312\n",
      "Recall : 0.754\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 2]\n",
      " [7 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.47058823529411764\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.417\n",
      "False positives : 0.4\n",
      "Specificity : 0.6\n",
      "Precision : 0.592436974789916\n",
      "Prevalence : 0.058\n",
      "Recall : 0.417\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00357966 0.01258305 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.01258305 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.01258305 0.00357966 0.00357966\n",
      " 0.00357966 0.01258305 0.00357966 0.01258305 0.00357966 0.00357966\n",
      " 0.00357966 0.01258305 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.01258305 0.00357966\n",
      " 0.01258305 0.00357966 0.01258305 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.01258305 0.00357966 0.00357966\n",
      " 0.01258305 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.01258305 0.01258305 0.00357966 0.00357966 0.00357966 0.01258305\n",
      " 0.01258305 0.00357966 0.01258305 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.01258305 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.01258305 0.00357966 0.00357966 0.01258305 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966 0.01258305\n",
      " 0.01258305 0.00357966 0.00357966 0.01258305 0.00357966 0.01258305\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.01258305 0.00357966 0.01258305\n",
      " 0.00357966 0.01258305 0.00357966 0.00357966 0.01258305 0.00357966\n",
      " 0.00357966 0.00357966 0.01258305 0.00357966 0.01258305 0.00357966\n",
      " 0.00357966 0.01258305 0.00357966 0.01258305 0.00357966 0.01258305\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.01258305]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2979362591431558\n",
      "Alpha : 0.42857231535573753\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[56 28]\n",
      " [21 44]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6711409395973155\n",
      "Misclassification rate : 0.236\n",
      "True positives : 0.677\n",
      "False positives : 0.333\n",
      "Specificity : 0.667\n",
      "Precision : 0.6765981967324249\n",
      "Prevalence : 0.312\n",
      "Recall : 0.677\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 1]\n",
      " [4 8]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7058823529411765\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.667\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.7745098039215685\n",
      "Prevalence : 0.058\n",
      "Recall : 0.667\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00549501 0.01931578 0.00233193 0.00233193 0.00549501 0.00549501\n",
      " 0.00233193 0.00549501 0.00819708 0.00233193 0.00233193 0.00233193\n",
      " 0.00233193 0.00549501 0.00233193 0.01931578 0.00233193 0.00233193\n",
      " 0.00549501 0.01931578 0.00549501 0.00819708 0.00233193 0.00233193\n",
      " 0.00549501 0.00819708 0.00233193 0.00549501 0.00549501 0.00233193\n",
      " 0.00233193 0.00233193 0.00549501 0.00233193 0.00819708 0.00549501\n",
      " 0.01931578 0.00233193 0.00819708 0.00549501 0.00233193 0.00549501\n",
      " 0.00549501 0.00549501 0.00549501 0.00549501 0.00549501 0.00233193\n",
      " 0.00233193 0.00233193 0.00549501 0.00819708 0.00233193 0.00233193\n",
      " 0.00819708 0.00233193 0.00549501 0.00549501 0.00233193 0.00233193\n",
      " 0.00549501 0.00549501 0.00549501 0.00549501 0.00233193 0.00233193\n",
      " 0.00819708 0.00819708 0.00549501 0.00233193 0.00549501 0.00819708\n",
      " 0.01931578 0.00233193 0.01931578 0.00233193 0.00233193 0.00233193\n",
      " 0.00233193 0.00549501 0.00233193 0.00549501 0.00233193 0.00233193\n",
      " 0.00233193 0.00549501 0.00549501 0.00233193 0.01931578 0.00233193\n",
      " 0.00233193 0.00549501 0.00549501 0.00233193 0.00233193 0.00233193\n",
      " 0.00819708 0.00233193 0.00233193 0.00819708 0.00549501 0.00549501\n",
      " 0.00233193 0.00233193 0.00233193 0.00233193 0.00233193 0.00819708\n",
      " 0.00819708 0.00233193 0.00233193 0.00819708 0.00233193 0.00819708\n",
      " 0.00233193 0.00233193 0.00233193 0.00233193 0.00233193 0.00233193\n",
      " 0.00549501 0.00549501 0.00549501 0.00819708 0.00233193 0.00819708\n",
      " 0.00549501 0.01931578 0.00233193 0.00233193 0.00819708 0.00233193\n",
      " 0.00233193 0.00549501 0.00819708 0.00233193 0.00819708 0.00233193\n",
      " 0.00233193 0.00819708 0.00233193 0.00819708 0.00233193 0.00819708\n",
      " 0.00233193 0.00233193 0.00233193 0.00233193 0.00819708]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2770144469479923\n",
      "Alpha : 0.4796597900687387\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[51 33]\n",
      " [22 43]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6308724832214765\n",
      "Misclassification rate : 0.264\n",
      "True positives : 0.662\n",
      "False positives : 0.393\n",
      "Specificity : 0.607\n",
      "Precision : 0.640679512055859\n",
      "Prevalence : 0.312\n",
      "Recall : 0.662\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[ 4  1]\n",
      " [ 2 10]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8235294117647058\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.833\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.8377896613190731\n",
      "Prevalence : 0.058\n",
      "Recall : 0.833\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00340138 0.01195635 0.00144345 0.00376729 0.00340138 0.00340138\n",
      " 0.00144345 0.00340138 0.00507394 0.00376729 0.00144345 0.00376729\n",
      " 0.00376729 0.00340138 0.00376729 0.01195635 0.00376729 0.00144345\n",
      " 0.00340138 0.01195635 0.00340138 0.00507394 0.00144345 0.00144345\n",
      " 0.00340138 0.00507394 0.00144345 0.00340138 0.00340138 0.00376729\n",
      " 0.00144345 0.00376729 0.00340138 0.00376729 0.00507394 0.00887732\n",
      " 0.01195635 0.00376729 0.01324258 0.00887732 0.00144345 0.00887732\n",
      " 0.00887732 0.00340138 0.00340138 0.00340138 0.00340138 0.00144345\n",
      " 0.00376729 0.00144345 0.00340138 0.00507394 0.00376729 0.00144345\n",
      " 0.00507394 0.00376729 0.00887732 0.00887732 0.00144345 0.00144345\n",
      " 0.00340138 0.00340138 0.00887732 0.00887732 0.00144345 0.00144345\n",
      " 0.00507394 0.00507394 0.00887732 0.00376729 0.00340138 0.00507394\n",
      " 0.01195635 0.00376729 0.01195635 0.00144345 0.00376729 0.00376729\n",
      " 0.00144345 0.00340138 0.00376729 0.00887732 0.00144345 0.00144345\n",
      " 0.00376729 0.00340138 0.00887732 0.00144345 0.01195635 0.00144345\n",
      " 0.00144345 0.00887732 0.00340138 0.00376729 0.00144345 0.00376729\n",
      " 0.00507394 0.00144345 0.00144345 0.00507394 0.00340138 0.00340138\n",
      " 0.00376729 0.00376729 0.00144345 0.00376729 0.00376729 0.00507394\n",
      " 0.00507394 0.00144345 0.00376729 0.01324258 0.00376729 0.00507394\n",
      " 0.00144345 0.00144345 0.00376729 0.00144345 0.00144345 0.00376729\n",
      " 0.00340138 0.00340138 0.00340138 0.00507394 0.00144345 0.01324258\n",
      " 0.00887732 0.01195635 0.00144345 0.00144345 0.01324258 0.00376729\n",
      " 0.00144345 0.00340138 0.01324258 0.00144345 0.00507394 0.00376729\n",
      " 0.00144345 0.01324258 0.00376729 0.01324258 0.00144345 0.00507394\n",
      " 0.00376729 0.00376729 0.00144345 0.00376729 0.00507394]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2861489309780387\n",
      "Alpha : 0.4570809704049355\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[78  6]\n",
      " [47 18]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6442953020134228\n",
      "Misclassification rate : 0.255\n",
      "True positives : 0.277\n",
      "False positives : 0.071\n",
      "Specificity : 0.929\n",
      "Precision : 0.6789664429530201\n",
      "Prevalence : 0.312\n",
      "Recall : 0.277\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[ 4  1]\n",
      " [11  1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.29411764705882354\n",
      "Misclassification rate : 0.058\n",
      "True positives : 0.083\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.4313725490196078\n",
      "Prevalence : 0.058\n",
      "Recall : 0.083\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00537233 0.00756992 0.00091389 0.00238518 0.00537233 0.00215351\n",
      " 0.00091389 0.00215351 0.00801407 0.00238518 0.00227987 0.00238518\n",
      " 0.00238518 0.00215351 0.00595027 0.00756992 0.00595027 0.00091389\n",
      " 0.00215351 0.00756992 0.00215351 0.00321246 0.00227987 0.00227987\n",
      " 0.00537233 0.00321246 0.00227987 0.00215351 0.00215351 0.00238518\n",
      " 0.00227987 0.00238518 0.00215351 0.00595027 0.00321246 0.01402134\n",
      " 0.00756992 0.00238518 0.00838427 0.00562049 0.00227987 0.00562049\n",
      " 0.00562049 0.00537233 0.00215351 0.00537233 0.00537233 0.00227987\n",
      " 0.00238518 0.00091389 0.00215351 0.00321246 0.00238518 0.00227987\n",
      " 0.00321246 0.00595027 0.00562049 0.00562049 0.00227987 0.00091389\n",
      " 0.00215351 0.00215351 0.00562049 0.00562049 0.00227987 0.00091389\n",
      " 0.00801407 0.00321246 0.00562049 0.00238518 0.00215351 0.00321246\n",
      " 0.01888454 0.00238518 0.00756992 0.00227987 0.00238518 0.00238518\n",
      " 0.00091389 0.00537233 0.00238518 0.00562049 0.00091389 0.00091389\n",
      " 0.00238518 0.00215351 0.00562049 0.00091389 0.01888454 0.00091389\n",
      " 0.00227987 0.01402134 0.00537233 0.00238518 0.00227987 0.00238518\n",
      " 0.00801407 0.00227987 0.00091389 0.00321246 0.00215351 0.00537233\n",
      " 0.00238518 0.00238518 0.00091389 0.00595027 0.00595027 0.00321246\n",
      " 0.00801407 0.00091389 0.00238518 0.00838427 0.00595027 0.00321246\n",
      " 0.00227987 0.00091389 0.00238518 0.00091389 0.00227987 0.00238518\n",
      " 0.00215351 0.00215351 0.00537233 0.00321246 0.00227987 0.00838427\n",
      " 0.01402134 0.00756992 0.00091389 0.00091389 0.00838427 0.00238518\n",
      " 0.00227987 0.00537233 0.02091609 0.00227987 0.00321246 0.00595027\n",
      " 0.00227987 0.00838427 0.00238518 0.00838427 0.00227987 0.00321246\n",
      " 0.00238518 0.00595027 0.00091389 0.00595027 0.00801407]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3432331064364485\n",
      "Alpha : 0.32445966213613525\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[71 13]\n",
      " [30 35]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7114093959731543\n",
      "Misclassification rate : 0.207\n",
      "True positives : 0.538\n",
      "False positives : 0.155\n",
      "Specificity : 0.845\n",
      "Precision : 0.7143982435156266\n",
      "Prevalence : 0.312\n",
      "Recall : 0.538\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 1]\n",
      " [7 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5294117647058824\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.417\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.6951871657754011\n",
      "Prevalence : 0.058\n",
      "Recall : 0.417\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00388375 0.00547243 0.00066067 0.00172429 0.00388375 0.00297891\n",
      " 0.00066067 0.00155681 0.00579352 0.00172429 0.00164816 0.00172429\n",
      " 0.00172429 0.00155681 0.0082309  0.00547243 0.00430155 0.00066067\n",
      " 0.00297891 0.01047133 0.00155681 0.00444374 0.0031537  0.0031537\n",
      " 0.00388375 0.00444374 0.00164816 0.00155681 0.00155681 0.00172429\n",
      " 0.00164816 0.00172429 0.00155681 0.00430155 0.00444374 0.01939549\n",
      " 0.01047133 0.00172429 0.00606114 0.00406315 0.0031537  0.00406315\n",
      " 0.00777473 0.00388375 0.00155681 0.00743145 0.00388375 0.00164816\n",
      " 0.00172429 0.00126417 0.00155681 0.00444374 0.00172429 0.00164816\n",
      " 0.00444374 0.00430155 0.00406315 0.00406315 0.00164816 0.00066067\n",
      " 0.00155681 0.00155681 0.00406315 0.00777473 0.00164816 0.00126417\n",
      " 0.00579352 0.00232235 0.00406315 0.00172429 0.00297891 0.00444374\n",
      " 0.01365197 0.00172429 0.01047133 0.0031537  0.00329938 0.00172429\n",
      " 0.00066067 0.00388375 0.00172429 0.00406315 0.00126417 0.00126417\n",
      " 0.00172429 0.00155681 0.00777473 0.00066067 0.01365197 0.00066067\n",
      " 0.00164816 0.01013628 0.00743145 0.00172429 0.0031537  0.00329938\n",
      " 0.01108573 0.00164816 0.00066067 0.00232235 0.00155681 0.00388375\n",
      " 0.00172429 0.00172429 0.00066067 0.0082309  0.00430155 0.00232235\n",
      " 0.00579352 0.00066067 0.00172429 0.01159781 0.00430155 0.00444374\n",
      " 0.0031537  0.00066067 0.00329938 0.00066067 0.00164816 0.00172429\n",
      " 0.00155681 0.00155681 0.00388375 0.00232235 0.00164816 0.01159781\n",
      " 0.01939549 0.01047133 0.00066067 0.00066067 0.00606114 0.00172429\n",
      " 0.00164816 0.00388375 0.02893287 0.00164816 0.00232235 0.00430155\n",
      " 0.00164816 0.01159781 0.00172429 0.00606114 0.00164816 0.00444374\n",
      " 0.00329938 0.00430155 0.00066067 0.00430155 0.00579352]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.26701962007323327\n",
      "Alpha : 0.5048983977977692\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[26 58]\n",
      " [ 8 57]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5570469798657718\n",
      "Misclassification rate : 0.317\n",
      "True positives : 0.877\n",
      "False positives : 0.69\n",
      "Specificity : 0.31\n",
      "Precision : 0.6473334592080193\n",
      "Prevalence : 0.312\n",
      "Recall : 0.877\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[0 5]\n",
      " [5 7]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.4117647058823529\n",
      "Misclassification rate : 0.048\n",
      "True positives : 0.583\n",
      "False positives : 1.0\n",
      "Specificity : 0.0\n",
      "Precision : 0.4117647058823529\n",
      "Prevalence : 0.058\n",
      "Recall : 0.583\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0023441  0.00330298 0.0010946  0.00285683 0.0023441  0.00179797\n",
      " 0.00039876 0.00093964 0.00349677 0.00285683 0.00099477 0.00285683\n",
      " 0.00285683 0.00093964 0.0136371  0.00330298 0.00259628 0.00039876\n",
      " 0.00179797 0.00632015 0.00257935 0.0026821  0.00190347 0.0052251\n",
      " 0.00643467 0.0026821  0.00099477 0.00257935 0.00257935 0.00285683\n",
      " 0.00099477 0.00285683 0.00093964 0.00712689 0.0026821  0.01170647\n",
      " 0.00632015 0.00285683 0.01004219 0.0067319  0.00190347 0.00245238\n",
      " 0.00469257 0.0023441  0.00257935 0.01231255 0.0023441  0.00099477\n",
      " 0.00285683 0.0020945  0.00257935 0.0026821  0.00285683 0.00099477\n",
      " 0.00736247 0.00259628 0.0067319  0.0067319  0.00099477 0.00039876\n",
      " 0.00257935 0.00257935 0.00245238 0.00469257 0.00273069 0.0020945\n",
      " 0.00349677 0.0038477  0.0067319  0.00285683 0.00493552 0.0026821\n",
      " 0.00823988 0.00285683 0.00632015 0.00190347 0.00546647 0.00285683\n",
      " 0.0010946  0.0023441  0.00285683 0.0067319  0.00076301 0.0020945\n",
      " 0.00104072 0.00093964 0.00469257 0.0010946  0.00823988 0.0010946\n",
      " 0.00273069 0.00611792 0.00448538 0.00285683 0.00190347 0.00546647\n",
      " 0.00669098 0.00099477 0.0010946  0.0038477  0.00093964 0.00643467\n",
      " 0.00285683 0.00285683 0.0010946  0.0049679  0.00259628 0.0038477\n",
      " 0.00349677 0.0010946  0.00285683 0.00700006 0.00259628 0.0026821\n",
      " 0.00190347 0.00039876 0.0019914  0.0010946  0.00099477 0.00285683\n",
      " 0.00257935 0.00257935 0.0023441  0.0038477  0.00273069 0.00700006\n",
      " 0.01170647 0.00632015 0.00039876 0.0010946  0.01004219 0.00104072\n",
      " 0.00099477 0.0023441  0.01746292 0.00099477 0.00140169 0.00259628\n",
      " 0.00099477 0.00700006 0.00285683 0.0036583  0.00099477 0.00736247\n",
      " 0.00546647 0.00259628 0.00039876 0.00259628 0.00349677]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.33616481227237355\n",
      "Alpha : 0.3402161774983915\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[82  2]\n",
      " [55 10]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6174496644295302\n",
      "Misclassification rate : 0.274\n",
      "True positives : 0.154\n",
      "False positives : 0.024\n",
      "Specificity : 0.976\n",
      "Precision : 0.7009667042244322\n",
      "Prevalence : 0.312\n",
      "Recall : 0.154\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[ 4  1]\n",
      " [11  1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.29411764705882354\n",
      "Misclassification rate : 0.058\n",
      "True positives : 0.083\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.4313725490196078\n",
      "Prevalence : 0.058\n",
      "Recall : 0.083\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00329405 0.00235045 0.00077894 0.00203297 0.00329405 0.00252661\n",
      " 0.00028376 0.00066866 0.00491385 0.00203297 0.0013979  0.00203297\n",
      " 0.00203297 0.00066866 0.01916356 0.00235045 0.00364842 0.00028376\n",
      " 0.00252661 0.00449752 0.00183551 0.00376902 0.00267485 0.00734258\n",
      " 0.00457901 0.00376902 0.0013979  0.00183551 0.00183551 0.00203297\n",
      " 0.0013979  0.00203297 0.00066866 0.00507161 0.00190862 0.00833052\n",
      " 0.0088814  0.00203297 0.00714619 0.00479053 0.00267485 0.00174516\n",
      " 0.00659424 0.00329405 0.00183551 0.00876181 0.0016681  0.0013979\n",
      " 0.00203297 0.00294329 0.00183551 0.00376902 0.00203297 0.0013979\n",
      " 0.00523925 0.00364842 0.00479053 0.00479053 0.0007079  0.00028376\n",
      " 0.00183551 0.00183551 0.00174516 0.00659424 0.00383731 0.00149048\n",
      " 0.00491385 0.00273809 0.00479053 0.00203297 0.00351219 0.00376902\n",
      " 0.0115791  0.00203297 0.0088814  0.00267485 0.00389003 0.00203297\n",
      " 0.00077894 0.00329405 0.00203297 0.00479053 0.00107222 0.00149048\n",
      " 0.0007406  0.00066866 0.00659424 0.00077894 0.0115791  0.00077894\n",
      " 0.00383731 0.00435361 0.00630308 0.00203297 0.00267485 0.00389003\n",
      " 0.00940251 0.0013979  0.00077894 0.00273809 0.00066866 0.00457901\n",
      " 0.00203297 0.00203297 0.00077894 0.00698115 0.00364842 0.00273809\n",
      " 0.00491385 0.00077894 0.00203297 0.00498135 0.00364842 0.00376902\n",
      " 0.00267485 0.00028376 0.00141711 0.00077894 0.0013979  0.00203297\n",
      " 0.00183551 0.00183551 0.00329405 0.00273809 0.00194321 0.00498135\n",
      " 0.00833052 0.00449752 0.00028376 0.00077894 0.00714619 0.0007406\n",
      " 0.0013979  0.00329405 0.0124269  0.0013979  0.00196973 0.00364842\n",
      " 0.0013979  0.00498135 0.00203297 0.00260331 0.0013979  0.00523925\n",
      " 0.00768176 0.00364842 0.00028376 0.00364842 0.00248836]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.27858564709863964\n",
      "Alpha : 0.4757440610517104\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[29 55]\n",
      " [ 8 57]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5771812080536913\n",
      "Misclassification rate : 0.303\n",
      "True positives : 0.877\n",
      "False positives : 0.655\n",
      "Specificity : 0.345\n",
      "Precision : 0.6638805032261408\n",
      "Prevalence : 0.312\n",
      "Recall : 0.877\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[1 4]\n",
      " [4 8]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5294117647058824\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.667\n",
      "False positives : 0.8\n",
      "Specificity : 0.2\n",
      "Precision : 0.5294117647058824\n",
      "Prevalence : 0.058\n",
      "Recall : 0.667\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00530083 0.00378237 0.00048405 0.00126333 0.002047   0.00157009\n",
      " 0.00045663 0.00041552 0.00790742 0.00126333 0.00086869 0.00327147\n",
      " 0.00327147 0.00107602 0.01190866 0.00378237 0.00226721 0.00045663\n",
      " 0.00157009 0.00279486 0.00295372 0.00606515 0.00166221 0.00456285\n",
      " 0.0073686  0.00234215 0.00086869 0.00295372 0.00295372 0.00126333\n",
      " 0.00086869 0.00327147 0.00107602 0.00315161 0.00118606 0.00517677\n",
      " 0.0055191  0.00126333 0.0044408  0.00297694 0.00166221 0.00108448\n",
      " 0.00409781 0.00530083 0.00114063 0.00544479 0.00268433 0.00086869\n",
      " 0.00327147 0.00182903 0.00114063 0.00234215 0.00327147 0.00086869\n",
      " 0.00325579 0.00226721 0.00297694 0.00770898 0.00113915 0.00045663\n",
      " 0.00295372 0.00114063 0.00280833 0.00409781 0.00238459 0.00239849\n",
      " 0.00790742 0.00440616 0.00770898 0.00126333 0.00565186 0.00234215\n",
      " 0.00719551 0.00126333 0.0055191  0.0043044  0.00241735 0.00327147\n",
      " 0.00048405 0.002047   0.00126333 0.00770898 0.0006663  0.00239849\n",
      " 0.00119178 0.00107602 0.00409781 0.00125348 0.00719551 0.00125348\n",
      " 0.00238459 0.00270543 0.00391688 0.00327147 0.00166221 0.00625987\n",
      " 0.00584293 0.00086869 0.00048405 0.00440616 0.00107602 0.0073686\n",
      " 0.00126333 0.00126333 0.00125348 0.00433824 0.00226721 0.00440616\n",
      " 0.00305358 0.00125348 0.00126333 0.00309553 0.00226721 0.00234215\n",
      " 0.00166221 0.00045663 0.00228043 0.00125348 0.00224952 0.00327147\n",
      " 0.00295372 0.00295372 0.00530083 0.00440616 0.00120755 0.00309553\n",
      " 0.00517677 0.00723746 0.00045663 0.00048405 0.0044408  0.00119178\n",
      " 0.00086869 0.002047   0.00772236 0.00086869 0.00122403 0.00226721\n",
      " 0.00224952 0.00309553 0.00126333 0.00418927 0.00086869 0.00843107\n",
      " 0.00477362 0.00226721 0.00045663 0.00226721 0.0040043 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.361497931564521\n",
      "Alpha : 0.2844342976105925\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[26 58]\n",
      " [ 3 62]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5906040268456376\n",
      "Misclassification rate : 0.293\n",
      "True positives : 0.954\n",
      "False positives : 0.69\n",
      "Specificity : 0.31\n",
      "Precision : 0.730830054771272\n",
      "Prevalence : 0.312\n",
      "Recall : 0.954\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[ 1  4]\n",
      " [ 2 10]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.833\n",
      "False positives : 0.8\n",
      "Specificity : 0.2\n",
      "Precision : 0.6022408963585434\n",
      "Prevalence : 0.058\n",
      "Recall : 0.833\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00398856 0.00502681 0.00064331 0.00167898 0.00154024 0.0011814\n",
      " 0.00060687 0.00055223 0.00594986 0.00095058 0.00065364 0.00434782\n",
      " 0.00246159 0.00143004 0.00896055 0.00502681 0.00170594 0.00060687\n",
      " 0.0011814  0.0037144  0.0022225  0.00806064 0.00125072 0.00343327\n",
      " 0.00979294 0.00176233 0.00065364 0.00392553 0.00392553 0.00095058\n",
      " 0.00065364 0.00246159 0.00143004 0.0023714  0.00157629 0.00389521\n",
      " 0.00415279 0.00167898 0.00590187 0.00223997 0.00125072 0.00081601\n",
      " 0.00308335 0.00398856 0.0015159  0.00409688 0.0035675  0.00065364\n",
      " 0.00246159 0.00137623 0.0015159  0.00311274 0.00434782 0.00065364\n",
      " 0.00432698 0.00170594 0.00395639 0.00580054 0.00151395 0.00060687\n",
      " 0.00392553 0.00085825 0.00373229 0.00308335 0.00179426 0.00318762\n",
      " 0.00594986 0.00585583 0.00580054 0.00167898 0.00751138 0.00176233\n",
      " 0.00541419 0.00095058 0.00415279 0.0032388  0.00321268 0.00246159\n",
      " 0.00036422 0.00272048 0.00095058 0.00580054 0.00050135 0.00318762\n",
      " 0.00158388 0.00143004 0.00308335 0.00166588 0.00541419 0.00166588\n",
      " 0.00179426 0.00203568 0.00294721 0.00246159 0.00125072 0.00831944\n",
      " 0.00776531 0.00065364 0.00064331 0.00585583 0.00143004 0.00979294\n",
      " 0.00167898 0.00095058 0.00094317 0.00326427 0.00170594 0.00585583\n",
      " 0.00229763 0.00094317 0.00095058 0.0023292  0.00170594 0.00176233\n",
      " 0.00125072 0.00060687 0.00303071 0.00094317 0.00169263 0.00246159\n",
      " 0.0022225  0.00392553 0.00398856 0.00585583 0.00160485 0.0023292\n",
      " 0.00389521 0.00961866 0.00060687 0.00036422 0.00590187 0.00158388\n",
      " 0.00065364 0.00272048 0.00581061 0.00065364 0.00092101 0.00170594\n",
      " 0.00169263 0.0023292  0.00167898 0.00315217 0.00065364 0.00634387\n",
      " 0.00359186 0.00170594 0.00060687 0.00170594 0.00532176]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3021321639398614\n",
      "Alpha : 0.4185825938160666\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[81  3]\n",
      " [38 27]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7248322147651006\n",
      "Misclassification rate : 0.197\n",
      "True positives : 0.415\n",
      "False positives : 0.036\n",
      "Specificity : 0.964\n",
      "Precision : 0.7763521515988947\n",
      "Prevalence : 0.312\n",
      "Recall : 0.415\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 1]\n",
      " [9 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.4117647058823529\n",
      "Misclassification rate : 0.048\n",
      "True positives : 0.25\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.6199095022624435\n",
      "Prevalence : 0.058\n",
      "Recall : 0.25\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00262438 0.00330754 0.0009777  0.00110473 0.00101345 0.0017955\n",
      " 0.00039931 0.00036336 0.00904263 0.00062546 0.00043008 0.00286077\n",
      " 0.00161967 0.00094094 0.0136183  0.00330754 0.00112247 0.00039931\n",
      " 0.0017955  0.002444   0.00146236 0.00530373 0.00190084 0.0052179\n",
      " 0.00644355 0.0026784  0.00043008 0.00258291 0.00258291 0.00062546\n",
      " 0.00043008 0.00161967 0.00094094 0.00156033 0.00103716 0.00591996\n",
      " 0.00631144 0.00110473 0.00388331 0.00147385 0.00082294 0.00053691\n",
      " 0.0046861  0.00262438 0.00099743 0.00622646 0.00234734 0.00043008\n",
      " 0.00161967 0.00090553 0.00099743 0.00204812 0.00286077 0.00043008\n",
      " 0.00657617 0.00112247 0.00260322 0.00381663 0.00099615 0.00039931\n",
      " 0.00258291 0.00056471 0.00245577 0.0046861  0.00118059 0.00209739\n",
      " 0.00904263 0.00385301 0.00381663 0.00110473 0.00494233 0.0026784\n",
      " 0.00822852 0.00062546 0.00631144 0.00492235 0.00211388 0.00161967\n",
      " 0.00023965 0.00413461 0.00062546 0.00381663 0.00076196 0.00209739\n",
      " 0.00104216 0.00094094 0.0046861  0.00109612 0.00822852 0.00109612\n",
      " 0.00272693 0.00309383 0.0019392  0.00161967 0.00082294 0.00547401\n",
      " 0.01180177 0.0009934  0.00042328 0.00385301 0.00094094 0.00644355\n",
      " 0.00110473 0.00062546 0.00062058 0.00496105 0.0025927  0.00889973\n",
      " 0.00349195 0.00062058 0.00062546 0.00353993 0.00112247 0.0026784\n",
      " 0.00082294 0.00039931 0.00199414 0.00062058 0.00111372 0.00161967\n",
      " 0.00146236 0.00258291 0.00262438 0.00385301 0.00105596 0.00353993\n",
      " 0.00591996 0.00632888 0.00039931 0.00023965 0.00388331 0.00104216\n",
      " 0.0009934  0.00179002 0.008831   0.00043008 0.00139976 0.00112247\n",
      " 0.00257247 0.00353993 0.00110473 0.00207406 0.0009934  0.00417413\n",
      " 0.00236337 0.00112247 0.00039931 0.00112247 0.0035016 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 4\n",
      "################################################\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165] [51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67]\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.24161073825503385\n",
      "Alpha : 0.5719344401281145\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[70 11]\n",
      " [25 43]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7583892617449665\n",
      "Misclassification rate : 0.173\n",
      "True positives : 0.632\n",
      "False positives : 0.136\n",
      "Specificity : 0.864\n",
      "Precision : 0.7639755615735835\n",
      "Prevalence : 0.327\n",
      "Recall : 0.632\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 1]\n",
      " [3 6]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7647058823529411\n",
      "Misclassification rate : 0.019\n",
      "True positives : 0.667\n",
      "False positives : 0.125\n",
      "Specificity : 0.875\n",
      "Precision : 0.7831932773109243\n",
      "Prevalence : 0.043\n",
      "Recall : 0.667\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00378814 0.00378814 0.01189054 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.01189054 0.01189054 0.00378814 0.00378814\n",
      " 0.01189054 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.01189054 0.01189054 0.01189054 0.00378814 0.00378814\n",
      " 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.01189054 0.00378814 0.00378814\n",
      " 0.01189054 0.00378814 0.00378814 0.01189054 0.00378814 0.01189054\n",
      " 0.01189054 0.00378814 0.01189054 0.01189054 0.00378814 0.00378814\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.01189054 0.01189054\n",
      " 0.00378814 0.00378814 0.01189054 0.00378814 0.01189054 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.01189054 0.00378814 0.00378814 0.01189054 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.354965585054081\n",
      "Alpha : 0.29864141530560334\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[75  6]\n",
      " [40 28]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6912751677852349\n",
      "Misclassification rate : 0.221\n",
      "True positives : 0.412\n",
      "False positives : 0.074\n",
      "Specificity : 0.926\n",
      "Precision : 0.7303764225269916\n",
      "Prevalence : 0.327\n",
      "Recall : 0.412\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 1]\n",
      " [8 1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.47058823529411764\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.111\n",
      "False positives : 0.125\n",
      "Specificity : 0.875\n",
      "Precision : 0.48431372549019613\n",
      "Prevalence : 0.043\n",
      "Recall : 0.111\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00510651 0.00510651 0.00882071 0.00281014 0.00510651 0.01602876\n",
      " 0.00281014 0.00281014 0.00510651 0.00281014 0.00281014 0.00281014\n",
      " 0.00281014 0.00281014 0.00882071 0.00882071 0.00281014 0.00281014\n",
      " 0.01602876 0.00882071 0.00281014 0.00281014 0.00510651 0.00281014\n",
      " 0.00510651 0.01602876 0.00281014 0.00510651 0.00281014 0.00281014\n",
      " 0.00281014 0.00281014 0.00510651 0.00281014 0.00882071 0.00281014\n",
      " 0.00281014 0.00510651 0.00510651 0.00510651 0.00281014 0.00281014\n",
      " 0.00882071 0.00281014 0.00281014 0.00281014 0.00281014 0.00882071\n",
      " 0.00281014 0.01602876 0.01602876 0.00882071 0.00281014 0.00281014\n",
      " 0.00882071 0.00510651 0.00281014 0.00281014 0.00281014 0.00281014\n",
      " 0.00510651 0.00281014 0.00281014 0.01602876 0.00510651 0.00281014\n",
      " 0.01602876 0.00281014 0.00281014 0.00882071 0.00510651 0.00882071\n",
      " 0.01602876 0.00281014 0.01602876 0.00882071 0.00281014 0.00281014\n",
      " 0.00281014 0.01602876 0.00281014 0.00281014 0.00882071 0.00882071\n",
      " 0.00281014 0.00281014 0.01602876 0.00281014 0.01602876 0.00281014\n",
      " 0.00281014 0.00510651 0.00510651 0.00281014 0.00281014 0.00281014\n",
      " 0.00882071 0.00510651 0.00281014 0.00281014 0.00281014 0.00281014\n",
      " 0.00281014 0.00281014 0.00281014 0.00510651 0.00281014 0.00882071\n",
      " 0.00882071 0.00281014 0.00281014 0.01602876 0.00510651 0.00882071\n",
      " 0.00281014 0.00281014 0.00281014 0.00281014 0.00510651 0.00281014\n",
      " 0.00281014 0.00281014 0.00510651 0.00281014 0.00281014 0.01602876\n",
      " 0.00510651 0.00882071 0.00281014 0.00281014 0.00281014 0.00281014\n",
      " 0.00281014 0.00510651 0.01602876 0.00281014 0.00510651 0.00510651\n",
      " 0.00510651 0.01602876 0.00281014 0.00281014 0.00510651 0.00882071\n",
      " 0.00510651 0.00510651 0.00281014 0.00281014 0.00281014]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2841013698398764\n",
      "Alpha : 0.46210373420914647\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[23 58]\n",
      " [ 2 66]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5973154362416108\n",
      "Misclassification rate : 0.288\n",
      "True positives : 0.971\n",
      "False positives : 0.716\n",
      "Specificity : 0.284\n",
      "Precision : 0.7430439489066898\n",
      "Prevalence : 0.327\n",
      "Recall : 0.971\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 5]\n",
      " [1 8]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.889\n",
      "False positives : 0.625\n",
      "Specificity : 0.375\n",
      "Precision : 0.6787330316742082\n",
      "Prevalence : 0.043\n",
      "Recall : 0.889\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00321688 0.00810612 0.01400208 0.00177027 0.00321688 0.01009743\n",
      " 0.00446084 0.00177027 0.00321688 0.00177027 0.00177027 0.00446084\n",
      " 0.00446084 0.00446084 0.00555667 0.01400208 0.00177027 0.00177027\n",
      " 0.01009743 0.01400208 0.00446084 0.00446084 0.00321688 0.00177027\n",
      " 0.00810612 0.01009743 0.00177027 0.00810612 0.00446084 0.00177027\n",
      " 0.00177027 0.00446084 0.00810612 0.00177027 0.00555667 0.00446084\n",
      " 0.00177027 0.00321688 0.00321688 0.00321688 0.00177027 0.00446084\n",
      " 0.00555667 0.00177027 0.00177027 0.00446084 0.00177027 0.00555667\n",
      " 0.00177027 0.01009743 0.01009743 0.01400208 0.00177027 0.00177027\n",
      " 0.01400208 0.00321688 0.00177027 0.00446084 0.00446084 0.00446084\n",
      " 0.00810612 0.00446084 0.00446084 0.01009743 0.00321688 0.00446084\n",
      " 0.01009743 0.00177027 0.00446084 0.00555667 0.00810612 0.00555667\n",
      " 0.01009743 0.00177027 0.01009743 0.00555667 0.00177027 0.00446084\n",
      " 0.00177027 0.01009743 0.00177027 0.00446084 0.00555667 0.01400208\n",
      " 0.00446084 0.00446084 0.01009743 0.00446084 0.01009743 0.00446084\n",
      " 0.00177027 0.00321688 0.00810612 0.00446084 0.00177027 0.00446084\n",
      " 0.00555667 0.00321688 0.00177027 0.00446084 0.00446084 0.00446084\n",
      " 0.00177027 0.00446084 0.00446084 0.00321688 0.00177027 0.01400208\n",
      " 0.00555667 0.00446084 0.00177027 0.01009743 0.00321688 0.00555667\n",
      " 0.00177027 0.00446084 0.00446084 0.00446084 0.00321688 0.00446084\n",
      " 0.00446084 0.00177027 0.00321688 0.00446084 0.00446084 0.01009743\n",
      " 0.00321688 0.01400208 0.00446084 0.00177027 0.00177027 0.00446084\n",
      " 0.00446084 0.00321688 0.01009743 0.00177027 0.00321688 0.00321688\n",
      " 0.00321688 0.01009743 0.00177027 0.00446084 0.00321688 0.00555667\n",
      " 0.00321688 0.00321688 0.00446084 0.00177027 0.00446084]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.29229124483183283\n",
      "Alpha : 0.44214096365737043\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[51 30]\n",
      " [21 47]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6577181208053692\n",
      "Misclassification rate : 0.245\n",
      "True positives : 0.691\n",
      "False positives : 0.37\n",
      "Specificity : 0.63\n",
      "Precision : 0.663634184607339\n",
      "Prevalence : 0.327\n",
      "Recall : 0.691\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 4]\n",
      " [3 6]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5882352941176471\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.667\n",
      "False positives : 0.5\n",
      "Specificity : 0.5\n",
      "Precision : 0.5865546218487395\n",
      "Prevalence : 0.043\n",
      "Recall : 0.667\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00206736 0.00520947 0.00899856 0.00275459 0.00206736 0.00648921\n",
      " 0.0028668  0.00113768 0.00206736 0.00275459 0.00113768 0.00694122\n",
      " 0.00694122 0.0028668  0.00864637 0.00899856 0.00275459 0.00113768\n",
      " 0.00648921 0.00899856 0.0028668  0.0028668  0.00206736 0.00113768\n",
      " 0.00520947 0.00648921 0.00113768 0.00520947 0.0028668  0.00275459\n",
      " 0.00113768 0.00694122 0.00520947 0.00275459 0.00357104 0.0028668\n",
      " 0.00113768 0.00206736 0.00500558 0.00206736 0.00113768 0.0028668\n",
      " 0.00357104 0.00113768 0.00113768 0.0028668  0.00113768 0.00864637\n",
      " 0.00113768 0.00648921 0.01571196 0.00899856 0.00275459 0.00113768\n",
      " 0.00899856 0.00500558 0.00275459 0.00694122 0.0028668  0.0028668\n",
      " 0.00520947 0.0028668  0.00694122 0.01571196 0.00206736 0.0028668\n",
      " 0.00648921 0.00113768 0.00694122 0.00864637 0.00520947 0.00357104\n",
      " 0.00648921 0.00275459 0.00648921 0.00357104 0.00275459 0.00694122\n",
      " 0.00113768 0.00648921 0.00275459 0.00694122 0.00357104 0.00899856\n",
      " 0.00694122 0.0028668  0.01571196 0.0028668  0.00648921 0.0028668\n",
      " 0.00113768 0.00500558 0.00520947 0.00694122 0.00113768 0.00694122\n",
      " 0.00357104 0.00206736 0.00113768 0.0028668  0.0028668  0.0028668\n",
      " 0.00275459 0.00694122 0.0028668  0.00500558 0.00275459 0.00899856\n",
      " 0.00357104 0.0028668  0.00275459 0.01571196 0.00500558 0.00357104\n",
      " 0.00113768 0.0028668  0.00694122 0.0028668  0.00206736 0.00694122\n",
      " 0.0028668  0.00113768 0.00206736 0.0028668  0.0028668  0.01571196\n",
      " 0.00500558 0.00899856 0.0028668  0.00113768 0.00275459 0.00694122\n",
      " 0.0028668  0.00206736 0.01571196 0.00113768 0.00206736 0.00500558\n",
      " 0.00206736 0.01571196 0.00275459 0.00694122 0.00206736 0.00357104\n",
      " 0.00500558 0.00500558 0.0028668  0.00275459 0.0028668 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3055109663036106\n",
      "Alpha : 0.41059534882042825\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[75  6]\n",
      " [53 15]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6040268456375839\n",
      "Misclassification rate : 0.284\n",
      "True positives : 0.221\n",
      "False positives : 0.074\n",
      "Specificity : 0.926\n",
      "Precision : 0.6445125239693192\n",
      "Prevalence : 0.327\n",
      "Recall : 0.221\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 1]\n",
      " [5 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.444\n",
      "False positives : 0.125\n",
      "Specificity : 0.875\n",
      "Precision : 0.6980392156862746\n",
      "Prevalence : 0.043\n",
      "Recall : 0.444\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00311699 0.00345521 0.00596834 0.001827   0.00311699 0.004304\n",
      " 0.00190142 0.00075457 0.00311699 0.001827   0.00171529 0.0046038\n",
      " 0.0046038  0.00190142 0.01303626 0.00596834 0.00415314 0.00075457\n",
      " 0.004304   0.00596834 0.00190142 0.00190142 0.00311699 0.00171529\n",
      " 0.0078544  0.004304   0.00171529 0.00345521 0.00190142 0.001827\n",
      " 0.00171529 0.0046038  0.00345521 0.00415314 0.00538411 0.00190142\n",
      " 0.00075457 0.00311699 0.00754699 0.00311699 0.00171529 0.00190142\n",
      " 0.00538411 0.00171529 0.00171529 0.00432232 0.00171529 0.00573475\n",
      " 0.00171529 0.004304   0.02368916 0.00596834 0.001827   0.00171529\n",
      " 0.00596834 0.00754699 0.001827   0.0046038  0.00432232 0.00190142\n",
      " 0.00345521 0.00190142 0.0046038  0.01042104 0.00311699 0.00190142\n",
      " 0.00978387 0.00075457 0.0046038  0.00573475 0.00345521 0.00236851\n",
      " 0.00978387 0.001827   0.004304   0.00538411 0.001827   0.0046038\n",
      " 0.00075457 0.00978387 0.001827   0.0046038  0.00236851 0.00596834\n",
      " 0.0046038  0.00190142 0.01042104 0.00190142 0.00978387 0.00190142\n",
      " 0.00171529 0.00754699 0.0078544  0.0046038  0.00171529 0.0046038\n",
      " 0.00538411 0.00311699 0.00075457 0.00190142 0.00190142 0.00432232\n",
      " 0.001827   0.0046038  0.00190142 0.00754699 0.00415314 0.00596834\n",
      " 0.00538411 0.00190142 0.001827   0.01042104 0.00754699 0.00236851\n",
      " 0.00171529 0.00190142 0.0046038  0.00190142 0.00311699 0.0046038\n",
      " 0.00190142 0.00075457 0.00311699 0.00190142 0.00432232 0.01042104\n",
      " 0.00754699 0.00596834 0.00190142 0.00075457 0.001827   0.0046038\n",
      " 0.00432232 0.00311699 0.02368916 0.00171529 0.00137119 0.00754699\n",
      " 0.00311699 0.01042104 0.001827   0.0046038  0.00311699 0.00236851\n",
      " 0.00331998 0.00754699 0.00190142 0.00415314 0.00432232]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2996451919013844\n",
      "Alpha : 0.42449399714054215\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[58 23]\n",
      " [18 50]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7248322147651006\n",
      "Misclassification rate : 0.197\n",
      "True positives : 0.735\n",
      "False positives : 0.284\n",
      "Specificity : 0.716\n",
      "Precision : 0.7274572613385075\n",
      "Prevalence : 0.327\n",
      "Recall : 0.735\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 4]\n",
      " [5 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.47058823529411764\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.444\n",
      "False positives : 0.5\n",
      "Specificity : 0.5\n",
      "Precision : 0.4738562091503268\n",
      "Prevalence : 0.043\n",
      "Recall : 0.444\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0047653  0.00528238 0.0039039  0.00119504 0.0047653  0.00658003\n",
      " 0.00124372 0.0011536  0.0047653  0.00119504 0.00112197 0.00301135\n",
      " 0.00301135 0.00124372 0.00852703 0.0091245  0.00271657 0.00049356\n",
      " 0.00658003 0.0091245  0.00290692 0.00124372 0.00203882 0.00112197\n",
      " 0.00513757 0.00658003 0.00112197 0.00528238 0.00290692 0.00119504\n",
      " 0.00112197 0.00301135 0.00528238 0.00271657 0.00352175 0.00124372\n",
      " 0.00049356 0.00203882 0.01153796 0.00203882 0.00112197 0.00124372\n",
      " 0.00352175 0.00112197 0.00112197 0.00282723 0.00112197 0.0037511\n",
      " 0.00112197 0.00658003 0.01549509 0.0039039  0.00119504 0.00112197\n",
      " 0.0039039  0.00493649 0.00119504 0.00301135 0.00282723 0.00124372\n",
      " 0.00528238 0.00290692 0.00703837 0.01593186 0.00203882 0.00124372\n",
      " 0.00639964 0.00049356 0.00301135 0.0037511  0.00528238 0.00154925\n",
      " 0.01495775 0.00119504 0.00658003 0.00352175 0.00119504 0.00301135\n",
      " 0.00049356 0.00639964 0.00119504 0.00301135 0.00154925 0.0091245\n",
      " 0.00301135 0.00290692 0.01593186 0.00290692 0.00639964 0.00124372\n",
      " 0.00112197 0.01153796 0.01200794 0.00301135 0.00112197 0.00301135\n",
      " 0.00352175 0.00203882 0.00049356 0.00124372 0.00290692 0.00660803\n",
      " 0.00119504 0.00301135 0.00124372 0.01153796 0.00271657 0.0091245\n",
      " 0.00352175 0.00124372 0.00119504 0.00681641 0.00493649 0.00154925\n",
      " 0.00112197 0.00124372 0.00301135 0.00124372 0.00203882 0.00301135\n",
      " 0.00290692 0.0011536  0.0047653  0.00124372 0.00660803 0.00681641\n",
      " 0.01153796 0.0091245  0.00124372 0.00049356 0.00119504 0.00301135\n",
      " 0.00282723 0.0047653  0.01549509 0.00112197 0.00089689 0.00493649\n",
      " 0.00203882 0.00681641 0.00119504 0.00703837 0.00203882 0.00154925\n",
      " 0.0021716  0.00493649 0.00124372 0.00271657 0.00282723]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3248372582648343\n",
      "Alpha : 0.36581472378229946\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[64 17]\n",
      " [33 35]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6644295302013423\n",
      "Misclassification rate : 0.24\n",
      "True positives : 0.515\n",
      "False positives : 0.21\n",
      "Specificity : 0.79\n",
      "Precision : 0.6658559042839124\n",
      "Prevalence : 0.327\n",
      "Recall : 0.515\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 1]\n",
      " [6 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5882352941176471\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.333\n",
      "False positives : 0.125\n",
      "Specificity : 0.875\n",
      "Precision : 0.6504524886877827\n",
      "Prevalence : 0.043\n",
      "Recall : 0.333\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00330536 0.00366403 0.0056282  0.00172288 0.00330536 0.00456411\n",
      " 0.00086268 0.00080017 0.00330536 0.00172288 0.00161754 0.00208877\n",
      " 0.00208877 0.00086268 0.01229331 0.00632904 0.00391645 0.00034235\n",
      " 0.00456411 0.00632904 0.00201633 0.00086268 0.00141419 0.00077824\n",
      " 0.00356358 0.00948635 0.00077824 0.00366403 0.00201633 0.00172288\n",
      " 0.00161754 0.00208877 0.00366403 0.00391645 0.00507727 0.00086268\n",
      " 0.00071157 0.00141419 0.00800309 0.00141419 0.00077824 0.00179306\n",
      " 0.0024428  0.00077824 0.00077824 0.00196105 0.00077824 0.00260188\n",
      " 0.00161754 0.00948635 0.01074788 0.00270787 0.00082892 0.00077824\n",
      " 0.00270787 0.00711688 0.00172288 0.00208877 0.00196105 0.00086268\n",
      " 0.00366403 0.00419087 0.00488203 0.01105083 0.00293935 0.00086268\n",
      " 0.00443899 0.00071157 0.00208877 0.00260188 0.00366403 0.00223353\n",
      " 0.02156441 0.00082892 0.00948635 0.0024428  0.00172288 0.00208877\n",
      " 0.00034235 0.00922628 0.00172288 0.00208877 0.00107461 0.00632904\n",
      " 0.00208877 0.00201633 0.01105083 0.00201633 0.00443899 0.00086268\n",
      " 0.00077824 0.00800309 0.0173117  0.00208877 0.00161754 0.00208877\n",
      " 0.00507727 0.00293935 0.00071157 0.00179306 0.00201633 0.00458353\n",
      " 0.00172288 0.00208877 0.00086268 0.00800309 0.00391645 0.00632904\n",
      " 0.0024428  0.00086268 0.00082892 0.00982713 0.00711688 0.00223353\n",
      " 0.00077824 0.00086268 0.00208877 0.00086268 0.00141419 0.00208877\n",
      " 0.00419087 0.00166313 0.00330536 0.00086268 0.00458353 0.00982713\n",
      " 0.01663414 0.00632904 0.00086268 0.00034235 0.00082892 0.00208877\n",
      " 0.00407598 0.00330536 0.02233909 0.00077824 0.00129304 0.00711688\n",
      " 0.00141419 0.00472807 0.00082892 0.00488203 0.00293935 0.00223353\n",
      " 0.00313077 0.00711688 0.00086268 0.00391645 0.00196105]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.282666012852263\n",
      "Alpha : 0.46563775498299614\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[40 41]\n",
      " [19 49]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5973154362416108\n",
      "Misclassification rate : 0.288\n",
      "True positives : 0.721\n",
      "False positives : 0.506\n",
      "Specificity : 0.494\n",
      "Precision : 0.6170300433524185\n",
      "Prevalence : 0.327\n",
      "Recall : 0.721\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[5 3]\n",
      " [4 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5882352941176471\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.556\n",
      "False positives : 0.375\n",
      "Specificity : 0.625\n",
      "Precision : 0.5923202614379085\n",
      "Prevalence : 0.043\n",
      "Recall : 0.556\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00207489 0.00230004 0.00896589 0.00274459 0.00207489 0.00727077\n",
      " 0.00054154 0.0005023  0.00526554 0.00274459 0.00101538 0.00332747\n",
      " 0.00332747 0.00054154 0.01958361 0.00397296 0.00623903 0.00021491\n",
      " 0.00727077 0.00397296 0.00126572 0.00054154 0.00088774 0.00123975\n",
      " 0.00567689 0.00595491 0.00048853 0.0058369  0.00126572 0.00274459\n",
      " 0.00101538 0.00131119 0.00230004 0.00623903 0.00318718 0.00054154\n",
      " 0.00113355 0.00088774 0.01274916 0.00225285 0.00123975 0.00112556\n",
      " 0.00153343 0.00048853 0.00123975 0.00312402 0.00123975 0.00414488\n",
      " 0.00257678 0.00595491 0.00674682 0.00169982 0.00132049 0.00048853\n",
      " 0.00431371 0.00446751 0.00274459 0.00332747 0.00123102 0.00054154\n",
      " 0.00230004 0.00667619 0.00306462 0.00693699 0.00468247 0.00137428\n",
      " 0.00707144 0.00113355 0.00332747 0.00414488 0.00230004 0.00140206\n",
      " 0.01353673 0.00132049 0.00595491 0.00153343 0.00108151 0.00131119\n",
      " 0.00054538 0.00579166 0.00274459 0.00332747 0.00067457 0.00397296\n",
      " 0.00131119 0.00126572 0.01760431 0.00321208 0.00278651 0.00137428\n",
      " 0.00123975 0.00502382 0.01086716 0.00131119 0.00101538 0.00332747\n",
      " 0.00318718 0.00184513 0.00113355 0.00285639 0.00126572 0.00730171\n",
      " 0.00274459 0.00332747 0.00054154 0.00502382 0.00245849 0.00397296\n",
      " 0.00153343 0.00137428 0.00132049 0.00616883 0.00446751 0.00140206\n",
      " 0.00123975 0.00054154 0.00131119 0.00054154 0.00088774 0.00332747\n",
      " 0.00263076 0.00264942 0.00207489 0.00054154 0.00730171 0.00616883\n",
      " 0.01044183 0.00397296 0.00054154 0.00054538 0.00132049 0.00131119\n",
      " 0.00255864 0.00207489 0.01402302 0.00048853 0.00081169 0.00446751\n",
      " 0.00088774 0.00296798 0.00132049 0.00306462 0.00184513 0.00355808\n",
      " 0.00498741 0.00446751 0.00054154 0.00245849 0.00123102]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.31584944088383327\n",
      "Alpha : 0.3864561809598299\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[67 14]\n",
      " [25 43]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.738255033557047\n",
      "Misclassification rate : 0.188\n",
      "True positives : 0.632\n",
      "False positives : 0.173\n",
      "Specificity : 0.827\n",
      "Precision : 0.7401837318712596\n",
      "Prevalence : 0.327\n",
      "Recall : 0.632\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[6 2]\n",
      " [2 7]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7647058823529411\n",
      "Misclassification rate : 0.019\n",
      "True positives : 0.778\n",
      "False positives : 0.25\n",
      "Specificity : 0.75\n",
      "Precision : 0.7647058823529411\n",
      "Prevalence : 0.043\n",
      "Recall : 0.778\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00305373 0.00338509 0.00609197 0.00186484 0.00140981 0.0049402\n",
      " 0.00036795 0.00034129 0.00774959 0.00186484 0.00068991 0.00226088\n",
      " 0.00226088 0.00036795 0.01330629 0.00584722 0.00423917 0.00014602\n",
      " 0.0049402  0.00584722 0.00086001 0.00079701 0.00060318 0.00084236\n",
      " 0.00385722 0.00876417 0.00033193 0.00396595 0.00086001 0.00186484\n",
      " 0.00068991 0.0008909  0.00156278 0.00423917 0.00469075 0.00036795\n",
      " 0.0016683  0.00130653 0.01876365 0.00331564 0.00084236 0.00076478\n",
      " 0.00225683 0.00033193 0.00084236 0.00212265 0.00084236 0.00610025\n",
      " 0.00175082 0.00876417 0.00992967 0.00115496 0.00089722 0.00033193\n",
      " 0.00634873 0.0030355  0.00186484 0.00226088 0.00083643 0.00036795\n",
      " 0.00156278 0.00453621 0.00208229 0.00471341 0.00318155 0.00093377\n",
      " 0.01040744 0.0016683  0.00226088 0.00281628 0.00156278 0.00206349\n",
      " 0.01992276 0.00089722 0.00876417 0.00225683 0.00073484 0.0008909\n",
      " 0.00037056 0.0039352  0.00186484 0.00226088 0.00045834 0.00269947\n",
      " 0.0008909  0.00086001 0.01196143 0.00218248 0.00410106 0.00093377\n",
      " 0.00084236 0.00341349 0.0073838  0.0008909  0.0014944  0.00226088\n",
      " 0.00469075 0.00125369 0.0007702  0.00420391 0.00086001 0.00496122\n",
      " 0.00186484 0.00226088 0.00036795 0.00341349 0.00167045 0.00584722\n",
      " 0.00225683 0.00093377 0.00089722 0.00907902 0.0030355  0.00206349\n",
      " 0.00084236 0.00036795 0.0008909  0.00036795 0.00060318 0.00226088\n",
      " 0.0017875  0.00180017 0.00140981 0.00079701 0.00496122 0.00907902\n",
      " 0.00709481 0.00269947 0.00036795 0.00037056 0.00194344 0.0008909\n",
      " 0.00173849 0.00140981 0.02063846 0.00033193 0.0011946  0.0030355\n",
      " 0.00060318 0.00436814 0.00089722 0.00208229 0.00125369 0.00523662\n",
      " 0.00338875 0.0030355  0.00036795 0.00167045 0.00181176]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.26261557026548704\n",
      "Alpha : 0.5162090588346591\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[21 60]\n",
      " [ 4 64]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5704697986577181\n",
      "Misclassification rate : 0.308\n",
      "True positives : 0.941\n",
      "False positives : 0.741\n",
      "Specificity : 0.259\n",
      "Precision : 0.6921931153929421\n",
      "Prevalence : 0.327\n",
      "Recall : 0.941\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[0 8]\n",
      " [2 7]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.4117647058823529\n",
      "Misclassification rate : 0.048\n",
      "True positives : 0.778\n",
      "False positives : 1.0\n",
      "Specificity : 0.0\n",
      "Precision : 0.24705882352941178\n",
      "Prevalence : 0.043\n",
      "Recall : 0.778\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0018224  0.00567227 0.00363556 0.00312485 0.00084134 0.00294821\n",
      " 0.00061656 0.00057189 0.00462479 0.00312485 0.00115606 0.00378848\n",
      " 0.00378848 0.00061656 0.00794091 0.00979798 0.00252985 0.00024468\n",
      " 0.00294821 0.0034895  0.00144108 0.00133552 0.00035997 0.0005027\n",
      " 0.0064634  0.00523027 0.00019809 0.00664559 0.00144108 0.00312485\n",
      " 0.00041173 0.00053167 0.0026187  0.00252985 0.00279934 0.00061656\n",
      " 0.00279552 0.00077971 0.01119775 0.00197871 0.0005027  0.0004564\n",
      " 0.00134683 0.00019809 0.0005027  0.00126675 0.0005027  0.01022196\n",
      " 0.00104485 0.00523027 0.00592581 0.00068926 0.00053544 0.00019809\n",
      " 0.00378879 0.00181152 0.0011129  0.00378848 0.00140158 0.00061656\n",
      " 0.00093264 0.00760115 0.00348922 0.00789809 0.00189868 0.00055725\n",
      " 0.00621094 0.00099561 0.00378848 0.00471914 0.00093264 0.00123145\n",
      " 0.01188948 0.00150344 0.00523027 0.00134683 0.00043854 0.00149285\n",
      " 0.00062094 0.00234844 0.00312485 0.00378848 0.00027353 0.0045234\n",
      " 0.00149285 0.00144108 0.00713833 0.0036571  0.00687199 0.00055725\n",
      " 0.0005027  0.0020371  0.0044065  0.00149285 0.00089182 0.00378848\n",
      " 0.00279934 0.00074818 0.0012906  0.0025088  0.00144108 0.00296075\n",
      " 0.00312485 0.00378848 0.00061656 0.0020371  0.00099689 0.00979798\n",
      " 0.00134683 0.00156468 0.00150344 0.00541816 0.00181152 0.00123145\n",
      " 0.0005027  0.00061656 0.00053167 0.00061656 0.00035997 0.00378848\n",
      " 0.00299524 0.00301649 0.00236236 0.00133552 0.00296075 0.00541816\n",
      " 0.00423403 0.0045234  0.00061656 0.00062094 0.0011598  0.00149285\n",
      " 0.00103749 0.00084134 0.01231659 0.00019809 0.00071291 0.00181152\n",
      " 0.00035997 0.00260681 0.00150344 0.00348922 0.00074818 0.00877481\n",
      " 0.00202233 0.00181152 0.00061656 0.00099689 0.00108122]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 5\n",
      "################################################\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165] [68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84]\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.24161073825503387\n",
      "Alpha : 0.5719344401281145\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[67 10]\n",
      " [26 46]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7583892617449665\n",
      "Misclassification rate : 0.173\n",
      "True positives : 0.639\n",
      "False positives : 0.13\n",
      "Specificity : 0.87\n",
      "Precision : 0.7692347343787049\n",
      "Prevalence : 0.346\n",
      "Recall : 0.639\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[10  2]\n",
      " [ 2  3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7647058823529411\n",
      "Misclassification rate : 0.019\n",
      "True positives : 0.6\n",
      "False positives : 0.167\n",
      "Specificity : 0.833\n",
      "Precision : 0.7647058823529411\n",
      "Prevalence : 0.024\n",
      "Recall : 0.6\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00378814 0.00378814 0.01189054 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.01189054 0.01189054 0.00378814 0.00378814\n",
      " 0.01189054 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.01189054 0.01189054 0.01189054 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.01189054 0.00378814 0.01189054\n",
      " 0.01189054 0.00378814 0.01189054 0.01189054 0.00378814 0.00378814\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.01189054 0.01189054\n",
      " 0.00378814 0.00378814 0.01189054 0.00378814 0.01189054 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.01189054 0.00378814 0.00378814 0.01189054 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3184611602753202\n",
      "Alpha : 0.38042635961117727\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[23 54]\n",
      " [ 3 69]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6174496644295302\n",
      "Misclassification rate : 0.274\n",
      "True positives : 0.958\n",
      "False positives : 0.701\n",
      "Specificity : 0.299\n",
      "Precision : 0.7282256947504943\n",
      "Prevalence : 0.346\n",
      "Recall : 0.958\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 9]\n",
      " [0 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.47058823529411764\n",
      "Misclassification rate : 0.043\n",
      "True positives : 1.0\n",
      "False positives : 0.75\n",
      "Specificity : 0.25\n",
      "Precision : 0.8109243697478992\n",
      "Prevalence : 0.024\n",
      "Recall : 1.0\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00258946 0.0055417  0.01739477 0.00258946 0.00258946 0.00812802\n",
      " 0.0055417  0.00258946 0.00258946 0.00258946 0.00258946 0.0055417\n",
      " 0.0055417  0.0055417  0.00812802 0.01739477 0.00258946 0.00258946\n",
      " 0.00812802 0.01739477 0.0055417  0.0055417  0.00258946 0.00258946\n",
      " 0.0055417  0.00812802 0.00258946 0.0055417  0.0055417  0.00258946\n",
      " 0.00258946 0.0055417  0.0055417  0.00258946 0.00812802 0.0055417\n",
      " 0.00258946 0.00258946 0.00258946 0.00258946 0.00258946 0.0055417\n",
      " 0.00812802 0.00258946 0.00258946 0.0055417  0.00258946 0.00812802\n",
      " 0.00258946 0.00812802 0.00812802 0.01739477 0.00258946 0.00812802\n",
      " 0.00258946 0.0055417  0.0055417  0.00258946 0.00258946 0.00812802\n",
      " 0.0055417  0.00258946 0.00812802 0.0055417  0.00258946 0.0055417\n",
      " 0.00258946 0.00258946 0.0055417  0.00812802 0.0055417  0.00812802\n",
      " 0.00812802 0.00258946 0.00812802 0.00812802 0.00258946 0.0055417\n",
      " 0.00258946 0.00812802 0.00258946 0.0055417  0.00812802 0.01739477\n",
      " 0.0055417  0.0055417  0.00812802 0.0055417  0.00812802 0.0055417\n",
      " 0.00258946 0.00258946 0.0055417  0.0055417  0.00258946 0.0055417\n",
      " 0.00812802 0.00258946 0.00258946 0.0055417  0.0055417  0.0055417\n",
      " 0.00258946 0.0055417  0.0055417  0.00258946 0.00258946 0.01739477\n",
      " 0.00812802 0.0055417  0.00258946 0.00812802 0.00258946 0.00812802\n",
      " 0.00258946 0.0055417  0.0055417  0.0055417  0.00258946 0.0055417\n",
      " 0.0055417  0.00258946 0.00258946 0.0055417  0.0055417  0.00812802\n",
      " 0.00258946 0.01739477 0.0055417  0.00258946 0.00258946 0.0055417\n",
      " 0.0055417  0.00258946 0.00812802 0.00258946 0.00258946 0.00258946\n",
      " 0.00258946 0.00812802 0.00258946 0.0055417  0.00258946 0.00812802\n",
      " 0.00258946 0.00258946 0.0055417  0.00258946 0.0055417 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.30114891006149813\n",
      "Alpha : 0.42091641315914013\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[47 30]\n",
      " [22 50]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6510067114093959\n",
      "Misclassification rate : 0.25\n",
      "True positives : 0.694\n",
      "False positives : 0.39\n",
      "Specificity : 0.61\n",
      "Precision : 0.6540219822974419\n",
      "Prevalence : 0.346\n",
      "Recall : 0.694\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 4]\n",
      " [3 2]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5882352941176471\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.4\n",
      "False positives : 0.333\n",
      "Specificity : 0.667\n",
      "Precision : 0.6114081996434937\n",
      "Prevalence : 0.024\n",
      "Recall : 0.4\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00169984 0.00363782 0.01141871 0.00394467 0.00169984 0.0053356\n",
      " 0.00363782 0.00169984 0.00169984 0.00394467 0.00169984 0.00844198\n",
      " 0.00844198 0.00363782 0.01238187 0.01141871 0.00394467 0.00169984\n",
      " 0.0053356  0.01141871 0.00363782 0.00363782 0.00169984 0.00169984\n",
      " 0.00363782 0.0053356  0.00169984 0.00363782 0.00363782 0.00394467\n",
      " 0.00169984 0.00844198 0.00363782 0.00394467 0.0053356  0.00363782\n",
      " 0.00169984 0.00169984 0.00394467 0.00169984 0.00169984 0.00363782\n",
      " 0.0053356  0.00169984 0.00169984 0.00363782 0.00169984 0.01238187\n",
      " 0.00169984 0.0053356  0.01238187 0.01141871 0.00394467 0.0053356\n",
      " 0.00394467 0.00844198 0.00844198 0.00169984 0.00394467 0.01238187\n",
      " 0.00363782 0.00169984 0.0053356  0.00363782 0.00169984 0.00844198\n",
      " 0.00169984 0.00169984 0.00844198 0.01238187 0.00363782 0.0053356\n",
      " 0.0053356  0.00394467 0.0053356  0.0053356  0.00394467 0.00844198\n",
      " 0.00169984 0.0053356  0.00394467 0.00844198 0.0053356  0.01141871\n",
      " 0.00844198 0.00363782 0.01238187 0.00363782 0.0053356  0.00363782\n",
      " 0.00169984 0.00394467 0.00363782 0.00844198 0.00169984 0.00844198\n",
      " 0.0053356  0.00169984 0.00169984 0.00363782 0.00363782 0.00363782\n",
      " 0.00394467 0.00844198 0.00363782 0.00394467 0.00394467 0.01141871\n",
      " 0.0053356  0.00363782 0.00394467 0.01238187 0.00394467 0.0053356\n",
      " 0.00169984 0.00363782 0.00844198 0.00363782 0.00169984 0.00844198\n",
      " 0.00363782 0.00169984 0.00169984 0.00363782 0.00363782 0.01238187\n",
      " 0.00394467 0.01141871 0.00363782 0.00169984 0.00394467 0.00844198\n",
      " 0.00363782 0.00169984 0.01238187 0.00169984 0.00169984 0.00394467\n",
      " 0.00169984 0.01238187 0.00394467 0.00844198 0.00169984 0.0053356\n",
      " 0.00394467 0.00394467 0.00363782 0.00394467 0.00363782]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.28847990566692133\n",
      "Alpha : 0.4513891134437468\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[71  6]\n",
      " [54 18]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5973154362416108\n",
      "Misclassification rate : 0.288\n",
      "True positives : 0.25\n",
      "False positives : 0.078\n",
      "Specificity : 0.922\n",
      "Precision : 0.6559463087248322\n",
      "Prevalence : 0.346\n",
      "Recall : 0.25\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[11  1]\n",
      " [ 4  1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7058823529411765\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.2\n",
      "False positives : 0.083\n",
      "Specificity : 0.917\n",
      "Precision : 0.6647058823529411\n",
      "Prevalence : 0.024\n",
      "Recall : 0.2\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00266958 0.00231636 0.00727078 0.00251174 0.00266958 0.0033974\n",
      " 0.00231636 0.00108236 0.00266958 0.00251174 0.00266958 0.00537537\n",
      " 0.00537537 0.00231636 0.01944563 0.00727078 0.00619507 0.00108236\n",
      " 0.0033974  0.00727078 0.00231636 0.00231636 0.00266958 0.00266958\n",
      " 0.00571317 0.0033974  0.00266958 0.00231636 0.00231636 0.00251174\n",
      " 0.00266958 0.00537537 0.00231636 0.00619507 0.00837951 0.00231636\n",
      " 0.00108236 0.00266958 0.00619507 0.00266958 0.00266958 0.00231636\n",
      " 0.00837951 0.00266958 0.00266958 0.00571317 0.00266958 0.00788407\n",
      " 0.00266958 0.0033974  0.01944563 0.00727078 0.00619507 0.0033974\n",
      " 0.00251174 0.00537537 0.00537537 0.00266958 0.00251174 0.00788407\n",
      " 0.00571317 0.00108236 0.00837951 0.00571317 0.00266958 0.00537537\n",
      " 0.00108236 0.00108236 0.00537537 0.00788407 0.00231636 0.0033974\n",
      " 0.00837951 0.00251174 0.0033974  0.00837951 0.00251174 0.00537537\n",
      " 0.00108236 0.00837951 0.00251174 0.00537537 0.0033974  0.00727078\n",
      " 0.00537537 0.00231636 0.00788407 0.00231636 0.00837951 0.00231636\n",
      " 0.00266958 0.00619507 0.00571317 0.00537537 0.00266958 0.00537537\n",
      " 0.00837951 0.00266958 0.00108236 0.00231636 0.00231636 0.00571317\n",
      " 0.00251174 0.00537537 0.00231636 0.00619507 0.00619507 0.00727078\n",
      " 0.00837951 0.00231636 0.00251174 0.00788407 0.00619507 0.0033974\n",
      " 0.00266958 0.00231636 0.00537537 0.00231636 0.00266958 0.00537537\n",
      " 0.00231636 0.00108236 0.00266958 0.00231636 0.00571317 0.00788407\n",
      " 0.00619507 0.00727078 0.00231636 0.00108236 0.00251174 0.00537537\n",
      " 0.00571317 0.00266958 0.01944563 0.00266958 0.00108236 0.00619507\n",
      " 0.00266958 0.00788407 0.00251174 0.00537537 0.00266958 0.0033974\n",
      " 0.00251174 0.00619507 0.00231636 0.00619507 0.00571317]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.28992333390175223\n",
      "Alpha : 0.4478782112261413\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[54 23]\n",
      " [23 49]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6912751677852349\n",
      "Misclassification rate : 0.221\n",
      "True positives : 0.681\n",
      "False positives : 0.299\n",
      "Specificity : 0.701\n",
      "Precision : 0.6912751677852349\n",
      "Prevalence : 0.346\n",
      "Recall : 0.681\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 3]\n",
      " [2 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7058823529411765\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.6\n",
      "False positives : 0.25\n",
      "Specificity : 0.75\n",
      "Precision : 0.7245989304812834\n",
      "Prevalence : 0.024\n",
      "Recall : 0.6\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00417786 0.00362507 0.0046459  0.00160496 0.00417786 0.0053169\n",
      " 0.00148011 0.00169388 0.00417786 0.00160496 0.00170581 0.00343477\n",
      " 0.00343477 0.00148011 0.01242542 0.01137869 0.00395854 0.00069161\n",
      " 0.0053169  0.01137869 0.00362507 0.00148011 0.00170581 0.00170581\n",
      " 0.00365061 0.0053169  0.00170581 0.00362507 0.00362507 0.00160496\n",
      " 0.00170581 0.00343477 0.00362507 0.00395854 0.00535436 0.00148011\n",
      " 0.00069161 0.00417786 0.00969521 0.00170581 0.00170581 0.00148011\n",
      " 0.00535436 0.00170581 0.00170581 0.00365061 0.00170581 0.00503778\n",
      " 0.00170581 0.0053169  0.01242542 0.0046459  0.00395854 0.0053169\n",
      " 0.00160496 0.00343477 0.0084124  0.00170581 0.00160496 0.01233848\n",
      " 0.00894104 0.00169388 0.01311384 0.00894104 0.00417786 0.00343477\n",
      " 0.00069161 0.00169388 0.00343477 0.00503778 0.00362507 0.00217088\n",
      " 0.01311384 0.00160496 0.0053169  0.00535436 0.00160496 0.00343477\n",
      " 0.00069161 0.00535436 0.00160496 0.00343477 0.00217088 0.01137869\n",
      " 0.00343477 0.00362507 0.01233848 0.00362507 0.00535436 0.00148011\n",
      " 0.00170581 0.00969521 0.00894104 0.00343477 0.00170581 0.00343477\n",
      " 0.00535436 0.00170581 0.00069161 0.00148011 0.00362507 0.00894104\n",
      " 0.00160496 0.00343477 0.00148011 0.00969521 0.00395854 0.0046459\n",
      " 0.00535436 0.00148011 0.00160496 0.00503778 0.00395854 0.00217088\n",
      " 0.00170581 0.00148011 0.00343477 0.00148011 0.00170581 0.00343477\n",
      " 0.00362507 0.00169388 0.00417786 0.00148011 0.00894104 0.00503778\n",
      " 0.00969521 0.01137869 0.00148011 0.00069161 0.00160496 0.00343477\n",
      " 0.00365061 0.00417786 0.01242542 0.00170581 0.00069161 0.00395854\n",
      " 0.00170581 0.00503778 0.00160496 0.0084124  0.00170581 0.00217088\n",
      " 0.00160496 0.00395854 0.00148011 0.00395854 0.00365061]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2995995082721511\n",
      "Alpha : 0.4246028460590559\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[61 16]\n",
      " [37 35]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6442953020134228\n",
      "Misclassification rate : 0.255\n",
      "True positives : 0.486\n",
      "False positives : 0.208\n",
      "Specificity : 0.792\n",
      "Precision : 0.6532908465399584\n",
      "Prevalence : 0.346\n",
      "Recall : 0.486\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 5]\n",
      " [2 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5882352941176471\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.6\n",
      "False positives : 0.417\n",
      "Specificity : 0.583\n",
      "Precision : 0.6593137254901961\n",
      "Prevalence : 0.024\n",
      "Recall : 0.6\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00273244 0.0023709  0.00710351 0.00245395 0.00273244 0.00347741\n",
      " 0.00096804 0.00110785 0.00273244 0.00245395 0.00111565 0.00224644\n",
      " 0.00224644 0.00096804 0.01899826 0.007442   0.00605254 0.00045233\n",
      " 0.00347741 0.007442   0.0023709  0.00096804 0.00111565 0.00111565\n",
      " 0.00238761 0.00812944 0.00111565 0.0023709  0.0023709  0.00245395\n",
      " 0.00260816 0.00224644 0.0023709  0.00605254 0.00818673 0.00096804\n",
      " 0.00105746 0.00273244 0.01482381 0.00260816 0.00111565 0.00226306\n",
      " 0.00350191 0.00111565 0.00111565 0.00238761 0.00111565 0.00329486\n",
      " 0.00260816 0.00812944 0.00812659 0.00303856 0.002589   0.00812944\n",
      " 0.00104969 0.00224644 0.00550196 0.00260816 0.00245395 0.00806973\n",
      " 0.0058477  0.00110785 0.00857684 0.0058477  0.00638788 0.00224644\n",
      " 0.00105746 0.00258991 0.00224644 0.00329486 0.0023709  0.00141982\n",
      " 0.00857684 0.00104969 0.00812944 0.00350191 0.00245395 0.00224644\n",
      " 0.00045233 0.00818673 0.00245395 0.00224644 0.00141982 0.007442\n",
      " 0.00224644 0.0023709  0.00806973 0.0023709  0.00350191 0.00096804\n",
      " 0.00260816 0.00634095 0.0058477  0.00224644 0.00260816 0.00224644\n",
      " 0.00818673 0.00260816 0.00105746 0.00226306 0.0023709  0.0058477\n",
      " 0.00245395 0.00224644 0.00096804 0.00634095 0.00605254 0.00303856\n",
      " 0.00350191 0.00096804 0.00104969 0.00770269 0.00605254 0.00331924\n",
      " 0.00260816 0.00096804 0.00525171 0.00096804 0.00260816 0.00224644\n",
      " 0.00554267 0.00258991 0.00273244 0.00096804 0.0058477  0.00770269\n",
      " 0.01482381 0.007442   0.00096804 0.00045233 0.00104969 0.00224644\n",
      " 0.00238761 0.00273244 0.01899826 0.00111565 0.00105746 0.00605254\n",
      " 0.00260816 0.00329486 0.00104969 0.00550196 0.00260816 0.00331924\n",
      " 0.00245395 0.00605254 0.00096804 0.00605254 0.00238761]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2827795002290715\n",
      "Alpha : 0.46535794078484694\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[41 36]\n",
      " [23 49]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6040268456375839\n",
      "Misclassification rate : 0.284\n",
      "True positives : 0.681\n",
      "False positives : 0.468\n",
      "Specificity : 0.532\n",
      "Precision : 0.609624210422424\n",
      "Prevalence : 0.346\n",
      "Recall : 0.681\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 8]\n",
      " [3 2]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.35294117647058826\n",
      "Misclassification rate : 0.053\n",
      "True positives : 0.4\n",
      "False positives : 0.667\n",
      "Specificity : 0.333\n",
      "Precision : 0.4621848739495798\n",
      "Prevalence : 0.024\n",
      "Recall : 0.4\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00171573 0.00148871 0.00446037 0.00390813 0.00171573 0.0021835\n",
      " 0.00154168 0.00176434 0.00435165 0.00154086 0.00177677 0.00141056\n",
      " 0.00141056 0.00060784 0.0119292  0.00467291 0.00380045 0.00072038\n",
      " 0.00553806 0.00467291 0.00148871 0.00154168 0.00070053 0.00177677\n",
      " 0.00380247 0.00510456 0.00070053 0.00148871 0.00148871 0.00154086\n",
      " 0.00415372 0.00141056 0.00377586 0.00380045 0.00514053 0.00060784\n",
      " 0.00168409 0.00171573 0.00930802 0.00415372 0.00070053 0.00360412\n",
      " 0.00219889 0.00070053 0.00177677 0.00380247 0.00177677 0.00524734\n",
      " 0.00163769 0.00510456 0.00510277 0.00190794 0.00162566 0.00510456\n",
      " 0.00065911 0.00141056 0.00345473 0.00163769 0.00390813 0.00506707\n",
      " 0.00367183 0.00069563 0.00538548 0.00367183 0.00401101 0.00357765\n",
      " 0.00168409 0.00162623 0.00141056 0.00524734 0.00377586 0.00089152\n",
      " 0.00538548 0.00167172 0.00510456 0.00219889 0.00390813 0.00141056\n",
      " 0.00072038 0.00514053 0.00154086 0.00141056 0.00089152 0.00467291\n",
      " 0.00357765 0.00148871 0.01285172 0.00148871 0.00219889 0.00154168\n",
      " 0.00415372 0.00398155 0.00367183 0.00141056 0.00163769 0.00357765\n",
      " 0.00514053 0.00415372 0.00168409 0.00360412 0.00377586 0.00931296\n",
      " 0.00390813 0.00141056 0.00060784 0.00398155 0.00380045 0.00190794\n",
      " 0.00219889 0.00060784 0.00167172 0.0048366  0.00963918 0.00528617\n",
      " 0.00415372 0.00060784 0.00836378 0.00060784 0.00415372 0.00141056\n",
      " 0.0034803  0.00412465 0.00171573 0.00060784 0.00367183 0.0048366\n",
      " 0.02360817 0.01185201 0.00060784 0.00072038 0.00167172 0.00357765\n",
      " 0.00380247 0.00435165 0.0119292  0.00070053 0.00066399 0.00380045\n",
      " 0.00415372 0.00206888 0.00167172 0.00876233 0.00415372 0.00208419\n",
      " 0.00390813 0.00380045 0.00154168 0.00380045 0.00380247]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2845741548084909\n",
      "Alpha : 0.4609420419444144\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[63 14]\n",
      " [26 46]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7315436241610739\n",
      "Misclassification rate : 0.192\n",
      "True positives : 0.639\n",
      "False positives : 0.182\n",
      "Specificity : 0.818\n",
      "Precision : 0.7362793152854235\n",
      "Prevalence : 0.346\n",
      "Recall : 0.639\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[10  2]\n",
      " [ 1  4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8235294117647058\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.8\n",
      "False positives : 0.167\n",
      "Specificity : 0.833\n",
      "Precision : 0.8377896613190731\n",
      "Prevalence : 0.024\n",
      "Recall : 0.8\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0027204  0.00236046 0.00281311 0.00246481 0.00108209 0.00137711\n",
      " 0.00097232 0.00111275 0.00689983 0.00097181 0.00112059 0.00088963\n",
      " 0.00088963 0.00038336 0.00752362 0.00740921 0.00239691 0.00045433\n",
      " 0.0034928  0.00740921 0.00093892 0.00244444 0.00044182 0.00112059\n",
      " 0.00239818 0.00809362 0.00044182 0.00093892 0.00093892 0.00097181\n",
      " 0.0026197  0.00088963 0.0023814  0.00239691 0.00815066 0.00038336\n",
      " 0.00267024 0.0027204  0.0147585  0.006586   0.00044182 0.00227308\n",
      " 0.00348648 0.00044182 0.00112059 0.00239818 0.00112059 0.00832001\n",
      " 0.00103287 0.00809362 0.00809078 0.00302517 0.00102529 0.00809362\n",
      " 0.00041569 0.00223654 0.00217886 0.00259667 0.00246481 0.00319574\n",
      " 0.00231579 0.00043873 0.00339657 0.00231579 0.0025297  0.00225638\n",
      " 0.00106214 0.00102565 0.00088963 0.00330944 0.0023814  0.00141356\n",
      " 0.00853905 0.00105434 0.00809362 0.00348648 0.00246481 0.00088963\n",
      " 0.00045433 0.00324208 0.00097181 0.00088963 0.00056227 0.00294715\n",
      " 0.00225638 0.00093892 0.00810544 0.00093892 0.00348648 0.00097232\n",
      " 0.0026197  0.00251112 0.00231579 0.00088963 0.00259667 0.00225638\n",
      " 0.00815066 0.0026197  0.00106214 0.00571458 0.0023814  0.00587358\n",
      " 0.00246481 0.00088963 0.00038336 0.00251112 0.00239691 0.00302517\n",
      " 0.00348648 0.00038336 0.00105434 0.00766875 0.00607933 0.00838158\n",
      " 0.0026197  0.00038336 0.00527495 0.00038336 0.0026197  0.00088963\n",
      " 0.00219499 0.00260137 0.00108209 0.00096377 0.00231579 0.00766875\n",
      " 0.01488942 0.00747494 0.00038336 0.00045433 0.00265062 0.00225638\n",
      " 0.00239818 0.00274454 0.01891455 0.00044182 0.0010528  0.00239691\n",
      " 0.0026197  0.00328034 0.00105434 0.00552631 0.0026197  0.00330462\n",
      " 0.00246481 0.00239691 0.00097232 0.00239691 0.00602907]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2656797802539647\n",
      "Alpha : 0.5083267251008146\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[42 35]\n",
      " [17 55]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6510067114093959\n",
      "Misclassification rate : 0.25\n",
      "True positives : 0.764\n",
      "False positives : 0.455\n",
      "Specificity : 0.545\n",
      "Precision : 0.6631782504834489\n",
      "Prevalence : 0.346\n",
      "Recall : 0.764\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[5 7]\n",
      " [1 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5294117647058824\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.8\n",
      "False positives : 0.583\n",
      "Specificity : 0.417\n",
      "Precision : 0.6951871657754011\n",
      "Prevalence : 0.024\n",
      "Recall : 0.8\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00163633 0.00392427 0.00169209 0.00148259 0.00065088 0.00228945\n",
      " 0.00058485 0.00184995 0.00415025 0.00161563 0.00067404 0.00147901\n",
      " 0.00147901 0.00063734 0.01250807 0.01231786 0.00144174 0.00075533\n",
      " 0.00210092 0.01231786 0.00056476 0.00147033 0.00026575 0.00067404\n",
      " 0.00144251 0.00486833 0.00026575 0.00156095 0.00156095 0.00161563\n",
      " 0.00157576 0.00053511 0.00395909 0.00398487 0.00490263 0.00023059\n",
      " 0.00160615 0.00163633 0.00887725 0.01094926 0.00026575 0.00377901\n",
      " 0.0057963  0.00026575 0.00067404 0.00144251 0.00067404 0.0050045\n",
      " 0.00062128 0.00486833 0.00486662 0.00181964 0.00061671 0.00486833\n",
      " 0.00069109 0.00371827 0.00362238 0.0015619  0.00148259 0.00531295\n",
      " 0.00385001 0.00072938 0.00564682 0.00139295 0.00152162 0.00135722\n",
      " 0.00063888 0.00170515 0.00147901 0.00199063 0.00395909 0.00085026\n",
      " 0.00513625 0.00063418 0.00486833 0.0057963  0.00148259 0.00147901\n",
      " 0.00027328 0.00195011 0.00161563 0.00053511 0.00033821 0.00489966\n",
      " 0.00135722 0.00156095 0.00487543 0.00156095 0.00209712 0.00161649\n",
      " 0.00157576 0.00417476 0.00385001 0.00147901 0.0015619  0.00135722\n",
      " 0.00490263 0.00157576 0.00063888 0.00343732 0.00143241 0.00976487\n",
      " 0.00148259 0.00053511 0.00063734 0.00417476 0.00144174 0.00181964\n",
      " 0.00209712 0.00023059 0.00063418 0.00461276 0.00365672 0.00504153\n",
      " 0.00157576 0.00063734 0.00317289 0.00023059 0.00157576 0.00053511\n",
      " 0.00364918 0.00156473 0.00065088 0.00160228 0.00139295 0.00461276\n",
      " 0.008956   0.01242713 0.00023059 0.00027328 0.00159435 0.00375125\n",
      " 0.00144251 0.00165084 0.01137712 0.00026575 0.00175028 0.00144174\n",
      " 0.00435528 0.00197313 0.00063418 0.00332408 0.00157576 0.00198773\n",
      " 0.00409777 0.00398487 0.00058485 0.00398487 0.00362649]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.29460434163779325\n",
      "Alpha : 0.43656281080227577\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[19 58]\n",
      " [ 9 63]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5503355704697986\n",
      "Misclassification rate : 0.322\n",
      "True positives : 0.875\n",
      "False positives : 0.753\n",
      "Specificity : 0.247\n",
      "Precision : 0.602265793998558\n",
      "Prevalence : 0.346\n",
      "Recall : 0.875\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 5]\n",
      " [1 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.8\n",
      "False positives : 0.417\n",
      "Specificity : 0.583\n",
      "Precision : 0.7483660130718954\n",
      "Prevalence : 0.024\n",
      "Recall : 0.8\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00105748 0.00607234 0.00109352 0.00229413 0.00042063 0.00147957\n",
      " 0.00090499 0.00286258 0.00268212 0.0025     0.00104299 0.00228859\n",
      " 0.00228859 0.0009862  0.00808339 0.01906041 0.00093173 0.00048814\n",
      " 0.00135773 0.00796047 0.0008739  0.00227516 0.00017174 0.0004356\n",
      " 0.00093222 0.00314617 0.00017174 0.00241539 0.00241539 0.0025\n",
      " 0.00101834 0.00034582 0.00612621 0.00257524 0.00758623 0.00035681\n",
      " 0.00248532 0.00105748 0.00573696 0.007076   0.00017174 0.0024422\n",
      " 0.00374588 0.00017174 0.0004356  0.00093222 0.0004356  0.00323417\n",
      " 0.0004015  0.00314617 0.00314507 0.00281568 0.00095429 0.00314617\n",
      " 0.00106939 0.00575357 0.00560519 0.00100938 0.00095813 0.00343351\n",
      " 0.00595743 0.00112863 0.00364928 0.00215542 0.00098335 0.00210013\n",
      " 0.00041288 0.00263851 0.00228859 0.00308026 0.00255858 0.00054948\n",
      " 0.00331932 0.00098132 0.00314617 0.00374588 0.00095813 0.00228859\n",
      " 0.00042287 0.00126027 0.0025     0.00082802 0.00052334 0.00316643\n",
      " 0.00210013 0.00241539 0.00315077 0.00241539 0.00324504 0.00104466\n",
      " 0.00101834 0.00645993 0.00248808 0.00228859 0.00100938 0.00210013\n",
      " 0.00316834 0.00101834 0.00098858 0.00222138 0.00221649 0.00631059\n",
      " 0.00229413 0.00082802 0.0009862  0.00269795 0.00093173 0.00281568\n",
      " 0.00135527 0.00035681 0.00098132 0.00713769 0.00236317 0.00325811\n",
      " 0.00101834 0.0009862  0.00205049 0.00035681 0.00101834 0.00082802\n",
      " 0.00564667 0.00242123 0.00100716 0.00247933 0.0009002  0.00298101\n",
      " 0.00578785 0.00803108 0.00035681 0.00042287 0.00103036 0.00580461\n",
      " 0.00093222 0.00106686 0.00735251 0.00017174 0.00113113 0.00093173\n",
      " 0.00281461 0.00127514 0.00098132 0.00514361 0.00101834 0.00307577\n",
      " 0.0026482  0.00257524 0.00090499 0.00257524 0.00234363]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 6\n",
      "################################################\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165] [ 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101]\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.21476510067114118\n",
      "Alpha : 0.6482190159990141\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[68 10]\n",
      " [22 49]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.785234899328859\n",
      "Misclassification rate : 0.154\n",
      "True positives : 0.69\n",
      "False positives : 0.128\n",
      "Specificity : 0.872\n",
      "Precision : 0.7912713760285139\n",
      "Prevalence : 0.341\n",
      "Recall : 0.69\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 2]\n",
      " [6 0]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5294117647058824\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.0\n",
      "False positives : 0.182\n",
      "Specificity : 0.818\n",
      "Precision : 0.388235294117647\n",
      "Prevalence : 0.029\n",
      "Recall : 0.0\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00350991 0.00350991 0.0128331  0.00350991 0.00350991 0.0128331\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.00350991 0.0128331  0.0128331  0.00350991 0.00350991\n",
      " 0.0128331  0.0128331  0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.0128331  0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.0128331  0.00350991\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.0128331  0.00350991 0.00350991 0.00350991 0.00350991 0.0128331\n",
      " 0.00350991 0.0128331  0.0128331  0.0128331  0.00350991 0.0128331\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.0128331\n",
      " 0.00350991 0.00350991 0.0128331  0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.00350991 0.0128331  0.00350991 0.00350991 0.0128331\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.00350991 0.0128331  0.00350991 0.00350991 0.0128331\n",
      " 0.00350991 0.00350991 0.0128331  0.00350991 0.0128331  0.00350991\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.0128331  0.00350991 0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.0128331\n",
      " 0.0128331  0.00350991 0.00350991 0.0128331  0.00350991 0.0128331\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.0128331\n",
      " 0.00350991 0.0128331  0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.00350991 0.0128331  0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.0128331  0.00350991 0.00350991 0.00350991 0.0128331\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.30021367521367603\n",
      "Alpha : 0.42314028315075114\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[44 34]\n",
      " [15 56]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6711409395973155\n",
      "Misclassification rate : 0.236\n",
      "True positives : 0.789\n",
      "False positives : 0.436\n",
      "Specificity : 0.564\n",
      "Precision : 0.6868944248537013\n",
      "Prevalence : 0.341\n",
      "Recall : 0.789\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[6 5]\n",
      " [4 2]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.47058823529411764\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.333\n",
      "False positives : 0.455\n",
      "Specificity : 0.545\n",
      "Precision : 0.48907563025210077\n",
      "Prevalence : 0.029\n",
      "Recall : 0.333\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00229894 0.00535875 0.00840551 0.00229894 0.00535875 0.01959292\n",
      " 0.00535875 0.00229894 0.00535875 0.00229894 0.00229894 0.00535875\n",
      " 0.00535875 0.00229894 0.00840551 0.00840551 0.00229894 0.00229894\n",
      " 0.01959292 0.00840551 0.00535875 0.00229894 0.00229894 0.00229894\n",
      " 0.00535875 0.00840551 0.00535875 0.00535875 0.00535875 0.00229894\n",
      " 0.00229894 0.00535875 0.00535875 0.00229894 0.00840551 0.00229894\n",
      " 0.00229894 0.00229894 0.00229894 0.00229894 0.00229894 0.00535875\n",
      " 0.00840551 0.00229894 0.00229894 0.00535875 0.00229894 0.00840551\n",
      " 0.00229894 0.01959292 0.00840551 0.01959292 0.00229894 0.00840551\n",
      " 0.00229894 0.00535875 0.00535875 0.00229894 0.00229894 0.01959292\n",
      " 0.00535875 0.00229894 0.00840551 0.00535875 0.00229894 0.00535875\n",
      " 0.00229894 0.00229894 0.00840551 0.00229894 0.00229894 0.01959292\n",
      " 0.00229894 0.00229894 0.00535875 0.00535875 0.00535875 0.00229894\n",
      " 0.00229894 0.00535875 0.00840551 0.00229894 0.00229894 0.00840551\n",
      " 0.00229894 0.00535875 0.01959292 0.00535875 0.00840551 0.00229894\n",
      " 0.00229894 0.00229894 0.00535875 0.00535875 0.00229894 0.00229894\n",
      " 0.00840551 0.00229894 0.00229894 0.00229894 0.00229894 0.00535875\n",
      " 0.00229894 0.00535875 0.00229894 0.00535875 0.00229894 0.00840551\n",
      " 0.00840551 0.00229894 0.00229894 0.00840551 0.00229894 0.00840551\n",
      " 0.00229894 0.00535875 0.00535875 0.00229894 0.00535875 0.00229894\n",
      " 0.00229894 0.00229894 0.00229894 0.00535875 0.00535875 0.00840551\n",
      " 0.00229894 0.00840551 0.00535875 0.00229894 0.00229894 0.00229894\n",
      " 0.00535875 0.00535875 0.01959292 0.00229894 0.00229894 0.00229894\n",
      " 0.00229894 0.00840551 0.00229894 0.00229894 0.00229894 0.00840551\n",
      " 0.00229894 0.00229894 0.00535875 0.00229894 0.00535875]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.29496346200863854\n",
      "Alpha : 0.435699068668201\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[62 16]\n",
      " [35 36]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6577181208053692\n",
      "Misclassification rate : 0.245\n",
      "True positives : 0.507\n",
      "False positives : 0.205\n",
      "Specificity : 0.795\n",
      "Precision : 0.6644933976975766\n",
      "Prevalence : 0.341\n",
      "Recall : 0.507\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 2]\n",
      " [4 2]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.333\n",
      "False positives : 0.182\n",
      "Specificity : 0.818\n",
      "Precision : 0.6244343891402715\n",
      "Prevalence : 0.029\n",
      "Recall : 0.333\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00148699 0.0034661  0.01299529 0.00355427 0.0034661  0.01267294\n",
      " 0.0034661  0.00148699 0.0034661  0.00355427 0.00355427 0.0034661\n",
      " 0.0034661  0.00148699 0.01299529 0.00543679 0.00355427 0.00148699\n",
      " 0.01267294 0.00543679 0.0034661  0.00148699 0.00148699 0.00148699\n",
      " 0.0034661  0.01299529 0.0034661  0.0034661  0.0034661  0.00355427\n",
      " 0.00355427 0.0034661  0.0034661  0.00355427 0.01299529 0.00148699\n",
      " 0.00355427 0.00148699 0.00148699 0.00148699 0.00148699 0.00828486\n",
      " 0.00543679 0.00148699 0.00148699 0.0034661  0.00148699 0.00543679\n",
      " 0.00355427 0.03029151 0.00543679 0.01267294 0.00355427 0.01299529\n",
      " 0.00148699 0.0034661  0.0034661  0.00355427 0.00355427 0.01267294\n",
      " 0.0034661  0.00148699 0.00543679 0.0034661  0.00355427 0.0034661\n",
      " 0.00355427 0.00355427 0.00543679 0.00148699 0.00148699 0.01267294\n",
      " 0.00355427 0.00355427 0.0034661  0.0034661  0.0034661  0.00148699\n",
      " 0.00355427 0.0034661  0.00543679 0.00355427 0.00148699 0.00543679\n",
      " 0.00355427 0.0034661  0.01267294 0.0034661  0.00543679 0.00148699\n",
      " 0.00148699 0.00148699 0.00828486 0.0034661  0.00355427 0.00148699\n",
      " 0.01299529 0.00355427 0.00355427 0.00355427 0.00148699 0.0034661\n",
      " 0.00355427 0.0034661  0.00148699 0.0034661  0.00355427 0.00543679\n",
      " 0.00543679 0.00148699 0.00148699 0.01299529 0.00355427 0.01299529\n",
      " 0.00148699 0.0034661  0.0034661  0.00148699 0.0034661  0.00148699\n",
      " 0.00355427 0.00355427 0.00148699 0.0034661  0.0034661  0.01299529\n",
      " 0.00355427 0.00543679 0.0034661  0.00148699 0.00148699 0.00148699\n",
      " 0.00828486 0.0034661  0.03029151 0.00148699 0.00355427 0.00355427\n",
      " 0.00148699 0.00543679 0.00148699 0.00148699 0.00355427 0.01299529\n",
      " 0.00355427 0.00355427 0.0034661  0.00355427 0.0034661 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.29015153474223926\n",
      "Alpha : 0.4473240989701874\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[29 49]\n",
      " [12 59]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5906040268456376\n",
      "Misclassification rate : 0.293\n",
      "True positives : 0.831\n",
      "False positives : 0.628\n",
      "Specificity : 0.372\n",
      "Precision : 0.6305890519755308\n",
      "Prevalence : 0.341\n",
      "Recall : 0.831\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[5 6]\n",
      " [1 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5882352941176471\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.833\n",
      "False positives : 0.545\n",
      "Specificity : 0.455\n",
      "Precision : 0.6996434937611409\n",
      "Prevalence : 0.029\n",
      "Recall : 0.833\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00232582 0.00542141 0.00830836 0.00227237 0.00221601 0.00810228\n",
      " 0.00542141 0.00095068 0.00542141 0.00227237 0.00227237 0.00542141\n",
      " 0.00542141 0.00232582 0.00830836 0.0085038  0.00227237 0.00095068\n",
      " 0.00810228 0.00347594 0.00542141 0.00232582 0.00095068 0.00095068\n",
      " 0.00542141 0.00830836 0.00221601 0.00542141 0.00542141 0.00227237\n",
      " 0.00227237 0.00542141 0.00542141 0.00227237 0.00830836 0.00232582\n",
      " 0.0055593  0.00232582 0.00232582 0.00232582 0.00095068 0.01295852\n",
      " 0.00347594 0.00095068 0.00095068 0.00542141 0.00095068 0.00347594\n",
      " 0.00227237 0.01936647 0.0085038  0.00810228 0.00227237 0.00830836\n",
      " 0.00095068 0.00221601 0.00221601 0.00227237 0.00227237 0.00810228\n",
      " 0.00542141 0.00095068 0.00347594 0.00542141 0.00227237 0.00542141\n",
      " 0.00227237 0.00227237 0.00347594 0.00232582 0.00095068 0.00810228\n",
      " 0.00227237 0.00227237 0.00542141 0.00542141 0.00542141 0.00232582\n",
      " 0.00227237 0.00542141 0.00347594 0.00227237 0.00232582 0.0085038\n",
      " 0.0055593  0.00542141 0.00810228 0.00221601 0.00347594 0.00232582\n",
      " 0.00095068 0.00095068 0.01295852 0.00542141 0.00227237 0.00232582\n",
      " 0.00830836 0.00227237 0.00227237 0.0055593  0.00232582 0.00542141\n",
      " 0.00227237 0.00221601 0.00232582 0.00221601 0.00227237 0.0085038\n",
      " 0.00347594 0.00232582 0.00095068 0.00830836 0.00227237 0.00830836\n",
      " 0.00095068 0.00542141 0.00221601 0.00232582 0.00542141 0.00232582\n",
      " 0.00227237 0.0055593  0.00232582 0.00542141 0.00221601 0.00830836\n",
      " 0.00227237 0.0085038  0.00542141 0.00095068 0.00095068 0.00232582\n",
      " 0.00529681 0.00221601 0.01936647 0.00095068 0.00227237 0.00227237\n",
      " 0.00232582 0.00347594 0.00095068 0.00232582 0.00227237 0.0203262\n",
      " 0.00227237 0.00227237 0.00542141 0.00227237 0.00542141]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2980933753718308\n",
      "Alpha : 0.42819680211500566\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[52 26]\n",
      " [24 47]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6644295302013423\n",
      "Misclassification rate : 0.24\n",
      "True positives : 0.662\n",
      "False positives : 0.333\n",
      "Specificity : 0.667\n",
      "Precision : 0.6649714753003683\n",
      "Prevalence : 0.341\n",
      "Recall : 0.662\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 8]\n",
      " [0 6]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5294117647058824\n",
      "Misclassification rate : 0.038\n",
      "True positives : 1.0\n",
      "False positives : 0.727\n",
      "Specificity : 0.273\n",
      "Precision : 0.7983193277310924\n",
      "Prevalence : 0.029\n",
      "Recall : 1.0\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0015157  0.00353304 0.00541442 0.00348693 0.00144413 0.00528012\n",
      " 0.00353304 0.00061954 0.00353304 0.00348693 0.00148087 0.00831908\n",
      " 0.00831908 0.0015157  0.01274908 0.00554178 0.00348693 0.00061954\n",
      " 0.00528012 0.00226521 0.00353304 0.0015157  0.00061954 0.00061954\n",
      " 0.00353304 0.00541442 0.00144413 0.00353304 0.00353304 0.00348693\n",
      " 0.00148087 0.00831908 0.00353304 0.00348693 0.00541442 0.0015157\n",
      " 0.0036229  0.0015157  0.00356895 0.0015157  0.00061954 0.00844485\n",
      " 0.00226521 0.00061954 0.00061954 0.00353304 0.00061954 0.00533379\n",
      " 0.00148087 0.0126208  0.01304897 0.00528012 0.00348693 0.00541442\n",
      " 0.00145881 0.00340044 0.00340044 0.00148087 0.00348693 0.01243285\n",
      " 0.00353304 0.00061954 0.00226521 0.00353304 0.00148087 0.00831908\n",
      " 0.00148087 0.00148087 0.00226521 0.00356895 0.00061954 0.00528012\n",
      " 0.00348693 0.00348693 0.00831908 0.00353304 0.00353304 0.0015157\n",
      " 0.00148087 0.00831908 0.00533379 0.00148087 0.0015157  0.00554178\n",
      " 0.0036229  0.00353304 0.01243285 0.00144413 0.00226521 0.0015157\n",
      " 0.00061954 0.00145881 0.00844485 0.00831908 0.00148087 0.00356895\n",
      " 0.00541442 0.00148087 0.00148087 0.0036229  0.0015157  0.00353304\n",
      " 0.00348693 0.00340044 0.0015157  0.00340044 0.00348693 0.00554178\n",
      " 0.00226521 0.0015157  0.00145881 0.01274908 0.00348693 0.00541442\n",
      " 0.00061954 0.00353304 0.00340044 0.0015157  0.00353304 0.00356895\n",
      " 0.00148087 0.0036229  0.0015157  0.00353304 0.00144413 0.01274908\n",
      " 0.00348693 0.00554178 0.00353304 0.00061954 0.00145881 0.00356895\n",
      " 0.00345184 0.00144413 0.02971762 0.00061954 0.00148087 0.00348693\n",
      " 0.0015157  0.00533379 0.00145881 0.00356895 0.00148087 0.01324624\n",
      " 0.00348693 0.00348693 0.00353304 0.00348693 0.00353304]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3018517073080089\n",
      "Alpha : 0.4192478362685854\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[36 42]\n",
      " [22 49]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5704697986577181\n",
      "Misclassification rate : 0.308\n",
      "True positives : 0.69\n",
      "False positives : 0.538\n",
      "Specificity : 0.462\n",
      "Precision : 0.5815071297598491\n",
      "Prevalence : 0.341\n",
      "Recall : 0.69\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 3]\n",
      " [3 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.5\n",
      "False positives : 0.273\n",
      "Specificity : 0.727\n",
      "Precision : 0.6470588235294118\n",
      "Prevalence : 0.029\n",
      "Recall : 0.5\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0023051  0.00537311 0.00823434 0.0022928  0.00094958 0.00347189\n",
      " 0.00537311 0.00094221 0.00232312 0.0022928  0.00097373 0.00547014\n",
      " 0.00547014 0.0023051  0.00838305 0.00364395 0.0022928  0.00094221\n",
      " 0.00347189 0.00344497 0.00232312 0.0023051  0.00094221 0.00094221\n",
      " 0.00537311 0.0035602  0.00094958 0.00537311 0.00537311 0.0022928\n",
      " 0.00225213 0.00547014 0.00537311 0.0022928  0.00823434 0.00099664\n",
      " 0.00550978 0.00099664 0.00234673 0.00099664 0.00094221 0.00555284\n",
      " 0.00344497 0.00040738 0.00094221 0.00537311 0.00094221 0.00811171\n",
      " 0.00225213 0.0082987  0.00858024 0.00803009 0.0022928  0.0035602\n",
      " 0.00221859 0.00223593 0.00223593 0.00225213 0.0022928  0.00817511\n",
      " 0.00232312 0.00094221 0.00148947 0.00537311 0.00097373 0.00547014\n",
      " 0.00097373 0.00097373 0.00344497 0.00542772 0.00040738 0.00803009\n",
      " 0.0022928  0.00530298 0.00547014 0.00537311 0.00232312 0.0023051\n",
      " 0.00097373 0.00547014 0.00350718 0.00097373 0.0023051  0.00364395\n",
      " 0.00550978 0.00232312 0.00817511 0.00219626 0.00148947 0.0023051\n",
      " 0.00094221 0.00095923 0.00555284 0.00547014 0.00097373 0.00234673\n",
      " 0.00823434 0.00225213 0.00225213 0.00550978 0.0023051  0.00537311\n",
      " 0.0022928  0.00223593 0.00099664 0.00517144 0.00530298 0.00842804\n",
      " 0.00344497 0.00099664 0.00095923 0.00838305 0.0022928  0.0035602\n",
      " 0.00094221 0.00232312 0.00517144 0.00099664 0.00537311 0.00234673\n",
      " 0.00097373 0.00550978 0.00099664 0.00537311 0.00219626 0.00838305\n",
      " 0.0022928  0.00842804 0.00232312 0.00040738 0.00095923 0.00542772\n",
      " 0.00226973 0.00219626 0.01954056 0.00040738 0.00097373 0.0022928\n",
      " 0.00099664 0.00350718 0.00095923 0.00234673 0.00225213 0.00870995\n",
      " 0.0022928  0.0022928  0.00537311 0.00530298 0.00537311]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3027858557757345\n",
      "Alpha : 0.4170333957959864\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[54 24]\n",
      " [23 48]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6845637583892618\n",
      "Misclassification rate : 0.226\n",
      "True positives : 0.676\n",
      "False positives : 0.308\n",
      "Specificity : 0.692\n",
      "Precision : 0.6847961881518929\n",
      "Prevalence : 0.341\n",
      "Recall : 0.676\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 2]\n",
      " [2 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7647058823529411\n",
      "Misclassification rate : 0.019\n",
      "True positives : 0.667\n",
      "False positives : 0.182\n",
      "Specificity : 0.818\n",
      "Precision : 0.7647058823529411\n",
      "Prevalence : 0.029\n",
      "Recall : 0.667\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00349789 0.00815344 0.00542642 0.00151095 0.00144094 0.00526844\n",
      " 0.00354087 0.00142977 0.00352522 0.00151095 0.00064169 0.00360482\n",
      " 0.00360482 0.00151906 0.00552442 0.00552952 0.00151095 0.00062092\n",
      " 0.00526844 0.00522758 0.00352522 0.00151906 0.00062092 0.00062092\n",
      " 0.00354087 0.00540244 0.00062577 0.00815344 0.00815344 0.00151095\n",
      " 0.00148415 0.00360482 0.00815344 0.00151095 0.00542642 0.00065678\n",
      " 0.00363094 0.00151235 0.00356106 0.00065678 0.00062092 0.00365931\n",
      " 0.00227023 0.00026846 0.00062092 0.00354087 0.00062092 0.00534561\n",
      " 0.00148415 0.01259289 0.00565437 0.00529182 0.00151095 0.00540244\n",
      " 0.00146205 0.00147347 0.00339292 0.00148415 0.00151095 0.01240535\n",
      " 0.00352522 0.00142977 0.0022602  0.00815344 0.00147759 0.00360482\n",
      " 0.00064169 0.00147759 0.00227023 0.00357686 0.00026846 0.00529182\n",
      " 0.00151095 0.00349466 0.00360482 0.00354087 0.00153093 0.00349789\n",
      " 0.00147759 0.00830068 0.00532199 0.00064169 0.00151906 0.00552952\n",
      " 0.00363094 0.00352522 0.01240535 0.00333273 0.00098156 0.00151906\n",
      " 0.00062092 0.00145559 0.00842617 0.00360482 0.00064169 0.00154649\n",
      " 0.00542642 0.00148415 0.00148415 0.00363094 0.00349789 0.00815344\n",
      " 0.00151095 0.00147347 0.00065678 0.00784742 0.00349466 0.00555407\n",
      " 0.00227023 0.00065678 0.00063213 0.00552442 0.00151095 0.00234617\n",
      " 0.00062092 0.00153093 0.00340798 0.00065678 0.00354087 0.00154649\n",
      " 0.00147759 0.00836083 0.00151235 0.00354087 0.00333273 0.00552442\n",
      " 0.00347922 0.01278915 0.00153093 0.00026846 0.00063213 0.00357686\n",
      " 0.00149575 0.00333273 0.01287721 0.00026846 0.00064169 0.00151095\n",
      " 0.00065678 0.00231123 0.00063213 0.00356106 0.00148415 0.00573985\n",
      " 0.00151095 0.00151095 0.00354087 0.00349466 0.00354087]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2986126130389554\n",
      "Alpha : 0.42695661504186566\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[56 22]\n",
      " [21 50]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7114093959731543\n",
      "Misclassification rate : 0.207\n",
      "True positives : 0.704\n",
      "False positives : 0.282\n",
      "Specificity : 0.718\n",
      "Precision : 0.7116297200189818\n",
      "Prevalence : 0.341\n",
      "Recall : 0.704\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[5 6]\n",
      " [3 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.47058823529411764\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.5\n",
      "False positives : 0.545\n",
      "Specificity : 0.455\n",
      "Precision : 0.5220588235294118\n",
      "Prevalence : 0.029\n",
      "Recall : 0.5\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00228234 0.00532005 0.00831646 0.00231566 0.0009402  0.00343761\n",
      " 0.00231039 0.00093291 0.00230018 0.00231566 0.0004187  0.00552469\n",
      " 0.00552469 0.00099117 0.00360464 0.00360797 0.00231566 0.00040514\n",
      " 0.00343761 0.00341096 0.00230018 0.00099117 0.00040514 0.00095161\n",
      " 0.00231039 0.00827971 0.00040831 0.01249585 0.00532005 0.00231566\n",
      " 0.0009684  0.00552469 0.00532005 0.00231566 0.0035407  0.00042854\n",
      " 0.00236916 0.00098679 0.00232356 0.00100657 0.00095161 0.00238767\n",
      " 0.00148131 0.00017517 0.00040514 0.00231039 0.00040514 0.00819261\n",
      " 0.0009684  0.01929968 0.00866581 0.00345287 0.00098588 0.00827971\n",
      " 0.00224071 0.00096143 0.00221385 0.0009684  0.00231566 0.00809439\n",
      " 0.00230018 0.00093291 0.00346395 0.00532005 0.00096412 0.00552469\n",
      " 0.00098344 0.00096412 0.00148131 0.00548185 0.00017517 0.00345287\n",
      " 0.00098588 0.00228024 0.00552469 0.00231039 0.00099892 0.00228234\n",
      " 0.00096412 0.00541613 0.00347255 0.00098344 0.00232809 0.00847447\n",
      " 0.00236916 0.00230018 0.00809439 0.00217458 0.00064046 0.00232809\n",
      " 0.00040514 0.00094976 0.00549801 0.00552469 0.0004187  0.00237013\n",
      " 0.0035407  0.0009684  0.0009684  0.00236916 0.00228234 0.00532005\n",
      " 0.00231566 0.00225823 0.00042854 0.00512038 0.00228024 0.00362398\n",
      " 0.00148131 0.00042854 0.00041246 0.00846665 0.00098588 0.00153086\n",
      " 0.00040514 0.00099892 0.00522302 0.00042854 0.00231039 0.00237013\n",
      " 0.00096412 0.00545537 0.00098679 0.00231039 0.00217458 0.00360464\n",
      " 0.0053322  0.00834482 0.00099892 0.00017517 0.00041246 0.00233387\n",
      " 0.00097596 0.00217458 0.01973543 0.00017517 0.0004187  0.00098588\n",
      " 0.00042854 0.00354216 0.00041246 0.00232356 0.0009684  0.00879681\n",
      " 0.00231566 0.00231566 0.00231039 0.00535587 0.00231039]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.34642453895709313\n",
      "Alpha : 0.31739649220616073\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[75  3]\n",
      " [60 11]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5771812080536913\n",
      "Misclassification rate : 0.303\n",
      "True positives : 0.155\n",
      "False positives : 0.038\n",
      "Specificity : 0.962\n",
      "Precision : 0.6652285075103868\n",
      "Prevalence : 0.341\n",
      "Recall : 0.155\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[11  0]\n",
      " [ 6  0]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.0\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 0.41868512110726647\n",
      "Prevalence : 0.029\n",
      "Recall : 0.0\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00313491 0.00387322 0.00605473 0.0016859  0.00129141 0.00472172\n",
      " 0.00168206 0.0006792  0.00315941 0.0016859  0.0005751  0.00402221\n",
      " 0.00402221 0.00072162 0.00495114 0.00262675 0.00318067 0.00029496\n",
      " 0.00472172 0.00248332 0.00167463 0.00136143 0.00055648 0.00130708\n",
      " 0.00168206 0.01137257 0.00056083 0.0090975  0.00387322 0.0016859\n",
      " 0.00133014 0.00402221 0.00387322 0.0016859  0.00486331 0.000312\n",
      " 0.00172485 0.00135541 0.00319152 0.00138258 0.00130708 0.00173833\n",
      " 0.00203465 0.0002406  0.00055648 0.00317343 0.00055648 0.00596456\n",
      " 0.00133014 0.02650902 0.00630907 0.00251384 0.00071777 0.01137257\n",
      " 0.00163133 0.00069996 0.00161178 0.00133014 0.0016859  0.01111802\n",
      " 0.00315941 0.0006792  0.0025219  0.00387322 0.00132426 0.00402221\n",
      " 0.0013508  0.00070192 0.00203465 0.00399102 0.0002406  0.00251384\n",
      " 0.00135416 0.00166011 0.00402221 0.00168206 0.00072726 0.00166164\n",
      " 0.00070192 0.00394317 0.00476972 0.0013508  0.00169495 0.01164008\n",
      " 0.00172485 0.00167463 0.01111802 0.00158318 0.0008797  0.00169495\n",
      " 0.00055648 0.00069146 0.00755177 0.00402221 0.0005751  0.00172556\n",
      " 0.00486331 0.00133014 0.00070503 0.00172485 0.00166164 0.00387322\n",
      " 0.0016859  0.00164408 0.000312   0.00703308 0.00313201 0.00263841\n",
      " 0.00203465 0.000312   0.00030029 0.00616408 0.00135416 0.0021027\n",
      " 0.00055648 0.00072726 0.00380257 0.000312   0.00317343 0.00172556\n",
      " 0.00070192 0.00397174 0.00135541 0.00168206 0.00158318 0.00262433\n",
      " 0.00388206 0.00607538 0.00072726 0.00012753 0.00030029 0.00169916\n",
      " 0.00134053 0.00298689 0.01436822 0.0002406  0.0005751  0.00135416\n",
      " 0.00058863 0.00257884 0.00030029 0.00169165 0.00133014 0.00640445\n",
      " 0.00318067 0.00318067 0.00168206 0.00735653 0.00168206]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3690458368257864\n",
      "Alpha : 0.26815618148718695\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[69  9]\n",
      " [50 21]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6040268456375839\n",
      "Misclassification rate : 0.284\n",
      "True positives : 0.296\n",
      "False positives : 0.115\n",
      "Specificity : 0.885\n",
      "Precision : 0.637093226552366\n",
      "Prevalence : 0.341\n",
      "Recall : 0.296\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[11  0]\n",
      " [ 4  2]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7647058823529411\n",
      "Misclassification rate : 0.019\n",
      "True positives : 0.333\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 0.8274509803921568\n",
      "Prevalence : 0.029\n",
      "Recall : 0.333\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[4.09904981e-03 2.96219460e-03 4.63058984e-03 1.28935766e-03\n",
      " 1.68858667e-03 6.17389501e-03 1.28642058e-03 5.19442918e-04\n",
      " 4.13108501e-03 1.28935766e-03 7.51971141e-04 5.25924324e-03\n",
      " 3.07613759e-03 5.51884250e-04 6.47387148e-03 3.43461407e-03\n",
      " 4.15889537e-03 2.25583445e-04 3.61111850e-03 1.89921317e-03\n",
      " 2.18966180e-03 1.04120223e-03 7.27632041e-04 1.70907696e-03\n",
      " 1.28642058e-03 1.48702225e-02 7.33318685e-04 6.95766300e-03\n",
      " 2.96219460e-03 1.28935766e-03 1.73922279e-03 3.07613759e-03\n",
      " 2.96219460e-03 1.28935766e-03 6.35903332e-03 4.07954245e-04\n",
      " 1.31914156e-03 1.77226700e-03 2.44083639e-03 1.80779154e-03\n",
      " 1.70907696e-03 1.32945101e-03 2.66040465e-03 3.14599314e-04\n",
      " 7.27632041e-04 2.42700164e-03 7.27632041e-04 4.56162866e-03\n",
      " 1.01727347e-03 2.02737901e-02 8.24943415e-03 1.92255197e-03\n",
      " 9.38514745e-04 8.69761073e-03 1.24762493e-03 5.35322106e-04\n",
      " 1.23266704e-03 1.73922279e-03 1.28935766e-03 8.50293299e-03\n",
      " 4.13108501e-03 5.19442918e-04 3.29751647e-03 2.96219460e-03\n",
      " 1.73153701e-03 3.07613759e-03 1.03307887e-03 5.36818147e-04\n",
      " 1.55607383e-03 3.05228316e-03 3.14599314e-04 1.92255197e-03\n",
      " 1.03564447e-03 1.26963137e-03 3.07613759e-03 1.28642058e-03\n",
      " 5.56197377e-04 1.27080409e-03 5.36818147e-04 3.01568905e-03\n",
      " 3.64782316e-03 1.03307887e-03 1.29627697e-03 8.90219984e-03\n",
      " 1.31914156e-03 1.28073578e-03 8.50293299e-03 1.21080111e-03\n",
      " 1.15025374e-03 1.29627697e-03 4.25592842e-04 9.04124635e-04\n",
      " 9.87432766e-03 3.07613759e-03 7.51971141e-04 1.31968651e-03\n",
      " 6.35903332e-03 1.01727347e-03 5.39200923e-04 1.31914156e-03\n",
      " 1.27080409e-03 2.96219460e-03 1.28935766e-03 2.14972289e-03\n",
      " 4.07954245e-04 9.19611549e-03 4.09526712e-03 3.44985930e-03\n",
      " 1.55607383e-03 4.07954245e-04 2.29657270e-04 8.05984681e-03\n",
      " 1.77063152e-03 2.74939448e-03 7.27632041e-04 5.56197377e-04\n",
      " 2.90816488e-03 4.07954245e-04 2.42700164e-03 1.31968651e-03\n",
      " 5.36818147e-04 3.03754002e-03 1.77226700e-03 1.28642058e-03\n",
      " 1.21080111e-03 3.43144454e-03 5.07599878e-03 4.64637747e-03\n",
      " 5.56197377e-04 9.75333589e-05 2.29657270e-04 1.29949621e-03\n",
      " 1.02522374e-03 3.90550682e-03 1.87871874e-02 3.14599314e-04\n",
      " 4.39828810e-04 1.77063152e-03 7.69659345e-04 3.37196754e-03\n",
      " 2.29657270e-04 1.29375362e-03 1.73922279e-03 4.89804811e-03\n",
      " 2.43254282e-03 4.15889537e-03 1.28642058e-03 9.61904680e-03\n",
      " 1.28642058e-03]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 7\n",
      "################################################\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 118 119 120 121 122 123\n",
      " 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161 162 163 164 165] [102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117]\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.24666666666666606\n",
      "Alpha : 0.5582349530340597\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[69 12]\n",
      " [25 44]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7533333333333333\n",
      "Misclassification rate : 0.178\n",
      "True positives : 0.638\n",
      "False positives : 0.148\n",
      "Specificity : 0.852\n",
      "Precision : 0.7578115501519758\n",
      "Prevalence : 0.332\n",
      "Recall : 0.638\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 0]\n",
      " [3 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8125\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.625\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 0.8636363636363636\n",
      "Prevalence : 0.038\n",
      "Recall : 0.625\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00381479 0.00381479 0.01165057 0.00381479 0.00381479 0.01165057\n",
      " 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.00381479 0.00381479 0.01165057 0.01165057 0.00381479 0.00381479\n",
      " 0.01165057 0.01165057 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.00381479 0.01165057 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.00381479 0.00381479 0.00381479 0.00381479 0.01165057 0.00381479\n",
      " 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.01165057 0.00381479 0.00381479 0.00381479 0.00381479 0.01165057\n",
      " 0.00381479 0.01165057 0.01165057 0.01165057 0.00381479 0.01165057\n",
      " 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479 0.01165057\n",
      " 0.00381479 0.00381479 0.01165057 0.00381479 0.00381479 0.00381479\n",
      " 0.00381479 0.00381479 0.01165057 0.00381479 0.00381479 0.01165057\n",
      " 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.00381479 0.00381479 0.01165057 0.00381479 0.00381479 0.01165057\n",
      " 0.00381479 0.00381479 0.01165057 0.00381479 0.01165057 0.01165057\n",
      " 0.00381479 0.01165057 0.01165057 0.00381479 0.00381479 0.00381479\n",
      " 0.01165057 0.00381479 0.00381479 0.01165057 0.01165057 0.00381479\n",
      " 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.01165057 0.01165057 0.00381479 0.00381479 0.01165057 0.00381479\n",
      " 0.01165057 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.01165057 0.00381479 0.01165057 0.00381479 0.00381479 0.00381479\n",
      " 0.00381479 0.00381479 0.00381479 0.01165057 0.00381479 0.00381479\n",
      " 0.00381479 0.00381479 0.01165057 0.00381479 0.00381479 0.00381479\n",
      " 0.01165057 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.34286055967471796\n",
      "Alpha : 0.3252862004771782\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[23 58]\n",
      " [ 1 68]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6066666666666667\n",
      "Misclassification rate : 0.284\n",
      "True positives : 0.986\n",
      "False positives : 0.716\n",
      "Specificity : 0.284\n",
      "Precision : 0.7657539682539682\n",
      "Prevalence : 0.332\n",
      "Recall : 0.986\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[1 7]\n",
      " [1 7]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.875\n",
      "False positives : 0.875\n",
      "Specificity : 0.125\n",
      "Precision : 0.5\n",
      "Prevalence : 0.038\n",
      "Recall : 0.875\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0027555  0.00528129 0.01612936 0.0027555  0.0027555  0.00841545\n",
      " 0.00528129 0.00528129 0.0027555  0.0027555  0.0027555  0.00528129\n",
      " 0.00528129 0.00528129 0.00841545 0.01612936 0.0027555  0.0027555\n",
      " 0.00841545 0.01612936 0.00528129 0.00528129 0.0027555  0.0027555\n",
      " 0.00528129 0.00841545 0.0027555  0.00528129 0.00528129 0.0027555\n",
      " 0.0027555  0.00528129 0.00528129 0.0027555  0.00841545 0.00528129\n",
      " 0.0027555  0.0027555  0.0027555  0.0027555  0.0027555  0.00528129\n",
      " 0.00841545 0.0027555  0.0027555  0.00528129 0.0027555  0.00841545\n",
      " 0.0027555  0.00841545 0.00841545 0.01612936 0.0027555  0.00841545\n",
      " 0.0027555  0.00528129 0.00528129 0.0027555  0.0027555  0.00841545\n",
      " 0.00528129 0.0027555  0.00841545 0.00528129 0.0027555  0.00528129\n",
      " 0.0027555  0.0027555  0.01612936 0.0027555  0.0027555  0.01612936\n",
      " 0.0027555  0.0027555  0.00528129 0.00528129 0.00528129 0.00528129\n",
      " 0.00528129 0.00528129 0.00841545 0.0027555  0.00528129 0.00841545\n",
      " 0.0027555  0.00528129 0.00841545 0.00528129 0.00841545 0.00841545\n",
      " 0.0027555  0.00841545 0.00841545 0.0027555  0.00528129 0.00528129\n",
      " 0.00841545 0.0027555  0.00528129 0.00841545 0.01612936 0.00528129\n",
      " 0.00528129 0.0027555  0.00528129 0.00528129 0.0027555  0.0027555\n",
      " 0.01612936 0.00841545 0.00528129 0.0027555  0.00841545 0.0027555\n",
      " 0.00841545 0.0027555  0.00528129 0.00528129 0.00528129 0.0027555\n",
      " 0.00528129 0.00528129 0.0027555  0.0027555  0.00528129 0.00528129\n",
      " 0.00841545 0.0027555  0.01612936 0.00528129 0.0027555  0.0027555\n",
      " 0.00528129 0.0027555  0.0027555  0.00841545 0.0027555  0.0027555\n",
      " 0.0027555  0.0027555  0.00841545 0.0027555  0.00528129 0.0027555\n",
      " 0.00841545 0.0027555  0.0027555  0.00528129 0.0027555  0.00528129]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.30341811197229424\n",
      "Alpha : 0.4155367976240785\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[49 32]\n",
      " [22 47]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.64\n",
      "Misclassification rate : 0.26\n",
      "True positives : 0.681\n",
      "False positives : 0.395\n",
      "Specificity : 0.605\n",
      "Precision : 0.6463469424139775\n",
      "Prevalence : 0.332\n",
      "Recall : 0.681\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[6 2]\n",
      " [2 6]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.75\n",
      "Misclassification rate : 0.019\n",
      "True positives : 0.75\n",
      "False positives : 0.25\n",
      "Specificity : 0.75\n",
      "Precision : 0.75\n",
      "Prevalence : 0.038\n",
      "Recall : 0.75\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00181859 0.00348558 0.01064515 0.00417509 0.00181859 0.00555408\n",
      " 0.00348558 0.00348558 0.00181859 0.00417509 0.00181859 0.00800213\n",
      " 0.00800213 0.00348558 0.01275095 0.01064515 0.00417509 0.00181859\n",
      " 0.00555408 0.01064515 0.00348558 0.00348558 0.00181859 0.00181859\n",
      " 0.00348558 0.00555408 0.00181859 0.00348558 0.00348558 0.00417509\n",
      " 0.00181859 0.00800213 0.00348558 0.00417509 0.00555408 0.00348558\n",
      " 0.00181859 0.00181859 0.00417509 0.00181859 0.00181859 0.00348558\n",
      " 0.00555408 0.00181859 0.00181859 0.00348558 0.00181859 0.01275095\n",
      " 0.00181859 0.00555408 0.01275095 0.01064515 0.00417509 0.00555408\n",
      " 0.00417509 0.00800213 0.00800213 0.00181859 0.00417509 0.01275095\n",
      " 0.00348558 0.00181859 0.00555408 0.00348558 0.00181859 0.00800213\n",
      " 0.00181859 0.00181859 0.01064515 0.00417509 0.00181859 0.01064515\n",
      " 0.00417509 0.00417509 0.00800213 0.00348558 0.00348558 0.00348558\n",
      " 0.00348558 0.00800213 0.01275095 0.00181859 0.00348558 0.00555408\n",
      " 0.00181859 0.00800213 0.01275095 0.00348558 0.00555408 0.00555408\n",
      " 0.00417509 0.00555408 0.00555408 0.00417509 0.00800213 0.00348558\n",
      " 0.00555408 0.00417509 0.00800213 0.00555408 0.01064515 0.00800213\n",
      " 0.00348558 0.00417509 0.00800213 0.00348558 0.00417509 0.00417509\n",
      " 0.01064515 0.00555408 0.00348558 0.00417509 0.01275095 0.00417509\n",
      " 0.00555408 0.00181859 0.00348558 0.00800213 0.00348558 0.00181859\n",
      " 0.00800213 0.00348558 0.00181859 0.00181859 0.00348558 0.00348558\n",
      " 0.01275095 0.00417509 0.01064515 0.00348558 0.00181859 0.00417509\n",
      " 0.00800213 0.00181859 0.00181859 0.01275095 0.00181859 0.00181859\n",
      " 0.00417509 0.00181859 0.01275095 0.00417509 0.00800213 0.00181859\n",
      " 0.00555408 0.00417509 0.00417509 0.00348558 0.00417509 0.00348558]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2787511217829959\n",
      "Alpha : 0.47533245769477067\n",
      "\n",
      ":: Treinamento :: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roberto/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[74  7]\n",
      " [51 18]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6133333333333333\n",
      "Misclassification rate : 0.279\n",
      "True positives : 0.261\n",
      "False positives : 0.086\n",
      "Specificity : 0.914\n",
      "Precision : 0.65088\n",
      "Prevalence : 0.332\n",
      "Recall : 0.261\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 0]\n",
      " [7 1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5625\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.125\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 0.7666666666666666\n",
      "Prevalence : 0.038\n",
      "Recall : 0.125\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00292529 0.00216691 0.00661786 0.00259556 0.00292529 0.00345285\n",
      " 0.00216691 0.00216691 0.00292529 0.00259556 0.00292529 0.00497475\n",
      " 0.00497475 0.00216691 0.02051052 0.00661786 0.00671583 0.00113058\n",
      " 0.00345285 0.00661786 0.00216691 0.00216691 0.00292529 0.00292529\n",
      " 0.00560673 0.00345285 0.00292529 0.00216691 0.00216691 0.00259556\n",
      " 0.00292529 0.00497475 0.00216691 0.00671583 0.008934   0.00216691\n",
      " 0.00113058 0.00292529 0.00671583 0.00292529 0.00292529 0.00216691\n",
      " 0.008934   0.00292529 0.00292529 0.00560673 0.00292529 0.00792699\n",
      " 0.00292529 0.00345285 0.02051052 0.00661786 0.00671583 0.00345285\n",
      " 0.00259556 0.00497475 0.00497475 0.00292529 0.00259556 0.00792699\n",
      " 0.00560673 0.00113058 0.008934   0.00560673 0.00292529 0.00497475\n",
      " 0.00113058 0.00113058 0.00661786 0.00259556 0.00292529 0.00661786\n",
      " 0.00671583 0.00259556 0.00497475 0.00560673 0.00216691 0.00216691\n",
      " 0.00216691 0.00497475 0.00792699 0.00292529 0.00216691 0.008934\n",
      " 0.00113058 0.00497475 0.00792699 0.00216691 0.00345285 0.008934\n",
      " 0.00259556 0.00345285 0.008934   0.00259556 0.00497475 0.00216691\n",
      " 0.008934   0.00259556 0.00497475 0.00345285 0.00661786 0.00497475\n",
      " 0.00560673 0.00259556 0.00497475 0.00216691 0.00671583 0.00671583\n",
      " 0.00661786 0.008934   0.00216691 0.00259556 0.00792699 0.00671583\n",
      " 0.00345285 0.00292529 0.00216691 0.00497475 0.00216691 0.00292529\n",
      " 0.00497475 0.00216691 0.00113058 0.00292529 0.00216691 0.00560673\n",
      " 0.00792699 0.00671583 0.00661786 0.00216691 0.00113058 0.00259556\n",
      " 0.00497475 0.00292529 0.00292529 0.02051052 0.00292529 0.00113058\n",
      " 0.00671583 0.00292529 0.00792699 0.00259556 0.00497475 0.00292529\n",
      " 0.00345285 0.00259556 0.00671583 0.00216691 0.00671583 0.00560673]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2780420355047956\n",
      "Alpha : 0.47709730358266844\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[57 24]\n",
      " [20 49]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7066666666666667\n",
      "Misclassification rate : 0.212\n",
      "True positives : 0.71\n",
      "False positives : 0.296\n",
      "Specificity : 0.704\n",
      "Precision : 0.708507383027931\n",
      "Prevalence : 0.332\n",
      "Recall : 0.71\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[5 3]\n",
      " [3 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.625\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.625\n",
      "False positives : 0.375\n",
      "Specificity : 0.625\n",
      "Precision : 0.625\n",
      "Prevalence : 0.038\n",
      "Recall : 0.625\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00471379 0.00349174 0.00410693 0.00161076 0.00471379 0.00556389\n",
      " 0.00134475 0.00349174 0.00471379 0.00161076 0.00181538 0.00308724\n",
      " 0.00308724 0.00134475 0.01272846 0.01066395 0.00416773 0.00070162\n",
      " 0.00556389 0.01066395 0.00349174 0.00134475 0.00181538 0.00181538\n",
      " 0.00347943 0.00556389 0.00181538 0.00349174 0.00349174 0.00161076\n",
      " 0.00181538 0.00308724 0.00349174 0.00416773 0.00554428 0.00134475\n",
      " 0.00070162 0.00181538 0.01082183 0.00181538 0.00181538 0.00134475\n",
      " 0.00554428 0.00181538 0.00181538 0.00347943 0.00181538 0.00491935\n",
      " 0.00181538 0.00556389 0.01272846 0.00410693 0.00416773 0.00556389\n",
      " 0.00161076 0.00308724 0.00801627 0.00181538 0.00161076 0.01277347\n",
      " 0.00903462 0.0018218  0.01439616 0.00903462 0.00471379 0.00308724\n",
      " 0.00070162 0.0018218  0.00410693 0.00161076 0.00181538 0.00410693\n",
      " 0.00416773 0.00161076 0.00308724 0.00347943 0.00134475 0.00349174\n",
      " 0.00349174 0.00801627 0.01277347 0.00181538 0.00134475 0.00554428\n",
      " 0.00070162 0.00308724 0.00491935 0.00349174 0.00214278 0.01439616\n",
      " 0.00161076 0.00556389 0.00554428 0.00161076 0.00308724 0.00134475\n",
      " 0.00554428 0.00161076 0.00308724 0.00214278 0.01066395 0.00308724\n",
      " 0.00903462 0.00161076 0.00308724 0.00134475 0.01082183 0.00416773\n",
      " 0.01066395 0.00554428 0.00134475 0.00161076 0.00491935 0.00416773\n",
      " 0.00214278 0.00181538 0.00134475 0.00308724 0.00134475 0.00181538\n",
      " 0.00308724 0.00349174 0.0018218  0.00471379 0.00134475 0.00903462\n",
      " 0.00491935 0.01082183 0.01066395 0.00134475 0.00070162 0.00161076\n",
      " 0.00308724 0.00181538 0.00471379 0.01272846 0.00181538 0.00070162\n",
      " 0.00416773 0.00181538 0.00491935 0.00161076 0.00801627 0.00181538\n",
      " 0.00214278 0.00161076 0.00416773 0.00134475 0.00416773 0.00347943]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.31187777255693055\n",
      "Alpha : 0.395677560946619\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[65 16]\n",
      " [35 34]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.66\n",
      "Misclassification rate : 0.245\n",
      "True positives : 0.493\n",
      "False positives : 0.198\n",
      "Specificity : 0.802\n",
      "Precision : 0.6638\n",
      "Prevalence : 0.332\n",
      "Recall : 0.493\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[6 2]\n",
      " [4 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.625\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.5\n",
      "False positives : 0.25\n",
      "Specificity : 0.75\n",
      "Precision : 0.6333333333333333\n",
      "Prevalence : 0.038\n",
      "Recall : 0.5\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00317343 0.00235072 0.00610039 0.00239261 0.00317343 0.00374574\n",
      " 0.00090531 0.00235072 0.00317343 0.00239261 0.00269655 0.0020784\n",
      " 0.0020784  0.00090531 0.01890674 0.00717923 0.0061907  0.00047235\n",
      " 0.00374574 0.00717923 0.00235072 0.00090531 0.00122216 0.00122216\n",
      " 0.00234244 0.00826454 0.00122216 0.00235072 0.00235072 0.00239261\n",
      " 0.00269655 0.0020784  0.00235072 0.0061907  0.00823542 0.00090531\n",
      " 0.00104217 0.00122216 0.00728551 0.00122216 0.00122216 0.00199747\n",
      " 0.00373254 0.00122216 0.00122216 0.00234244 0.00122216 0.00331182\n",
      " 0.00269655 0.00826454 0.0085691  0.00276488 0.0061907  0.00826454\n",
      " 0.0010844  0.0020784  0.00539674 0.00269655 0.00239261 0.0085994\n",
      " 0.00608232 0.00122648 0.00969184 0.00608232 0.00700181 0.0020784\n",
      " 0.00104217 0.00270609 0.00276488 0.0010844  0.00122216 0.00276488\n",
      " 0.0061907  0.00239261 0.0020784  0.00234244 0.00090531 0.00235072\n",
      " 0.00518659 0.00539674 0.0085994  0.00269655 0.00090531 0.00373254\n",
      " 0.00104217 0.0020784  0.00331182 0.00235072 0.00318286 0.02138392\n",
      " 0.0010844  0.00826454 0.00373254 0.00239261 0.0020784  0.00090531\n",
      " 0.00823542 0.00239261 0.0020784  0.00144257 0.00717923 0.0020784\n",
      " 0.00608232 0.00239261 0.0020784  0.00090531 0.00728551 0.0061907\n",
      " 0.00717923 0.00373254 0.00090531 0.0010844  0.00730715 0.0061907\n",
      " 0.00318286 0.00122216 0.00090531 0.0020784  0.00090531 0.00122216\n",
      " 0.0020784  0.00518659 0.00270609 0.00317343 0.00090531 0.00608232\n",
      " 0.00730715 0.01607464 0.00717923 0.00090531 0.00047235 0.0010844\n",
      " 0.0020784  0.00269655 0.00317343 0.01890674 0.00122216 0.00104217\n",
      " 0.0061907  0.00122216 0.00331182 0.0010844  0.00539674 0.00269655\n",
      " 0.00318286 0.00239261 0.0061907  0.00090531 0.0061907  0.00234244]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3192677385594743\n",
      "Alpha : 0.3785695086217574\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[55 26]\n",
      " [29 40]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6333333333333333\n",
      "Misclassification rate : 0.264\n",
      "True positives : 0.58\n",
      "False positives : 0.321\n",
      "Specificity : 0.679\n",
      "Precision : 0.6323593073593073\n",
      "Prevalence : 0.332\n",
      "Recall : 0.58\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 5]\n",
      " [4 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.4375\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.5\n",
      "False positives : 0.625\n",
      "Specificity : 0.375\n",
      "Precision : 0.4365079365079365\n",
      "Prevalence : 0.038\n",
      "Recall : 0.5\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00463383 0.00343251 0.00417779 0.00163855 0.00463383 0.00256523\n",
      " 0.00062    0.00160987 0.00463383 0.00163855 0.00184671 0.00303487\n",
      " 0.00303487 0.00062    0.0129481  0.00491662 0.00423964 0.00032348\n",
      " 0.00546951 0.00491662 0.00160987 0.00132194 0.00178459 0.00083698\n",
      " 0.00342041 0.00565989 0.00178459 0.00343251 0.00343251 0.00163855\n",
      " 0.00184671 0.00303487 0.00343251 0.00423964 0.01202532 0.00062\n",
      " 0.00071372 0.00178459 0.01063826 0.00178459 0.00083698 0.00136795\n",
      " 0.0025562  0.00083698 0.00083698 0.00342041 0.00083698 0.00226807\n",
      " 0.00184671 0.00565989 0.01251256 0.0018935  0.00903963 0.00565989\n",
      " 0.00074264 0.00142338 0.00369591 0.00184671 0.00163855 0.0125568\n",
      " 0.00888137 0.00083994 0.01415197 0.00416542 0.00479513 0.00303487\n",
      " 0.00071372 0.00185324 0.00403726 0.00074264 0.00083698 0.0018935\n",
      " 0.00423964 0.00163855 0.00303487 0.0016042  0.00062    0.00160987\n",
      " 0.00355199 0.00788029 0.0125568  0.00184671 0.00062    0.00545024\n",
      " 0.00071372 0.00303487 0.00226807 0.00343251 0.00464759 0.01464457\n",
      " 0.00074264 0.00565989 0.00545024 0.00349367 0.00142338 0.00062\n",
      " 0.00563995 0.00163855 0.00303487 0.00210643 0.00491662 0.00303487\n",
      " 0.00888137 0.00163855 0.00303487 0.00062    0.01063826 0.00423964\n",
      " 0.00491662 0.0025562  0.00062    0.00074264 0.00500423 0.00423964\n",
      " 0.00217975 0.00083698 0.00132194 0.00303487 0.00062    0.00178459\n",
      " 0.00303487 0.00355199 0.00185324 0.00463383 0.00132194 0.00416542\n",
      " 0.00500423 0.01100856 0.00491662 0.00062    0.00032348 0.00074264\n",
      " 0.00142338 0.00393749 0.00463383 0.0129481  0.00083698 0.00152178\n",
      " 0.00423964 0.00178459 0.0048359  0.00074264 0.00369591 0.00393749\n",
      " 0.00217975 0.00163855 0.00423964 0.00132194 0.00423964 0.0016042 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.329503322943522\n",
      "Alpha : 0.35521615404657936\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[67 14]\n",
      " [24 45]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7466666666666667\n",
      "Misclassification rate : 0.183\n",
      "True positives : 0.652\n",
      "False positives : 0.173\n",
      "Specificity : 0.827\n",
      "Precision : 0.7484298752095362\n",
      "Prevalence : 0.332\n",
      "Recall : 0.652\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 1]\n",
      " [4 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6875\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.5\n",
      "False positives : 0.125\n",
      "Specificity : 0.875\n",
      "Precision : 0.7181818181818183\n",
      "Prevalence : 0.038\n",
      "Recall : 0.5\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00661011 0.00489643 0.00292872 0.00114866 0.00324842 0.00179829\n",
      " 0.00043463 0.00112855 0.00661011 0.00114866 0.00129458 0.00212751\n",
      " 0.00212751 0.00043463 0.0090769  0.00701351 0.00297208 0.00022677\n",
      " 0.00383425 0.00701351 0.00112855 0.00188573 0.00125104 0.00058674\n",
      " 0.00239778 0.00807377 0.00125104 0.00240626 0.00240626 0.00114866\n",
      " 0.00129458 0.00212751 0.00240626 0.00297208 0.01715398 0.00043463\n",
      " 0.00101812 0.0025457  0.01517537 0.0025457  0.00058674 0.00095896\n",
      " 0.00364638 0.00058674 0.00058674 0.00239778 0.00058674 0.00323538\n",
      " 0.00129458 0.00807377 0.01784902 0.00270106 0.00633698 0.00807377\n",
      " 0.00052061 0.00099782 0.00259091 0.00263431 0.00114866 0.00880259\n",
      " 0.00622604 0.00058882 0.00992084 0.00292005 0.00336149 0.00212751\n",
      " 0.00050034 0.00129916 0.00283021 0.00052061 0.00058674 0.00270106\n",
      " 0.00297208 0.00114866 0.00212751 0.00112458 0.00043463 0.00112855\n",
      " 0.00249002 0.00552426 0.00880259 0.00129458 0.00043463 0.0077747\n",
      " 0.00101812 0.00212751 0.00158997 0.00240626 0.00662974 0.02089032\n",
      " 0.00052061 0.00807377 0.0077747  0.00244914 0.00099782 0.00043463\n",
      " 0.00395373 0.00114866 0.00212751 0.00147665 0.00344666 0.00212751\n",
      " 0.00622604 0.00114866 0.00212751 0.00043463 0.00745766 0.00297208\n",
      " 0.00701351 0.00364638 0.00043463 0.00052061 0.00713848 0.00297208\n",
      " 0.00310939 0.00058674 0.00092671 0.00212751 0.00043463 0.00125104\n",
      " 0.00212751 0.00249002 0.00129916 0.00324842 0.00188573 0.00292005\n",
      " 0.00713848 0.00771724 0.00344666 0.00043463 0.00022677 0.00105937\n",
      " 0.00099782 0.00276027 0.00324842 0.01847032 0.00058674 0.0021708\n",
      " 0.00297208 0.00125104 0.00689836 0.00052061 0.00259091 0.00276027\n",
      " 0.00310939 0.00114866 0.00297208 0.00092671 0.00297208 0.00228837]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.25629518516680777\n",
      "Alpha : 0.532657177291333\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[42 39]\n",
      " [23 46]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5866666666666667\n",
      "Misclassification rate : 0.298\n",
      "True positives : 0.667\n",
      "False positives : 0.481\n",
      "Specificity : 0.519\n",
      "Precision : 0.5978642533936651\n",
      "Prevalence : 0.332\n",
      "Recall : 0.667\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 5]\n",
      " [3 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.625\n",
      "False positives : 0.625\n",
      "Specificity : 0.375\n",
      "Precision : 0.5\n",
      "Prevalence : 0.038\n",
      "Recall : 0.625\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00388042 0.00287442 0.00171929 0.00195669 0.00190696 0.00105567\n",
      " 0.00074037 0.00192244 0.01126001 0.00067431 0.00220526 0.00124894\n",
      " 0.00124894 0.00025515 0.00532853 0.00411723 0.00174474 0.00038629\n",
      " 0.00653146 0.00411723 0.00066251 0.00321224 0.00073441 0.00099949\n",
      " 0.00408451 0.00473965 0.00073441 0.00141258 0.00141258 0.00067431\n",
      " 0.00220526 0.00124894 0.00409896 0.00174474 0.01007013 0.00025515\n",
      " 0.00173432 0.00149443 0.00890859 0.00433648 0.00034444 0.00163355\n",
      " 0.00214058 0.00034444 0.00099949 0.00408451 0.00099949 0.00551131\n",
      " 0.00075998 0.00473965 0.01047814 0.00158564 0.00372008 0.00473965\n",
      " 0.00030562 0.00058576 0.00152098 0.00154645 0.00195669 0.0051675\n",
      " 0.00365495 0.00034566 0.00582396 0.0017142  0.00197334 0.00362412\n",
      " 0.0008523  0.00076266 0.00482113 0.00088683 0.00034444 0.00158564\n",
      " 0.0050628  0.00195669 0.00362412 0.00191566 0.00025515 0.00066251\n",
      " 0.00146175 0.00941031 0.0149948  0.00220526 0.00074037 0.00456408\n",
      " 0.00173432 0.00124894 0.00270843 0.00409896 0.00389194 0.01226352\n",
      " 0.00088683 0.00473965 0.00456408 0.00417199 0.00058576 0.00074037\n",
      " 0.00232101 0.00067431 0.00124894 0.00086686 0.00202334 0.00362412\n",
      " 0.01060576 0.00195669 0.00124894 0.00025515 0.00437797 0.00174474\n",
      " 0.00411723 0.00214058 0.00025515 0.00088683 0.0041906  0.0050628\n",
      " 0.0052967  0.00099949 0.00054402 0.00362412 0.00025515 0.00213108\n",
      " 0.00124894 0.00146175 0.00221306 0.00190696 0.001107   0.0017142\n",
      " 0.0041906  0.01314596 0.00587122 0.00025515 0.00038629 0.00180459\n",
      " 0.00169973 0.00470199 0.00553352 0.01084287 0.00034444 0.00127435\n",
      " 0.00174474 0.00213108 0.00404963 0.00088683 0.00441349 0.00470199\n",
      " 0.00182535 0.00195669 0.00174474 0.0015786  0.00174474 0.00389813]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2920773444419189\n",
      "Alpha : 0.44265809937209366\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[28 53]\n",
      " [13 56]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.56\n",
      "Misclassification rate : 0.317\n",
      "True positives : 0.812\n",
      "False positives : 0.654\n",
      "Specificity : 0.346\n",
      "Precision : 0.6051107630342358\n",
      "Prevalence : 0.332\n",
      "Recall : 0.812\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[2 6]\n",
      " [2 6]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.75\n",
      "False positives : 0.75\n",
      "Specificity : 0.25\n",
      "Precision : 0.5\n",
      "Prevalence : 0.038\n",
      "Recall : 0.75\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0024925  0.00184632 0.00267665 0.00304626 0.00122489 0.00067809\n",
      " 0.00047556 0.00123483 0.0072326  0.0010498  0.0014165  0.0019444\n",
      " 0.0019444  0.00016389 0.00829567 0.00264461 0.00112069 0.00024812\n",
      " 0.01016843 0.00264461 0.00103142 0.00206331 0.00047173 0.00155605\n",
      " 0.00635893 0.00304441 0.00047173 0.00219916 0.00219916 0.0010498\n",
      " 0.0014165  0.0019444  0.00263287 0.00271628 0.00646831 0.00039722\n",
      " 0.00270005 0.00095992 0.00572223 0.0067512  0.00053624 0.00104927\n",
      " 0.00137495 0.00022125 0.00155605 0.00635893 0.00155605 0.00858022\n",
      " 0.00118316 0.00304441 0.00673039 0.0010185  0.00238951 0.00304441\n",
      " 0.0004758  0.00091194 0.00236792 0.00099333 0.00125684 0.00331922\n",
      " 0.00234767 0.00022203 0.00906697 0.00110107 0.00126753 0.00564217\n",
      " 0.00132689 0.00118734 0.00309674 0.00138065 0.00022125 0.00246858\n",
      " 0.00325197 0.00304626 0.00564217 0.00123048 0.00016389 0.00103142\n",
      " 0.00227571 0.00604449 0.00963156 0.00343324 0.00115264 0.00293163\n",
      " 0.00270005 0.0019444  0.00421659 0.00638142 0.0024999  0.00787719\n",
      " 0.00138065 0.00304441 0.00293163 0.00267978 0.00091194 0.00115264\n",
      " 0.00149085 0.0010498  0.0019444  0.00055681 0.00315001 0.00232787\n",
      " 0.01651147 0.00304626 0.0019444  0.00039722 0.00281208 0.00112069\n",
      " 0.00640987 0.00137495 0.00039722 0.00138065 0.00269173 0.00325197\n",
      " 0.00340221 0.000642   0.00034944 0.00232787 0.00039722 0.00136885\n",
      " 0.0019444  0.00093892 0.00344538 0.00122489 0.00172343 0.00266873\n",
      " 0.00269173 0.008444   0.00377124 0.00016389 0.00060139 0.00280945\n",
      " 0.00109179 0.00302021 0.00355433 0.00696467 0.00022125 0.00081855\n",
      " 0.00112069 0.00136885 0.00260119 0.00138065 0.00283491 0.00302021\n",
      " 0.00284177 0.00304626 0.00112069 0.00101398 0.00112069 0.00250387]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 8\n",
      "################################################\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 134 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161 162 163 164 165] [118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133]\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.23333333333333273\n",
      "Alpha : 0.5947920334369199\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[67 13]\n",
      " [22 48]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7666666666666667\n",
      "Misclassification rate : 0.168\n",
      "True positives : 0.686\n",
      "False positives : 0.163\n",
      "Specificity : 0.838\n",
      "Precision : 0.7687112420949223\n",
      "Prevalence : 0.337\n",
      "Recall : 0.686\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 2]\n",
      " [3 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6875\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.571\n",
      "False positives : 0.222\n",
      "Specificity : 0.778\n",
      "Precision : 0.6854166666666666\n",
      "Prevalence : 0.034\n",
      "Recall : 0.571\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00367785 0.01208436 0.01208436 0.00367785 0.00367785 0.01208436\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.01208436 0.01208436 0.00367785 0.00367785\n",
      " 0.01208436 0.01208436 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.01208436 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.01208436 0.00367785\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.01208436 0.00367785 0.00367785 0.00367785 0.00367785 0.01208436\n",
      " 0.00367785 0.01208436 0.01208436 0.01208436 0.00367785 0.01208436\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.01208436\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.01208436 0.00367785 0.00367785 0.01208436\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.01208436 0.00367785 0.00367785 0.01208436\n",
      " 0.00367785 0.01208436 0.01208436 0.00367785 0.01208436 0.00367785\n",
      " 0.00367785 0.01208436 0.01208436 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.00367785 0.01208436 0.01208436 0.00367785\n",
      " 0.00367785 0.01208436 0.00367785 0.01208436 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.01208436\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.01208436 0.00367785 0.01208436 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.00367785 0.01208436 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.01208436 0.00367785 0.00367785 0.00367785\n",
      " 0.01208436 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3459627329192547\n",
      "Alpha : 0.3184166361033456\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[74  6]\n",
      " [53 17]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6066666666666667\n",
      "Misclassification rate : 0.284\n",
      "True positives : 0.243\n",
      "False positives : 0.075\n",
      "Specificity : 0.925\n",
      "Precision : 0.655688691087527\n",
      "Prevalence : 0.337\n",
      "Recall : 0.243\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 1]\n",
      " [5 2]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.625\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.286\n",
      "False positives : 0.111\n",
      "Specificity : 0.889\n",
      "Precision : 0.6378205128205128\n",
      "Prevalence : 0.034\n",
      "Recall : 0.286\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00505685 0.00878895 0.00878895 0.0026749  0.00505685 0.00878895\n",
      " 0.0026749  0.0026749  0.00505685 0.0026749  0.00505685 0.0026749\n",
      " 0.0026749  0.0026749  0.01661538 0.00878895 0.00505685 0.0026749\n",
      " 0.00878895 0.00878895 0.0026749  0.0026749  0.00505685 0.00505685\n",
      " 0.00505685 0.00878895 0.00505685 0.0026749  0.0026749  0.0026749\n",
      " 0.00505685 0.0026749  0.0026749  0.00505685 0.01661538 0.0026749\n",
      " 0.0026749  0.00505685 0.00505685 0.00505685 0.00505685 0.0026749\n",
      " 0.01661538 0.00505685 0.00505685 0.00505685 0.00505685 0.00878895\n",
      " 0.00505685 0.00878895 0.01661538 0.00878895 0.00505685 0.00878895\n",
      " 0.0026749  0.0026749  0.0026749  0.00505685 0.0026749  0.00878895\n",
      " 0.00505685 0.0026749  0.00505685 0.00505685 0.00505685 0.0026749\n",
      " 0.0026749  0.0026749  0.00878895 0.0026749  0.00505685 0.00878895\n",
      " 0.00505685 0.0026749  0.0026749  0.00505685 0.0026749  0.0026749\n",
      " 0.0026749  0.0026749  0.00878895 0.00505685 0.0026749  0.01661538\n",
      " 0.0026749  0.00878895 0.00878895 0.0026749  0.00878895 0.00505685\n",
      " 0.0026749  0.00878895 0.01661538 0.0026749  0.0026749  0.0026749\n",
      " 0.00505685 0.0026749  0.0026749  0.00878895 0.00878895 0.0026749\n",
      " 0.0026749  0.00878895 0.0026749  0.01661538 0.0026749  0.00505685\n",
      " 0.00505685 0.00505685 0.0026749  0.00505685 0.0026749  0.01661538\n",
      " 0.00505685 0.0026749  0.0026749  0.0026749  0.0026749  0.00505685\n",
      " 0.0026749  0.0026749  0.0026749  0.00505685 0.0026749  0.00505685\n",
      " 0.00878895 0.00505685 0.00878895 0.0026749  0.0026749  0.0026749\n",
      " 0.0026749  0.00505685 0.00505685 0.01661538 0.00505685 0.0026749\n",
      " 0.00505685 0.00505685 0.00878895 0.0026749  0.0026749  0.00505685\n",
      " 0.00878895 0.0026749  0.00505685 0.0026749  0.00505685 0.00505685]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3022526047660693\n",
      "Alpha : 0.41829701596945545\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[50 30]\n",
      " [19 51]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6733333333333333\n",
      "Misclassification rate : 0.236\n",
      "True positives : 0.729\n",
      "False positives : 0.375\n",
      "Specificity : 0.625\n",
      "Precision : 0.680300590445518\n",
      "Prevalence : 0.337\n",
      "Recall : 0.729\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 5]\n",
      " [4 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.4375\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.429\n",
      "False positives : 0.556\n",
      "Specificity : 0.444\n",
      "Precision : 0.4453125\n",
      "Prevalence : 0.034\n",
      "Recall : 0.429\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00332825 0.0057846  0.0057846  0.00406417 0.00332825 0.0057846\n",
      " 0.00176053 0.00176053 0.00332825 0.00406417 0.00332825 0.00406417\n",
      " 0.00406417 0.00176053 0.02524494 0.0057846  0.00768324 0.00176053\n",
      " 0.0057846  0.0057846  0.00176053 0.00176053 0.00332825 0.00332825\n",
      " 0.00332825 0.0057846  0.00332825 0.00176053 0.00176053 0.00406417\n",
      " 0.00332825 0.00406417 0.00176053 0.00768324 0.01093569 0.00176053\n",
      " 0.00176053 0.00332825 0.00332825 0.00332825 0.00332825 0.00176053\n",
      " 0.01093569 0.00332825 0.00332825 0.00332825 0.00332825 0.01335369\n",
      " 0.00332825 0.0057846  0.02524494 0.0057846  0.00768324 0.0057846\n",
      " 0.00406417 0.00406417 0.00406417 0.00332825 0.00406417 0.01335369\n",
      " 0.00332825 0.00176053 0.00332825 0.00332825 0.00332825 0.00406417\n",
      " 0.00176053 0.00176053 0.0057846  0.00406417 0.00332825 0.0057846\n",
      " 0.00768324 0.00406417 0.00406417 0.00332825 0.00176053 0.00176053\n",
      " 0.00176053 0.00406417 0.01335369 0.00332825 0.00176053 0.01093569\n",
      " 0.00176053 0.01335369 0.01335369 0.00176053 0.0057846  0.00332825\n",
      " 0.00406417 0.0057846  0.01093569 0.00406417 0.00406417 0.00176053\n",
      " 0.00332825 0.00406417 0.00406417 0.0057846  0.0057846  0.00406417\n",
      " 0.00176053 0.01335369 0.00176053 0.01093569 0.00176053 0.00332825\n",
      " 0.00768324 0.00332825 0.00406417 0.00332825 0.00406417 0.01093569\n",
      " 0.00332825 0.00176053 0.00176053 0.00176053 0.00176053 0.00332825\n",
      " 0.00406417 0.00176053 0.00176053 0.00332825 0.00176053 0.00332825\n",
      " 0.01335369 0.00768324 0.0057846  0.00176053 0.00176053 0.00406417\n",
      " 0.00406417 0.00332825 0.00332825 0.02524494 0.00332825 0.00176053\n",
      " 0.00768324 0.00332825 0.01335369 0.00406417 0.00406417 0.00332825\n",
      " 0.0057846  0.00406417 0.00768324 0.00176053 0.00768324 0.00332825]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.27183414232751985\n",
      "Alpha : 0.4926683696329648\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[55 25]\n",
      " [22 48]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6866666666666666\n",
      "Misclassification rate : 0.226\n",
      "True positives : 0.686\n",
      "False positives : 0.312\n",
      "Specificity : 0.688\n",
      "Precision : 0.687801696020874\n",
      "Prevalence : 0.337\n",
      "Recall : 0.686\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 2]\n",
      " [1 6]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8125\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.857\n",
      "False positives : 0.222\n",
      "Specificity : 0.778\n",
      "Precision : 0.8203125\n",
      "Prevalence : 0.034\n",
      "Recall : 0.857\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00544728 0.00946752 0.00353435 0.00248318 0.00544728 0.00946752\n",
      " 0.00107567 0.00288142 0.00544728 0.00248318 0.00203354 0.00248318\n",
      " 0.00248318 0.00107567 0.0154245  0.00946752 0.00469441 0.00107567\n",
      " 0.00946752 0.00946752 0.00288142 0.00107567 0.00203354 0.00203354\n",
      " 0.00203354 0.00946752 0.00203354 0.00288142 0.00288142 0.00248318\n",
      " 0.00203354 0.00248318 0.00288142 0.00469441 0.00668164 0.00107567\n",
      " 0.00107567 0.00203354 0.00544728 0.00203354 0.00203354 0.00107567\n",
      " 0.00668164 0.00203354 0.00203354 0.00203354 0.00203354 0.00815902\n",
      " 0.00203354 0.00946752 0.0154245  0.00353435 0.00469441 0.00946752\n",
      " 0.00248318 0.00248318 0.00665173 0.00203354 0.00248318 0.02185568\n",
      " 0.00544728 0.00288142 0.00544728 0.00544728 0.00544728 0.00248318\n",
      " 0.00107567 0.00288142 0.00353435 0.00248318 0.00203354 0.00353435\n",
      " 0.00469441 0.00248318 0.00248318 0.00203354 0.00107567 0.00288142\n",
      " 0.00288142 0.00665173 0.02185568 0.00203354 0.00107567 0.00668164\n",
      " 0.00107567 0.00815902 0.00815902 0.00288142 0.00353435 0.00544728\n",
      " 0.00248318 0.00946752 0.00668164 0.00248318 0.00248318 0.00107567\n",
      " 0.00203354 0.00248318 0.00248318 0.00353435 0.00946752 0.00248318\n",
      " 0.00288142 0.02185568 0.00288142 0.00668164 0.00107567 0.00203354\n",
      " 0.01257499 0.00544728 0.00248318 0.00203354 0.00248318 0.00668164\n",
      " 0.00203354 0.00107567 0.00107567 0.00288142 0.00107567 0.00203354\n",
      " 0.00248318 0.00288142 0.00288142 0.00544728 0.00107567 0.00544728\n",
      " 0.00815902 0.01257499 0.00946752 0.00107567 0.00107567 0.00248318\n",
      " 0.00248318 0.00203354 0.00544728 0.0154245  0.00203354 0.00107567\n",
      " 0.00469441 0.00203354 0.00815902 0.00248318 0.00665173 0.00203354\n",
      " 0.00353435 0.00248318 0.00469441 0.00107567 0.00469441 0.00203354]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.32892808716672517\n",
      "Alpha : 0.3565185785120065\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[63 17]\n",
      " [36 34]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6466666666666666\n",
      "Misclassification rate : 0.255\n",
      "True positives : 0.486\n",
      "False positives : 0.212\n",
      "Specificity : 0.787\n",
      "Precision : 0.6505050505050505\n",
      "Prevalence : 0.337\n",
      "Recall : 0.486\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 2]\n",
      " [6 1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.143\n",
      "False positives : 0.222\n",
      "Specificity : 0.778\n",
      "Precision : 0.4487179487179487\n",
      "Prevalence : 0.034\n",
      "Recall : 0.143\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00381369 0.0066283  0.00504828 0.00354685 0.00381369 0.0066283\n",
      " 0.00075309 0.00201731 0.00381369 0.00354685 0.0014237  0.0017385\n",
      " 0.0017385  0.00075309 0.02203156 0.0066283  0.00670526 0.00075309\n",
      " 0.0066283  0.0066283  0.00201731 0.00075309 0.0014237  0.0014237\n",
      " 0.0014237  0.01352291 0.0014237  0.00201731 0.00201731 0.00354685\n",
      " 0.00290461 0.0017385  0.00201731 0.00670526 0.00954371 0.00075309\n",
      " 0.00153643 0.0014237  0.00778061 0.00290461 0.0014237  0.00153643\n",
      " 0.00467788 0.0014237  0.0014237  0.0014237  0.0014237  0.00571221\n",
      " 0.00290461 0.01352291 0.01079884 0.00247443 0.0032866  0.01352291\n",
      " 0.0017385  0.0017385  0.00465694 0.00290461 0.00354685 0.01530137\n",
      " 0.00381369 0.00201731 0.00381369 0.00381369 0.00778061 0.0017385\n",
      " 0.00153643 0.00411567 0.00247443 0.0017385  0.00290461 0.00247443\n",
      " 0.00670526 0.00354685 0.0017385  0.0014237  0.00075309 0.00201731\n",
      " 0.00411567 0.00465694 0.01530137 0.00290461 0.00075309 0.00467788\n",
      " 0.00153643 0.00571221 0.00571221 0.00201731 0.00247443 0.00381369\n",
      " 0.0017385  0.01352291 0.00467788 0.00354685 0.0017385  0.00075309\n",
      " 0.00290461 0.00354685 0.0017385  0.00247443 0.0066283  0.0017385\n",
      " 0.00201731 0.01530137 0.00201731 0.00467788 0.00075309 0.00290461\n",
      " 0.00880387 0.00381369 0.0017385  0.00290461 0.0017385  0.00954371\n",
      " 0.00290461 0.00153643 0.00153643 0.00201731 0.00075309 0.00290461\n",
      " 0.0017385  0.00411567 0.00411567 0.00381369 0.00075309 0.00381369\n",
      " 0.01165392 0.01796146 0.0066283  0.00075309 0.00075309 0.0017385\n",
      " 0.0017385  0.00290461 0.00381369 0.02203156 0.0014237  0.00153643\n",
      " 0.00670526 0.00290461 0.00571221 0.0017385  0.00465694 0.00290461\n",
      " 0.00504828 0.00354685 0.00670526 0.00075309 0.00670526 0.0014237 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.23688889506440083\n",
      "Alpha : 0.5849062012849254\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[28 52]\n",
      " [ 5 65]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.62\n",
      "Misclassification rate : 0.274\n",
      "True positives : 0.929\n",
      "False positives : 0.65\n",
      "Specificity : 0.35\n",
      "Precision : 0.7117845117845117\n",
      "Prevalence : 0.337\n",
      "Recall : 0.929\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[2 7]\n",
      " [0 7]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5625\n",
      "Misclassification rate : 0.034\n",
      "True positives : 1.0\n",
      "False positives : 0.778\n",
      "Specificity : 0.222\n",
      "Precision : 0.78125\n",
      "Prevalence : 0.034\n",
      "Recall : 1.0\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00212483 0.01189662 0.00906078 0.00197615 0.0068449  0.00369301\n",
      " 0.00135166 0.00112396 0.0068449  0.00197615 0.00079323 0.0031203\n",
      " 0.0031203  0.00135166 0.01227506 0.01189662 0.00373589 0.00041959\n",
      " 0.00369301 0.01189662 0.00362071 0.00135166 0.00079323 0.00079323\n",
      " 0.00255529 0.0075344  0.00079323 0.00362071 0.00362071 0.00197615\n",
      " 0.00161832 0.0031203  0.00362071 0.00373589 0.00531735 0.00135166\n",
      " 0.00085604 0.00079323 0.00433503 0.00161832 0.00079323 0.00275763\n",
      " 0.00260632 0.00079323 0.00079323 0.00255529 0.00079323 0.0031826\n",
      " 0.00161832 0.0075344  0.00601666 0.00444117 0.00183116 0.0075344\n",
      " 0.00096862 0.0031203  0.00835838 0.00161832 0.00197615 0.00852528\n",
      " 0.0068449  0.00112396 0.00212483 0.0068449  0.00433503 0.0031203\n",
      " 0.00085604 0.00229308 0.00444117 0.00096862 0.00161832 0.00444117\n",
      " 0.00373589 0.00197615 0.0031203  0.00255529 0.00135166 0.00362071\n",
      " 0.00229308 0.00835838 0.00852528 0.00161832 0.00135166 0.00260632\n",
      " 0.00085604 0.0102524  0.0031826  0.00362071 0.00137865 0.00212483\n",
      " 0.00096862 0.0075344  0.00260632 0.00197615 0.0031203  0.00041959\n",
      " 0.00161832 0.00197615 0.0031203  0.00137865 0.01189662 0.0031203\n",
      " 0.00362071 0.00852528 0.00362071 0.00260632 0.00041959 0.00161832\n",
      " 0.00490515 0.0068449  0.0031203  0.00161832 0.0031203  0.00531735\n",
      " 0.00161832 0.00085604 0.00275763 0.00362071 0.00135166 0.00161832\n",
      " 0.0031203  0.00229308 0.00229308 0.00212483 0.00135166 0.0068449\n",
      " 0.00649308 0.01000738 0.01189662 0.00135166 0.00041959 0.00096862\n",
      " 0.00096862 0.00521325 0.00212483 0.01227506 0.00079323 0.00085604\n",
      " 0.00373589 0.00161832 0.0031826  0.00096862 0.00835838 0.00161832\n",
      " 0.00281269 0.00197615 0.00373589 0.00135166 0.00373589 0.00255529]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3198672053818348\n",
      "Alpha : 0.37719106941240593\n",
      "\n",
      ":: Treinamento :: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[71  9]\n",
      " [29 41]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7466666666666667\n",
      "Misclassification rate : 0.183\n",
      "True positives : 0.586\n",
      "False positives : 0.113\n",
      "Specificity : 0.887\n",
      "Precision : 0.7613333333333333\n",
      "Prevalence : 0.337\n",
      "Recall : 0.586\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 1]\n",
      " [4 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6875\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.429\n",
      "False positives : 0.111\n",
      "Specificity : 0.889\n",
      "Precision : 0.703125\n",
      "Prevalence : 0.034\n",
      "Recall : 0.429\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00309839 0.01734745 0.00621374 0.00135522 0.00469413 0.00253261\n",
      " 0.00092695 0.00077079 0.00998111 0.00135522 0.00054398 0.00213985\n",
      " 0.00213985 0.00092695 0.01789928 0.01734745 0.00256202 0.00028775\n",
      " 0.00253261 0.00815852 0.00248303 0.00092695 0.00054398 0.00054398\n",
      " 0.00175238 0.01098653 0.00115667 0.00248303 0.00248303 0.00135522\n",
      " 0.00110982 0.00213985 0.00248303 0.00256202 0.00775367 0.00092695\n",
      " 0.00124826 0.00115667 0.00632127 0.00235981 0.00054398 0.00189114\n",
      " 0.00380049 0.00054398 0.00054398 0.00175238 0.00054398 0.00464082\n",
      " 0.00110982 0.01098653 0.00877339 0.00647604 0.00267016 0.01098653\n",
      " 0.00066426 0.00213985 0.00573205 0.00235981 0.00135522 0.00584651\n",
      " 0.00469413 0.00077079 0.00145718 0.00469413 0.0029729  0.00213985\n",
      " 0.00058706 0.00157256 0.00304569 0.00066426 0.00110982 0.00304569\n",
      " 0.00256202 0.00135522 0.00213985 0.00175238 0.00092695 0.00248303\n",
      " 0.00157256 0.00573205 0.00584651 0.00110982 0.00092695 0.00380049\n",
      " 0.00058706 0.00703094 0.00218258 0.00248303 0.00201032 0.00309839\n",
      " 0.00066426 0.01098653 0.00380049 0.00135522 0.00213985 0.00028775\n",
      " 0.00110982 0.00135522 0.00213985 0.00094546 0.00815852 0.00213985\n",
      " 0.00248303 0.00584651 0.00248303 0.00380049 0.00028775 0.00110982\n",
      " 0.00336388 0.00998111 0.00213985 0.00235981 0.00213985 0.00775367\n",
      " 0.00110982 0.00058706 0.00402113 0.00248303 0.00092695 0.00110982\n",
      " 0.00213985 0.00157256 0.00157256 0.00309839 0.00197097 0.00469413\n",
      " 0.00946809 0.00686291 0.00815852 0.00092695 0.00028775 0.00066426\n",
      " 0.00066426 0.00357517 0.00145718 0.01789928 0.00054398 0.00124826\n",
      " 0.00256202 0.00110982 0.00464082 0.00066426 0.00573205 0.00110982\n",
      " 0.00410142 0.00135522 0.00256202 0.00092695 0.00256202 0.00372608]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2685935266616891\n",
      "Alpha : 0.5008850863909474\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[40 40]\n",
      " [23 47]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.58\n",
      "Misclassification rate : 0.303\n",
      "True positives : 0.671\n",
      "False positives : 0.5\n",
      "Specificity : 0.5\n",
      "Precision : 0.5907316183178252\n",
      "Prevalence : 0.337\n",
      "Recall : 0.671\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[5 4]\n",
      " [3 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5625\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.571\n",
      "False positives : 0.444\n",
      "Specificity : 0.556\n",
      "Precision : 0.5703125\n",
      "Prevalence : 0.034\n",
      "Recall : 0.571\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00187761 0.01051245 0.00376549 0.00223635 0.00284461 0.00153475\n",
      " 0.00152963 0.00127195 0.01647065 0.00082125 0.00089767 0.00129674\n",
      " 0.00129674 0.00056173 0.01084686 0.01051245 0.00155257 0.00047484\n",
      " 0.00417927 0.00494402 0.0015047  0.00152963 0.00032965 0.00089767\n",
      " 0.00289175 0.00665777 0.00070094 0.0015047  0.0015047  0.00082125\n",
      " 0.00183141 0.00129674 0.00409745 0.00155257 0.00469868 0.00056173\n",
      " 0.00205985 0.00070094 0.00383065 0.00389412 0.00032965 0.00312072\n",
      " 0.00230307 0.00032965 0.00089767 0.00289175 0.00089767 0.00765819\n",
      " 0.00067255 0.00665777 0.00531662 0.00392444 0.0016181  0.00665777\n",
      " 0.00040254 0.00129674 0.00347359 0.00143003 0.00223635 0.00354295\n",
      " 0.00284461 0.0004671  0.00088304 0.00284461 0.00180156 0.00353114\n",
      " 0.00096875 0.00095296 0.00502594 0.00109616 0.00067255 0.00184567\n",
      " 0.00422779 0.00223635 0.00353114 0.00289175 0.00056173 0.0015047\n",
      " 0.00095296 0.00945892 0.0096478  0.00183141 0.00152963 0.00230307\n",
      " 0.00096875 0.00426071 0.00360165 0.00409745 0.00121824 0.00187761\n",
      " 0.00109616 0.00665777 0.00230307 0.00223635 0.00129674 0.00047484\n",
      " 0.00067255 0.00082125 0.00129674 0.00057294 0.00494402 0.00353114\n",
      " 0.0015047  0.0096478  0.0015047  0.00230307 0.00047484 0.00183141\n",
      " 0.00203849 0.0060485  0.00129674 0.00143003 0.00353114 0.00469868\n",
      " 0.00183141 0.00096875 0.00663559 0.00409745 0.00056173 0.00183141\n",
      " 0.00129674 0.00095296 0.00259501 0.00187761 0.00119439 0.00284461\n",
      " 0.00573761 0.01132504 0.01346304 0.00056173 0.00047484 0.00109616\n",
      " 0.00109616 0.00589968 0.0024046  0.01084686 0.00032965 0.00075644\n",
      " 0.00155257 0.00183141 0.00281231 0.00109616 0.00945892 0.00183141\n",
      " 0.00248544 0.00223635 0.00155257 0.00152963 0.00155257 0.00614871]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.33223771761312926\n",
      "Alpha : 0.3490407579528858\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[72  8]\n",
      " [46 24]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.64\n",
      "Misclassification rate : 0.26\n",
      "True positives : 0.343\n",
      "False positives : 0.1\n",
      "Specificity : 0.9\n",
      "Precision : 0.6754237288135594\n",
      "Prevalence : 0.337\n",
      "Recall : 0.343\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 5]\n",
      " [6 1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.3125\n",
      "Misclassification rate : 0.053\n",
      "True positives : 0.143\n",
      "False positives : 0.556\n",
      "Specificity : 0.444\n",
      "Precision : 0.29791666666666666\n",
      "Prevalence : 0.034\n",
      "Recall : 0.143\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00266189 0.00741511 0.00265604 0.00157744 0.00403283 0.00217582\n",
      " 0.00107895 0.00089719 0.02335055 0.00057928 0.00127263 0.00183839\n",
      " 0.00091467 0.00039622 0.01537767 0.01490357 0.00220108 0.00033493\n",
      " 0.00294791 0.00348733 0.00213322 0.00107895 0.00046735 0.00127263\n",
      " 0.00203974 0.00943877 0.00099372 0.00106136 0.00106136 0.00057928\n",
      " 0.0025964  0.00183839 0.00289019 0.00109513 0.00666135 0.00079636\n",
      " 0.00145295 0.00099372 0.002702   0.00552072 0.00046735 0.00220125\n",
      " 0.00326508 0.00046735 0.00127263 0.00203974 0.00127263 0.00540181\n",
      " 0.00047439 0.00469616 0.00753741 0.00276816 0.002294   0.00469616\n",
      " 0.00028394 0.00091467 0.00245015 0.00202737 0.00157744 0.00249907\n",
      " 0.00403283 0.00032947 0.00125189 0.00200649 0.00255408 0.00249074\n",
      " 0.00068332 0.00067218 0.00354512 0.00077319 0.00095347 0.00130187\n",
      " 0.00298213 0.00157744 0.00249074 0.00203974 0.00039622 0.00106136\n",
      " 0.00067218 0.00667199 0.00680522 0.00129181 0.00107895 0.00162451\n",
      " 0.00068332 0.00300535 0.00254048 0.00289019 0.00172711 0.00266189\n",
      " 0.00077319 0.00469616 0.00162451 0.00157744 0.00091467 0.00033493\n",
      " 0.00095347 0.00057928 0.00091467 0.00081226 0.00348733 0.00249074\n",
      " 0.00213322 0.00680522 0.00106136 0.00326508 0.00033493 0.00129181\n",
      " 0.00288998 0.00857499 0.00091467 0.00202737 0.00249074 0.00666135\n",
      " 0.00129181 0.00068332 0.00468051 0.00289019 0.00079636 0.00129181\n",
      " 0.00183839 0.00067218 0.00183043 0.00266189 0.00084248 0.00200649\n",
      " 0.00813425 0.00798828 0.00949635 0.00039622 0.00033493 0.00077319\n",
      " 0.00077319 0.00416142 0.00169612 0.01537767 0.00046735 0.00053356\n",
      " 0.00220108 0.0025964  0.00398703 0.00077319 0.00667199 0.0025964\n",
      " 0.00175314 0.00157744 0.00220108 0.00107895 0.00220108 0.00433708]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2783792001383885\n",
      "Alpha : 0.4762577897261673\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[16 64]\n",
      " [ 5 65]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.54\n",
      "Misclassification rate : 0.332\n",
      "True positives : 0.929\n",
      "False positives : 0.8\n",
      "Specificity : 0.2\n",
      "Precision : 0.6414913252122555\n",
      "Prevalence : 0.337\n",
      "Recall : 0.929\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[2 7]\n",
      " [1 6]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.857\n",
      "False positives : 0.778\n",
      "Specificity : 0.222\n",
      "Precision : 0.5769230769230769\n",
      "Prevalence : 0.034\n",
      "Recall : 0.857\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00165331 0.00460555 0.00427633 0.00253974 0.0025048  0.00135141\n",
      " 0.00067014 0.00144451 0.0145031  0.00093267 0.00079044 0.00295988\n",
      " 0.00147266 0.00063793 0.00955112 0.00925666 0.0013671  0.00020803\n",
      " 0.00183095 0.00216599 0.00343457 0.00067014 0.00029027 0.00079044\n",
      " 0.00328405 0.00586245 0.0006172  0.00170883 0.00065922 0.00093267\n",
      " 0.00161263 0.00295988 0.00465332 0.00176319 0.00413739 0.00128217\n",
      " 0.0023393  0.0006172  0.00167822 0.00342894 0.00029027 0.00354409\n",
      " 0.00202795 0.00029027 0.00079044 0.00328405 0.00079044 0.00869712\n",
      " 0.00029465 0.0029168  0.00468151 0.00171931 0.00142481 0.0029168\n",
      " 0.00045715 0.00147266 0.00394483 0.0012592  0.00097976 0.00155218\n",
      " 0.0025048  0.00053047 0.00201559 0.00124624 0.00158635 0.00401019\n",
      " 0.00110018 0.00108224 0.00220188 0.00124486 0.00059221 0.00209606\n",
      " 0.00185221 0.00253974 0.00401019 0.00126689 0.00024609 0.00170883\n",
      " 0.00108224 0.01074215 0.00422674 0.00207986 0.00173715 0.00100899\n",
      " 0.00110018 0.00483873 0.00409027 0.00465332 0.00107272 0.00165331\n",
      " 0.00124486 0.0029168  0.00100899 0.00253974 0.00147266 0.00053925\n",
      " 0.00059221 0.00093267 0.00147266 0.0005045  0.00561474 0.00401019\n",
      " 0.00343457 0.00422674 0.00170883 0.00202795 0.00053925 0.00080235\n",
      " 0.00179498 0.00532596 0.00147266 0.0012592  0.00401019 0.00413739\n",
      " 0.00080235 0.00110018 0.00753579 0.00465332 0.00128217 0.00080235\n",
      " 0.00295988 0.00108224 0.00294705 0.00165331 0.00052327 0.00323052\n",
      " 0.00505221 0.00496155 0.00589822 0.00063793 0.00053925 0.00124486\n",
      " 0.00124486 0.00258467 0.00105347 0.00955112 0.00029027 0.0003314\n",
      " 0.0013671  0.00161263 0.00247636 0.00124486 0.01074215 0.00161263\n",
      " 0.00282262 0.00253974 0.0013671  0.00067014 0.0013671  0.00269378]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 9\n",
      "################################################\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161 162 163 164 165] [134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2533333333333327\n",
      "Alpha : 0.540456355784356\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[67 11]\n",
      " [27 45]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7466666666666667\n",
      "Misclassification rate : 0.183\n",
      "True positives : 0.625\n",
      "False positives : 0.141\n",
      "Specificity : 0.859\n",
      "Precision : 0.7563525835866262\n",
      "Prevalence : 0.346\n",
      "Recall : 0.625\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[10  1]\n",
      " [ 1  4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.875\n",
      "Misclassification rate : 0.01\n",
      "True positives : 0.8\n",
      "False positives : 0.091\n",
      "Specificity : 0.909\n",
      "Precision : 0.875\n",
      "Prevalence : 0.024\n",
      "Recall : 0.8\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00388322 0.00388322 0.01144527 0.00388322 0.00388322 0.01144527\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322\n",
      " 0.00388322 0.00388322 0.01144527 0.01144527 0.00388322 0.00388322\n",
      " 0.01144527 0.01144527 0.00388322 0.00388322 0.00388322 0.00388322\n",
      " 0.00388322 0.01144527 0.00388322 0.00388322 0.00388322 0.00388322\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.01144527 0.00388322\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322\n",
      " 0.01144527 0.00388322 0.00388322 0.00388322 0.00388322 0.01144527\n",
      " 0.00388322 0.01144527 0.01144527 0.01144527 0.00388322 0.01144527\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322 0.01144527\n",
      " 0.00388322 0.00388322 0.01144527 0.00388322 0.00388322 0.00388322\n",
      " 0.00388322 0.00388322 0.01144527 0.00388322 0.00388322 0.01144527\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322\n",
      " 0.00388322 0.00388322 0.01144527 0.00388322 0.00388322 0.01144527\n",
      " 0.00388322 0.00388322 0.01144527 0.00388322 0.01144527 0.01144527\n",
      " 0.00388322 0.01144527 0.01144527 0.00388322 0.00388322 0.00388322\n",
      " 0.01144527 0.00388322 0.00388322 0.01144527 0.01144527 0.00388322\n",
      " 0.00388322 0.01144527 0.00388322 0.01144527 0.00388322 0.00388322\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322 0.01144527\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.01144527 0.01144527\n",
      " 0.00388322 0.00388322 0.01144527 0.00388322 0.01144527 0.00388322\n",
      " 0.00388322 0.00388322 0.00388322 0.01144527 0.00388322 0.00388322\n",
      " 0.00388322 0.00388322 0.01144527 0.00388322 0.00388322 0.00388322\n",
      " 0.01144527 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.32401315789473656\n",
      "Alpha : 0.3676947428791238\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[23 55]\n",
      " [ 2 70]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.62\n",
      "Misclassification rate : 0.274\n",
      "True positives : 0.972\n",
      "False positives : 0.705\n",
      "Specificity : 0.295\n",
      "Precision : 0.7472000000000001\n",
      "Prevalence : 0.346\n",
      "Recall : 0.972\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 8]\n",
      " [1 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.4375\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.8\n",
      "False positives : 0.727\n",
      "Specificity : 0.273\n",
      "Precision : 0.6197916666666666\n",
      "Prevalence : 0.024\n",
      "Recall : 0.8\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00268846 0.00560892 0.01653156 0.00268846 0.00268846 0.00792388\n",
      " 0.00560892 0.00268846 0.00268846 0.00268846 0.00268846 0.00560892\n",
      " 0.00560892 0.00560892 0.00792388 0.01653156 0.00268846 0.00268846\n",
      " 0.00792388 0.01653156 0.00560892 0.00560892 0.00268846 0.00268846\n",
      " 0.00560892 0.00792388 0.00268846 0.00560892 0.00560892 0.00268846\n",
      " 0.00268846 0.00560892 0.00560892 0.00268846 0.00792388 0.00560892\n",
      " 0.00268846 0.00268846 0.00268846 0.00268846 0.00268846 0.00560892\n",
      " 0.00792388 0.00268846 0.00268846 0.00560892 0.00268846 0.00792388\n",
      " 0.00268846 0.00792388 0.00792388 0.01653156 0.00268846 0.00792388\n",
      " 0.00268846 0.00560892 0.00560892 0.00268846 0.00268846 0.00792388\n",
      " 0.00560892 0.00268846 0.00792388 0.00560892 0.00268846 0.00560892\n",
      " 0.00268846 0.00268846 0.01653156 0.00268846 0.00268846 0.01653156\n",
      " 0.00268846 0.00268846 0.00560892 0.00560892 0.00560892 0.00560892\n",
      " 0.00560892 0.00560892 0.00792388 0.00268846 0.00560892 0.00792388\n",
      " 0.00268846 0.00560892 0.00792388 0.00560892 0.00792388 0.00792388\n",
      " 0.00268846 0.00792388 0.00792388 0.00268846 0.00560892 0.00268846\n",
      " 0.00792388 0.00268846 0.00560892 0.00792388 0.01653156 0.00560892\n",
      " 0.00560892 0.00792388 0.00560892 0.00792388 0.00560892 0.00268846\n",
      " 0.00268846 0.00560892 0.00560892 0.00268846 0.00560892 0.00792388\n",
      " 0.00268846 0.00268846 0.00560892 0.00560892 0.00560892 0.00268846\n",
      " 0.00560892 0.00560892 0.00268846 0.00268846 0.01653156 0.00792388\n",
      " 0.00560892 0.00268846 0.00792388 0.00268846 0.00792388 0.00268846\n",
      " 0.00560892 0.00560892 0.00268846 0.00792388 0.00268846 0.00268846\n",
      " 0.00268846 0.00268846 0.00792388 0.00268846 0.00560892 0.00268846\n",
      " 0.00792388 0.00268846 0.00268846 0.00560892 0.00268846 0.00560892]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3002907710195865\n",
      "Alpha : 0.4229568097969481\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[47 31]\n",
      " [22 50]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6466666666666666\n",
      "Misclassification rate : 0.255\n",
      "True positives : 0.694\n",
      "False positives : 0.397\n",
      "Specificity : 0.603\n",
      "Precision : 0.650499194847021\n",
      "Prevalence : 0.346\n",
      "Recall : 0.694\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 3]\n",
      " [2 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6875\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.6\n",
      "False positives : 0.273\n",
      "Specificity : 0.727\n",
      "Precision : 0.70625\n",
      "Prevalence : 0.024\n",
      "Recall : 0.6\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00176123 0.00367444 0.01082994 0.00410385 0.00176123 0.00519099\n",
      " 0.00367444 0.00176123 0.00176123 0.00410385 0.00176123 0.00856184\n",
      " 0.00856184 0.00367444 0.01209556 0.01082994 0.00410385 0.00176123\n",
      " 0.00519099 0.01082994 0.00367444 0.00367444 0.00176123 0.00176123\n",
      " 0.00367444 0.00519099 0.00176123 0.00367444 0.00367444 0.00410385\n",
      " 0.00176123 0.00856184 0.00367444 0.00410385 0.00519099 0.00367444\n",
      " 0.00176123 0.00176123 0.00410385 0.00176123 0.00176123 0.00367444\n",
      " 0.00519099 0.00176123 0.00176123 0.00367444 0.00176123 0.01209556\n",
      " 0.00176123 0.00519099 0.01209556 0.01082994 0.00410385 0.00519099\n",
      " 0.00410385 0.00856184 0.00856184 0.00176123 0.00410385 0.01209556\n",
      " 0.00367444 0.00176123 0.00519099 0.00367444 0.00176123 0.00856184\n",
      " 0.00176123 0.00176123 0.01082994 0.00410385 0.00176123 0.01082994\n",
      " 0.00410385 0.00410385 0.00856184 0.00367444 0.00367444 0.00367444\n",
      " 0.00367444 0.00856184 0.01209556 0.00176123 0.00367444 0.00519099\n",
      " 0.00176123 0.00856184 0.01209556 0.00367444 0.00519099 0.00519099\n",
      " 0.00410385 0.00519099 0.00519099 0.00410385 0.00856184 0.00176123\n",
      " 0.00519099 0.00410385 0.00856184 0.00519099 0.01082994 0.00856184\n",
      " 0.00367444 0.01209556 0.00367444 0.00519099 0.00367444 0.00176123\n",
      " 0.00410385 0.00367444 0.00856184 0.00176123 0.00856184 0.00519099\n",
      " 0.00176123 0.00176123 0.00367444 0.00367444 0.00367444 0.00410385\n",
      " 0.00856184 0.00367444 0.00410385 0.00410385 0.01082994 0.00519099\n",
      " 0.00367444 0.00410385 0.01209556 0.00410385 0.00519099 0.00176123\n",
      " 0.00367444 0.00856184 0.00176123 0.01209556 0.00176123 0.00176123\n",
      " 0.00410385 0.00176123 0.01209556 0.00410385 0.00856184 0.00176123\n",
      " 0.00519099 0.00410385 0.00410385 0.00367444 0.00410385 0.00367444]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.28926050513361046\n",
      "Alpha : 0.4494891430659648\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[73  5]\n",
      " [55 17]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6\n",
      "Misclassification rate : 0.288\n",
      "True positives : 0.236\n",
      "False positives : 0.064\n",
      "Specificity : 0.936\n",
      "Precision : 0.6674715909090908\n",
      "Prevalence : 0.346\n",
      "Recall : 0.236\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[10  1]\n",
      " [ 4  1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6875\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.2\n",
      "False positives : 0.091\n",
      "Specificity : 0.909\n",
      "Precision : 0.6473214285714286\n",
      "Prevalence : 0.024\n",
      "Recall : 0.2\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00276075 0.00234413 0.006909   0.00261807 0.00276075 0.00331161\n",
      " 0.00234413 0.00112358 0.00276075 0.00261807 0.00276075 0.00546206\n",
      " 0.00546206 0.00234413 0.01895993 0.006909   0.00643283 0.00112358\n",
      " 0.00813694 0.006909   0.00234413 0.00234413 0.00276075 0.00276075\n",
      " 0.00575973 0.00331161 0.00276075 0.00234413 0.00234413 0.00261807\n",
      " 0.00276075 0.00546206 0.00234413 0.00643283 0.00813694 0.00234413\n",
      " 0.00112358 0.00276075 0.00643283 0.00276075 0.00276075 0.00234413\n",
      " 0.00813694 0.00276075 0.00276075 0.00575973 0.00276075 0.00771641\n",
      " 0.00276075 0.00331161 0.01895993 0.006909   0.00643283 0.00331161\n",
      " 0.00261807 0.00546206 0.00546206 0.00276075 0.00261807 0.00771641\n",
      " 0.00575973 0.00112358 0.00813694 0.00575973 0.00276075 0.00546206\n",
      " 0.00112358 0.00112358 0.006909   0.00261807 0.00276075 0.006909\n",
      " 0.00643283 0.00261807 0.00546206 0.00234413 0.00234413 0.00234413\n",
      " 0.00234413 0.00546206 0.00771641 0.00276075 0.00234413 0.00813694\n",
      " 0.00112358 0.00546206 0.00771641 0.00234413 0.00331161 0.00813694\n",
      " 0.00261807 0.00331161 0.00813694 0.00261807 0.00546206 0.00112358\n",
      " 0.00813694 0.00261807 0.00546206 0.00331161 0.006909   0.00546206\n",
      " 0.00234413 0.00771641 0.00234413 0.00813694 0.00234413 0.00276075\n",
      " 0.00643283 0.00575973 0.00546206 0.00276075 0.00546206 0.00813694\n",
      " 0.00276075 0.00112358 0.00234413 0.00234413 0.00575973 0.00261807\n",
      " 0.00546206 0.00234413 0.00643283 0.00643283 0.006909   0.00813694\n",
      " 0.00234413 0.00261807 0.00771641 0.00643283 0.00331161 0.00276075\n",
      " 0.00234413 0.00546206 0.00276075 0.01895993 0.00276075 0.00112358\n",
      " 0.00643283 0.00276075 0.00771641 0.00261807 0.00546206 0.00276075\n",
      " 0.00331161 0.00261807 0.00643283 0.00234413 0.00643283 0.00575973]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.28577964344618695\n",
      "Alpha : 0.4579852504805733\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[55 23]\n",
      " [21 51]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7066666666666667\n",
      "Misclassification rate : 0.212\n",
      "True positives : 0.708\n",
      "False positives : 0.295\n",
      "Specificity : 0.705\n",
      "Precision : 0.707126600284495\n",
      "Prevalence : 0.346\n",
      "Recall : 0.708\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 4]\n",
      " [2 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.625\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.6\n",
      "False positives : 0.364\n",
      "Specificity : 0.636\n",
      "Precision : 0.6686507936507936\n",
      "Prevalence : 0.024\n",
      "Recall : 0.6\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00436443 0.00370579 0.00437034 0.00165608 0.00436443 0.00523528\n",
      " 0.00148279 0.00177626 0.00436443 0.00165608 0.00174633 0.00345506\n",
      " 0.00345506 0.00148279 0.01199323 0.01092234 0.00406913 0.00071073\n",
      " 0.01286357 0.01092234 0.00370579 0.00148279 0.00174633 0.00174633\n",
      " 0.00364336 0.00523528 0.00174633 0.00370579 0.00370579 0.00165608\n",
      " 0.00174633 0.00345506 0.00370579 0.00406913 0.00514708 0.00148279\n",
      " 0.00071073 0.00174633 0.01016957 0.00174633 0.00174633 0.00148279\n",
      " 0.00514708 0.00174633 0.00174633 0.00364336 0.00174633 0.00488107\n",
      " 0.00174633 0.00523528 0.01199323 0.00437034 0.00406913 0.00523528\n",
      " 0.00165608 0.00345506 0.00863489 0.00174633 0.00165608 0.01219876\n",
      " 0.00910548 0.00177626 0.01286357 0.00910548 0.00436443 0.00345506\n",
      " 0.00071073 0.00177626 0.00437034 0.00165608 0.00174633 0.00437034\n",
      " 0.00406913 0.00165608 0.00345506 0.00148279 0.00148279 0.00370579\n",
      " 0.00370579 0.00863489 0.01219876 0.00174633 0.00148279 0.00514708\n",
      " 0.00071073 0.00345506 0.00488107 0.00370579 0.00209478 0.01286357\n",
      " 0.00165608 0.00523528 0.00514708 0.00165608 0.00345506 0.00071073\n",
      " 0.00514708 0.00165608 0.00345506 0.00209478 0.01092234 0.00345506\n",
      " 0.00370579 0.01219876 0.00370579 0.00514708 0.00148279 0.00174633\n",
      " 0.01016957 0.00910548 0.00345506 0.00174633 0.00345506 0.00514708\n",
      " 0.00174633 0.00071073 0.00148279 0.00370579 0.00910548 0.00165608\n",
      " 0.00345506 0.00148279 0.01016957 0.00406913 0.01092234 0.00514708\n",
      " 0.00148279 0.00165608 0.00488107 0.00406913 0.00209478 0.00174633\n",
      " 0.00148279 0.00345506 0.00436443 0.01199323 0.00174633 0.00071073\n",
      " 0.00406913 0.00174633 0.00488107 0.00165608 0.00863489 0.00174633\n",
      " 0.00209478 0.00165608 0.00406913 0.00148279 0.00406913 0.00364336]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.28999237166285247\n",
      "Alpha : 0.4477105480453884\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[61 17]\n",
      " [38 34]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6333333333333333\n",
      "Misclassification rate : 0.264\n",
      "True positives : 0.472\n",
      "False positives : 0.218\n",
      "Specificity : 0.782\n",
      "Precision : 0.6404040404040404\n",
      "Prevalence : 0.346\n",
      "Recall : 0.472\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 2]\n",
      " [4 1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.625\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.2\n",
      "False positives : 0.182\n",
      "Specificity : 0.818\n",
      "Precision : 0.5801282051282051\n",
      "Prevalence : 0.024\n",
      "Recall : 0.2\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00278926 0.00236833 0.00683838 0.00259131 0.00278926 0.00334582\n",
      " 0.00094764 0.00113519 0.00278926 0.00259131 0.00111606 0.0022081\n",
      " 0.0022081  0.00094764 0.01876611 0.00698036 0.00636707 0.00045422\n",
      " 0.00822097 0.00698036 0.00236833 0.00094764 0.00111606 0.00111606\n",
      " 0.00232843 0.00819178 0.00111606 0.00236833 0.00236833 0.00259131\n",
      " 0.00273253 0.0022081  0.00236833 0.00636707 0.00805376 0.00094764\n",
      " 0.0011121  0.00111606 0.01591259 0.00273253 0.00111606 0.00232016\n",
      " 0.00328944 0.00111606 0.00111606 0.00232843 0.00111606 0.00311944\n",
      " 0.00273253 0.00819178 0.00766475 0.00279304 0.00260054 0.00819178\n",
      " 0.00105838 0.0022081  0.00551847 0.00273253 0.00259131 0.0077961\n",
      " 0.00581922 0.00113519 0.00822097 0.00581922 0.00682913 0.0022081\n",
      " 0.0011121  0.00277935 0.00279304 0.00105838 0.00273253 0.00279304\n",
      " 0.00636707 0.00259131 0.0022081  0.00094764 0.00094764 0.00236833\n",
      " 0.00579855 0.00551847 0.0077961  0.00273253 0.00094764 0.00328944\n",
      " 0.0011121  0.0022081  0.00311944 0.00236833 0.00133875 0.00822097\n",
      " 0.00105838 0.00819178 0.00328944 0.00259131 0.0022081  0.00045422\n",
      " 0.00805376 0.00259131 0.0022081  0.00133875 0.00698036 0.0022081\n",
      " 0.00236833 0.0077961  0.00236833 0.00328944 0.00094764 0.00273253\n",
      " 0.00649927 0.00581922 0.0022081  0.00273253 0.0022081  0.00805376\n",
      " 0.00273253 0.0011121  0.00232016 0.00236833 0.00581922 0.00259131\n",
      " 0.0022081  0.00094764 0.00649927 0.00636707 0.00698036 0.00805376\n",
      " 0.00094764 0.00105838 0.00763753 0.00636707 0.00327776 0.00273253\n",
      " 0.00094764 0.00540623 0.00278926 0.01876611 0.00111606 0.0011121\n",
      " 0.00636707 0.00273253 0.00311944 0.00105838 0.00551847 0.00273253\n",
      " 0.00327776 0.00259131 0.00636707 0.00094764 0.00636707 0.00232843]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2878254540162094\n",
      "Alpha : 0.4529843981296984\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[39 39]\n",
      " [22 50]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5933333333333334\n",
      "Misclassification rate : 0.293\n",
      "True positives : 0.694\n",
      "False positives : 0.5\n",
      "Specificity : 0.5\n",
      "Precision : 0.6021219377417573\n",
      "Prevalence : 0.346\n",
      "Recall : 0.694\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[5 6]\n",
      " [3 2]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.4375\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.4\n",
      "False positives : 0.545\n",
      "Specificity : 0.455\n",
      "Precision : 0.5078125\n",
      "Prevalence : 0.024\n",
      "Recall : 0.4\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00177321 0.00150562 0.00434735 0.00407612 0.00177321 0.00212703\n",
      " 0.00149063 0.00178565 0.0043875  0.00164737 0.00175556 0.00140375\n",
      " 0.00140375 0.00060244 0.01193015 0.00443761 0.00404773 0.00071449\n",
      " 0.01293159 0.00443761 0.00150562 0.00149063 0.00070951 0.00175556\n",
      " 0.00366262 0.00520775 0.00070951 0.00150562 0.00150562 0.00164737\n",
      " 0.00429826 0.00140375 0.00372539 0.00404773 0.00512    0.00060244\n",
      " 0.00174933 0.00070951 0.01011608 0.00429826 0.00070951 0.00364962\n",
      " 0.00209119 0.00070951 0.00175556 0.00366262 0.00175556 0.00490688\n",
      " 0.00173714 0.00520775 0.0048727  0.00177561 0.00165324 0.00520775\n",
      " 0.00067284 0.00140375 0.00350825 0.00173714 0.00407612 0.0049562\n",
      " 0.00369944 0.00072167 0.0052263  0.00369944 0.00434147 0.00347333\n",
      " 0.00174933 0.00176691 0.00439345 0.00166483 0.00173714 0.00177561\n",
      " 0.01001541 0.00407612 0.00347333 0.00149063 0.00060244 0.00150562\n",
      " 0.0036863  0.00868055 0.01226327 0.00429826 0.00149063 0.00209119\n",
      " 0.00174933 0.00140375 0.00490688 0.00372539 0.00085108 0.0052263\n",
      " 0.00166483 0.00520775 0.00209119 0.00407612 0.00140375 0.00071449\n",
      " 0.00512    0.00164737 0.00140375 0.00085108 0.00443761 0.00347333\n",
      " 0.00150562 0.01226327 0.00150562 0.00209119 0.00149063 0.00429826\n",
      " 0.00413177 0.00369944 0.00140375 0.00173714 0.00347333 0.00512\n",
      " 0.00429826 0.00174933 0.00364962 0.00372539 0.00915362 0.00407612\n",
      " 0.00140375 0.00060244 0.00413177 0.00404773 0.00443761 0.00512\n",
      " 0.00060244 0.00166483 0.00485539 0.01001541 0.00515592 0.00429826\n",
      " 0.00060244 0.00850399 0.00177321 0.01193015 0.00070951 0.00070699\n",
      " 0.00404773 0.00429826 0.00198312 0.00166483 0.00868055 0.00429826\n",
      " 0.00208377 0.00407612 0.00404773 0.00149063 0.00404773 0.00366262]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2829117231945872\n",
      "Alpha : 0.4650320179430814\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[64 14]\n",
      " [25 47]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.74\n",
      "Misclassification rate : 0.188\n",
      "True positives : 0.653\n",
      "False positives : 0.179\n",
      "Specificity : 0.821\n",
      "Precision : 0.7437686498434334\n",
      "Prevalence : 0.346\n",
      "Recall : 0.653\n",
      "\n",
      ":: Teste ::\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[8 3]\n",
      " [1 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.75\n",
      "Misclassification rate : 0.019\n",
      "True positives : 0.8\n",
      "False positives : 0.273\n",
      "Specificity : 0.727\n",
      "Precision : 0.7896825396825395\n",
      "Prevalence : 0.024\n",
      "Recall : 0.8\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00111378 0.00239704 0.00273063 0.00256027 0.00111378 0.00133602\n",
      " 0.00093629 0.00112159 0.00698519 0.00103474 0.0011027  0.00088172\n",
      " 0.00088172 0.0003784  0.0074935  0.00706496 0.00254244 0.00044878\n",
      " 0.00812252 0.00706496 0.0009457  0.00237319 0.00044565 0.0011027\n",
      " 0.00230055 0.00829107 0.00044565 0.0009457  0.0009457  0.00103474\n",
      " 0.0026998  0.00088172 0.00233997 0.00254244 0.00815138 0.0003784\n",
      " 0.00278505 0.00112959 0.01610546 0.00684311 0.00044565 0.00229238\n",
      " 0.00332931 0.00044565 0.0011027  0.00230055 0.0011027  0.00781207\n",
      " 0.00109113 0.00829107 0.00775765 0.00282689 0.00103842 0.00829107\n",
      " 0.00042262 0.00223486 0.00220358 0.00276565 0.00256027 0.00311306\n",
      " 0.00232367 0.00045329 0.00328272 0.00232367 0.00272694 0.00218165\n",
      " 0.00109878 0.00110982 0.00275959 0.00104571 0.00109113 0.00282689\n",
      " 0.00629083 0.00256027 0.00218165 0.00093629 0.0003784  0.0009457\n",
      " 0.00231542 0.00545238 0.00770274 0.0026998  0.00093629 0.00332931\n",
      " 0.00278505 0.00088172 0.00308208 0.00233997 0.00135498 0.00832062\n",
      " 0.00104571 0.00829107 0.00332931 0.00256027 0.00088172 0.00044878\n",
      " 0.00321595 0.00103474 0.00088172 0.00053458 0.00278733 0.00218165\n",
      " 0.0009457  0.00770274 0.0009457  0.00332931 0.00093629 0.0026998\n",
      " 0.00259522 0.00232367 0.00088172 0.00276565 0.00218165 0.00815138\n",
      " 0.0026998  0.00109878 0.00581043 0.00233997 0.00574953 0.00256027\n",
      " 0.00088172 0.0003784  0.00259522 0.00254244 0.00706496 0.00815138\n",
      " 0.0003784  0.00104571 0.0077301  0.00629083 0.00820856 0.0026998\n",
      " 0.0003784  0.00534149 0.00111378 0.01899357 0.00044565 0.00112558\n",
      " 0.00254244 0.0026998  0.00315725 0.00104571 0.00545238 0.0026998\n",
      " 0.00331749 0.00256027 0.00254244 0.00093629 0.00254244 0.00583113]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.277584599120255\n",
      "Alpha : 0.47823728625128803\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[39 39]\n",
      " [13 59]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6533333333333333\n",
      "Misclassification rate : 0.25\n",
      "True positives : 0.819\n",
      "False positives : 0.5\n",
      "Specificity : 0.5\n",
      "Precision : 0.6789795918367347\n",
      "Prevalence : 0.346\n",
      "Recall : 0.819\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 8]\n",
      " [1 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.4375\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.8\n",
      "False positives : 0.727\n",
      "Specificity : 0.273\n",
      "Precision : 0.6197916666666666\n",
      "Prevalence : 0.024\n",
      "Recall : 0.8\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0006904  0.00386697 0.00169265 0.00413031 0.0006904  0.00082816\n",
      " 0.00058038 0.00180939 0.00432995 0.00064141 0.0017789  0.00054655\n",
      " 0.00142241 0.00061045 0.00464504 0.00437939 0.00410153 0.00072399\n",
      " 0.00503495 0.00437939 0.00152563 0.00147108 0.00027625 0.00068353\n",
      " 0.00142605 0.00513943 0.00027625 0.00058622 0.00152563 0.00166926\n",
      " 0.00167354 0.00142241 0.00145049 0.00157599 0.00505284 0.00061045\n",
      " 0.00449292 0.0007002  0.00998337 0.00424188 0.00027625 0.00142099\n",
      " 0.00206376 0.00027625 0.00068353 0.00142605 0.00068353 0.00484251\n",
      " 0.00067636 0.00513943 0.01251486 0.00175232 0.00064369 0.00513943\n",
      " 0.00068179 0.00360534 0.00136595 0.00171435 0.00158705 0.00502208\n",
      " 0.00144039 0.00073126 0.00529578 0.00374861 0.00169036 0.00135235\n",
      " 0.00068111 0.0017904  0.0017106  0.00064821 0.00067636 0.00175232\n",
      " 0.00389953 0.00158705 0.0035195  0.00151045 0.00061045 0.00058622\n",
      " 0.00143527 0.00879594 0.00477474 0.00167354 0.00058038 0.00537094\n",
      " 0.00172638 0.00142241 0.0049721  0.00145049 0.00218589 0.01342305\n",
      " 0.00168696 0.00513943 0.00206376 0.00158705 0.00142241 0.00027819\n",
      " 0.00199349 0.00064141 0.00142241 0.00033137 0.0017278  0.0035195\n",
      " 0.00058622 0.01242628 0.00058622 0.00537094 0.00058038 0.00167354\n",
      " 0.00418669 0.00144039 0.00054655 0.00171435 0.00135235 0.00505284\n",
      " 0.00167354 0.00068111 0.00360174 0.00377491 0.0092753  0.00413031\n",
      " 0.00142241 0.00061045 0.00160872 0.00157599 0.01139739 0.00505284\n",
      " 0.00061045 0.00168696 0.01247042 0.00389953 0.00508828 0.00167354\n",
      " 0.00023456 0.00331105 0.0006904  0.01177364 0.00027625 0.00069772\n",
      " 0.00157599 0.00167354 0.00509336 0.00168696 0.00879594 0.00167354\n",
      " 0.00535187 0.00158705 0.00157599 0.00151045 0.00157599 0.00361457]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2882214369337091\n",
      "Alpha : 0.45201889658369104\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[40 38]\n",
      " [18 54]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6266666666666667\n",
      "Misclassification rate : 0.269\n",
      "True positives : 0.75\n",
      "False positives : 0.487\n",
      "Specificity : 0.513\n",
      "Precision : 0.6403598200899551\n",
      "Prevalence : 0.346\n",
      "Recall : 0.75\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 4]\n",
      " [0 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.75\n",
      "Misclassification rate : 0.019\n",
      "True positives : 1.0\n",
      "False positives : 0.364\n",
      "Specificity : 0.636\n",
      "Precision : 0.8611111111111112\n",
      "Prevalence : 0.024\n",
      "Recall : 1.0\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00043933 0.00607688 0.00107711 0.00262829 0.00043933 0.00130145\n",
      " 0.00036932 0.00284342 0.00275533 0.00100796 0.00113199 0.0008589\n",
      " 0.00223529 0.00095931 0.00729959 0.00688214 0.00260998 0.00113773\n",
      " 0.00320395 0.00688214 0.00097082 0.00093611 0.00017579 0.00043496\n",
      " 0.00090746 0.00327043 0.00017579 0.00092123 0.0023975  0.00262322\n",
      " 0.00106494 0.00090514 0.00227942 0.00247665 0.00321533 0.00038845\n",
      " 0.00285903 0.00044557 0.00635284 0.00666603 0.00017579 0.00223306\n",
      " 0.00324316 0.00017579 0.00043496 0.00090746 0.00043496 0.00308149\n",
      " 0.0004304  0.00327043 0.00796373 0.00111507 0.00040961 0.00327043\n",
      " 0.00107142 0.00566572 0.00214656 0.00109092 0.00100991 0.00789211\n",
      " 0.00226354 0.00114917 0.00832221 0.0023854  0.00107565 0.00086056\n",
      " 0.00043342 0.00281358 0.00108853 0.00041248 0.0004304  0.00275374\n",
      " 0.00248143 0.00249402 0.00553084 0.00096116 0.00095931 0.00037303\n",
      " 0.0022555  0.01382266 0.00750341 0.00106494 0.00091206 0.00341776\n",
      " 0.00109857 0.00223529 0.00316396 0.00227942 0.00139098 0.00854165\n",
      " 0.00107349 0.00327043 0.00324316 0.00100991 0.00223529 0.00017702\n",
      " 0.00126854 0.00100796 0.00090514 0.00021087 0.0027152  0.00223961\n",
      " 0.00092123 0.00790737 0.00092123 0.00341776 0.00091206 0.00106494\n",
      " 0.00657931 0.00226354 0.0008589  0.00109092 0.00086056 0.00321533\n",
      " 0.00106494 0.00043342 0.00229194 0.00240213 0.01457597 0.00262829\n",
      " 0.00090514 0.00095931 0.00252807 0.00100287 0.00725264 0.00321533\n",
      " 0.00038845 0.00107349 0.00793545 0.00248143 0.00323789 0.00106494\n",
      " 0.00036861 0.00210696 0.00043933 0.00749206 0.00017579 0.00109645\n",
      " 0.00100287 0.00262994 0.00324112 0.00107349 0.00559723 0.00106494\n",
      " 0.00340562 0.00249402 0.00247665 0.00096116 0.00247665 0.00230011]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 10\n",
      "################################################\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149] [150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165]\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2399999999999994\n",
      "Alpha : 0.5763397549691943\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[68 16]\n",
      " [20 46]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.76\n",
      "Misclassification rate : 0.173\n",
      "True positives : 0.697\n",
      "False positives : 0.19\n",
      "Specificity : 0.81\n",
      "Precision : 0.7591788856304985\n",
      "Prevalence : 0.317\n",
      "Recall : 0.697\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[2 3]\n",
      " [3 8]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.625\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.727\n",
      "False positives : 0.6\n",
      "Specificity : 0.4\n",
      "Precision : 0.625\n",
      "Prevalence : 0.053\n",
      "Recall : 0.727\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00374634 0.01186342 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.01186342 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.01186342 0.00374634 0.00374634\n",
      " 0.00374634 0.01186342 0.00374634 0.01186342 0.00374634 0.00374634\n",
      " 0.00374634 0.01186342 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.01186342 0.00374634\n",
      " 0.01186342 0.01186342 0.01186342 0.01186342 0.00374634 0.00374634\n",
      " 0.01186342 0.00374634 0.00374634 0.00374634 0.00374634 0.01186342\n",
      " 0.00374634 0.01186342 0.01186342 0.01186342 0.00374634 0.01186342\n",
      " 0.00374634 0.01186342 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.01186342 0.00374634 0.00374634 0.01186342\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634 0.01186342\n",
      " 0.01186342 0.00374634 0.00374634 0.00374634 0.01186342 0.01186342\n",
      " 0.00374634 0.01186342 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.01186342 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634 0.01186342\n",
      " 0.00374634 0.00374634 0.01186342 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.01186342 0.01186342\n",
      " 0.00374634 0.00374634 0.01186342 0.00374634 0.01186342 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.01186342 0.00374634 0.01186342 0.00374634\n",
      " 0.01186342 0.00374634 0.00374634 0.01186342 0.00374634 0.00374634]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2858187134502929\n",
      "Alpha : 0.4578895460287072\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[51 33]\n",
      " [17 49]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6666666666666666\n",
      "Misclassification rate : 0.24\n",
      "True positives : 0.742\n",
      "False positives : 0.393\n",
      "Specificity : 0.607\n",
      "Precision : 0.6829268292682926\n",
      "Prevalence : 0.317\n",
      "Recall : 0.742\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 2]\n",
      " [6 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.455\n",
      "False positives : 0.4\n",
      "Specificity : 0.6\n",
      "Precision : 0.5952380952380952\n",
      "Prevalence : 0.053\n",
      "Recall : 0.455\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00237    0.00750501 0.00237    0.00592197 0.00237    0.00237\n",
      " 0.00237    0.00237    0.00750501 0.00592197 0.00237    0.00592197\n",
      " 0.00592197 0.00237    0.00592197 0.00750501 0.00592197 0.00237\n",
      " 0.00237    0.00750501 0.00237    0.00750501 0.00237    0.00237\n",
      " 0.00237    0.00750501 0.00237    0.00237    0.00237    0.00592197\n",
      " 0.00237    0.00592197 0.00237    0.00592197 0.00750501 0.00237\n",
      " 0.00750501 0.00750501 0.00750501 0.00750501 0.00237    0.00237\n",
      " 0.00750501 0.00237    0.00237    0.00237    0.00237    0.01875292\n",
      " 0.00237    0.00750501 0.01875292 0.00750501 0.00592197 0.00750501\n",
      " 0.00592197 0.01875292 0.00592197 0.00237    0.00592197 0.00592197\n",
      " 0.00237    0.00237    0.00237    0.00237    0.00237    0.00592197\n",
      " 0.00237    0.00237    0.00750501 0.00592197 0.00237    0.00750501\n",
      " 0.00592197 0.00592197 0.00592197 0.00237    0.00237    0.00237\n",
      " 0.00237    0.00592197 0.00592197 0.00237    0.00237    0.00750501\n",
      " 0.00750501 0.00592197 0.00592197 0.00237    0.00750501 0.00750501\n",
      " 0.00592197 0.00750501 0.00237    0.00592197 0.00592197 0.00237\n",
      " 0.00237    0.00592197 0.00592197 0.00237    0.00237    0.00592197\n",
      " 0.00237    0.00592197 0.00237    0.00750501 0.00237    0.00237\n",
      " 0.00592197 0.00237    0.00592197 0.00237    0.00592197 0.00750501\n",
      " 0.00237    0.00237    0.00750501 0.00237    0.00237    0.00592197\n",
      " 0.00592197 0.00237    0.00592197 0.00592197 0.01875292 0.00750501\n",
      " 0.00237    0.00592197 0.01875292 0.00592197 0.00750501 0.00237\n",
      " 0.00237    0.00592197 0.00237    0.00237    0.00592197 0.00237\n",
      " 0.00237    0.00237    0.00750501 0.00237    0.01875292 0.00592197\n",
      " 0.00750501 0.00237    0.00237    0.01875292 0.00592197 0.00237   ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2737659257552875\n",
      "Alpha : 0.48779946173064825\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[59 25]\n",
      " [24 42]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6733333333333333\n",
      "Misclassification rate : 0.236\n",
      "True positives : 0.636\n",
      "False positives : 0.298\n",
      "Specificity : 0.702\n",
      "Precision : 0.6738931846790145\n",
      "Prevalence : 0.317\n",
      "Recall : 0.636\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[ 4  1]\n",
      " [ 1 10]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.875\n",
      "Misclassification rate : 0.01\n",
      "True positives : 0.909\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.875\n",
      "Prevalence : 0.053\n",
      "Recall : 0.909\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00386009 0.01222361 0.00145512 0.00363595 0.00386009 0.00386009\n",
      " 0.00145512 0.00386009 0.01222361 0.00363595 0.00145512 0.00363595\n",
      " 0.00363595 0.00145512 0.00363595 0.01222361 0.00363595 0.00145512\n",
      " 0.00386009 0.01222361 0.00386009 0.00460789 0.00145512 0.00145512\n",
      " 0.00145512 0.01222361 0.00145512 0.00386009 0.00386009 0.00363595\n",
      " 0.00145512 0.00363595 0.00386009 0.00363595 0.00460789 0.00145512\n",
      " 0.00460789 0.01222361 0.01222361 0.00460789 0.00145512 0.00145512\n",
      " 0.00460789 0.00145512 0.00145512 0.00145512 0.00145512 0.01151384\n",
      " 0.00145512 0.01222361 0.01151384 0.00460789 0.00363595 0.01222361\n",
      " 0.00363595 0.01151384 0.00964529 0.00145512 0.00363595 0.00964529\n",
      " 0.00386009 0.00386009 0.00386009 0.00386009 0.00386009 0.00363595\n",
      " 0.00145512 0.00386009 0.00460789 0.00363595 0.00145512 0.00460789\n",
      " 0.00363595 0.00363595 0.00363595 0.00145512 0.00145512 0.00386009\n",
      " 0.00386009 0.00964529 0.00964529 0.00145512 0.00145512 0.01222361\n",
      " 0.00460789 0.00363595 0.00363595 0.00386009 0.00460789 0.01222361\n",
      " 0.00363595 0.01222361 0.00145512 0.00363595 0.00363595 0.00145512\n",
      " 0.00145512 0.00363595 0.00363595 0.00145512 0.00386009 0.00363595\n",
      " 0.00386009 0.00964529 0.00386009 0.00460789 0.00145512 0.00145512\n",
      " 0.00964529 0.00386009 0.00363595 0.00145512 0.00363595 0.00460789\n",
      " 0.00145512 0.00145512 0.00460789 0.00386009 0.00386009 0.00363595\n",
      " 0.00363595 0.00145512 0.00964529 0.00363595 0.01151384 0.00460789\n",
      " 0.00145512 0.00363595 0.01151384 0.00363595 0.00460789 0.00145512\n",
      " 0.00145512 0.00363595 0.00145512 0.00145512 0.00363595 0.00386009\n",
      " 0.00386009 0.00386009 0.00460789 0.00386009 0.01151384 0.00964529\n",
      " 0.01222361 0.00145512 0.00145512 0.01151384 0.00363595 0.00145512]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.33152619510633213\n",
      "Alpha : 0.35064519222030915\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[78  6]\n",
      " [50 16]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6266666666666667\n",
      "Misclassification rate : 0.269\n",
      "True positives : 0.242\n",
      "False positives : 0.071\n",
      "Specificity : 0.929\n",
      "Precision : 0.66125\n",
      "Prevalence : 0.317\n",
      "Recall : 0.242\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 1]\n",
      " [8 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.4375\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.273\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.6197916666666666\n",
      "Prevalence : 0.053\n",
      "Recall : 0.273\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00548126 0.00860828 0.00102475 0.00256056 0.00548126 0.0027184\n",
      " 0.00102475 0.0027184  0.01735733 0.00256056 0.00206625 0.00256056\n",
      " 0.00256056 0.00102475 0.00516299 0.00860828 0.00516299 0.00102475\n",
      " 0.0027184  0.00860828 0.0027184  0.00324503 0.00206625 0.00206625\n",
      " 0.00206625 0.00860828 0.00206625 0.0027184  0.0027184  0.00256056\n",
      " 0.00206625 0.00256056 0.0027184  0.00516299 0.00654313 0.00102475\n",
      " 0.00324503 0.01735733 0.01735733 0.00654313 0.00206625 0.00102475\n",
      " 0.00654313 0.00206625 0.00206625 0.00206625 0.00206625 0.00810843\n",
      " 0.00206625 0.00860828 0.01634946 0.00324503 0.00516299 0.00860828\n",
      " 0.00256056 0.00810843 0.00679253 0.00206625 0.00256056 0.00679253\n",
      " 0.00548126 0.0027184  0.00548126 0.00548126 0.00548126 0.00256056\n",
      " 0.00102475 0.0027184  0.00324503 0.00256056 0.00206625 0.00324503\n",
      " 0.00516299 0.00256056 0.00256056 0.00206625 0.00102475 0.0027184\n",
      " 0.0027184  0.00679253 0.00679253 0.00206625 0.00102475 0.01735733\n",
      " 0.00324503 0.00256056 0.00256056 0.0027184  0.00324503 0.01735733\n",
      " 0.00256056 0.00860828 0.00206625 0.00256056 0.00256056 0.00102475\n",
      " 0.00206625 0.00256056 0.00256056 0.00102475 0.0027184  0.00256056\n",
      " 0.0027184  0.00679253 0.0027184  0.00654313 0.00102475 0.00206625\n",
      " 0.01369615 0.00548126 0.00256056 0.00206625 0.00256056 0.00654313\n",
      " 0.00206625 0.00102475 0.00324503 0.0027184  0.00548126 0.00256056\n",
      " 0.00256056 0.00102475 0.01369615 0.00516299 0.00810843 0.00654313\n",
      " 0.00102475 0.00256056 0.00810843 0.00516299 0.00324503 0.00206625\n",
      " 0.00102475 0.00256056 0.00102475 0.00206625 0.00256056 0.0027184\n",
      " 0.0027184  0.00548126 0.00324503 0.00548126 0.00810843 0.01369615\n",
      " 0.00860828 0.00102475 0.00102475 0.00810843 0.00256056 0.00206625]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3135240781357535\n",
      "Alpha : 0.3918474947245899\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[63 21]\n",
      " [30 36]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.66\n",
      "Misclassification rate : 0.245\n",
      "True positives : 0.545\n",
      "False positives : 0.25\n",
      "Specificity : 0.75\n",
      "Precision : 0.6572495755517826\n",
      "Prevalence : 0.317\n",
      "Recall : 0.545\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 1]\n",
      " [7 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.364\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.6636363636363637\n",
      "Prevalence : 0.053\n",
      "Recall : 0.364\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00370428 0.00581754 0.00151633 0.00378889 0.00370428 0.00183712\n",
      " 0.00069253 0.00183712 0.01173021 0.00378889 0.00305746 0.00173044\n",
      " 0.00173044 0.00069253 0.00763974 0.00581754 0.00763974 0.00069253\n",
      " 0.00183712 0.00581754 0.00183712 0.00219302 0.00139639 0.00139639\n",
      " 0.00139639 0.01273777 0.00139639 0.00183712 0.00183712 0.00378889\n",
      " 0.00305746 0.00173044 0.00183712 0.00763974 0.00968195 0.00069253\n",
      " 0.00480171 0.01173021 0.01173021 0.0044219  0.00139639 0.00151633\n",
      " 0.0044219  0.00139639 0.00139639 0.00139639 0.00139639 0.00547974\n",
      " 0.00305746 0.01273777 0.01104908 0.00219302 0.00763974 0.01273777\n",
      " 0.00173044 0.00547974 0.00459044 0.00305746 0.00378889 0.00459044\n",
      " 0.00370428 0.00183712 0.00370428 0.00370428 0.00811069 0.00173044\n",
      " 0.00151633 0.00402246 0.00480171 0.00378889 0.00139639 0.00480171\n",
      " 0.00763974 0.00378889 0.00173044 0.00139639 0.00069253 0.00183712\n",
      " 0.00402246 0.00459044 0.00459044 0.00305746 0.00069253 0.01173021\n",
      " 0.00480171 0.00173044 0.00173044 0.00183712 0.00480171 0.01173021\n",
      " 0.00173044 0.01273777 0.00139639 0.00378889 0.00173044 0.00069253\n",
      " 0.00305746 0.00378889 0.00173044 0.00069253 0.00183712 0.00378889\n",
      " 0.00183712 0.00459044 0.00183712 0.0044219  0.00069253 0.00139639\n",
      " 0.00925595 0.00811069 0.00173044 0.00305746 0.00173044 0.00968195\n",
      " 0.00305746 0.00151633 0.00480171 0.00183712 0.00370428 0.00378889\n",
      " 0.00173044 0.00069253 0.00925595 0.00763974 0.00547974 0.0044219\n",
      " 0.00069253 0.00173044 0.01199815 0.00763974 0.00219302 0.00139639\n",
      " 0.00069253 0.00173044 0.00069253 0.00139639 0.00173044 0.00402246\n",
      " 0.00402246 0.00370428 0.00219302 0.00370428 0.01199815 0.02026635\n",
      " 0.00581754 0.00069253 0.00069253 0.00547974 0.00173044 0.00305746]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2646328420627224\n",
      "Alpha : 0.5110132727271293\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[22 62]\n",
      " [ 2 64]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5733333333333334\n",
      "Misclassification rate : 0.308\n",
      "True positives : 0.97\n",
      "False positives : 0.738\n",
      "Specificity : 0.262\n",
      "Precision : 0.7368253968253968\n",
      "Prevalence : 0.317\n",
      "Recall : 0.97\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[ 2  3]\n",
      " [ 0 11]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8125\n",
      "Misclassification rate : 0.014\n",
      "True positives : 1.0\n",
      "False positives : 0.6\n",
      "Specificity : 0.4\n",
      "Precision : 0.8526785714285714\n",
      "Prevalence : 0.053\n",
      "Recall : 1.0\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00222215 0.00969771 0.00252769 0.00227291 0.00222215 0.00110206\n",
      " 0.00115444 0.00306244 0.0070368  0.00227291 0.00183413 0.00288461\n",
      " 0.00288461 0.00115444 0.00458298 0.00969771 0.00458298 0.00041544\n",
      " 0.00110206 0.00969771 0.00306244 0.00365571 0.00083768 0.00083768\n",
      " 0.00232775 0.00764123 0.00083768 0.00306244 0.00306244 0.00227291\n",
      " 0.00183413 0.00288461 0.00306244 0.00458298 0.00580808 0.00115444\n",
      " 0.00288049 0.0070368  0.0070368  0.00265264 0.00083768 0.00252769\n",
      " 0.00265264 0.00083768 0.00083768 0.00232775 0.00083768 0.00328723\n",
      " 0.00183413 0.00764123 0.00662821 0.00365571 0.00458298 0.00764123\n",
      " 0.00103807 0.00913461 0.00765217 0.00183413 0.00227291 0.00275375\n",
      " 0.00617495 0.00110206 0.00222215 0.00617495 0.0048655  0.00288461\n",
      " 0.00090963 0.00241302 0.00800436 0.00227291 0.00083768 0.00800436\n",
      " 0.00458298 0.00227291 0.00288461 0.00232775 0.00115444 0.00306244\n",
      " 0.00670535 0.00765217 0.00275375 0.00183413 0.00115444 0.0070368\n",
      " 0.00288049 0.00288461 0.00103807 0.00306244 0.00288049 0.0070368\n",
      " 0.00103807 0.00764123 0.00083768 0.00227291 0.00288461 0.00115444\n",
      " 0.00183413 0.00227291 0.00288461 0.00041544 0.00306244 0.006316\n",
      " 0.00306244 0.00275375 0.00306244 0.00265264 0.00115444 0.00083768\n",
      " 0.00555253 0.01352035 0.00288461 0.00183413 0.00288461 0.00580808\n",
      " 0.00183413 0.00090963 0.00800436 0.00306244 0.00617495 0.00227291\n",
      " 0.00288461 0.00115444 0.00555253 0.00458298 0.00913461 0.00265264\n",
      " 0.00115444 0.00103807 0.00719754 0.00458298 0.00131556 0.00083768\n",
      " 0.00115444 0.00288461 0.00115444 0.00083768 0.00288461 0.00670535\n",
      " 0.00241302 0.00222215 0.00365571 0.00617495 0.00719754 0.01215753\n",
      " 0.00969771 0.00115444 0.00041544 0.00328723 0.00288461 0.00183413]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.30330793820688823\n",
      "Alpha : 0.4157974604100021\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[57 27]\n",
      " [19 47]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6933333333333334\n",
      "Misclassification rate : 0.221\n",
      "True positives : 0.712\n",
      "False positives : 0.321\n",
      "Specificity : 0.679\n",
      "Precision : 0.6994594594594594\n",
      "Prevalence : 0.317\n",
      "Recall : 0.712\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 1]\n",
      " [5 6]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.625\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.545\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.7281746031746033\n",
      "Prevalence : 0.053\n",
      "Recall : 0.545\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0014662  0.00639869 0.00383092 0.00344477 0.0014662  0.00072716\n",
      " 0.00076171 0.00202064 0.00464298 0.00344477 0.00121018 0.00437186\n",
      " 0.00437186 0.00076171 0.00302391 0.00639869 0.00694587 0.00027411\n",
      " 0.00072716 0.00639869 0.00202064 0.00241209 0.00055271 0.00126956\n",
      " 0.00153588 0.01158089 0.00055271 0.00464136 0.00202064 0.00344477\n",
      " 0.00121018 0.00437186 0.00202064 0.00694587 0.00383225 0.00076171\n",
      " 0.00190059 0.00464298 0.00464298 0.00402028 0.00126956 0.00166781\n",
      " 0.00175025 0.00055271 0.00055271 0.00153588 0.00055271 0.00498205\n",
      " 0.00121018 0.01158089 0.01004557 0.00241209 0.00302391 0.01158089\n",
      " 0.00157328 0.00602714 0.00504901 0.00121018 0.00344477 0.00181696\n",
      " 0.00407432 0.00072716 0.00336784 0.00407432 0.00321032 0.00437186\n",
      " 0.00137861 0.00159214 0.00528139 0.00344477 0.00055271 0.00528139\n",
      " 0.00302391 0.0014997  0.00437186 0.00153588 0.00076171 0.00202064\n",
      " 0.00442428 0.00504901 0.00181696 0.00277977 0.00174964 0.01066483\n",
      " 0.00190059 0.00437186 0.00157328 0.00202064 0.00436561 0.01066483\n",
      " 0.00068493 0.01158089 0.00055271 0.00344477 0.00437186 0.00076171\n",
      " 0.00121018 0.00344477 0.00437186 0.00027411 0.00202064 0.00416738\n",
      " 0.00202064 0.00181696 0.00202064 0.00175025 0.00174964 0.00055271\n",
      " 0.00366364 0.00892092 0.00437186 0.00121018 0.00437186 0.00383225\n",
      " 0.00121018 0.00060019 0.00528139 0.00202064 0.00407432 0.00344477\n",
      " 0.00437186 0.00076171 0.00366364 0.00302391 0.00602714 0.00175025\n",
      " 0.00076171 0.00068493 0.01090843 0.00302391 0.00086803 0.00055271\n",
      " 0.00076171 0.00437186 0.00076171 0.00055271 0.00437186 0.00442428\n",
      " 0.00159214 0.0014662  0.00241209 0.00407432 0.00474903 0.01842569\n",
      " 0.00639869 0.00076171 0.00027411 0.00216896 0.00190331 0.00121018]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3262562980506331\n",
      "Alpha : 0.3625832558015709\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[33 51]\n",
      " [14 52]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5666666666666667\n",
      "Misclassification rate : 0.312\n",
      "True positives : 0.788\n",
      "False positives : 0.607\n",
      "Specificity : 0.393\n",
      "Precision : 0.6153274116917993\n",
      "Prevalence : 0.317\n",
      "Recall : 0.788\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[1 4]\n",
      " [3 8]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5625\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.727\n",
      "False positives : 0.8\n",
      "Specificity : 0.2\n",
      "Precision : 0.5364583333333333\n",
      "Prevalence : 0.053\n",
      "Recall : 0.727\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0010203  0.00445269 0.00550517 0.00495026 0.0010203  0.00050601\n",
      " 0.00109461 0.00290373 0.00667213 0.00239713 0.00084214 0.00304227\n",
      " 0.00628252 0.00053006 0.00210427 0.00445269 0.00483347 0.00039391\n",
      " 0.00104495 0.00445269 0.00140611 0.00346626 0.00038462 0.00182441\n",
      " 0.00220712 0.00805887 0.00038462 0.00322982 0.00140611 0.00239713\n",
      " 0.00084214 0.00304227 0.00290373 0.00483347 0.00266677 0.00053006\n",
      " 0.00273121 0.00323094 0.00323094 0.00279762 0.00088346 0.0023967\n",
      " 0.00121796 0.00038462 0.00079426 0.00220712 0.00079426 0.00715939\n",
      " 0.00084214 0.00805887 0.00699047 0.00167852 0.00210427 0.00805887\n",
      " 0.00109481 0.00866123 0.00351349 0.00084214 0.00239713 0.00126438\n",
      " 0.00283522 0.00050601 0.0023436  0.00283522 0.00223399 0.00628252\n",
      " 0.00198112 0.00110794 0.00758955 0.00495026 0.00038462 0.00367519\n",
      " 0.00434548 0.00215512 0.00628252 0.00220712 0.00109461 0.00290373\n",
      " 0.00307875 0.00725561 0.00261104 0.00399463 0.0025143  0.0074214\n",
      " 0.00273121 0.00628252 0.00226086 0.00290373 0.00303792 0.0074214\n",
      " 0.00098428 0.00805887 0.00038462 0.00495026 0.00628252 0.00109461\n",
      " 0.00084214 0.00239713 0.00304227 0.00019075 0.00290373 0.00598868\n",
      " 0.00140611 0.00261104 0.00140611 0.00121796 0.0025143  0.00038462\n",
      " 0.00254944 0.00620785 0.00304227 0.00084214 0.00628252 0.00266677\n",
      " 0.00173908 0.00086249 0.00758955 0.00290373 0.00585495 0.00495026\n",
      " 0.00304227 0.00109461 0.00254944 0.00210427 0.00419415 0.00121796\n",
      " 0.00053006 0.00098428 0.00759092 0.00210427 0.00124739 0.00038462\n",
      " 0.00053006 0.00628252 0.00109461 0.00079426 0.00304227 0.00307875\n",
      " 0.00228797 0.0010203  0.00167852 0.00585495 0.00330474 0.01282201\n",
      " 0.00919515 0.00053006 0.00039391 0.00311687 0.00273512 0.00173908]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2980354193284936\n",
      "Alpha : 0.42833530580975376\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[79  5]\n",
      " [50 16]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6333333333333333\n",
      "Misclassification rate : 0.264\n",
      "True positives : 0.242\n",
      "False positives : 0.06\n",
      "Specificity : 0.94\n",
      "Precision : 0.6781838316722038\n",
      "Prevalence : 0.317\n",
      "Recall : 0.242\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[ 5  0]\n",
      " [10  1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.375\n",
      "Misclassification rate : 0.048\n",
      "True positives : 0.091\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 0.7916666666666666\n",
      "Prevalence : 0.053\n",
      "Recall : 0.091\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00156585 0.00290134 0.00358713 0.00322555 0.00156585 0.00077658\n",
      " 0.00071324 0.00189205 0.01023973 0.00156196 0.00129243 0.00198232\n",
      " 0.00409365 0.00034538 0.00322943 0.00683355 0.00741792 0.00025667\n",
      " 0.00160369 0.00290134 0.00091621 0.00225859 0.00059027 0.00279992\n",
      " 0.00143814 0.01236795 0.00059027 0.00210452 0.00091621 0.00156196\n",
      " 0.00129243 0.00198232 0.00189205 0.00314945 0.0040927  0.00081348\n",
      " 0.00177964 0.00495853 0.00210526 0.00429351 0.00135585 0.00156167\n",
      " 0.0018692  0.00059027 0.00121896 0.00143814 0.00121896 0.00466501\n",
      " 0.00054873 0.01236795 0.01072829 0.00109371 0.00322943 0.0052511\n",
      " 0.00071337 0.00564359 0.00228936 0.00129243 0.00156196 0.00082386\n",
      " 0.00435122 0.00032971 0.00359673 0.00184741 0.0034285  0.00409365\n",
      " 0.00129088 0.00072192 0.0049453  0.00322555 0.00059027 0.00239473\n",
      " 0.00283148 0.00140426 0.00409365 0.00143814 0.00071324 0.00189205\n",
      " 0.00200609 0.00472771 0.00170134 0.00260287 0.0016383  0.00483573\n",
      " 0.00177964 0.00409365 0.00147316 0.00189205 0.0046623  0.01138963\n",
      " 0.00064135 0.0052511  0.00025061 0.00322555 0.00409365 0.00071324\n",
      " 0.00129243 0.00156196 0.00198232 0.00029274 0.00189205 0.00390218\n",
      " 0.00091621 0.00170134 0.00091621 0.0018692  0.0016383  0.00059027\n",
      " 0.00391262 0.0095272  0.00198232 0.00129243 0.00409365 0.0040927\n",
      " 0.00113317 0.00056199 0.0049453  0.00189205 0.00381504 0.00322555\n",
      " 0.00198232 0.0016799  0.00391262 0.00322943 0.00273288 0.0018692\n",
      " 0.00081348 0.00064135 0.01164979 0.00322943 0.00191436 0.00059027\n",
      " 0.00034538 0.00409365 0.0016799  0.00121896 0.00198232 0.00200609\n",
      " 0.00149083 0.00156585 0.00109371 0.00381504 0.00507179 0.01967794\n",
      " 0.00599149 0.00034538 0.00025667 0.00203093 0.00178219 0.00113317]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.32974398374212416\n",
      "Alpha : 0.3546716033456159\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[18 66]\n",
      " [ 3 63]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.54\n",
      "Misclassification rate : 0.332\n",
      "True positives : 0.955\n",
      "False positives : 0.786\n",
      "Specificity : 0.214\n",
      "Precision : 0.6948837209302325\n",
      "Prevalence : 0.317\n",
      "Recall : 0.955\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[1 4]\n",
      " [2 9]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.625\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.818\n",
      "False positives : 0.8\n",
      "Specificity : 0.2\n",
      "Precision : 0.5801282051282051\n",
      "Prevalence : 0.053\n",
      "Recall : 0.818\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00109829 0.00413648 0.00511421 0.00459871 0.00109829 0.00054469\n",
      " 0.00101687 0.00269752 0.00718218 0.0022269  0.00184264 0.00282622\n",
      " 0.00583636 0.00049242 0.00226513 0.00974268 0.00520296 0.00036594\n",
      " 0.00112483 0.00413648 0.00130626 0.00158419 0.00041402 0.00196388\n",
      " 0.00205038 0.00867492 0.00041402 0.00300045 0.00130626 0.0022269\n",
      " 0.00090652 0.00139041 0.00132709 0.00220904 0.00287063 0.00115979\n",
      " 0.00253725 0.00347793 0.00147664 0.00301148 0.000951   0.00109536\n",
      " 0.00131106 0.00041402 0.00085498 0.00205038 0.00085498 0.00665096\n",
      " 0.00038488 0.00867492 0.00752486 0.00155932 0.00226513 0.00368314\n",
      " 0.00101706 0.00804614 0.00326397 0.00090652 0.00109556 0.00117459\n",
      " 0.00305196 0.00047008 0.00252276 0.00129578 0.00240477 0.00583636\n",
      " 0.00090543 0.00102925 0.00346865 0.00226242 0.00041402 0.0034142\n",
      " 0.00198601 0.00200207 0.00583636 0.00100872 0.00101687 0.00269752\n",
      " 0.00286011 0.00674035 0.00119332 0.00182567 0.00233574 0.0033918\n",
      " 0.00124825 0.00583636 0.00103328 0.00269752 0.00327016 0.00798873\n",
      " 0.00091438 0.00368314 0.00017578 0.00459871 0.00583636 0.00101687\n",
      " 0.00090652 0.0022269  0.00282622 0.00041737 0.00269752 0.00556339\n",
      " 0.00130626 0.00119332 0.00130626 0.00131106 0.00233574 0.00041402\n",
      " 0.00274433 0.00668241 0.00282622 0.00090652 0.0028713  0.00287063\n",
      " 0.00079481 0.00039418 0.00346865 0.00132709 0.00543915 0.00459871\n",
      " 0.00282622 0.00239505 0.00274433 0.00226513 0.00389629 0.00131106\n",
      " 0.00115979 0.00091438 0.00817121 0.00226513 0.00134274 0.00041402\n",
      " 0.00049242 0.0028713  0.00239505 0.00085498 0.00282622 0.00286011\n",
      " 0.00104567 0.00109829 0.00155932 0.00267588 0.00355737 0.01380218\n",
      " 0.00420246 0.00049242 0.00036594 0.00289552 0.00254089 0.00079481]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "scores_test = []\n",
    "error_train = []\n",
    "error_test = []\n",
    "\n",
    "\n",
    "\n",
    "# Define quantos folds\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "print()\n",
    "print(\"....Iniciando treinamento com 10 K-folds....\" )\n",
    "print()\n",
    "\n",
    "kfold = 0    \n",
    "for train_index, test_index in kf.split(trainData):\n",
    "    \n",
    "    print(\"################################################\")\n",
    "    print(\"K-fold : \"+str(kfold+1))    \n",
    "    print(\"################################################\")\n",
    "    print(train_index, test_index)\n",
    "    print()\n",
    "\n",
    "    # Obten os subdados de treinamento e teste no n fold\n",
    "    #---------------------------------------------------------------------\n",
    "    X_train, X_test = trainData.iloc[train_index,:], trainData.iloc[test_index,:]\n",
    "    #print(len(X_train), len(X_test))\n",
    "\n",
    "    y_train, y_test = trainLabels.iloc[train_index], trainLabels.iloc[test_index]\n",
    "    #print(len(y_train), len(y_test))\n",
    "    \n",
    "    print(\"....Inicializando vetor de pesos....\")\n",
    "    print()\n",
    "\n",
    "\n",
    "    n_train, n_test = len(X_train), len(X_test)\n",
    "    #pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)]\n",
    "\n",
    "    # Initialize weights\n",
    "    w = np.ones(n_train) / n_train\n",
    "    print(w)\n",
    "    \n",
    "    pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)]\n",
    "    print(pred_train)\n",
    "    \n",
    "    # Fit um classificador\n",
    "    model = DecisionTreeClassifier(max_depth = 1, random_state = 1)\n",
    "    \n",
    "    model_index = 0\n",
    "    for i in range(10):\n",
    "        print()\n",
    "        # Treina o modelo de classificação\n",
    "        #---------------------------------------------------------------------\n",
    "        print(\"Treinando o modelo....\")\n",
    "\n",
    "        # Treina o classificador com os pesos de treinamento\n",
    "        model.fit(X=X_train, y=y_train, sample_weight=w)\n",
    "        print(model)\n",
    "\n",
    "        # Classifica o treino\n",
    "        pred_train_i = model.predict(X_train)\n",
    "        #print(pred_train_i)\n",
    "\n",
    "        # Classifica o teste\n",
    "        pred_test_i = model.predict(X_test)\n",
    "        #print(pred_test_i)        \n",
    "\n",
    "        print()\n",
    "        print(\"...:::: Avaliação ::::....  \")\n",
    "        print()\n",
    "\n",
    "        # Obtem o index dos erros da classificação de treino e teste\n",
    "        #---------------------------------------------------------------------\n",
    "        missTrain = [int(x) for x in (pred_train_i != y_train)]\n",
    "        #print(\"Training Miss : \"+str(missTrain))\n",
    "        missTest = [int(x) for x in (pred_test_i != y_test)]\n",
    "        #print(\"Testing Miss : \"+str(missTest))\n",
    "\n",
    "        # Equivale os valores entre 1/-1 para atualização dos pesos\n",
    "        #---------------------------------------------------------------------\n",
    "        miss2Train = [x if x==1 else -1 for x in missTrain]\n",
    "        #print(\"Training Miss2 : \"+str(miss2))\n",
    "        miss2Test = [x if x==1 else -1 for x in missTest]\n",
    "        #print(\"Testing Miss2 : \"+str(miss2Test))\n",
    "\n",
    "\n",
    "        # Calcula o erro\n",
    "        #---------------------------------------------------------------------\n",
    "        err_m = np.dot(w, missTrain) / sum(w)\n",
    "        print(\"Error : \"+str(err_m))\n",
    "\n",
    "        # Calcula o Alpha \n",
    "        #---------------------------------------------------------------------\n",
    "        alpha_m = alpha * np.log( (1 - err_m) / float(err_m))\n",
    "        print(\"Alpha : \"+str(alpha_m))\n",
    "\n",
    "\n",
    "        # Mostra a Matriz de Confusão para treino e teste\n",
    "        #---------------------------------------------------------------------\n",
    "        print()\n",
    "        print(\":: Treinamento :: \")\n",
    "        print(\"\")\n",
    "        train_acc_score, train_precision_score, train_recall_score = printCM(y_train, pred_train_i)\n",
    "\n",
    "        print()\n",
    "        print(\":: Teste ::\")\n",
    "        print()\n",
    "        test_acc_score, test_precision_score, test_recall_score = printCM(y_test, pred_test_i)\n",
    "        print\n",
    "\n",
    "\n",
    "        # Atualiza os valores dos pesos\n",
    "        #---------------------------------------------------------------------\n",
    "        w = np.multiply(w, np.exp([float(x) * alpha_m for x in miss2Train]))\n",
    "        print()\n",
    "        print(\"Novos pesos atualizados : \")\n",
    "        print(w)\n",
    "        print()\n",
    "        print(\"---------------------------------------------------------------------------\")\n",
    "        print()\n",
    "\n",
    "\n",
    "        scores.append([kfold, model_index, train_acc_score, train_precision_score, train_recall_score, err_m, alpha_m, model])\n",
    "        scores_test.append([kfold, model_index, test_acc_score, test_precision_score, test_recall_score, err_m, alpha_m, model])\n",
    "    \n",
    "        error_train.append([i, err_m])\n",
    "    \n",
    "        model_index += 1\n",
    "        # Add to prediction\n",
    "        ##pred_train = [sum(x) for x in zip(pred_train, [x * alpha_m for x in pred_train_i])]\n",
    "        ##pred_test = [sum(x) for x in zip(pred_test, [x * alpha_m for x in pred_test_i])]\n",
    "        \n",
    "    ##pred_train, pred_test = np.sign(pred_train), np.sign(pred_test)\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    kfold += 1 \n",
    "    print\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0.23489932885906067],\n",
       " [1, 0.33032581453634086],\n",
       " [2, 0.26916391988405547],\n",
       " [3, 0.32960639871747777],\n",
       " [4, 0.2688210741082501],\n",
       " [5, 0.2909425261559668],\n",
       " [6, 0.290505664233224],\n",
       " [7, 0.3063719047258378],\n",
       " [8, 0.2715534734507066],\n",
       " [9, 0.26684629567876683],\n",
       " [0, 0.24832214765100702],\n",
       " [1, 0.3223938223938217],\n",
       " [2, 0.3003352269819334],\n",
       " [3, 0.30010861594741883],\n",
       " [4, 0.31439917452435057],\n",
       " [5, 0.3529680664260112],\n",
       " [6, 0.3123303322509476],\n",
       " [7, 0.29673599061966477],\n",
       " [8, 0.29795883890641567],\n",
       " [9, 0.25660291917041383],\n",
       " [0, 0.22147651006711436],\n",
       " [1, 0.2979362591431558],\n",
       " [2, 0.2770144469479923],\n",
       " [3, 0.2861489309780387],\n",
       " [4, 0.3432331064364485],\n",
       " [5, 0.26701962007323327],\n",
       " [6, 0.33616481227237355],\n",
       " [7, 0.27858564709863964],\n",
       " [8, 0.361497931564521],\n",
       " [9, 0.3021321639398614],\n",
       " [0, 0.24161073825503385],\n",
       " [1, 0.354965585054081],\n",
       " [2, 0.2841013698398764],\n",
       " [3, 0.29229124483183283],\n",
       " [4, 0.3055109663036106],\n",
       " [5, 0.2996451919013844],\n",
       " [6, 0.3248372582648343],\n",
       " [7, 0.282666012852263],\n",
       " [8, 0.31584944088383327],\n",
       " [9, 0.26261557026548704],\n",
       " [0, 0.24161073825503387],\n",
       " [1, 0.3184611602753202],\n",
       " [2, 0.30114891006149813],\n",
       " [3, 0.28847990566692133],\n",
       " [4, 0.28992333390175223],\n",
       " [5, 0.2995995082721511],\n",
       " [6, 0.2827795002290715],\n",
       " [7, 0.2845741548084909],\n",
       " [8, 0.2656797802539647],\n",
       " [9, 0.29460434163779325],\n",
       " [0, 0.21476510067114118],\n",
       " [1, 0.30021367521367603],\n",
       " [2, 0.29496346200863854],\n",
       " [3, 0.29015153474223926],\n",
       " [4, 0.2980933753718308],\n",
       " [5, 0.3018517073080089],\n",
       " [6, 0.3027858557757345],\n",
       " [7, 0.2986126130389554],\n",
       " [8, 0.34642453895709313],\n",
       " [9, 0.3690458368257864],\n",
       " [0, 0.24666666666666606],\n",
       " [1, 0.34286055967471796],\n",
       " [2, 0.30341811197229424],\n",
       " [3, 0.2787511217829959],\n",
       " [4, 0.2780420355047956],\n",
       " [5, 0.31187777255693055],\n",
       " [6, 0.3192677385594743],\n",
       " [7, 0.329503322943522],\n",
       " [8, 0.25629518516680777],\n",
       " [9, 0.2920773444419189],\n",
       " [0, 0.23333333333333273],\n",
       " [1, 0.3459627329192547],\n",
       " [2, 0.3022526047660693],\n",
       " [3, 0.27183414232751985],\n",
       " [4, 0.32892808716672517],\n",
       " [5, 0.23688889506440083],\n",
       " [6, 0.3198672053818348],\n",
       " [7, 0.2685935266616891],\n",
       " [8, 0.33223771761312926],\n",
       " [9, 0.2783792001383885],\n",
       " [0, 0.2533333333333327],\n",
       " [1, 0.32401315789473656],\n",
       " [2, 0.3002907710195865],\n",
       " [3, 0.28926050513361046],\n",
       " [4, 0.28577964344618695],\n",
       " [5, 0.28999237166285247],\n",
       " [6, 0.2878254540162094],\n",
       " [7, 0.2829117231945872],\n",
       " [8, 0.277584599120255],\n",
       " [9, 0.2882214369337091],\n",
       " [0, 0.2399999999999994],\n",
       " [1, 0.2858187134502929],\n",
       " [2, 0.2737659257552875],\n",
       " [3, 0.33152619510633213],\n",
       " [4, 0.3135240781357535],\n",
       " [5, 0.2646328420627224],\n",
       " [6, 0.30330793820688823],\n",
       " [7, 0.3262562980506331],\n",
       " [8, 0.2980354193284936],\n",
       " [9, 0.32974398374212416]]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Error rate vs number of iterations')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_error = pd.DataFrame(error_train)\n",
    "df_error.head(10)\n",
    "df_error.columns = ['It', 'Error']\n",
    "plot1 = df_error.plot(linewidth = 3, \n",
    "                      figsize = (8,6),\n",
    "                      color = ['lightblue', 'darkblue'], \n",
    "                      grid = True)\n",
    "plot1.set_xlabel('Number of iterations', fontsize = 12)\n",
    "plot1.set_xticklabels(range(0,450,50))\n",
    "plot1.set_ylabel('Error rate', fontsize = 12)\n",
    "plot1.set_title('Error rate vs number of iterations', fontsize = 16)\n",
    "#plt.axhline(y=error_test[0], linewidth=1, color = 'red', ls = 'dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Apresentação dos Resultados</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-fold</th>\n",
       "      <th>Model Idx</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Error</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.768952</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.234899</td>\n",
       "      <td>0.590425</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630872</td>\n",
       "      <td>0.741690</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.330326</td>\n",
       "      <td>0.353356</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.657718</td>\n",
       "      <td>0.665312</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.269164</td>\n",
       "      <td>0.499434</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.604027</td>\n",
       "      <td>0.654423</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.329606</td>\n",
       "      <td>0.354983</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.644295</td>\n",
       "      <td>0.688609</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.268821</td>\n",
       "      <td>0.500306</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.704698</td>\n",
       "      <td>0.705325</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.290943</td>\n",
       "      <td>0.445405</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.610738</td>\n",
       "      <td>0.625678</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.290506</td>\n",
       "      <td>0.446465</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.630872</td>\n",
       "      <td>0.703691</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.306372</td>\n",
       "      <td>0.408568</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.610738</td>\n",
       "      <td>0.675630</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.271553</td>\n",
       "      <td>0.493378</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.651007</td>\n",
       "      <td>0.655020</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.266846</td>\n",
       "      <td>0.505341</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.759389</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.248322</td>\n",
       "      <td>0.553790</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.624161</td>\n",
       "      <td>0.713117</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.322394</td>\n",
       "      <td>0.371396</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.671141</td>\n",
       "      <td>0.736375</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.300335</td>\n",
       "      <td>0.422851</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.617450</td>\n",
       "      <td>0.673821</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.300109</td>\n",
       "      <td>0.423390</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.610738</td>\n",
       "      <td>0.671962</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.314399</td>\n",
       "      <td>0.389816</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.644295</td>\n",
       "      <td>0.648633</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.352968</td>\n",
       "      <td>0.303009</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.711409</td>\n",
       "      <td>0.711682</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.312330</td>\n",
       "      <td>0.394624</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.577181</td>\n",
       "      <td>0.587313</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.296736</td>\n",
       "      <td>0.431445</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.731544</td>\n",
       "      <td>0.735114</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.297959</td>\n",
       "      <td>0.428518</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.644295</td>\n",
       "      <td>0.659745</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.256603</td>\n",
       "      <td>0.531850</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>0.778958</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.221477</td>\n",
       "      <td>0.628541</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671141</td>\n",
       "      <td>0.676598</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.297936</td>\n",
       "      <td>0.428572</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.630872</td>\n",
       "      <td>0.640680</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.277014</td>\n",
       "      <td>0.479660</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.644295</td>\n",
       "      <td>0.678966</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.286149</td>\n",
       "      <td>0.457081</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.711409</td>\n",
       "      <td>0.714398</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.343233</td>\n",
       "      <td>0.324460</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.557047</td>\n",
       "      <td>0.647333</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.267020</td>\n",
       "      <td>0.504898</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.617450</td>\n",
       "      <td>0.700967</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.336165</td>\n",
       "      <td>0.340216</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.577181</td>\n",
       "      <td>0.663881</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.278586</td>\n",
       "      <td>0.475744</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.590604</td>\n",
       "      <td>0.730830</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.361498</td>\n",
       "      <td>0.284434</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.724832</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.302132</td>\n",
       "      <td>0.418583</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.768711</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.594792</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.655689</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.345963</td>\n",
       "      <td>0.318417</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.680301</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.302253</td>\n",
       "      <td>0.418297</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.687802</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.271834</td>\n",
       "      <td>0.492668</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.650505</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.328928</td>\n",
       "      <td>0.356519</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.711785</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.236889</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.761333</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.319867</td>\n",
       "      <td>0.377191</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.590732</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.268594</td>\n",
       "      <td>0.500885</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.675424</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.332238</td>\n",
       "      <td>0.349041</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.641491</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.278379</td>\n",
       "      <td>0.476258</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.756353</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.540456</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.747200</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.324013</td>\n",
       "      <td>0.367695</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.650499</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.300291</td>\n",
       "      <td>0.422957</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.667472</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.289261</td>\n",
       "      <td>0.449489</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.707127</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.285780</td>\n",
       "      <td>0.457985</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.640404</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.289992</td>\n",
       "      <td>0.447711</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.602122</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.287825</td>\n",
       "      <td>0.452984</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.743769</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.282912</td>\n",
       "      <td>0.465032</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.678980</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.277585</td>\n",
       "      <td>0.478237</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.640360</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.288221</td>\n",
       "      <td>0.452019</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.759179</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.576340</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.285819</td>\n",
       "      <td>0.457890</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.673893</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.273766</td>\n",
       "      <td>0.487799</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.661250</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.331526</td>\n",
       "      <td>0.350645</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.657250</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.313524</td>\n",
       "      <td>0.391847</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.736825</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.264633</td>\n",
       "      <td>0.511013</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.699459</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.303308</td>\n",
       "      <td>0.415797</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.615327</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.326256</td>\n",
       "      <td>0.362583</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.678184</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.298035</td>\n",
       "      <td>0.428335</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.694884</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.329744</td>\n",
       "      <td>0.354672</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n-fold  Model Idx       Acc  Precision  Recall     Error     Alpha  \\\n",
       "0        0          0  0.765101   0.768952   0.671  0.234899  0.590425   \n",
       "1        0          1  0.630872   0.741690   0.957  0.330326  0.353356   \n",
       "2        0          2  0.657718   0.665312   0.486  0.269164  0.499434   \n",
       "3        0          3  0.604027   0.654423   0.243  0.329606  0.354983   \n",
       "4        0          4  0.644295   0.688609   0.857  0.268821  0.500306   \n",
       "5        0          5  0.704698   0.705325   0.700  0.290943  0.445405   \n",
       "6        0          6  0.610738   0.625678   0.729  0.290506  0.446465   \n",
       "7        0          7  0.630872   0.703691   0.271  0.306372  0.408568   \n",
       "8        0          8  0.610738   0.675630   0.886  0.271553  0.493378   \n",
       "9        0          9  0.651007   0.655020   0.686  0.266846  0.505341   \n",
       "10       1          0  0.751678   0.759389   0.629  0.248322  0.553790   \n",
       "11       1          1  0.624161   0.713117   0.929  0.322394  0.371396   \n",
       "12       1          2  0.671141   0.736375   0.357  0.300335  0.422851   \n",
       "13       1          3  0.617450   0.673821   0.871  0.300109  0.423390   \n",
       "14       1          4  0.610738   0.671962   0.243  0.314399  0.389816   \n",
       "15       1          5  0.644295   0.648633   0.486  0.352968  0.303009   \n",
       "16       1          6  0.711409   0.711682   0.700  0.312330  0.394624   \n",
       "17       1          7  0.577181   0.587313   0.671  0.296736  0.431445   \n",
       "18       1          8  0.731544   0.735114   0.629  0.297959  0.428518   \n",
       "19       1          9  0.644295   0.659745   0.757  0.256603  0.531850   \n",
       "20       2          0  0.778523   0.778958   0.754  0.221477  0.628541   \n",
       "21       2          1  0.671141   0.676598   0.677  0.297936  0.428572   \n",
       "22       2          2  0.630872   0.640680   0.662  0.277014  0.479660   \n",
       "23       2          3  0.644295   0.678966   0.277  0.286149  0.457081   \n",
       "24       2          4  0.711409   0.714398   0.538  0.343233  0.324460   \n",
       "25       2          5  0.557047   0.647333   0.877  0.267020  0.504898   \n",
       "26       2          6  0.617450   0.700967   0.154  0.336165  0.340216   \n",
       "27       2          7  0.577181   0.663881   0.877  0.278586  0.475744   \n",
       "28       2          8  0.590604   0.730830   0.954  0.361498  0.284434   \n",
       "29       2          9  0.724832   0.776352   0.415  0.302132  0.418583   \n",
       "..     ...        ...       ...        ...     ...       ...       ...   \n",
       "70       7          0  0.766667   0.768711   0.686  0.233333  0.594792   \n",
       "71       7          1  0.606667   0.655689   0.243  0.345963  0.318417   \n",
       "72       7          2  0.673333   0.680301   0.729  0.302253  0.418297   \n",
       "73       7          3  0.686667   0.687802   0.686  0.271834  0.492668   \n",
       "74       7          4  0.646667   0.650505   0.486  0.328928  0.356519   \n",
       "75       7          5  0.620000   0.711785   0.929  0.236889  0.584906   \n",
       "76       7          6  0.746667   0.761333   0.586  0.319867  0.377191   \n",
       "77       7          7  0.580000   0.590732   0.671  0.268594  0.500885   \n",
       "78       7          8  0.640000   0.675424   0.343  0.332238  0.349041   \n",
       "79       7          9  0.540000   0.641491   0.929  0.278379  0.476258   \n",
       "80       8          0  0.746667   0.756353   0.625  0.253333  0.540456   \n",
       "81       8          1  0.620000   0.747200   0.972  0.324013  0.367695   \n",
       "82       8          2  0.646667   0.650499   0.694  0.300291  0.422957   \n",
       "83       8          3  0.600000   0.667472   0.236  0.289261  0.449489   \n",
       "84       8          4  0.706667   0.707127   0.708  0.285780  0.457985   \n",
       "85       8          5  0.633333   0.640404   0.472  0.289992  0.447711   \n",
       "86       8          6  0.593333   0.602122   0.694  0.287825  0.452984   \n",
       "87       8          7  0.740000   0.743769   0.653  0.282912  0.465032   \n",
       "88       8          8  0.653333   0.678980   0.819  0.277585  0.478237   \n",
       "89       8          9  0.626667   0.640360   0.750  0.288221  0.452019   \n",
       "90       9          0  0.760000   0.759179   0.697  0.240000  0.576340   \n",
       "91       9          1  0.666667   0.682927   0.742  0.285819  0.457890   \n",
       "92       9          2  0.673333   0.673893   0.636  0.273766  0.487799   \n",
       "93       9          3  0.626667   0.661250   0.242  0.331526  0.350645   \n",
       "94       9          4  0.660000   0.657250   0.545  0.313524  0.391847   \n",
       "95       9          5  0.573333   0.736825   0.970  0.264633  0.511013   \n",
       "96       9          6  0.693333   0.699459   0.712  0.303308  0.415797   \n",
       "97       9          7  0.566667   0.615327   0.788  0.326256  0.362583   \n",
       "98       9          8  0.633333   0.678184   0.242  0.298035  0.428335   \n",
       "99       9          9  0.540000   0.694884   0.955  0.329744  0.354672   \n",
       "\n",
       "                                                Model  \n",
       "0   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "1   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "2   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "3   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "4   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "5   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "6   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "7   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "8   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "9   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "10  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "11  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "12  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "13  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "14  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "15  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "16  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "17  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "18  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "19  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "20  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "21  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "22  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "23  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "24  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "25  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "26  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "27  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "28  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "29  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "..                                                ...  \n",
       "70  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "71  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "72  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "73  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "74  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "75  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "76  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "77  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "78  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "79  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "80  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "81  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "82  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "83  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "84  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "85  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "86  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "87  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "88  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "89  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "90  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "91  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "92  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "93  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "94  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "95  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "96  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "97  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "98  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "99  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresDF = pd.DataFrame(scores, columns=[\"n-fold\", \n",
    "                                         \"Model Idx\",\n",
    "                                         \"Acc\", \n",
    "                                         \"Precision\", \n",
    "                                         \"Recall\",\n",
    "                                         \"Error\", \n",
    "                                         \"Alpha\", \n",
    "                                         \"Model\"])\n",
    "\n",
    "#scoresDF.sort_values([\"Acc\",\"Error\"], ascending=False)\n",
    "scoresDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = scoresDF.iloc[0, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_validation = bestModel.predict(validationData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[11 11]\n",
      " [ 5 15]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6190476190476191\n",
      "Misclassification rate : 0.077\n",
      "True positives : 0.75\n",
      "False positives : 0.5\n",
      "Specificity : 0.5\n",
      "Precision : 0.6348443223443223\n",
      "Prevalence : 0.096\n",
      "Recall : 0.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6190476190476191, 0.6348443223443223, 0.75)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printCM(validationLabels, pred_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-fold</th>\n",
       "      <th>Model Idx</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Error</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.284386</td>\n",
       "      <td>0.461404</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.824421</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.292199</td>\n",
       "      <td>0.442364</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.824421</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.234899</td>\n",
       "      <td>0.590425</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.272401</td>\n",
       "      <td>0.491237</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.823413</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.594792</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.783193</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.228188</td>\n",
       "      <td>0.609286</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.228188</td>\n",
       "      <td>0.609286</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.297824</td>\n",
       "      <td>0.428841</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.576340</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.613615</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.330460</td>\n",
       "      <td>0.353053</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.740642</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.313838</td>\n",
       "      <td>0.391119</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.716063</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.303256</td>\n",
       "      <td>0.415921</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.724599</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.221477</td>\n",
       "      <td>0.628541</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.346349</td>\n",
       "      <td>0.317564</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.312135</td>\n",
       "      <td>0.395080</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.679545</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.293168</td>\n",
       "      <td>0.440024</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.660504</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.322634</td>\n",
       "      <td>0.370846</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.748366</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.294620</td>\n",
       "      <td>0.436524</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.290704</td>\n",
       "      <td>0.445984</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.679739</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.288810</td>\n",
       "      <td>0.450586</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.221477</td>\n",
       "      <td>0.628541</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.400762</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.637821</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.299245</td>\n",
       "      <td>0.425449</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.275973</td>\n",
       "      <td>0.482263</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.620455</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.594792</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.307928</td>\n",
       "      <td>0.404911</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.306868</td>\n",
       "      <td>0.407402</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.592320</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.296351</td>\n",
       "      <td>0.432367</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.592320</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.255644</td>\n",
       "      <td>0.534366</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.659314</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.255102</td>\n",
       "      <td>0.535792</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.254514</td>\n",
       "      <td>0.537339</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.642157</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.249083</td>\n",
       "      <td>0.551754</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.572727</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.300834</td>\n",
       "      <td>0.421665</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.572727</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.265735</td>\n",
       "      <td>0.508186</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.550654</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.325932</td>\n",
       "      <td>0.363321</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.603361</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.324114</td>\n",
       "      <td>0.367464</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.579323</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.311132</td>\n",
       "      <td>0.397415</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.579323</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.307393</td>\n",
       "      <td>0.406167</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.486425</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.270961</td>\n",
       "      <td>0.494877</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.563725</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.268816</td>\n",
       "      <td>0.500319</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.798319</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.201342</td>\n",
       "      <td>0.688963</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.524510</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.317268</td>\n",
       "      <td>0.383179</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.325351</td>\n",
       "      <td>0.364645</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.668182</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.292650</td>\n",
       "      <td>0.441274</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.463542</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.277019</td>\n",
       "      <td>0.479649</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.302656</td>\n",
       "      <td>0.417340</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.308496</td>\n",
       "      <td>0.403580</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.300187</td>\n",
       "      <td>0.423204</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.432127</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.284734</td>\n",
       "      <td>0.460550</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n-fold  Model Idx       Acc  Precision  Recall     Error     Alpha  \\\n",
       "42       8          2  0.875000   0.875000   0.833  0.284386  0.461404   \n",
       "27       5          2  0.823529   0.824421   0.714  0.292199  0.442364   \n",
       "15       3          0  0.823529   0.824421   0.714  0.234899  0.590425   \n",
       "37       7          2  0.812500   0.892857   1.000  0.272401  0.491237   \n",
       "40       8          0  0.812500   0.823413   0.833  0.233333  0.594792   \n",
       "5        1          0  0.764706   0.783193   0.667  0.228188  0.609286   \n",
       "20       4          0  0.764706   0.764706   0.667  0.228188  0.609286   \n",
       "48       9          3  0.750000   0.750000   0.750  0.297824  0.428841   \n",
       "45       9          0  0.750000   0.766667   0.625  0.240000  0.576340   \n",
       "35       7          0  0.750000   0.800000   0.750  0.226667  0.613615   \n",
       "1        0          1  0.705882   0.774510   0.667  0.330460  0.353053   \n",
       "8        1          3  0.705882   0.740642   0.556  0.313838  0.391119   \n",
       "17       3          2  0.705882   0.716063   0.429  0.303256  0.415921   \n",
       "0        0          0  0.705882   0.724599   0.750  0.221477  0.628541   \n",
       "36       7          1  0.687500   0.550000   0.000  0.346349  0.317564   \n",
       "46       9          1  0.687500   0.690476   0.750  0.312135  0.395080   \n",
       "41       8          1  0.687500   0.679545   0.500  0.293168  0.440024   \n",
       "6        1          1  0.647059   0.660504   0.556  0.322634  0.370846   \n",
       "3        0          3  0.647059   0.748366   0.583  0.294620  0.436524   \n",
       "28       5          3  0.647059   0.647059   0.571  0.290704  0.445984   \n",
       "23       4          3  0.647059   0.679739   0.667  0.288810  0.450586   \n",
       "25       5          0  0.647059   0.647059   0.571  0.221477  0.628541   \n",
       "34       6          4  0.625000   0.625000   0.571  0.309700  0.400762   \n",
       "32       6          2  0.625000   0.637821   0.286  0.299245  0.425449   \n",
       "43       8          3  0.625000   0.708333   0.833  0.275973  0.482263   \n",
       "30       6          0  0.625000   0.620455   0.429  0.233333  0.594792   \n",
       "21       4          1  0.588235   0.572549   0.333  0.307928  0.404911   \n",
       "24       4          4  0.588235   0.809955   1.000  0.306868  0.407402   \n",
       "9        1          4  0.588235   0.592320   0.556  0.296351  0.432367   \n",
       "7        1          2  0.588235   0.592320   0.556  0.255644  0.534366   \n",
       "2        0          2  0.588235   0.659314   0.583  0.255102  0.535792   \n",
       "18       3          3  0.588235   0.676471   0.857  0.254514  0.537339   \n",
       "22       4          2  0.588235   0.642157   0.667  0.249083  0.551754   \n",
       "49       9          4  0.562500   0.572727   0.750  0.300834  0.421665   \n",
       "47       9          2  0.562500   0.572727   0.375  0.265735  0.508186   \n",
       "19       3          4  0.529412   0.550654   0.571  0.325932  0.363321   \n",
       "12       2          2  0.529412   0.603361   0.455  0.324114  0.367464   \n",
       "29       5          4  0.529412   0.579323   0.714  0.311132  0.397415   \n",
       "16       3          1  0.529412   0.579323   0.714  0.307393  0.406167   \n",
       "13       2          3  0.529412   0.486425   0.727  0.270961  0.494877   \n",
       "14       2          4  0.529412   0.563725   0.545  0.268816  0.500319   \n",
       "10       2          0  0.529412   0.798319   0.273  0.201342  0.688963   \n",
       "26       5          1  0.470588   0.524510   0.714  0.317268  0.383179   \n",
       "44       8          4  0.437500   0.775000   1.000  0.325351  0.364645   \n",
       "39       7          4  0.437500   0.668182   0.750  0.292650  0.441274   \n",
       "31       6          1  0.437500   0.463542   0.714  0.277019  0.479649   \n",
       "4        0          4  0.411765   0.411765   0.583  0.302656  0.417340   \n",
       "38       7          3  0.375000   0.500000   0.250  0.308496  0.403580   \n",
       "33       6          3  0.375000   0.175000   0.857  0.300187  0.423204   \n",
       "11       2          1  0.352941   0.432127   0.182  0.284734  0.460550   \n",
       "\n",
       "                                                Model  \n",
       "42  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "27  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "15  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "37  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "40  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "5   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "20  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "48  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "45  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "35  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "1   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "8   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "17  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "0   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "36  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "46  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "41  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "6   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "3   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "28  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "23  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "25  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "34  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "32  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "43  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "30  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "21  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "24  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "9   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "7   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "2   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "18  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "22  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "49  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "47  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "19  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "12  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "29  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "16  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "13  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "14  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "10  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "26  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "44  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "39  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "31  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "4   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "38  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "33  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "11  DecisionTreeClassifier(class_weight=None, crit...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresDF = pd.DataFrame(scores_test, columns=[\"n-fold\", \n",
    "                                         \"Model Idx\",\n",
    "                                         \"Acc\", \n",
    "                                         \"Precision\", \n",
    "                                         \"Recall\",\n",
    "                                         \"Error\", \n",
    "                                         \"Alpha\", \n",
    "                                         \"Model\"])\n",
    "\n",
    "scoresDF.sort_values([\"Acc\",\"Error\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
