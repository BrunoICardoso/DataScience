{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 1 - Machine Learning II \n",
    "Prof: Carlos Padilha\n",
    "\n",
    "#### Alunos:  \n",
    "\n",
    "Roberto A. Coutinho  \n",
    "Thais Galho\n",
    "\n",
    "\n",
    "## Sistemas com Multi-classificadores ou Ensembles\n",
    "\n",
    "#### Este trabalho visa avaliar o entendimento em relaçãao á construção de sistemas com multi-classificadores ou ensembles. Para tal, os alunos deverão fazer o seguinte:\n",
    "\n",
    "\n",
    "* Implementar o algoritmo AdaBoost (nos mesmos moldes que fizemos com o algoritmo Bagging).\n",
    "    – Podem escolher qualquer tipo de classificador (MLP, SVM, etc).\n",
    "* Processar os dados presente no arquivo sonar.all-data.\n",
    "* Realizar treinamento e teste usando validação cruzada com 10 folds.\n",
    "* Avaliar os resultados em termos de acurácia, recall e precisão.\n",
    "\n",
    "Obs: O trabalho pode ser feito em dupla e deve ser enviado por email (carlos.engcomp@gmail.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modelos\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# K-fold CrossValidation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.0709</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.1918</td>\n",
       "      <td>0.3362</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1088</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.1948</td>\n",
       "      <td>0.4262</td>\n",
       "      <td>0.6828</td>\n",
       "      <td>0.5761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.1606</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.3061</td>\n",
       "      <td>0.2936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.1117</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.0997</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.2227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>0.1693</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.1583</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0477</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.1664</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.0804</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.1117</td>\n",
       "      <td>0.2984</td>\n",
       "      <td>0.3473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0578</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.0873</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.1563</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.2002</td>\n",
       "      <td>0.2876</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.1997</td>\n",
       "      <td>0.2604</td>\n",
       "      <td>0.3225</td>\n",
       "      <td>0.2247</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.2287</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.0740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0724</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.2103</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.2524</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.1163</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.2417</td>\n",
       "      <td>0.2661</td>\n",
       "      <td>0.4346</td>\n",
       "      <td>0.5378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.1972</td>\n",
       "      <td>0.1873</td>\n",
       "      <td>0.1806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.1627</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>0.2696</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.1048</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.0780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1058</td>\n",
       "      <td>0.1023</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.1795</td>\n",
       "      <td>0.1909</td>\n",
       "      <td>0.1692</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.1725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0654</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>0.2482</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.0989</td>\n",
       "      <td>0.2460</td>\n",
       "      <td>0.3422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.1493</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.1977</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.0759</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.1883</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.0554</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.2707</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>0.4117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.1161</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.1738</td>\n",
       "      <td>0.1351</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>0.3887</td>\n",
       "      <td>0.7106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0507</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.3823</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>0.3429</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.1515</td>\n",
       "      <td>0.2134</td>\n",
       "      <td>0.2613</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.2718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.0989</td>\n",
       "      <td>0.1093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.1164</td>\n",
       "      <td>0.1398</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.2795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.2770</td>\n",
       "      <td>0.2555</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.4110</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.5920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1384</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.0962</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1409</td>\n",
       "      <td>0.1916</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6       7       8   \\\n",
       "0   0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "1   0.0635  0.0709  0.0453  0.0333  0.0185  0.1260  0.1015  0.1918  0.3362   \n",
       "2   0.1088  0.1278  0.0926  0.1234  0.1276  0.1731  0.1948  0.4262  0.6828   \n",
       "3   0.0107  0.0453  0.0289  0.0713  0.1075  0.1019  0.1606  0.2119  0.3061   \n",
       "4   0.0228  0.0106  0.0130  0.0842  0.1117  0.1506  0.1776  0.0997  0.1428   \n",
       "5   0.0707  0.1252  0.1447  0.1644  0.1693  0.0844  0.0715  0.0947  0.1583   \n",
       "6   0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "7   0.0442  0.0477  0.0049  0.0581  0.0278  0.0678  0.1664  0.1490  0.0974   \n",
       "8   0.0336  0.0294  0.0476  0.0539  0.0794  0.0804  0.1136  0.1228  0.1235   \n",
       "9   0.0294  0.0123  0.0117  0.0113  0.0497  0.0998  0.1326  0.1117  0.2984   \n",
       "10  0.0197  0.0394  0.0384  0.0076  0.0251  0.0629  0.0747  0.0578  0.1357   \n",
       "11  0.0125  0.0152  0.0218  0.0175  0.0362  0.0696  0.0873  0.0616  0.1252   \n",
       "12  0.0211  0.0128  0.0015  0.0450  0.0711  0.1563  0.1518  0.1206  0.1666   \n",
       "13  0.0235  0.0291  0.0749  0.0519  0.0227  0.0834  0.0677  0.2002  0.2876   \n",
       "14  0.0530  0.0885  0.1997  0.2604  0.3225  0.2247  0.0617  0.2287  0.0950   \n",
       "15  0.0201  0.0178  0.0274  0.0232  0.0724  0.0833  0.1232  0.1298  0.2085   \n",
       "16  0.0269  0.0383  0.0505  0.0707  0.1313  0.2103  0.2263  0.2524  0.3595   \n",
       "17  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "18  0.1150  0.1163  0.0866  0.0358  0.0232  0.1267  0.2417  0.2661  0.4346   \n",
       "19  0.0188  0.0370  0.0953  0.0824  0.0249  0.0488  0.1424  0.1972  0.1873   \n",
       "20  0.0299  0.0688  0.0992  0.1021  0.0800  0.0629  0.0130  0.0813  0.1761   \n",
       "21  0.0100  0.0194  0.0155  0.0489  0.0839  0.1009  0.1627  0.2071  0.2696   \n",
       "22  0.0164  0.0627  0.0738  0.0608  0.0233  0.1048  0.1338  0.0644  0.1522   \n",
       "23  0.0115  0.0150  0.0136  0.0076  0.0211  0.1058  0.1023  0.0440  0.0931   \n",
       "24  0.0094  0.0333  0.0306  0.0376  0.1296  0.1795  0.1909  0.1692  0.1870   \n",
       "25  0.0654  0.0649  0.0737  0.1132  0.2482  0.1257  0.1797  0.0989  0.2460   \n",
       "26  0.0454  0.0472  0.0697  0.1021  0.1397  0.1493  0.1487  0.0771  0.1171   \n",
       "27  0.0050  0.0017  0.0270  0.0450  0.0958  0.0830  0.0879  0.1220  0.1977   \n",
       "28  0.0333  0.0221  0.0270  0.0481  0.0679  0.0981  0.0843  0.1172  0.0759   \n",
       "29  0.0119  0.0582  0.0623  0.0600  0.1397  0.1883  0.1422  0.1447  0.0487   \n",
       "30  0.0201  0.0423  0.0554  0.0783  0.0620  0.0871  0.1201  0.2707  0.1206   \n",
       "31  0.0340  0.0625  0.0381  0.0257  0.0441  0.1027  0.1287  0.1850  0.2647   \n",
       "32  0.0353  0.0713  0.0326  0.0272  0.0370  0.0792  0.1083  0.0687  0.0298   \n",
       "33  0.0368  0.0403  0.0317  0.0293  0.0820  0.1342  0.1161  0.0663  0.0155   \n",
       "34  0.0231  0.0351  0.0030  0.0304  0.0339  0.0860  0.1738  0.1351  0.1063   \n",
       "35  0.0430  0.0902  0.0833  0.0813  0.0165  0.0277  0.0569  0.2057  0.3887   \n",
       "36  0.0253  0.0808  0.0507  0.0244  0.1724  0.3823  0.3729  0.3583  0.3429   \n",
       "37  0.0311  0.0491  0.0692  0.0831  0.0079  0.0200  0.0981  0.1016  0.2025   \n",
       "38  0.0388  0.0324  0.0688  0.0898  0.1267  0.1515  0.2134  0.2613  0.2832   \n",
       "39  0.0208  0.0186  0.0131  0.0211  0.0610  0.0613  0.0612  0.0506  0.0989   \n",
       "40  0.0217  0.0340  0.0392  0.0236  0.1081  0.1164  0.1398  0.1009  0.1147   \n",
       "41  0.0308  0.0339  0.0202  0.0889  0.1570  0.1750  0.0920  0.1353  0.1593   \n",
       "42  0.0731  0.1249  0.1665  0.1496  0.1443  0.2770  0.2555  0.1712  0.0466   \n",
       "43  0.0126  0.0149  0.0641  0.1732  0.2565  0.2559  0.2947  0.4110  0.4983   \n",
       "44  0.0526  0.0563  0.1219  0.1206  0.0246  0.1022  0.0539  0.0439  0.2291   \n",
       "45  0.0260  0.0192  0.0254  0.0061  0.0352  0.0701  0.1263  0.1080  0.1523   \n",
       "46  0.0239  0.0189  0.0466  0.0440  0.0657  0.0742  0.1380  0.1099  0.1384   \n",
       "47  0.0164  0.0173  0.0347  0.0070  0.0187  0.0671  0.1056  0.0697  0.0962   \n",
       "48  0.0363  0.0478  0.0298  0.0210  0.1409  0.1916  0.1349  0.1613  0.1703   \n",
       "49  0.0109  0.0093  0.0121  0.0378  0.0679  0.0863  0.1004  0.0664  0.0941   \n",
       "\n",
       "        9  ...      51      52      53      54      55      56      57  \\\n",
       "0   0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "1   0.3900 ...  0.0048  0.0025  0.0087  0.0072  0.0095  0.0086  0.0085   \n",
       "2   0.5761 ...  0.0455  0.0213  0.0082  0.0124  0.0167  0.0103  0.0205   \n",
       "3   0.2936 ...  0.0164  0.0120  0.0113  0.0021  0.0097  0.0072  0.0060   \n",
       "4   0.2227 ...  0.0098  0.0178  0.0077  0.0074  0.0095  0.0055  0.0045   \n",
       "5   0.1247 ...  0.0156  0.0197  0.0135  0.0127  0.0138  0.0133  0.0131   \n",
       "6   0.2154 ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "7   0.1268 ...  0.0204  0.0216  0.0135  0.0055  0.0073  0.0080  0.0105   \n",
       "8   0.0842 ...  0.0150  0.0111  0.0032  0.0035  0.0169  0.0137  0.0015   \n",
       "9   0.3473 ...  0.0056  0.0104  0.0079  0.0014  0.0054  0.0015  0.0006   \n",
       "10  0.1695 ...  0.0134  0.0097  0.0042  0.0058  0.0072  0.0041  0.0045   \n",
       "11  0.1302 ...  0.0041  0.0074  0.0030  0.0050  0.0048  0.0017  0.0041   \n",
       "12  0.1345 ...  0.0117  0.0023  0.0047  0.0049  0.0031  0.0024  0.0039   \n",
       "13  0.3674 ...  0.0083  0.0037  0.0095  0.0105  0.0030  0.0132  0.0068   \n",
       "14  0.0740 ...  0.0244  0.0199  0.0257  0.0082  0.0151  0.0171  0.0146   \n",
       "15  0.2720 ...  0.0131  0.0049  0.0104  0.0102  0.0092  0.0083  0.0020   \n",
       "16  0.5915 ...  0.0167  0.0199  0.0145  0.0081  0.0045  0.0043  0.0027   \n",
       "17  0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "18  0.5378 ...  0.0099  0.0065  0.0085  0.0166  0.0110  0.0190  0.0141   \n",
       "19  0.1806 ...  0.0093  0.0033  0.0113  0.0030  0.0057  0.0090  0.0057   \n",
       "20  0.0998 ...  0.0459  0.0277  0.0172  0.0087  0.0046  0.0203  0.0130   \n",
       "21  0.2990 ...  0.0130  0.0073  0.0077  0.0075  0.0060  0.0080  0.0019   \n",
       "22  0.0780 ...  0.0258  0.0143  0.0226  0.0187  0.0185  0.0110  0.0094   \n",
       "23  0.0734 ...  0.0091  0.0016  0.0084  0.0064  0.0026  0.0029  0.0037   \n",
       "24  0.1725 ...  0.0153  0.0112  0.0241  0.0164  0.0055  0.0078  0.0055   \n",
       "25  0.3422 ...  0.0210  0.0361  0.0239  0.0447  0.0394  0.0355  0.0440   \n",
       "26  0.1675 ...  0.0120  0.0042  0.0238  0.0129  0.0084  0.0218  0.0321   \n",
       "27  0.2282 ...  0.0165  0.0056  0.0010  0.0027  0.0062  0.0024  0.0063   \n",
       "28  0.0920 ...  0.0022  0.0032  0.0060  0.0054  0.0063  0.0143  0.0132   \n",
       "29  0.0864 ...  0.0025  0.0103  0.0074  0.0123  0.0069  0.0076  0.0073   \n",
       "30  0.0279 ...  0.0191  0.0182  0.0160  0.0290  0.0090  0.0242  0.0224   \n",
       "31  0.4117 ...  0.0141  0.0019  0.0067  0.0099  0.0042  0.0057  0.0051   \n",
       "32  0.0880 ...  0.0163  0.0242  0.0043  0.0202  0.0108  0.0037  0.0096   \n",
       "33  0.0506 ...  0.0091  0.0160  0.0160  0.0081  0.0070  0.0135  0.0067   \n",
       "34  0.0347 ...  0.0106  0.0097  0.0022  0.0052  0.0072  0.0056  0.0038   \n",
       "35  0.7106 ...  0.0176  0.0197  0.0210  0.0141  0.0049  0.0027  0.0162   \n",
       "36  0.2197 ...  0.0178  0.0073  0.0079  0.0038  0.0116  0.0033  0.0039   \n",
       "37  0.0767 ...  0.0087  0.0032  0.0130  0.0188  0.0101  0.0229  0.0182   \n",
       "38  0.2718 ...  0.0255  0.0071  0.0263  0.0079  0.0111  0.0107  0.0068   \n",
       "39  0.1093 ...  0.0074  0.0063  0.0081  0.0087  0.0044  0.0028  0.0019   \n",
       "40  0.1777 ...  0.0031  0.0103  0.0078  0.0077  0.0094  0.0031  0.0030   \n",
       "41  0.2795 ...  0.0167  0.0127  0.0138  0.0090  0.0051  0.0029  0.0122   \n",
       "42  0.1114 ...  0.0444  0.0230  0.0290  0.0141  0.0161  0.0177  0.0194   \n",
       "43  0.5920 ...  0.0092  0.0035  0.0098  0.0121  0.0006  0.0181  0.0094   \n",
       "44  0.1632 ...  0.0339  0.0149  0.0335  0.0376  0.0174  0.0132  0.0103   \n",
       "45  0.1630 ...  0.0118  0.0120  0.0051  0.0070  0.0015  0.0035  0.0008   \n",
       "46  0.1376 ...  0.0091  0.0151  0.0080  0.0018  0.0078  0.0045  0.0026   \n",
       "47  0.0251 ...  0.0090  0.0223  0.0179  0.0084  0.0068  0.0032  0.0035   \n",
       "48  0.1444 ...  0.0115  0.0190  0.0055  0.0096  0.0050  0.0066  0.0114   \n",
       "49  0.1036 ...  0.0077  0.0023  0.0117  0.0053  0.0077  0.0076  0.0056   \n",
       "\n",
       "        58      59  60  \n",
       "0   0.0040  0.0117   1  \n",
       "1   0.0040  0.0051   0  \n",
       "2   0.0178  0.0187   0  \n",
       "3   0.0017  0.0036   0  \n",
       "4   0.0063  0.0039   0  \n",
       "5   0.0154  0.0218   0  \n",
       "6   0.0062  0.0067   0  \n",
       "7   0.0059  0.0105   1  \n",
       "8   0.0069  0.0051   1  \n",
       "9   0.0081  0.0043   0  \n",
       "10  0.0047  0.0054   0  \n",
       "11  0.0086  0.0058   1  \n",
       "12  0.0051  0.0015   0  \n",
       "13  0.0108  0.0090   1  \n",
       "14  0.0134  0.0056   0  \n",
       "15  0.0048  0.0036   0  \n",
       "16  0.0055  0.0057   0  \n",
       "17  0.0090  0.0032   1  \n",
       "18  0.0068  0.0086   0  \n",
       "19  0.0068  0.0024   1  \n",
       "20  0.0115  0.0015   0  \n",
       "21  0.0053  0.0019   1  \n",
       "22  0.0078  0.0112   0  \n",
       "23  0.0070  0.0041   1  \n",
       "24  0.0091  0.0067   0  \n",
       "25  0.0243  0.0098   0  \n",
       "26  0.0154  0.0053   0  \n",
       "27  0.0017  0.0028   0  \n",
       "28  0.0051  0.0041   1  \n",
       "29  0.0030  0.0138   1  \n",
       "30  0.0190  0.0096   0  \n",
       "31  0.0033  0.0058   0  \n",
       "32  0.0093  0.0053   1  \n",
       "33  0.0078  0.0068   1  \n",
       "34  0.0043  0.0030   1  \n",
       "35  0.0059  0.0021   0  \n",
       "36  0.0081  0.0053   1  \n",
       "37  0.0046  0.0038   1  \n",
       "38  0.0097  0.0067   0  \n",
       "39  0.0049  0.0023   1  \n",
       "40  0.0013  0.0069   1  \n",
       "41  0.0056  0.0020   1  \n",
       "42  0.0207  0.0057   0  \n",
       "43  0.0116  0.0063   1  \n",
       "44  0.0364  0.0208   0  \n",
       "45  0.0044  0.0077   1  \n",
       "46  0.0036  0.0024   1  \n",
       "47  0.0056  0.0040   1  \n",
       "48  0.0073  0.0033   0  \n",
       "49  0.0055  0.0039   1  \n",
       "\n",
       "[50 rows x 61 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_data = pd.read_csv('sonar.all-data.csv', header=None)\n",
    "\n",
    "imported_data.iloc[:,-1] = imported_data.iloc[:,-1].astype('category')\n",
    "categories = imported_data.select_dtypes(['category']).columns\n",
    "imported_data[categories] = imported_data[categories].apply(lambda x:x.cat.codes) \n",
    "\n",
    "imported_data = imported_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "imported_data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 208)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# Separação entre dados e labels\n",
    "\n",
    "labels = imported_data.iloc[:,-1]\n",
    "\n",
    "data = imported_data.iloc[:,:-1]\n",
    "len(data), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "def printCM(Y_test, predictions):\n",
    "    cm = confusion_matrix(Y_test, predictions)\n",
    "    acc_score = accuracy_score(Y_test, predictions)\n",
    "    prec_score = precision_score(Y_test, predictions, average='weighted')\n",
    "    \n",
    "    print ('Confusion Matrix : ')\n",
    "    print (cm)\n",
    "    print\n",
    "    \n",
    "    tn = float(cm[0][0])\n",
    "    fp = float(cm[0][1])\n",
    "    fn = float(cm[1][0])\n",
    "    tp = float(cm[1][1])\n",
    "\n",
    "    actual_yes = fn+tp\n",
    "    actual_no = tn+fp\n",
    "    predicted_yes = fp+tp\n",
    "    predicted_no = tn+fn\n",
    "\n",
    "    total = float(len(imported_data))\n",
    "    print ('Total : '+ str(total))\n",
    "\n",
    "    print ('Acurácia : ' + str(acc_score))\n",
    "\n",
    "    misclassification_rate = round((fp+fn)/total,3) # Overall, how often is it wrong?\n",
    "    print ('Misclassification rate : ' +str(misclassification_rate))\n",
    "\n",
    "    true_positive = round(tp/actual_yes,3) # When it's actually yes, how often does it predict yes?\n",
    "    print ('True positives : ' +str(true_positive))\n",
    "\n",
    "    false_positive = round(fp/actual_no,3) # When it's actually no, how often does it predict yes?\n",
    "    print ('False positives : ' +str(false_positive))\n",
    "\n",
    "    specificity = round(tn/actual_no,3) # When it's actually no, how often does it predict no?\n",
    "    print ('Specificity : ' +str(specificity))\n",
    "\n",
    "    #precision = round(tp/predicted_yes,3) # When it predicts yes, how often is it correct?\n",
    "    print ('Precision : ' +str(prec_score))\n",
    "\n",
    "    prevalence = round(actual_yes/total,3) # How often does the yes condition actually occur in our sample?\n",
    "    print ('Prevalence : ' +str(prevalence))\n",
    "    \n",
    "    recall = round(tp / (tp + fn), 3)\n",
    "    print ('Recall : ' +str(recall))\n",
    "\n",
    "    #f1 = round(2 * ((precision * true_positive) / (precision + true_positive)),3)\n",
    "    #print ('F1 Score : ' +str(f1))\n",
    "    \n",
    "    return acc_score, prec_score, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Separação entre treino e teste</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 166\n",
      "42 42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# utiliza 25% do dataset para teste\n",
    "trainData, validationData, trainLabels, validationLabels = train_test_split(data, labels, \n",
    "                                                    train_size=0.8, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=labels,\n",
    "                                                    random_state=43)\n",
    "\n",
    "print(len(trainData), len(trainLabels))\n",
    "print(len(validationData), len(validationLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....Iniciando treinamento com 10 K-folds....\n",
      "\n",
      "################################################\n",
      "K-fold : 1\n",
      "################################################\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.23489932885906067\n",
      "Alpha : 0.5904251934525402\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[67 12]\n",
      " [23 47]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7651006711409396\n",
      "Misclassification rate : 0.168\n",
      "True positives : 0.671\n",
      "False positives : 0.152\n",
      "Specificity : 0.848\n",
      "Precision : 0.7689518320504556\n",
      "Prevalence : 0.337\n",
      "Recall : 0.671\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 3]\n",
      " [2 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7058823529411765\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.714\n",
      "False positives : 0.3\n",
      "Specificity : 0.7\n",
      "Precision : 0.7148692810457516\n",
      "Prevalence : 0.034\n",
      "Recall : 0.714\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00371874 0.01211245 0.01211245 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.01211245 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874 0.01211245\n",
      " 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.01211245 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.01211245 0.00371874 0.01211245 0.01211245 0.01211245 0.00371874\n",
      " 0.01211245 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.01211245 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.00371874 0.01211245 0.00371874 0.00371874\n",
      " 0.01211245 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.00371874 0.01211245 0.00371874 0.00371874\n",
      " 0.01211245 0.00371874 0.01211245 0.01211245 0.00371874 0.01211245\n",
      " 0.00371874 0.00371874 0.01211245 0.01211245 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.00371874 0.00371874 0.01211245 0.01211245\n",
      " 0.00371874 0.00371874 0.01211245 0.00371874 0.01211245 0.00371874\n",
      " 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.01211245 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874 0.01211245\n",
      " 0.01211245 0.00371874 0.00371874 0.01211245 0.00371874 0.01211245\n",
      " 0.00371874 0.00371874 0.01211245 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874 0.01211245\n",
      " 0.00371874 0.01211245 0.00371874 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.00371874 0.01211245 0.00371874 0.00371874 0.00371874\n",
      " 0.00371874 0.01211245 0.00371874 0.00371874 0.00371874 0.01211245\n",
      " 0.00371874 0.00371874 0.00371874 0.00371874 0.00371874]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.33032581453634086\n",
      "Alpha : 0.3533559097970419\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[27 52]\n",
      " [ 3 67]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6308724832214765\n",
      "Misclassification rate : 0.264\n",
      "True positives : 0.957\n",
      "False positives : 0.658\n",
      "Specificity : 0.342\n",
      "Precision : 0.7416896960126333\n",
      "Prevalence : 0.337\n",
      "Recall : 0.957\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 7]\n",
      " [2 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.47058823529411764\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.714\n",
      "False positives : 0.7\n",
      "Specificity : 0.3\n",
      "Precision : 0.5245098039215687\n",
      "Prevalence : 0.034\n",
      "Recall : 0.714\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00261177 0.00850691 0.01724617 0.00529488 0.00529488 0.00261177\n",
      " 0.00261177 0.00529488 0.00850691 0.00261177 0.00529488 0.00529488\n",
      " 0.00261177 0.00261177 0.00529488 0.00529488 0.00261177 0.00850691\n",
      " 0.00529488 0.00261177 0.00261177 0.00261177 0.00261177 0.00261177\n",
      " 0.00529488 0.00850691 0.00261177 0.00261177 0.00529488 0.00261177\n",
      " 0.00850691 0.00261177 0.00850691 0.00850691 0.01724617 0.00261177\n",
      " 0.00850691 0.00261177 0.00529488 0.00529488 0.00261177 0.00261177\n",
      " 0.00850691 0.00529488 0.00261177 0.00261177 0.00529488 0.00261177\n",
      " 0.00529488 0.00261177 0.00261177 0.01724617 0.00261177 0.00261177\n",
      " 0.01724617 0.00261177 0.00261177 0.00529488 0.00529488 0.00529488\n",
      " 0.00529488 0.00261177 0.00529488 0.00850691 0.00261177 0.00529488\n",
      " 0.00850691 0.00261177 0.01724617 0.00850691 0.00529488 0.00850691\n",
      " 0.00261177 0.00261177 0.00850691 0.00850691 0.00261177 0.00529488\n",
      " 0.00261177 0.00261177 0.00261177 0.00529488 0.00850691 0.01724617\n",
      " 0.00529488 0.00529488 0.00850691 0.00529488 0.00850691 0.00261177\n",
      " 0.00261177 0.00261177 0.00529488 0.00529488 0.00261177 0.00529488\n",
      " 0.00850691 0.00261177 0.00261177 0.00529488 0.00529488 0.00529488\n",
      " 0.00261177 0.00529488 0.00529488 0.00261177 0.00261177 0.01724617\n",
      " 0.00850691 0.00529488 0.00261177 0.00850691 0.00261177 0.00850691\n",
      " 0.00261177 0.00529488 0.01724617 0.00529488 0.00261177 0.00529488\n",
      " 0.00261177 0.00261177 0.00261177 0.00529488 0.00529488 0.00850691\n",
      " 0.00261177 0.01724617 0.00529488 0.00261177 0.00261177 0.00261177\n",
      " 0.00529488 0.00261177 0.00850691 0.00261177 0.00261177 0.00261177\n",
      " 0.00261177 0.00850691 0.00261177 0.00529488 0.00261177 0.00850691\n",
      " 0.00261177 0.00261177 0.00529488 0.00261177 0.00529488]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.26916391988405547\n",
      "Alpha : 0.4994343161925587\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[64 15]\n",
      " [36 34]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6577181208053692\n",
      "Misclassification rate : 0.245\n",
      "True positives : 0.486\n",
      "False positives : 0.19\n",
      "Specificity : 0.81\n",
      "Precision : 0.6653116011505273\n",
      "Prevalence : 0.337\n",
      "Recall : 0.486\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 3]\n",
      " [3 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.571\n",
      "False positives : 0.3\n",
      "Specificity : 0.7\n",
      "Precision : 0.6470588235294118\n",
      "Prevalence : 0.034\n",
      "Recall : 0.571\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00158501 0.00516262 0.01046625 0.00321332 0.00321332 0.00158501\n",
      " 0.00158501 0.00321332 0.01401758 0.00158501 0.00321332 0.00321332\n",
      " 0.00430364 0.00430364 0.00321332 0.00321332 0.00430364 0.01401758\n",
      " 0.00321332 0.00430364 0.00158501 0.00158501 0.00158501 0.00158501\n",
      " 0.00872484 0.00516262 0.00158501 0.00158501 0.00321332 0.00158501\n",
      " 0.00516262 0.00430364 0.01401758 0.00516262 0.01046625 0.00430364\n",
      " 0.01401758 0.00158501 0.00321332 0.00321332 0.00430364 0.00430364\n",
      " 0.00516262 0.00321332 0.00158501 0.00158501 0.00321332 0.00430364\n",
      " 0.00321332 0.00430364 0.00430364 0.01046625 0.00158501 0.00158501\n",
      " 0.01046625 0.00430364 0.00430364 0.00321332 0.00321332 0.00321332\n",
      " 0.00321332 0.00430364 0.00321332 0.00516262 0.00430364 0.00321332\n",
      " 0.00516262 0.00430364 0.01046625 0.00516262 0.00321332 0.01401758\n",
      " 0.00430364 0.00158501 0.01401758 0.00516262 0.00430364 0.00321332\n",
      " 0.00158501 0.00430364 0.00430364 0.00321332 0.00516262 0.01046625\n",
      " 0.00321332 0.00321332 0.00516262 0.00321332 0.00516262 0.00158501\n",
      " 0.00158501 0.00158501 0.00872484 0.00321332 0.00430364 0.00321332\n",
      " 0.01401758 0.00430364 0.00430364 0.00872484 0.00321332 0.00321332\n",
      " 0.00430364 0.00321332 0.00321332 0.00158501 0.00430364 0.01046625\n",
      " 0.00516262 0.00321332 0.00158501 0.01401758 0.00430364 0.01401758\n",
      " 0.00158501 0.00321332 0.01046625 0.00321332 0.00158501 0.00321332\n",
      " 0.00430364 0.00430364 0.00158501 0.00321332 0.00321332 0.01401758\n",
      " 0.00430364 0.01046625 0.00321332 0.00158501 0.00158501 0.00158501\n",
      " 0.00872484 0.00158501 0.01401758 0.00158501 0.00430364 0.00430364\n",
      " 0.00158501 0.00516262 0.00158501 0.00321332 0.00430364 0.01401758\n",
      " 0.00430364 0.00430364 0.00321332 0.00430364 0.00321332]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.32960639871747777\n",
      "Alpha : 0.3549828965322788\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[73  6]\n",
      " [53 17]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6040268456375839\n",
      "Misclassification rate : 0.284\n",
      "True positives : 0.243\n",
      "False positives : 0.076\n",
      "Specificity : 0.924\n",
      "Precision : 0.6544226288900932\n",
      "Prevalence : 0.337\n",
      "Recall : 0.243\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[10  0]\n",
      " [ 6  1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.143\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 0.7794117647058824\n",
      "Prevalence : 0.034\n",
      "Recall : 0.143\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00111139 0.0073627  0.00733878 0.00225313 0.00225313 0.00226048\n",
      " 0.00226048 0.0045827  0.00982893 0.00226048 0.00225313 0.00225313\n",
      " 0.00301765 0.00613767 0.00225313 0.00225313 0.00613767 0.01999127\n",
      " 0.00225313 0.00301765 0.00226048 0.00226048 0.00226048 0.00226048\n",
      " 0.00611773 0.0073627  0.00226048 0.00226048 0.0045827  0.00226048\n",
      " 0.00361995 0.00613767 0.00982893 0.0073627  0.00733878 0.00613767\n",
      " 0.00982893 0.00111139 0.00225313 0.00225313 0.00613767 0.00301765\n",
      " 0.00361995 0.0045827  0.00111139 0.00226048 0.0045827  0.00613767\n",
      " 0.00225313 0.00301765 0.00301765 0.00733878 0.00111139 0.00226048\n",
      " 0.00733878 0.00613767 0.00301765 0.00225313 0.00225313 0.00225313\n",
      " 0.00225313 0.00301765 0.00225313 0.00361995 0.00613767 0.00225313\n",
      " 0.0073627  0.00301765 0.00733878 0.00361995 0.00225313 0.00982893\n",
      " 0.00613767 0.00111139 0.00982893 0.0073627  0.00301765 0.00225313\n",
      " 0.00111139 0.00613767 0.00301765 0.00225313 0.00361995 0.00733878\n",
      " 0.00225313 0.00225313 0.00361995 0.00225313 0.0073627  0.00111139\n",
      " 0.00226048 0.00226048 0.01244298 0.00225313 0.00613767 0.00225313\n",
      " 0.01999127 0.00613767 0.00301765 0.00611773 0.00225313 0.0045827\n",
      " 0.00301765 0.00225313 0.00225313 0.00226048 0.00613767 0.00733878\n",
      " 0.0073627  0.00225313 0.00111139 0.00982893 0.00613767 0.00982893\n",
      " 0.00226048 0.00225313 0.00733878 0.00225313 0.00226048 0.00225313\n",
      " 0.00301765 0.00301765 0.00226048 0.00225313 0.0045827  0.00982893\n",
      " 0.00613767 0.00733878 0.00225313 0.00111139 0.00111139 0.00111139\n",
      " 0.01244298 0.00226048 0.01999127 0.00226048 0.00301765 0.00613767\n",
      " 0.00226048 0.00361995 0.00111139 0.00225313 0.00613767 0.00982893\n",
      " 0.00301765 0.00613767 0.00225313 0.00613767 0.0045827 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2688210741082501\n",
      "Alpha : 0.5003060960922129\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[36 43]\n",
      " [10 60]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6442953020134228\n",
      "Misclassification rate : 0.255\n",
      "True positives : 0.857\n",
      "False positives : 0.544\n",
      "Specificity : 0.456\n",
      "Precision : 0.6886093019171003\n",
      "Prevalence : 0.337\n",
      "Recall : 0.857\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 6]\n",
      " [2 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5294117647058824\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.714\n",
      "False positives : 0.6\n",
      "Specificity : 0.4\n",
      "Precision : 0.5793226381461675\n",
      "Prevalence : 0.034\n",
      "Recall : 0.714\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00183293 0.00446434 0.00444983 0.00371593 0.00136618 0.00137063\n",
      " 0.00137063 0.0027787  0.00595972 0.00137063 0.00136618 0.00371593\n",
      " 0.00497679 0.00372155 0.00371593 0.00136618 0.00372155 0.0121216\n",
      " 0.00371593 0.00497679 0.00137063 0.00137063 0.00137063 0.00137063\n",
      " 0.00370946 0.00446434 0.00137063 0.00137063 0.0027787  0.00137063\n",
      " 0.00219494 0.00372155 0.00595972 0.00446434 0.00444983 0.00372155\n",
      " 0.00595972 0.00183293 0.00371593 0.00136618 0.00372155 0.00182974\n",
      " 0.00597012 0.0027787  0.00183293 0.00372804 0.00755791 0.00372155\n",
      " 0.00371593 0.00182974 0.00497679 0.00444983 0.00067389 0.00137063\n",
      " 0.00444983 0.00372155 0.00182974 0.00371593 0.00371593 0.00371593\n",
      " 0.00136618 0.00182974 0.00371593 0.00219494 0.00372155 0.00136618\n",
      " 0.00446434 0.00182974 0.01210331 0.00597012 0.00136618 0.01621012\n",
      " 0.0101224  0.00183293 0.00595972 0.00446434 0.00182974 0.00371593\n",
      " 0.00067389 0.00372155 0.00182974 0.00371593 0.00219494 0.00444983\n",
      " 0.00371593 0.00136618 0.00597012 0.00136618 0.01214276 0.00067389\n",
      " 0.00137063 0.00372804 0.00754474 0.00136618 0.00372155 0.00136618\n",
      " 0.0121216  0.00372155 0.00182974 0.00370946 0.00371593 0.00755791\n",
      " 0.00497679 0.00371593 0.00371593 0.00137063 0.00372155 0.01210331\n",
      " 0.00446434 0.00371593 0.00183293 0.01621012 0.00372155 0.00595972\n",
      " 0.00137063 0.00136618 0.00444983 0.00371593 0.00137063 0.00371593\n",
      " 0.00497679 0.00182974 0.00137063 0.00371593 0.0027787  0.01621012\n",
      " 0.00372155 0.01210331 0.00371593 0.00183293 0.00067389 0.00183293\n",
      " 0.00754474 0.00137063 0.0121216  0.00137063 0.00182974 0.00372155\n",
      " 0.00137063 0.00597012 0.00183293 0.00371593 0.00372155 0.01621012\n",
      " 0.00182974 0.00372155 0.00371593 0.00372155 0.0027787 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 2\n",
      "################################################\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.24832214765100702\n",
      "Alpha : 0.5537904793254342\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[68 11]\n",
      " [26 44]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7516778523489933\n",
      "Misclassification rate : 0.178\n",
      "True positives : 0.629\n",
      "False positives : 0.139\n",
      "Specificity : 0.861\n",
      "Precision : 0.7593888333571327\n",
      "Prevalence : 0.337\n",
      "Recall : 0.629\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 1]\n",
      " [2 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8235294117647058\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.714\n",
      "False positives : 0.1\n",
      "Specificity : 0.9\n",
      "Precision : 0.8244206773618539\n",
      "Prevalence : 0.034\n",
      "Recall : 0.714\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0038575  0.0038575  0.01167675 0.0038575  0.0038575  0.01167675\n",
      " 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.0038575  0.0038575  0.01167675 0.01167675 0.0038575  0.01167675\n",
      " 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.0038575  0.01167675 0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.01167675 0.0038575  0.01167675 0.01167675 0.01167675 0.0038575\n",
      " 0.01167675 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.01167675 0.0038575  0.0038575  0.01167675 0.0038575  0.0038575\n",
      " 0.0038575  0.0038575  0.0038575  0.01167675 0.0038575  0.0038575\n",
      " 0.01167675 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.0038575  0.0038575  0.0038575  0.01167675 0.0038575  0.0038575\n",
      " 0.01167675 0.0038575  0.0038575  0.01167675 0.0038575  0.01167675\n",
      " 0.01167675 0.0038575  0.01167675 0.01167675 0.0038575  0.0038575\n",
      " 0.0038575  0.01167675 0.0038575  0.0038575  0.01167675 0.01167675\n",
      " 0.0038575  0.0038575  0.01167675 0.0038575  0.01167675 0.0038575\n",
      " 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.01167675 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575  0.01167675\n",
      " 0.01167675 0.0038575  0.0038575  0.01167675 0.0038575  0.01167675\n",
      " 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575  0.01167675\n",
      " 0.0038575  0.01167675 0.0038575  0.0038575  0.0038575  0.0038575\n",
      " 0.0038575  0.0038575  0.01167675 0.0038575  0.0038575  0.0038575\n",
      " 0.0038575  0.01167675 0.0038575  0.0038575  0.0038575  0.01167675\n",
      " 0.0038575  0.0038575  0.0038575  0.0038575  0.0038575 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3223938223938217\n",
      "Alpha : 0.371396205524557\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[28 51]\n",
      " [ 5 65]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6241610738255033\n",
      "Misclassification rate : 0.269\n",
      "True positives : 0.929\n",
      "False positives : 0.646\n",
      "Specificity : 0.354\n",
      "Precision : 0.7131170534317953\n",
      "Prevalence : 0.337\n",
      "Recall : 0.929\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[2 8]\n",
      " [0 7]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5294117647058824\n",
      "Misclassification rate : 0.038\n",
      "True positives : 1.0\n",
      "False positives : 0.8\n",
      "Specificity : 0.2\n",
      "Precision : 0.780392156862745\n",
      "Prevalence : 0.034\n",
      "Recall : 1.0\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00266079 0.00559243 0.01692845 0.00266079 0.00559243 0.00805428\n",
      " 0.00559243 0.00266079 0.00559243 0.00266079 0.00266079 0.00559243\n",
      " 0.00559243 0.00559243 0.00805428 0.01692845 0.00266079 0.00805428\n",
      " 0.00559243 0.00266079 0.00266079 0.00266079 0.00266079 0.00266079\n",
      " 0.00559243 0.00805428 0.00266079 0.00266079 0.00559243 0.00266079\n",
      " 0.00805428 0.00266079 0.00805428 0.00805428 0.01692845 0.00266079\n",
      " 0.00805428 0.00266079 0.00559243 0.00559243 0.00266079 0.00266079\n",
      " 0.00805428 0.00559243 0.00266079 0.00805428 0.00559243 0.00266079\n",
      " 0.00559243 0.00266079 0.00266079 0.01692845 0.00266079 0.00266079\n",
      " 0.01692845 0.00266079 0.00266079 0.00559243 0.00559243 0.00559243\n",
      " 0.00559243 0.00266079 0.00559243 0.00805428 0.00266079 0.00559243\n",
      " 0.00805428 0.00266079 0.00559243 0.00805428 0.00559243 0.00805428\n",
      " 0.00805428 0.00266079 0.00805428 0.00805428 0.00266079 0.00559243\n",
      " 0.00266079 0.00805428 0.00266079 0.00559243 0.00805428 0.01692845\n",
      " 0.00559243 0.00559243 0.00805428 0.00559243 0.00805428 0.00266079\n",
      " 0.00266079 0.00266079 0.00559243 0.00559243 0.00266079 0.00559243\n",
      " 0.00805428 0.00266079 0.00266079 0.00559243 0.00559243 0.00559243\n",
      " 0.00266079 0.00559243 0.00559243 0.00266079 0.00266079 0.01692845\n",
      " 0.00805428 0.00559243 0.00266079 0.00805428 0.00266079 0.00805428\n",
      " 0.00266079 0.00559243 0.00559243 0.00559243 0.00266079 0.00559243\n",
      " 0.00266079 0.00266079 0.00266079 0.00559243 0.00559243 0.00805428\n",
      " 0.00266079 0.01692845 0.00559243 0.00266079 0.00266079 0.00266079\n",
      " 0.00559243 0.00266079 0.00805428 0.00266079 0.00266079 0.00266079\n",
      " 0.00266079 0.00805428 0.00266079 0.00559243 0.00266079 0.00805428\n",
      " 0.00266079 0.00266079 0.00559243 0.00266079 0.00559243]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3003352269819334\n",
      "Alpha : 0.4228510252855715\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[75  4]\n",
      " [45 25]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6711409395973155\n",
      "Misclassification rate : 0.236\n",
      "True positives : 0.357\n",
      "False positives : 0.051\n",
      "Specificity : 0.949\n",
      "Precision : 0.7363746817866235\n",
      "Prevalence : 0.337\n",
      "Recall : 0.357\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 3]\n",
      " [3 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.571\n",
      "False positives : 0.3\n",
      "Specificity : 0.7\n",
      "Precision : 0.6470588235294118\n",
      "Prevalence : 0.034\n",
      "Recall : 0.571\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00406118 0.00853577 0.01109112 0.00174328 0.00853577 0.0122933\n",
      " 0.00366403 0.00174328 0.00853577 0.00174328 0.00174328 0.00366403\n",
      " 0.00366403 0.00366403 0.00527697 0.01109112 0.00174328 0.00527697\n",
      " 0.00366403 0.00174328 0.00406118 0.00406118 0.00406118 0.00174328\n",
      " 0.00366403 0.00527697 0.00174328 0.00174328 0.00366403 0.00174328\n",
      " 0.00527697 0.00174328 0.0122933  0.0122933  0.01109112 0.00406118\n",
      " 0.0122933  0.00174328 0.00366403 0.00366403 0.00406118 0.00406118\n",
      " 0.0122933  0.00853577 0.00406118 0.0122933  0.00366403 0.00406118\n",
      " 0.00366403 0.00174328 0.00174328 0.01109112 0.00174328 0.00174328\n",
      " 0.01109112 0.00406118 0.00174328 0.00366403 0.00366403 0.00366403\n",
      " 0.00853577 0.00174328 0.00366403 0.0122933  0.00406118 0.00366403\n",
      " 0.0122933  0.00174328 0.00366403 0.00527697 0.00853577 0.00527697\n",
      " 0.0122933  0.00174328 0.0122933  0.00527697 0.00174328 0.00366403\n",
      " 0.00174328 0.0122933  0.00174328 0.00366403 0.00527697 0.01109112\n",
      " 0.00366403 0.00366403 0.0122933  0.00366403 0.0122933  0.00174328\n",
      " 0.00174328 0.00406118 0.00853577 0.00366403 0.00174328 0.00366403\n",
      " 0.00527697 0.00406118 0.00174328 0.00366403 0.00366403 0.00366403\n",
      " 0.00174328 0.00366403 0.00366403 0.00406118 0.00174328 0.01109112\n",
      " 0.00527697 0.00366403 0.00174328 0.0122933  0.00406118 0.00527697\n",
      " 0.00174328 0.00366403 0.00366403 0.00366403 0.00406118 0.00366403\n",
      " 0.00174328 0.00174328 0.00406118 0.00366403 0.00366403 0.0122933\n",
      " 0.00406118 0.01109112 0.00366403 0.00174328 0.00174328 0.00174328\n",
      " 0.00366403 0.00406118 0.0122933  0.00174328 0.00406118 0.00406118\n",
      " 0.00406118 0.0122933  0.00174328 0.00366403 0.00406118 0.00527697\n",
      " 0.00406118 0.00406118 0.00366403 0.00174328 0.00366403]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.30010861594741883\n",
      "Alpha : 0.42339034753798355\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[31 48]\n",
      " [ 9 61]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6174496644295302\n",
      "Misclassification rate : 0.274\n",
      "True positives : 0.871\n",
      "False positives : 0.608\n",
      "Specificity : 0.392\n",
      "Precision : 0.6738208854134597\n",
      "Prevalence : 0.337\n",
      "Recall : 0.871\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[2 8]\n",
      " [2 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.4117647058823529\n",
      "Misclassification rate : 0.048\n",
      "True positives : 0.714\n",
      "False positives : 0.8\n",
      "Specificity : 0.2\n",
      "Precision : 0.45248868778280543\n",
      "Prevalence : 0.034\n",
      "Recall : 0.714\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00265935 0.00558942 0.01693758 0.00266222 0.00558942 0.00804993\n",
      " 0.00239929 0.00266222 0.00558942 0.00266222 0.00114154 0.00559545\n",
      " 0.00559545 0.00559545 0.00345548 0.00726272 0.00114154 0.00345548\n",
      " 0.00239929 0.00114154 0.00265935 0.00265935 0.00265935 0.00114154\n",
      " 0.00239929 0.00345548 0.00114154 0.00114154 0.00559545 0.00114154\n",
      " 0.00805862 0.00114154 0.00804993 0.01877347 0.00726272 0.00265935\n",
      " 0.00804993 0.00266222 0.00559545 0.00559545 0.00265935 0.00620195\n",
      " 0.00804993 0.00558942 0.00620195 0.00804993 0.00239929 0.00265935\n",
      " 0.00559545 0.00266222 0.00266222 0.00726272 0.00266222 0.00114154\n",
      " 0.01693758 0.00265935 0.00114154 0.00559545 0.00239929 0.00239929\n",
      " 0.00558942 0.00266222 0.00559545 0.00804993 0.00620195 0.00559545\n",
      " 0.00804993 0.00114154 0.00559545 0.00805862 0.00558942 0.00345548\n",
      " 0.00804993 0.00114154 0.00804993 0.00345548 0.00266222 0.00559545\n",
      " 0.00114154 0.00804993 0.00266222 0.00559545 0.00345548 0.00726272\n",
      " 0.00559545 0.00239929 0.00804993 0.00239929 0.00804993 0.00266222\n",
      " 0.00114154 0.00265935 0.00558942 0.00559545 0.00114154 0.00559545\n",
      " 0.00345548 0.00265935 0.00114154 0.00239929 0.00559545 0.00239929\n",
      " 0.00266222 0.00559545 0.00559545 0.00265935 0.00114154 0.00726272\n",
      " 0.00345548 0.00559545 0.00266222 0.01877347 0.00265935 0.00345548\n",
      " 0.00114154 0.00239929 0.00559545 0.00559545 0.00265935 0.00559545\n",
      " 0.00266222 0.00266222 0.00265935 0.00239929 0.00559545 0.00804993\n",
      " 0.00620195 0.00726272 0.00559545 0.00114154 0.00266222 0.00266222\n",
      " 0.00239929 0.00265935 0.00804993 0.00114154 0.00265935 0.00265935\n",
      " 0.00265935 0.01877347 0.00266222 0.00239929 0.00265935 0.00805862\n",
      " 0.00620195 0.00620195 0.00239929 0.00114154 0.00239929]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.31439917452435057\n",
      "Alpha : 0.3898160681546236\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[74  5]\n",
      " [53 17]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.610738255033557\n",
      "Misclassification rate : 0.279\n",
      "True positives : 0.243\n",
      "False positives : 0.063\n",
      "Specificity : 0.937\n",
      "Precision : 0.6719624506973235\n",
      "Prevalence : 0.337\n",
      "Recall : 0.243\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 1]\n",
      " [6 1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5882352941176471\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.143\n",
      "False positives : 0.1\n",
      "Specificity : 0.9\n",
      "Precision : 0.5588235294117647\n",
      "Prevalence : 0.034\n",
      "Recall : 0.143\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00392709 0.00378505 0.01146982 0.00180281 0.00825395 0.00545127\n",
      " 0.00162476 0.00180281 0.00825395 0.00180281 0.00168573 0.00378914\n",
      " 0.00378914 0.00378914 0.00510274 0.00491818 0.00168573 0.00510274\n",
      " 0.00162476 0.00077303 0.00392709 0.00392709 0.00392709 0.00168573\n",
      " 0.00162476 0.00510274 0.00168573 0.00168573 0.00826285 0.00168573\n",
      " 0.00545715 0.00168573 0.00545127 0.02772295 0.00491818 0.00392709\n",
      " 0.00545127 0.00180281 0.00378914 0.00378914 0.00392709 0.00419984\n",
      " 0.00545127 0.00825395 0.00419984 0.01188741 0.00354306 0.00392709\n",
      " 0.00378914 0.00180281 0.00180281 0.00491818 0.00180281 0.00168573\n",
      " 0.01146982 0.00392709 0.00077303 0.00378914 0.00162476 0.00162476\n",
      " 0.00378505 0.00180281 0.00378914 0.00545127 0.00915848 0.00378914\n",
      " 0.01188741 0.00077303 0.00378914 0.00545715 0.00378505 0.00233999\n",
      " 0.01188741 0.00077303 0.00545127 0.00510274 0.00180281 0.00378914\n",
      " 0.00077303 0.01188741 0.00180281 0.00378914 0.00233999 0.00491818\n",
      " 0.00378914 0.00162476 0.00545127 0.00162476 0.01188741 0.00180281\n",
      " 0.00168573 0.00392709 0.00825395 0.00378914 0.00168573 0.00378914\n",
      " 0.00510274 0.00392709 0.00077303 0.00162476 0.00378914 0.00354306\n",
      " 0.00180281 0.00378914 0.00378914 0.00392709 0.00168573 0.00491818\n",
      " 0.00510274 0.00378914 0.00180281 0.01271304 0.00392709 0.00233999\n",
      " 0.00168573 0.00162476 0.00378914 0.00378914 0.00392709 0.00378914\n",
      " 0.00180281 0.00180281 0.00392709 0.00162476 0.00826285 0.00545127\n",
      " 0.00915848 0.00491818 0.00378914 0.00077303 0.00180281 0.00180281\n",
      " 0.00354306 0.00392709 0.01188741 0.00168573 0.00180086 0.00392709\n",
      " 0.00392709 0.01271304 0.00180281 0.00162476 0.00392709 0.00545715\n",
      " 0.00419984 0.00915848 0.00162476 0.00168573 0.00354306]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 3\n",
      "################################################\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.22147651006711436\n",
      "Alpha : 0.6285413148199415\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[67 17]\n",
      " [16 49]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7785234899328859\n",
      "Misclassification rate : 0.159\n",
      "True positives : 0.754\n",
      "False positives : 0.202\n",
      "Specificity : 0.798\n",
      "Precision : 0.778958420625761\n",
      "Prevalence : 0.312\n",
      "Recall : 0.754\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 2]\n",
      " [7 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.47058823529411764\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.417\n",
      "False positives : 0.4\n",
      "Specificity : 0.6\n",
      "Precision : 0.592436974789916\n",
      "Prevalence : 0.058\n",
      "Recall : 0.417\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00357966 0.01258305 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.01258305 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.01258305 0.00357966 0.00357966\n",
      " 0.00357966 0.01258305 0.00357966 0.01258305 0.00357966 0.00357966\n",
      " 0.00357966 0.01258305 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.01258305 0.00357966\n",
      " 0.01258305 0.00357966 0.01258305 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.01258305 0.00357966 0.00357966\n",
      " 0.01258305 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.01258305 0.01258305 0.00357966 0.00357966 0.00357966 0.01258305\n",
      " 0.01258305 0.00357966 0.01258305 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.01258305 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.01258305 0.00357966 0.00357966 0.01258305 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966 0.01258305\n",
      " 0.01258305 0.00357966 0.00357966 0.01258305 0.00357966 0.01258305\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966 0.00357966\n",
      " 0.00357966 0.00357966 0.00357966 0.01258305 0.00357966 0.01258305\n",
      " 0.00357966 0.01258305 0.00357966 0.00357966 0.01258305 0.00357966\n",
      " 0.00357966 0.00357966 0.01258305 0.00357966 0.01258305 0.00357966\n",
      " 0.00357966 0.01258305 0.00357966 0.01258305 0.00357966 0.01258305\n",
      " 0.00357966 0.00357966 0.00357966 0.00357966 0.01258305]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2979362591431558\n",
      "Alpha : 0.42857231535573753\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[56 28]\n",
      " [21 44]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6711409395973155\n",
      "Misclassification rate : 0.236\n",
      "True positives : 0.677\n",
      "False positives : 0.333\n",
      "Specificity : 0.667\n",
      "Precision : 0.6765981967324249\n",
      "Prevalence : 0.312\n",
      "Recall : 0.677\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 1]\n",
      " [4 8]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7058823529411765\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.667\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.7745098039215685\n",
      "Prevalence : 0.058\n",
      "Recall : 0.667\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00549501 0.01931578 0.00233193 0.00233193 0.00549501 0.00549501\n",
      " 0.00233193 0.00549501 0.00819708 0.00233193 0.00233193 0.00233193\n",
      " 0.00233193 0.00549501 0.00233193 0.01931578 0.00233193 0.00233193\n",
      " 0.00549501 0.01931578 0.00549501 0.00819708 0.00233193 0.00233193\n",
      " 0.00549501 0.00819708 0.00233193 0.00549501 0.00549501 0.00233193\n",
      " 0.00233193 0.00233193 0.00549501 0.00233193 0.00819708 0.00549501\n",
      " 0.01931578 0.00233193 0.00819708 0.00549501 0.00233193 0.00549501\n",
      " 0.00549501 0.00549501 0.00549501 0.00549501 0.00549501 0.00233193\n",
      " 0.00233193 0.00233193 0.00549501 0.00819708 0.00233193 0.00233193\n",
      " 0.00819708 0.00233193 0.00549501 0.00549501 0.00233193 0.00233193\n",
      " 0.00549501 0.00549501 0.00549501 0.00549501 0.00233193 0.00233193\n",
      " 0.00819708 0.00819708 0.00549501 0.00233193 0.00549501 0.00819708\n",
      " 0.01931578 0.00233193 0.01931578 0.00233193 0.00233193 0.00233193\n",
      " 0.00233193 0.00549501 0.00233193 0.00549501 0.00233193 0.00233193\n",
      " 0.00233193 0.00549501 0.00549501 0.00233193 0.01931578 0.00233193\n",
      " 0.00233193 0.00549501 0.00549501 0.00233193 0.00233193 0.00233193\n",
      " 0.00819708 0.00233193 0.00233193 0.00819708 0.00549501 0.00549501\n",
      " 0.00233193 0.00233193 0.00233193 0.00233193 0.00233193 0.00819708\n",
      " 0.00819708 0.00233193 0.00233193 0.00819708 0.00233193 0.00819708\n",
      " 0.00233193 0.00233193 0.00233193 0.00233193 0.00233193 0.00233193\n",
      " 0.00549501 0.00549501 0.00549501 0.00819708 0.00233193 0.00819708\n",
      " 0.00549501 0.01931578 0.00233193 0.00233193 0.00819708 0.00233193\n",
      " 0.00233193 0.00549501 0.00819708 0.00233193 0.00819708 0.00233193\n",
      " 0.00233193 0.00819708 0.00233193 0.00819708 0.00233193 0.00819708\n",
      " 0.00233193 0.00233193 0.00233193 0.00233193 0.00819708]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2770144469479923\n",
      "Alpha : 0.4796597900687387\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[51 33]\n",
      " [22 43]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6308724832214765\n",
      "Misclassification rate : 0.264\n",
      "True positives : 0.662\n",
      "False positives : 0.393\n",
      "Specificity : 0.607\n",
      "Precision : 0.640679512055859\n",
      "Prevalence : 0.312\n",
      "Recall : 0.662\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[ 4  1]\n",
      " [ 2 10]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8235294117647058\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.833\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.8377896613190731\n",
      "Prevalence : 0.058\n",
      "Recall : 0.833\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00340138 0.01195635 0.00144345 0.00376729 0.00340138 0.00340138\n",
      " 0.00144345 0.00340138 0.00507394 0.00376729 0.00144345 0.00376729\n",
      " 0.00376729 0.00340138 0.00376729 0.01195635 0.00376729 0.00144345\n",
      " 0.00340138 0.01195635 0.00340138 0.00507394 0.00144345 0.00144345\n",
      " 0.00340138 0.00507394 0.00144345 0.00340138 0.00340138 0.00376729\n",
      " 0.00144345 0.00376729 0.00340138 0.00376729 0.00507394 0.00887732\n",
      " 0.01195635 0.00376729 0.01324258 0.00887732 0.00144345 0.00887732\n",
      " 0.00887732 0.00340138 0.00340138 0.00340138 0.00340138 0.00144345\n",
      " 0.00376729 0.00144345 0.00340138 0.00507394 0.00376729 0.00144345\n",
      " 0.00507394 0.00376729 0.00887732 0.00887732 0.00144345 0.00144345\n",
      " 0.00340138 0.00340138 0.00887732 0.00887732 0.00144345 0.00144345\n",
      " 0.00507394 0.00507394 0.00887732 0.00376729 0.00340138 0.00507394\n",
      " 0.01195635 0.00376729 0.01195635 0.00144345 0.00376729 0.00376729\n",
      " 0.00144345 0.00340138 0.00376729 0.00887732 0.00144345 0.00144345\n",
      " 0.00376729 0.00340138 0.00887732 0.00144345 0.01195635 0.00144345\n",
      " 0.00144345 0.00887732 0.00340138 0.00376729 0.00144345 0.00376729\n",
      " 0.00507394 0.00144345 0.00144345 0.00507394 0.00340138 0.00340138\n",
      " 0.00376729 0.00376729 0.00144345 0.00376729 0.00376729 0.00507394\n",
      " 0.00507394 0.00144345 0.00376729 0.01324258 0.00376729 0.00507394\n",
      " 0.00144345 0.00144345 0.00376729 0.00144345 0.00144345 0.00376729\n",
      " 0.00340138 0.00340138 0.00340138 0.00507394 0.00144345 0.01324258\n",
      " 0.00887732 0.01195635 0.00144345 0.00144345 0.01324258 0.00376729\n",
      " 0.00144345 0.00340138 0.01324258 0.00144345 0.00507394 0.00376729\n",
      " 0.00144345 0.01324258 0.00376729 0.01324258 0.00144345 0.00507394\n",
      " 0.00376729 0.00376729 0.00144345 0.00376729 0.00507394]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2861489309780387\n",
      "Alpha : 0.4570809704049355\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[78  6]\n",
      " [47 18]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6442953020134228\n",
      "Misclassification rate : 0.255\n",
      "True positives : 0.277\n",
      "False positives : 0.071\n",
      "Specificity : 0.929\n",
      "Precision : 0.6789664429530201\n",
      "Prevalence : 0.312\n",
      "Recall : 0.277\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[ 4  1]\n",
      " [11  1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.29411764705882354\n",
      "Misclassification rate : 0.058\n",
      "True positives : 0.083\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.4313725490196078\n",
      "Prevalence : 0.058\n",
      "Recall : 0.083\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00537233 0.00756992 0.00091389 0.00238518 0.00537233 0.00215351\n",
      " 0.00091389 0.00215351 0.00801407 0.00238518 0.00227987 0.00238518\n",
      " 0.00238518 0.00215351 0.00595027 0.00756992 0.00595027 0.00091389\n",
      " 0.00215351 0.00756992 0.00215351 0.00321246 0.00227987 0.00227987\n",
      " 0.00537233 0.00321246 0.00227987 0.00215351 0.00215351 0.00238518\n",
      " 0.00227987 0.00238518 0.00215351 0.00595027 0.00321246 0.01402134\n",
      " 0.00756992 0.00238518 0.00838427 0.00562049 0.00227987 0.00562049\n",
      " 0.00562049 0.00537233 0.00215351 0.00537233 0.00537233 0.00227987\n",
      " 0.00238518 0.00091389 0.00215351 0.00321246 0.00238518 0.00227987\n",
      " 0.00321246 0.00595027 0.00562049 0.00562049 0.00227987 0.00091389\n",
      " 0.00215351 0.00215351 0.00562049 0.00562049 0.00227987 0.00091389\n",
      " 0.00801407 0.00321246 0.00562049 0.00238518 0.00215351 0.00321246\n",
      " 0.01888454 0.00238518 0.00756992 0.00227987 0.00238518 0.00238518\n",
      " 0.00091389 0.00537233 0.00238518 0.00562049 0.00091389 0.00091389\n",
      " 0.00238518 0.00215351 0.00562049 0.00091389 0.01888454 0.00091389\n",
      " 0.00227987 0.01402134 0.00537233 0.00238518 0.00227987 0.00238518\n",
      " 0.00801407 0.00227987 0.00091389 0.00321246 0.00215351 0.00537233\n",
      " 0.00238518 0.00238518 0.00091389 0.00595027 0.00595027 0.00321246\n",
      " 0.00801407 0.00091389 0.00238518 0.00838427 0.00595027 0.00321246\n",
      " 0.00227987 0.00091389 0.00238518 0.00091389 0.00227987 0.00238518\n",
      " 0.00215351 0.00215351 0.00537233 0.00321246 0.00227987 0.00838427\n",
      " 0.01402134 0.00756992 0.00091389 0.00091389 0.00838427 0.00238518\n",
      " 0.00227987 0.00537233 0.02091609 0.00227987 0.00321246 0.00595027\n",
      " 0.00227987 0.00838427 0.00238518 0.00838427 0.00227987 0.00321246\n",
      " 0.00238518 0.00595027 0.00091389 0.00595027 0.00801407]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3432331064364485\n",
      "Alpha : 0.32445966213613525\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[71 13]\n",
      " [30 35]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7114093959731543\n",
      "Misclassification rate : 0.207\n",
      "True positives : 0.538\n",
      "False positives : 0.155\n",
      "Specificity : 0.845\n",
      "Precision : 0.7143982435156266\n",
      "Prevalence : 0.312\n",
      "Recall : 0.538\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 1]\n",
      " [7 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5294117647058824\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.417\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.6951871657754011\n",
      "Prevalence : 0.058\n",
      "Recall : 0.417\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00388375 0.00547243 0.00066067 0.00172429 0.00388375 0.00297891\n",
      " 0.00066067 0.00155681 0.00579352 0.00172429 0.00164816 0.00172429\n",
      " 0.00172429 0.00155681 0.0082309  0.00547243 0.00430155 0.00066067\n",
      " 0.00297891 0.01047133 0.00155681 0.00444374 0.0031537  0.0031537\n",
      " 0.00388375 0.00444374 0.00164816 0.00155681 0.00155681 0.00172429\n",
      " 0.00164816 0.00172429 0.00155681 0.00430155 0.00444374 0.01939549\n",
      " 0.01047133 0.00172429 0.00606114 0.00406315 0.0031537  0.00406315\n",
      " 0.00777473 0.00388375 0.00155681 0.00743145 0.00388375 0.00164816\n",
      " 0.00172429 0.00126417 0.00155681 0.00444374 0.00172429 0.00164816\n",
      " 0.00444374 0.00430155 0.00406315 0.00406315 0.00164816 0.00066067\n",
      " 0.00155681 0.00155681 0.00406315 0.00777473 0.00164816 0.00126417\n",
      " 0.00579352 0.00232235 0.00406315 0.00172429 0.00297891 0.00444374\n",
      " 0.01365197 0.00172429 0.01047133 0.0031537  0.00329938 0.00172429\n",
      " 0.00066067 0.00388375 0.00172429 0.00406315 0.00126417 0.00126417\n",
      " 0.00172429 0.00155681 0.00777473 0.00066067 0.01365197 0.00066067\n",
      " 0.00164816 0.01013628 0.00743145 0.00172429 0.0031537  0.00329938\n",
      " 0.01108573 0.00164816 0.00066067 0.00232235 0.00155681 0.00388375\n",
      " 0.00172429 0.00172429 0.00066067 0.0082309  0.00430155 0.00232235\n",
      " 0.00579352 0.00066067 0.00172429 0.01159781 0.00430155 0.00444374\n",
      " 0.0031537  0.00066067 0.00329938 0.00066067 0.00164816 0.00172429\n",
      " 0.00155681 0.00155681 0.00388375 0.00232235 0.00164816 0.01159781\n",
      " 0.01939549 0.01047133 0.00066067 0.00066067 0.00606114 0.00172429\n",
      " 0.00164816 0.00388375 0.02893287 0.00164816 0.00232235 0.00430155\n",
      " 0.00164816 0.01159781 0.00172429 0.00606114 0.00164816 0.00444374\n",
      " 0.00329938 0.00430155 0.00066067 0.00430155 0.00579352]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 4\n",
      "################################################\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.24161073825503385\n",
      "Alpha : 0.5719344401281145\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[70 11]\n",
      " [25 43]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7583892617449665\n",
      "Misclassification rate : 0.173\n",
      "True positives : 0.632\n",
      "False positives : 0.136\n",
      "Specificity : 0.864\n",
      "Precision : 0.7639755615735835\n",
      "Prevalence : 0.327\n",
      "Recall : 0.632\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 1]\n",
      " [3 6]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7647058823529411\n",
      "Misclassification rate : 0.019\n",
      "True positives : 0.667\n",
      "False positives : 0.125\n",
      "Specificity : 0.875\n",
      "Precision : 0.7831932773109243\n",
      "Prevalence : 0.043\n",
      "Recall : 0.667\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00378814 0.00378814 0.01189054 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.01189054 0.01189054 0.00378814 0.00378814\n",
      " 0.01189054 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.01189054 0.01189054 0.01189054 0.00378814 0.00378814\n",
      " 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.01189054 0.00378814 0.00378814\n",
      " 0.01189054 0.00378814 0.00378814 0.01189054 0.00378814 0.01189054\n",
      " 0.01189054 0.00378814 0.01189054 0.01189054 0.00378814 0.00378814\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.01189054 0.01189054\n",
      " 0.00378814 0.00378814 0.01189054 0.00378814 0.01189054 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.01189054 0.00378814 0.00378814 0.01189054 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.354965585054081\n",
      "Alpha : 0.29864141530560334\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[75  6]\n",
      " [40 28]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6912751677852349\n",
      "Misclassification rate : 0.221\n",
      "True positives : 0.412\n",
      "False positives : 0.074\n",
      "Specificity : 0.926\n",
      "Precision : 0.7303764225269916\n",
      "Prevalence : 0.327\n",
      "Recall : 0.412\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 1]\n",
      " [8 1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.47058823529411764\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.111\n",
      "False positives : 0.125\n",
      "Specificity : 0.875\n",
      "Precision : 0.48431372549019613\n",
      "Prevalence : 0.043\n",
      "Recall : 0.111\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00510651 0.00510651 0.00882071 0.00281014 0.00510651 0.01602876\n",
      " 0.00281014 0.00281014 0.00510651 0.00281014 0.00281014 0.00281014\n",
      " 0.00281014 0.00281014 0.00882071 0.00882071 0.00281014 0.00281014\n",
      " 0.01602876 0.00882071 0.00281014 0.00281014 0.00510651 0.00281014\n",
      " 0.00510651 0.01602876 0.00281014 0.00510651 0.00281014 0.00281014\n",
      " 0.00281014 0.00281014 0.00510651 0.00281014 0.00882071 0.00281014\n",
      " 0.00281014 0.00510651 0.00510651 0.00510651 0.00281014 0.00281014\n",
      " 0.00882071 0.00281014 0.00281014 0.00281014 0.00281014 0.00882071\n",
      " 0.00281014 0.01602876 0.01602876 0.00882071 0.00281014 0.00281014\n",
      " 0.00882071 0.00510651 0.00281014 0.00281014 0.00281014 0.00281014\n",
      " 0.00510651 0.00281014 0.00281014 0.01602876 0.00510651 0.00281014\n",
      " 0.01602876 0.00281014 0.00281014 0.00882071 0.00510651 0.00882071\n",
      " 0.01602876 0.00281014 0.01602876 0.00882071 0.00281014 0.00281014\n",
      " 0.00281014 0.01602876 0.00281014 0.00281014 0.00882071 0.00882071\n",
      " 0.00281014 0.00281014 0.01602876 0.00281014 0.01602876 0.00281014\n",
      " 0.00281014 0.00510651 0.00510651 0.00281014 0.00281014 0.00281014\n",
      " 0.00882071 0.00510651 0.00281014 0.00281014 0.00281014 0.00281014\n",
      " 0.00281014 0.00281014 0.00281014 0.00510651 0.00281014 0.00882071\n",
      " 0.00882071 0.00281014 0.00281014 0.01602876 0.00510651 0.00882071\n",
      " 0.00281014 0.00281014 0.00281014 0.00281014 0.00510651 0.00281014\n",
      " 0.00281014 0.00281014 0.00510651 0.00281014 0.00281014 0.01602876\n",
      " 0.00510651 0.00882071 0.00281014 0.00281014 0.00281014 0.00281014\n",
      " 0.00281014 0.00510651 0.01602876 0.00281014 0.00510651 0.00510651\n",
      " 0.00510651 0.01602876 0.00281014 0.00281014 0.00510651 0.00882071\n",
      " 0.00510651 0.00510651 0.00281014 0.00281014 0.00281014]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2841013698398764\n",
      "Alpha : 0.46210373420914647\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[23 58]\n",
      " [ 2 66]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5973154362416108\n",
      "Misclassification rate : 0.288\n",
      "True positives : 0.971\n",
      "False positives : 0.716\n",
      "Specificity : 0.284\n",
      "Precision : 0.7430439489066898\n",
      "Prevalence : 0.327\n",
      "Recall : 0.971\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 5]\n",
      " [1 8]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.889\n",
      "False positives : 0.625\n",
      "Specificity : 0.375\n",
      "Precision : 0.6787330316742082\n",
      "Prevalence : 0.043\n",
      "Recall : 0.889\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00321688 0.00810612 0.01400208 0.00177027 0.00321688 0.01009743\n",
      " 0.00446084 0.00177027 0.00321688 0.00177027 0.00177027 0.00446084\n",
      " 0.00446084 0.00446084 0.00555667 0.01400208 0.00177027 0.00177027\n",
      " 0.01009743 0.01400208 0.00446084 0.00446084 0.00321688 0.00177027\n",
      " 0.00810612 0.01009743 0.00177027 0.00810612 0.00446084 0.00177027\n",
      " 0.00177027 0.00446084 0.00810612 0.00177027 0.00555667 0.00446084\n",
      " 0.00177027 0.00321688 0.00321688 0.00321688 0.00177027 0.00446084\n",
      " 0.00555667 0.00177027 0.00177027 0.00446084 0.00177027 0.00555667\n",
      " 0.00177027 0.01009743 0.01009743 0.01400208 0.00177027 0.00177027\n",
      " 0.01400208 0.00321688 0.00177027 0.00446084 0.00446084 0.00446084\n",
      " 0.00810612 0.00446084 0.00446084 0.01009743 0.00321688 0.00446084\n",
      " 0.01009743 0.00177027 0.00446084 0.00555667 0.00810612 0.00555667\n",
      " 0.01009743 0.00177027 0.01009743 0.00555667 0.00177027 0.00446084\n",
      " 0.00177027 0.01009743 0.00177027 0.00446084 0.00555667 0.01400208\n",
      " 0.00446084 0.00446084 0.01009743 0.00446084 0.01009743 0.00446084\n",
      " 0.00177027 0.00321688 0.00810612 0.00446084 0.00177027 0.00446084\n",
      " 0.00555667 0.00321688 0.00177027 0.00446084 0.00446084 0.00446084\n",
      " 0.00177027 0.00446084 0.00446084 0.00321688 0.00177027 0.01400208\n",
      " 0.00555667 0.00446084 0.00177027 0.01009743 0.00321688 0.00555667\n",
      " 0.00177027 0.00446084 0.00446084 0.00446084 0.00321688 0.00446084\n",
      " 0.00446084 0.00177027 0.00321688 0.00446084 0.00446084 0.01009743\n",
      " 0.00321688 0.01400208 0.00446084 0.00177027 0.00177027 0.00446084\n",
      " 0.00446084 0.00321688 0.01009743 0.00177027 0.00321688 0.00321688\n",
      " 0.00321688 0.01009743 0.00177027 0.00446084 0.00321688 0.00555667\n",
      " 0.00321688 0.00321688 0.00446084 0.00177027 0.00446084]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.29229124483183283\n",
      "Alpha : 0.44214096365737043\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[51 30]\n",
      " [21 47]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6577181208053692\n",
      "Misclassification rate : 0.245\n",
      "True positives : 0.691\n",
      "False positives : 0.37\n",
      "Specificity : 0.63\n",
      "Precision : 0.663634184607339\n",
      "Prevalence : 0.327\n",
      "Recall : 0.691\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 4]\n",
      " [3 6]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5882352941176471\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.667\n",
      "False positives : 0.5\n",
      "Specificity : 0.5\n",
      "Precision : 0.5865546218487395\n",
      "Prevalence : 0.043\n",
      "Recall : 0.667\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00206736 0.00520947 0.00899856 0.00275459 0.00206736 0.00648921\n",
      " 0.0028668  0.00113768 0.00206736 0.00275459 0.00113768 0.00694122\n",
      " 0.00694122 0.0028668  0.00864637 0.00899856 0.00275459 0.00113768\n",
      " 0.00648921 0.00899856 0.0028668  0.0028668  0.00206736 0.00113768\n",
      " 0.00520947 0.00648921 0.00113768 0.00520947 0.0028668  0.00275459\n",
      " 0.00113768 0.00694122 0.00520947 0.00275459 0.00357104 0.0028668\n",
      " 0.00113768 0.00206736 0.00500558 0.00206736 0.00113768 0.0028668\n",
      " 0.00357104 0.00113768 0.00113768 0.0028668  0.00113768 0.00864637\n",
      " 0.00113768 0.00648921 0.01571196 0.00899856 0.00275459 0.00113768\n",
      " 0.00899856 0.00500558 0.00275459 0.00694122 0.0028668  0.0028668\n",
      " 0.00520947 0.0028668  0.00694122 0.01571196 0.00206736 0.0028668\n",
      " 0.00648921 0.00113768 0.00694122 0.00864637 0.00520947 0.00357104\n",
      " 0.00648921 0.00275459 0.00648921 0.00357104 0.00275459 0.00694122\n",
      " 0.00113768 0.00648921 0.00275459 0.00694122 0.00357104 0.00899856\n",
      " 0.00694122 0.0028668  0.01571196 0.0028668  0.00648921 0.0028668\n",
      " 0.00113768 0.00500558 0.00520947 0.00694122 0.00113768 0.00694122\n",
      " 0.00357104 0.00206736 0.00113768 0.0028668  0.0028668  0.0028668\n",
      " 0.00275459 0.00694122 0.0028668  0.00500558 0.00275459 0.00899856\n",
      " 0.00357104 0.0028668  0.00275459 0.01571196 0.00500558 0.00357104\n",
      " 0.00113768 0.0028668  0.00694122 0.0028668  0.00206736 0.00694122\n",
      " 0.0028668  0.00113768 0.00206736 0.0028668  0.0028668  0.01571196\n",
      " 0.00500558 0.00899856 0.0028668  0.00113768 0.00275459 0.00694122\n",
      " 0.0028668  0.00206736 0.01571196 0.00113768 0.00206736 0.00500558\n",
      " 0.00206736 0.01571196 0.00275459 0.00694122 0.00206736 0.00357104\n",
      " 0.00500558 0.00500558 0.0028668  0.00275459 0.0028668 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3055109663036106\n",
      "Alpha : 0.41059534882042825\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[75  6]\n",
      " [53 15]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6040268456375839\n",
      "Misclassification rate : 0.284\n",
      "True positives : 0.221\n",
      "False positives : 0.074\n",
      "Specificity : 0.926\n",
      "Precision : 0.6445125239693192\n",
      "Prevalence : 0.327\n",
      "Recall : 0.221\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 1]\n",
      " [5 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.444\n",
      "False positives : 0.125\n",
      "Specificity : 0.875\n",
      "Precision : 0.6980392156862746\n",
      "Prevalence : 0.043\n",
      "Recall : 0.444\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00311699 0.00345521 0.00596834 0.001827   0.00311699 0.004304\n",
      " 0.00190142 0.00075457 0.00311699 0.001827   0.00171529 0.0046038\n",
      " 0.0046038  0.00190142 0.01303626 0.00596834 0.00415314 0.00075457\n",
      " 0.004304   0.00596834 0.00190142 0.00190142 0.00311699 0.00171529\n",
      " 0.0078544  0.004304   0.00171529 0.00345521 0.00190142 0.001827\n",
      " 0.00171529 0.0046038  0.00345521 0.00415314 0.00538411 0.00190142\n",
      " 0.00075457 0.00311699 0.00754699 0.00311699 0.00171529 0.00190142\n",
      " 0.00538411 0.00171529 0.00171529 0.00432232 0.00171529 0.00573475\n",
      " 0.00171529 0.004304   0.02368916 0.00596834 0.001827   0.00171529\n",
      " 0.00596834 0.00754699 0.001827   0.0046038  0.00432232 0.00190142\n",
      " 0.00345521 0.00190142 0.0046038  0.01042104 0.00311699 0.00190142\n",
      " 0.00978387 0.00075457 0.0046038  0.00573475 0.00345521 0.00236851\n",
      " 0.00978387 0.001827   0.004304   0.00538411 0.001827   0.0046038\n",
      " 0.00075457 0.00978387 0.001827   0.0046038  0.00236851 0.00596834\n",
      " 0.0046038  0.00190142 0.01042104 0.00190142 0.00978387 0.00190142\n",
      " 0.00171529 0.00754699 0.0078544  0.0046038  0.00171529 0.0046038\n",
      " 0.00538411 0.00311699 0.00075457 0.00190142 0.00190142 0.00432232\n",
      " 0.001827   0.0046038  0.00190142 0.00754699 0.00415314 0.00596834\n",
      " 0.00538411 0.00190142 0.001827   0.01042104 0.00754699 0.00236851\n",
      " 0.00171529 0.00190142 0.0046038  0.00190142 0.00311699 0.0046038\n",
      " 0.00190142 0.00075457 0.00311699 0.00190142 0.00432232 0.01042104\n",
      " 0.00754699 0.00596834 0.00190142 0.00075457 0.001827   0.0046038\n",
      " 0.00432232 0.00311699 0.02368916 0.00171529 0.00137119 0.00754699\n",
      " 0.00311699 0.01042104 0.001827   0.0046038  0.00311699 0.00236851\n",
      " 0.00331998 0.00754699 0.00190142 0.00415314 0.00432232]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 5\n",
      "################################################\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.24161073825503387\n",
      "Alpha : 0.5719344401281145\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[67 10]\n",
      " [26 46]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7583892617449665\n",
      "Misclassification rate : 0.173\n",
      "True positives : 0.639\n",
      "False positives : 0.13\n",
      "Specificity : 0.87\n",
      "Precision : 0.7692347343787049\n",
      "Prevalence : 0.346\n",
      "Recall : 0.639\n",
      "\n",
      ":: Teste ::\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[10  2]\n",
      " [ 2  3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7647058823529411\n",
      "Misclassification rate : 0.019\n",
      "True positives : 0.6\n",
      "False positives : 0.167\n",
      "Specificity : 0.833\n",
      "Precision : 0.7647058823529411\n",
      "Prevalence : 0.024\n",
      "Recall : 0.6\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00378814 0.00378814 0.01189054 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.01189054 0.01189054 0.00378814 0.00378814\n",
      " 0.01189054 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.01189054 0.01189054 0.01189054 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.01189054 0.00378814 0.01189054\n",
      " 0.01189054 0.00378814 0.01189054 0.01189054 0.00378814 0.00378814\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.01189054 0.01189054\n",
      " 0.00378814 0.00378814 0.01189054 0.00378814 0.01189054 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.01189054 0.00378814 0.00378814 0.01189054 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814\n",
      " 0.00378814 0.01189054 0.00378814 0.00378814 0.00378814 0.01189054\n",
      " 0.00378814 0.00378814 0.00378814 0.00378814 0.00378814]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3184611602753202\n",
      "Alpha : 0.38042635961117727\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[23 54]\n",
      " [ 3 69]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6174496644295302\n",
      "Misclassification rate : 0.274\n",
      "True positives : 0.958\n",
      "False positives : 0.701\n",
      "Specificity : 0.299\n",
      "Precision : 0.7282256947504943\n",
      "Prevalence : 0.346\n",
      "Recall : 0.958\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 9]\n",
      " [0 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.47058823529411764\n",
      "Misclassification rate : 0.043\n",
      "True positives : 1.0\n",
      "False positives : 0.75\n",
      "Specificity : 0.25\n",
      "Precision : 0.8109243697478992\n",
      "Prevalence : 0.024\n",
      "Recall : 1.0\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00258946 0.0055417  0.01739477 0.00258946 0.00258946 0.00812802\n",
      " 0.0055417  0.00258946 0.00258946 0.00258946 0.00258946 0.0055417\n",
      " 0.0055417  0.0055417  0.00812802 0.01739477 0.00258946 0.00258946\n",
      " 0.00812802 0.01739477 0.0055417  0.0055417  0.00258946 0.00258946\n",
      " 0.0055417  0.00812802 0.00258946 0.0055417  0.0055417  0.00258946\n",
      " 0.00258946 0.0055417  0.0055417  0.00258946 0.00812802 0.0055417\n",
      " 0.00258946 0.00258946 0.00258946 0.00258946 0.00258946 0.0055417\n",
      " 0.00812802 0.00258946 0.00258946 0.0055417  0.00258946 0.00812802\n",
      " 0.00258946 0.00812802 0.00812802 0.01739477 0.00258946 0.00812802\n",
      " 0.00258946 0.0055417  0.0055417  0.00258946 0.00258946 0.00812802\n",
      " 0.0055417  0.00258946 0.00812802 0.0055417  0.00258946 0.0055417\n",
      " 0.00258946 0.00258946 0.0055417  0.00812802 0.0055417  0.00812802\n",
      " 0.00812802 0.00258946 0.00812802 0.00812802 0.00258946 0.0055417\n",
      " 0.00258946 0.00812802 0.00258946 0.0055417  0.00812802 0.01739477\n",
      " 0.0055417  0.0055417  0.00812802 0.0055417  0.00812802 0.0055417\n",
      " 0.00258946 0.00258946 0.0055417  0.0055417  0.00258946 0.0055417\n",
      " 0.00812802 0.00258946 0.00258946 0.0055417  0.0055417  0.0055417\n",
      " 0.00258946 0.0055417  0.0055417  0.00258946 0.00258946 0.01739477\n",
      " 0.00812802 0.0055417  0.00258946 0.00812802 0.00258946 0.00812802\n",
      " 0.00258946 0.0055417  0.0055417  0.0055417  0.00258946 0.0055417\n",
      " 0.0055417  0.00258946 0.00258946 0.0055417  0.0055417  0.00812802\n",
      " 0.00258946 0.01739477 0.0055417  0.00258946 0.00258946 0.0055417\n",
      " 0.0055417  0.00258946 0.00812802 0.00258946 0.00258946 0.00258946\n",
      " 0.00258946 0.00812802 0.00258946 0.0055417  0.00258946 0.00812802\n",
      " 0.00258946 0.00258946 0.0055417  0.00258946 0.0055417 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.30114891006149813\n",
      "Alpha : 0.42091641315914013\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[47 30]\n",
      " [22 50]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6510067114093959\n",
      "Misclassification rate : 0.25\n",
      "True positives : 0.694\n",
      "False positives : 0.39\n",
      "Specificity : 0.61\n",
      "Precision : 0.6540219822974419\n",
      "Prevalence : 0.346\n",
      "Recall : 0.694\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 4]\n",
      " [3 2]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5882352941176471\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.4\n",
      "False positives : 0.333\n",
      "Specificity : 0.667\n",
      "Precision : 0.6114081996434937\n",
      "Prevalence : 0.024\n",
      "Recall : 0.4\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00169984 0.00363782 0.01141871 0.00394467 0.00169984 0.0053356\n",
      " 0.00363782 0.00169984 0.00169984 0.00394467 0.00169984 0.00844198\n",
      " 0.00844198 0.00363782 0.01238187 0.01141871 0.00394467 0.00169984\n",
      " 0.0053356  0.01141871 0.00363782 0.00363782 0.00169984 0.00169984\n",
      " 0.00363782 0.0053356  0.00169984 0.00363782 0.00363782 0.00394467\n",
      " 0.00169984 0.00844198 0.00363782 0.00394467 0.0053356  0.00363782\n",
      " 0.00169984 0.00169984 0.00394467 0.00169984 0.00169984 0.00363782\n",
      " 0.0053356  0.00169984 0.00169984 0.00363782 0.00169984 0.01238187\n",
      " 0.00169984 0.0053356  0.01238187 0.01141871 0.00394467 0.0053356\n",
      " 0.00394467 0.00844198 0.00844198 0.00169984 0.00394467 0.01238187\n",
      " 0.00363782 0.00169984 0.0053356  0.00363782 0.00169984 0.00844198\n",
      " 0.00169984 0.00169984 0.00844198 0.01238187 0.00363782 0.0053356\n",
      " 0.0053356  0.00394467 0.0053356  0.0053356  0.00394467 0.00844198\n",
      " 0.00169984 0.0053356  0.00394467 0.00844198 0.0053356  0.01141871\n",
      " 0.00844198 0.00363782 0.01238187 0.00363782 0.0053356  0.00363782\n",
      " 0.00169984 0.00394467 0.00363782 0.00844198 0.00169984 0.00844198\n",
      " 0.0053356  0.00169984 0.00169984 0.00363782 0.00363782 0.00363782\n",
      " 0.00394467 0.00844198 0.00363782 0.00394467 0.00394467 0.01141871\n",
      " 0.0053356  0.00363782 0.00394467 0.01238187 0.00394467 0.0053356\n",
      " 0.00169984 0.00363782 0.00844198 0.00363782 0.00169984 0.00844198\n",
      " 0.00363782 0.00169984 0.00169984 0.00363782 0.00363782 0.01238187\n",
      " 0.00394467 0.01141871 0.00363782 0.00169984 0.00394467 0.00844198\n",
      " 0.00363782 0.00169984 0.01238187 0.00169984 0.00169984 0.00394467\n",
      " 0.00169984 0.01238187 0.00394467 0.00844198 0.00169984 0.0053356\n",
      " 0.00394467 0.00394467 0.00363782 0.00394467 0.00363782]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.28847990566692133\n",
      "Alpha : 0.4513891134437468\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[71  6]\n",
      " [54 18]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5973154362416108\n",
      "Misclassification rate : 0.288\n",
      "True positives : 0.25\n",
      "False positives : 0.078\n",
      "Specificity : 0.922\n",
      "Precision : 0.6559463087248322\n",
      "Prevalence : 0.346\n",
      "Recall : 0.25\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[11  1]\n",
      " [ 4  1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7058823529411765\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.2\n",
      "False positives : 0.083\n",
      "Specificity : 0.917\n",
      "Precision : 0.6647058823529411\n",
      "Prevalence : 0.024\n",
      "Recall : 0.2\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00266958 0.00231636 0.00727078 0.00251174 0.00266958 0.0033974\n",
      " 0.00231636 0.00108236 0.00266958 0.00251174 0.00266958 0.00537537\n",
      " 0.00537537 0.00231636 0.01944563 0.00727078 0.00619507 0.00108236\n",
      " 0.0033974  0.00727078 0.00231636 0.00231636 0.00266958 0.00266958\n",
      " 0.00571317 0.0033974  0.00266958 0.00231636 0.00231636 0.00251174\n",
      " 0.00266958 0.00537537 0.00231636 0.00619507 0.00837951 0.00231636\n",
      " 0.00108236 0.00266958 0.00619507 0.00266958 0.00266958 0.00231636\n",
      " 0.00837951 0.00266958 0.00266958 0.00571317 0.00266958 0.00788407\n",
      " 0.00266958 0.0033974  0.01944563 0.00727078 0.00619507 0.0033974\n",
      " 0.00251174 0.00537537 0.00537537 0.00266958 0.00251174 0.00788407\n",
      " 0.00571317 0.00108236 0.00837951 0.00571317 0.00266958 0.00537537\n",
      " 0.00108236 0.00108236 0.00537537 0.00788407 0.00231636 0.0033974\n",
      " 0.00837951 0.00251174 0.0033974  0.00837951 0.00251174 0.00537537\n",
      " 0.00108236 0.00837951 0.00251174 0.00537537 0.0033974  0.00727078\n",
      " 0.00537537 0.00231636 0.00788407 0.00231636 0.00837951 0.00231636\n",
      " 0.00266958 0.00619507 0.00571317 0.00537537 0.00266958 0.00537537\n",
      " 0.00837951 0.00266958 0.00108236 0.00231636 0.00231636 0.00571317\n",
      " 0.00251174 0.00537537 0.00231636 0.00619507 0.00619507 0.00727078\n",
      " 0.00837951 0.00231636 0.00251174 0.00788407 0.00619507 0.0033974\n",
      " 0.00266958 0.00231636 0.00537537 0.00231636 0.00266958 0.00537537\n",
      " 0.00231636 0.00108236 0.00266958 0.00231636 0.00571317 0.00788407\n",
      " 0.00619507 0.00727078 0.00231636 0.00108236 0.00251174 0.00537537\n",
      " 0.00571317 0.00266958 0.01944563 0.00266958 0.00108236 0.00619507\n",
      " 0.00266958 0.00788407 0.00251174 0.00537537 0.00266958 0.0033974\n",
      " 0.00251174 0.00619507 0.00231636 0.00619507 0.00571317]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.28992333390175223\n",
      "Alpha : 0.4478782112261413\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[54 23]\n",
      " [23 49]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6912751677852349\n",
      "Misclassification rate : 0.221\n",
      "True positives : 0.681\n",
      "False positives : 0.299\n",
      "Specificity : 0.701\n",
      "Precision : 0.6912751677852349\n",
      "Prevalence : 0.346\n",
      "Recall : 0.681\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 3]\n",
      " [2 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7058823529411765\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.6\n",
      "False positives : 0.25\n",
      "Specificity : 0.75\n",
      "Precision : 0.7245989304812834\n",
      "Prevalence : 0.024\n",
      "Recall : 0.6\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00417786 0.00362507 0.0046459  0.00160496 0.00417786 0.0053169\n",
      " 0.00148011 0.00169388 0.00417786 0.00160496 0.00170581 0.00343477\n",
      " 0.00343477 0.00148011 0.01242542 0.01137869 0.00395854 0.00069161\n",
      " 0.0053169  0.01137869 0.00362507 0.00148011 0.00170581 0.00170581\n",
      " 0.00365061 0.0053169  0.00170581 0.00362507 0.00362507 0.00160496\n",
      " 0.00170581 0.00343477 0.00362507 0.00395854 0.00535436 0.00148011\n",
      " 0.00069161 0.00417786 0.00969521 0.00170581 0.00170581 0.00148011\n",
      " 0.00535436 0.00170581 0.00170581 0.00365061 0.00170581 0.00503778\n",
      " 0.00170581 0.0053169  0.01242542 0.0046459  0.00395854 0.0053169\n",
      " 0.00160496 0.00343477 0.0084124  0.00170581 0.00160496 0.01233848\n",
      " 0.00894104 0.00169388 0.01311384 0.00894104 0.00417786 0.00343477\n",
      " 0.00069161 0.00169388 0.00343477 0.00503778 0.00362507 0.00217088\n",
      " 0.01311384 0.00160496 0.0053169  0.00535436 0.00160496 0.00343477\n",
      " 0.00069161 0.00535436 0.00160496 0.00343477 0.00217088 0.01137869\n",
      " 0.00343477 0.00362507 0.01233848 0.00362507 0.00535436 0.00148011\n",
      " 0.00170581 0.00969521 0.00894104 0.00343477 0.00170581 0.00343477\n",
      " 0.00535436 0.00170581 0.00069161 0.00148011 0.00362507 0.00894104\n",
      " 0.00160496 0.00343477 0.00148011 0.00969521 0.00395854 0.0046459\n",
      " 0.00535436 0.00148011 0.00160496 0.00503778 0.00395854 0.00217088\n",
      " 0.00170581 0.00148011 0.00343477 0.00148011 0.00170581 0.00343477\n",
      " 0.00362507 0.00169388 0.00417786 0.00148011 0.00894104 0.00503778\n",
      " 0.00969521 0.01137869 0.00148011 0.00069161 0.00160496 0.00343477\n",
      " 0.00365061 0.00417786 0.01242542 0.00170581 0.00069161 0.00395854\n",
      " 0.00170581 0.00503778 0.00160496 0.0084124  0.00170581 0.00217088\n",
      " 0.00160496 0.00395854 0.00148011 0.00395854 0.00365061]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 6\n",
      "################################################\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141\n",
      " 0.00671141 0.00671141 0.00671141 0.00671141 0.00671141]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.21476510067114118\n",
      "Alpha : 0.6482190159990141\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[68 10]\n",
      " [22 49]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.785234899328859\n",
      "Misclassification rate : 0.154\n",
      "True positives : 0.69\n",
      "False positives : 0.128\n",
      "Specificity : 0.872\n",
      "Precision : 0.7912713760285139\n",
      "Prevalence : 0.341\n",
      "Recall : 0.69\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 2]\n",
      " [6 0]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5294117647058824\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.0\n",
      "False positives : 0.182\n",
      "Specificity : 0.818\n",
      "Precision : 0.388235294117647\n",
      "Prevalence : 0.029\n",
      "Recall : 0.0\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00350991 0.00350991 0.0128331  0.00350991 0.00350991 0.0128331\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.00350991 0.0128331  0.0128331  0.00350991 0.00350991\n",
      " 0.0128331  0.0128331  0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.0128331  0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.0128331  0.00350991\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.0128331  0.00350991 0.00350991 0.00350991 0.00350991 0.0128331\n",
      " 0.00350991 0.0128331  0.0128331  0.0128331  0.00350991 0.0128331\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.0128331\n",
      " 0.00350991 0.00350991 0.0128331  0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.00350991 0.0128331  0.00350991 0.00350991 0.0128331\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.00350991 0.0128331  0.00350991 0.00350991 0.0128331\n",
      " 0.00350991 0.00350991 0.0128331  0.00350991 0.0128331  0.00350991\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.0128331  0.00350991 0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.0128331\n",
      " 0.0128331  0.00350991 0.00350991 0.0128331  0.00350991 0.0128331\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991 0.0128331\n",
      " 0.00350991 0.0128331  0.00350991 0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.00350991 0.0128331  0.00350991 0.00350991 0.00350991\n",
      " 0.00350991 0.0128331  0.00350991 0.00350991 0.00350991 0.0128331\n",
      " 0.00350991 0.00350991 0.00350991 0.00350991 0.00350991]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.30021367521367603\n",
      "Alpha : 0.42314028315075114\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[44 34]\n",
      " [15 56]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6711409395973155\n",
      "Misclassification rate : 0.236\n",
      "True positives : 0.789\n",
      "False positives : 0.436\n",
      "Specificity : 0.564\n",
      "Precision : 0.6868944248537013\n",
      "Prevalence : 0.341\n",
      "Recall : 0.789\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[6 5]\n",
      " [4 2]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.47058823529411764\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.333\n",
      "False positives : 0.455\n",
      "Specificity : 0.545\n",
      "Precision : 0.48907563025210077\n",
      "Prevalence : 0.029\n",
      "Recall : 0.333\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00229894 0.00535875 0.00840551 0.00229894 0.00535875 0.01959292\n",
      " 0.00535875 0.00229894 0.00535875 0.00229894 0.00229894 0.00535875\n",
      " 0.00535875 0.00229894 0.00840551 0.00840551 0.00229894 0.00229894\n",
      " 0.01959292 0.00840551 0.00535875 0.00229894 0.00229894 0.00229894\n",
      " 0.00535875 0.00840551 0.00535875 0.00535875 0.00535875 0.00229894\n",
      " 0.00229894 0.00535875 0.00535875 0.00229894 0.00840551 0.00229894\n",
      " 0.00229894 0.00229894 0.00229894 0.00229894 0.00229894 0.00535875\n",
      " 0.00840551 0.00229894 0.00229894 0.00535875 0.00229894 0.00840551\n",
      " 0.00229894 0.01959292 0.00840551 0.01959292 0.00229894 0.00840551\n",
      " 0.00229894 0.00535875 0.00535875 0.00229894 0.00229894 0.01959292\n",
      " 0.00535875 0.00229894 0.00840551 0.00535875 0.00229894 0.00535875\n",
      " 0.00229894 0.00229894 0.00840551 0.00229894 0.00229894 0.01959292\n",
      " 0.00229894 0.00229894 0.00535875 0.00535875 0.00535875 0.00229894\n",
      " 0.00229894 0.00535875 0.00840551 0.00229894 0.00229894 0.00840551\n",
      " 0.00229894 0.00535875 0.01959292 0.00535875 0.00840551 0.00229894\n",
      " 0.00229894 0.00229894 0.00535875 0.00535875 0.00229894 0.00229894\n",
      " 0.00840551 0.00229894 0.00229894 0.00229894 0.00229894 0.00535875\n",
      " 0.00229894 0.00535875 0.00229894 0.00535875 0.00229894 0.00840551\n",
      " 0.00840551 0.00229894 0.00229894 0.00840551 0.00229894 0.00840551\n",
      " 0.00229894 0.00535875 0.00535875 0.00229894 0.00535875 0.00229894\n",
      " 0.00229894 0.00229894 0.00229894 0.00535875 0.00535875 0.00840551\n",
      " 0.00229894 0.00840551 0.00535875 0.00229894 0.00229894 0.00229894\n",
      " 0.00535875 0.00535875 0.01959292 0.00229894 0.00229894 0.00229894\n",
      " 0.00229894 0.00840551 0.00229894 0.00229894 0.00229894 0.00840551\n",
      " 0.00229894 0.00229894 0.00535875 0.00229894 0.00535875]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.29496346200863854\n",
      "Alpha : 0.435699068668201\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[62 16]\n",
      " [35 36]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6577181208053692\n",
      "Misclassification rate : 0.245\n",
      "True positives : 0.507\n",
      "False positives : 0.205\n",
      "Specificity : 0.795\n",
      "Precision : 0.6644933976975766\n",
      "Prevalence : 0.341\n",
      "Recall : 0.507\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 2]\n",
      " [4 2]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6470588235294118\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.333\n",
      "False positives : 0.182\n",
      "Specificity : 0.818\n",
      "Precision : 0.6244343891402715\n",
      "Prevalence : 0.029\n",
      "Recall : 0.333\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00148699 0.0034661  0.01299529 0.00355427 0.0034661  0.01267294\n",
      " 0.0034661  0.00148699 0.0034661  0.00355427 0.00355427 0.0034661\n",
      " 0.0034661  0.00148699 0.01299529 0.00543679 0.00355427 0.00148699\n",
      " 0.01267294 0.00543679 0.0034661  0.00148699 0.00148699 0.00148699\n",
      " 0.0034661  0.01299529 0.0034661  0.0034661  0.0034661  0.00355427\n",
      " 0.00355427 0.0034661  0.0034661  0.00355427 0.01299529 0.00148699\n",
      " 0.00355427 0.00148699 0.00148699 0.00148699 0.00148699 0.00828486\n",
      " 0.00543679 0.00148699 0.00148699 0.0034661  0.00148699 0.00543679\n",
      " 0.00355427 0.03029151 0.00543679 0.01267294 0.00355427 0.01299529\n",
      " 0.00148699 0.0034661  0.0034661  0.00355427 0.00355427 0.01267294\n",
      " 0.0034661  0.00148699 0.00543679 0.0034661  0.00355427 0.0034661\n",
      " 0.00355427 0.00355427 0.00543679 0.00148699 0.00148699 0.01267294\n",
      " 0.00355427 0.00355427 0.0034661  0.0034661  0.0034661  0.00148699\n",
      " 0.00355427 0.0034661  0.00543679 0.00355427 0.00148699 0.00543679\n",
      " 0.00355427 0.0034661  0.01267294 0.0034661  0.00543679 0.00148699\n",
      " 0.00148699 0.00148699 0.00828486 0.0034661  0.00355427 0.00148699\n",
      " 0.01299529 0.00355427 0.00355427 0.00355427 0.00148699 0.0034661\n",
      " 0.00355427 0.0034661  0.00148699 0.0034661  0.00355427 0.00543679\n",
      " 0.00543679 0.00148699 0.00148699 0.01299529 0.00355427 0.01299529\n",
      " 0.00148699 0.0034661  0.0034661  0.00148699 0.0034661  0.00148699\n",
      " 0.00355427 0.00355427 0.00148699 0.0034661  0.0034661  0.01299529\n",
      " 0.00355427 0.00543679 0.0034661  0.00148699 0.00148699 0.00148699\n",
      " 0.00828486 0.0034661  0.03029151 0.00148699 0.00355427 0.00355427\n",
      " 0.00148699 0.00543679 0.00148699 0.00148699 0.00355427 0.01299529\n",
      " 0.00355427 0.00355427 0.0034661  0.00355427 0.0034661 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.29015153474223926\n",
      "Alpha : 0.4473240989701874\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[29 49]\n",
      " [12 59]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5906040268456376\n",
      "Misclassification rate : 0.293\n",
      "True positives : 0.831\n",
      "False positives : 0.628\n",
      "Specificity : 0.372\n",
      "Precision : 0.6305890519755308\n",
      "Prevalence : 0.341\n",
      "Recall : 0.831\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[5 6]\n",
      " [1 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5882352941176471\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.833\n",
      "False positives : 0.545\n",
      "Specificity : 0.455\n",
      "Precision : 0.6996434937611409\n",
      "Prevalence : 0.029\n",
      "Recall : 0.833\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00232582 0.00542141 0.00830836 0.00227237 0.00221601 0.00810228\n",
      " 0.00542141 0.00095068 0.00542141 0.00227237 0.00227237 0.00542141\n",
      " 0.00542141 0.00232582 0.00830836 0.0085038  0.00227237 0.00095068\n",
      " 0.00810228 0.00347594 0.00542141 0.00232582 0.00095068 0.00095068\n",
      " 0.00542141 0.00830836 0.00221601 0.00542141 0.00542141 0.00227237\n",
      " 0.00227237 0.00542141 0.00542141 0.00227237 0.00830836 0.00232582\n",
      " 0.0055593  0.00232582 0.00232582 0.00232582 0.00095068 0.01295852\n",
      " 0.00347594 0.00095068 0.00095068 0.00542141 0.00095068 0.00347594\n",
      " 0.00227237 0.01936647 0.0085038  0.00810228 0.00227237 0.00830836\n",
      " 0.00095068 0.00221601 0.00221601 0.00227237 0.00227237 0.00810228\n",
      " 0.00542141 0.00095068 0.00347594 0.00542141 0.00227237 0.00542141\n",
      " 0.00227237 0.00227237 0.00347594 0.00232582 0.00095068 0.00810228\n",
      " 0.00227237 0.00227237 0.00542141 0.00542141 0.00542141 0.00232582\n",
      " 0.00227237 0.00542141 0.00347594 0.00227237 0.00232582 0.0085038\n",
      " 0.0055593  0.00542141 0.00810228 0.00221601 0.00347594 0.00232582\n",
      " 0.00095068 0.00095068 0.01295852 0.00542141 0.00227237 0.00232582\n",
      " 0.00830836 0.00227237 0.00227237 0.0055593  0.00232582 0.00542141\n",
      " 0.00227237 0.00221601 0.00232582 0.00221601 0.00227237 0.0085038\n",
      " 0.00347594 0.00232582 0.00095068 0.00830836 0.00227237 0.00830836\n",
      " 0.00095068 0.00542141 0.00221601 0.00232582 0.00542141 0.00232582\n",
      " 0.00227237 0.0055593  0.00232582 0.00542141 0.00221601 0.00830836\n",
      " 0.00227237 0.0085038  0.00542141 0.00095068 0.00095068 0.00232582\n",
      " 0.00529681 0.00221601 0.01936647 0.00095068 0.00227237 0.00227237\n",
      " 0.00232582 0.00347594 0.00095068 0.00232582 0.00227237 0.0203262\n",
      " 0.00227237 0.00227237 0.00542141 0.00227237 0.00542141]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2980933753718308\n",
      "Alpha : 0.42819680211500566\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[52 26]\n",
      " [24 47]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6644295302013423\n",
      "Misclassification rate : 0.24\n",
      "True positives : 0.662\n",
      "False positives : 0.333\n",
      "Specificity : 0.667\n",
      "Precision : 0.6649714753003683\n",
      "Prevalence : 0.341\n",
      "Recall : 0.662\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 8]\n",
      " [0 6]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5294117647058824\n",
      "Misclassification rate : 0.038\n",
      "True positives : 1.0\n",
      "False positives : 0.727\n",
      "Specificity : 0.273\n",
      "Precision : 0.7983193277310924\n",
      "Prevalence : 0.029\n",
      "Recall : 1.0\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0015157  0.00353304 0.00541442 0.00348693 0.00144413 0.00528012\n",
      " 0.00353304 0.00061954 0.00353304 0.00348693 0.00148087 0.00831908\n",
      " 0.00831908 0.0015157  0.01274908 0.00554178 0.00348693 0.00061954\n",
      " 0.00528012 0.00226521 0.00353304 0.0015157  0.00061954 0.00061954\n",
      " 0.00353304 0.00541442 0.00144413 0.00353304 0.00353304 0.00348693\n",
      " 0.00148087 0.00831908 0.00353304 0.00348693 0.00541442 0.0015157\n",
      " 0.0036229  0.0015157  0.00356895 0.0015157  0.00061954 0.00844485\n",
      " 0.00226521 0.00061954 0.00061954 0.00353304 0.00061954 0.00533379\n",
      " 0.00148087 0.0126208  0.01304897 0.00528012 0.00348693 0.00541442\n",
      " 0.00145881 0.00340044 0.00340044 0.00148087 0.00348693 0.01243285\n",
      " 0.00353304 0.00061954 0.00226521 0.00353304 0.00148087 0.00831908\n",
      " 0.00148087 0.00148087 0.00226521 0.00356895 0.00061954 0.00528012\n",
      " 0.00348693 0.00348693 0.00831908 0.00353304 0.00353304 0.0015157\n",
      " 0.00148087 0.00831908 0.00533379 0.00148087 0.0015157  0.00554178\n",
      " 0.0036229  0.00353304 0.01243285 0.00144413 0.00226521 0.0015157\n",
      " 0.00061954 0.00145881 0.00844485 0.00831908 0.00148087 0.00356895\n",
      " 0.00541442 0.00148087 0.00148087 0.0036229  0.0015157  0.00353304\n",
      " 0.00348693 0.00340044 0.0015157  0.00340044 0.00348693 0.00554178\n",
      " 0.00226521 0.0015157  0.00145881 0.01274908 0.00348693 0.00541442\n",
      " 0.00061954 0.00353304 0.00340044 0.0015157  0.00353304 0.00356895\n",
      " 0.00148087 0.0036229  0.0015157  0.00353304 0.00144413 0.01274908\n",
      " 0.00348693 0.00554178 0.00353304 0.00061954 0.00145881 0.00356895\n",
      " 0.00345184 0.00144413 0.02971762 0.00061954 0.00148087 0.00348693\n",
      " 0.0015157  0.00533379 0.00145881 0.00356895 0.00148087 0.01324624\n",
      " 0.00348693 0.00348693 0.00353304 0.00348693 0.00353304]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 7\n",
      "################################################\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.24666666666666606\n",
      "Alpha : 0.5582349530340597\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[69 12]\n",
      " [25 44]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7533333333333333\n",
      "Misclassification rate : 0.178\n",
      "True positives : 0.638\n",
      "False positives : 0.148\n",
      "Specificity : 0.852\n",
      "Precision : 0.7578115501519758\n",
      "Prevalence : 0.332\n",
      "Recall : 0.638\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 0]\n",
      " [3 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8125\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.625\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 0.8636363636363636\n",
      "Prevalence : 0.038\n",
      "Recall : 0.625\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00381479 0.00381479 0.01165057 0.00381479 0.00381479 0.01165057\n",
      " 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.00381479 0.00381479 0.01165057 0.01165057 0.00381479 0.00381479\n",
      " 0.01165057 0.01165057 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.00381479 0.01165057 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.00381479 0.00381479 0.00381479 0.00381479 0.01165057 0.00381479\n",
      " 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.01165057 0.00381479 0.00381479 0.00381479 0.00381479 0.01165057\n",
      " 0.00381479 0.01165057 0.01165057 0.01165057 0.00381479 0.01165057\n",
      " 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479 0.01165057\n",
      " 0.00381479 0.00381479 0.01165057 0.00381479 0.00381479 0.00381479\n",
      " 0.00381479 0.00381479 0.01165057 0.00381479 0.00381479 0.01165057\n",
      " 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.00381479 0.00381479 0.01165057 0.00381479 0.00381479 0.01165057\n",
      " 0.00381479 0.00381479 0.01165057 0.00381479 0.01165057 0.01165057\n",
      " 0.00381479 0.01165057 0.01165057 0.00381479 0.00381479 0.00381479\n",
      " 0.01165057 0.00381479 0.00381479 0.01165057 0.01165057 0.00381479\n",
      " 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.01165057 0.01165057 0.00381479 0.00381479 0.01165057 0.00381479\n",
      " 0.01165057 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479\n",
      " 0.01165057 0.00381479 0.01165057 0.00381479 0.00381479 0.00381479\n",
      " 0.00381479 0.00381479 0.00381479 0.01165057 0.00381479 0.00381479\n",
      " 0.00381479 0.00381479 0.01165057 0.00381479 0.00381479 0.00381479\n",
      " 0.01165057 0.00381479 0.00381479 0.00381479 0.00381479 0.00381479]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.34286055967471796\n",
      "Alpha : 0.3252862004771782\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[23 58]\n",
      " [ 1 68]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6066666666666667\n",
      "Misclassification rate : 0.284\n",
      "True positives : 0.986\n",
      "False positives : 0.716\n",
      "Specificity : 0.284\n",
      "Precision : 0.7657539682539682\n",
      "Prevalence : 0.332\n",
      "Recall : 0.986\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[1 7]\n",
      " [1 7]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.875\n",
      "False positives : 0.875\n",
      "Specificity : 0.125\n",
      "Precision : 0.5\n",
      "Prevalence : 0.038\n",
      "Recall : 0.875\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0027555  0.00528129 0.01612936 0.0027555  0.0027555  0.00841545\n",
      " 0.00528129 0.00528129 0.0027555  0.0027555  0.0027555  0.00528129\n",
      " 0.00528129 0.00528129 0.00841545 0.01612936 0.0027555  0.0027555\n",
      " 0.00841545 0.01612936 0.00528129 0.00528129 0.0027555  0.0027555\n",
      " 0.00528129 0.00841545 0.0027555  0.00528129 0.00528129 0.0027555\n",
      " 0.0027555  0.00528129 0.00528129 0.0027555  0.00841545 0.00528129\n",
      " 0.0027555  0.0027555  0.0027555  0.0027555  0.0027555  0.00528129\n",
      " 0.00841545 0.0027555  0.0027555  0.00528129 0.0027555  0.00841545\n",
      " 0.0027555  0.00841545 0.00841545 0.01612936 0.0027555  0.00841545\n",
      " 0.0027555  0.00528129 0.00528129 0.0027555  0.0027555  0.00841545\n",
      " 0.00528129 0.0027555  0.00841545 0.00528129 0.0027555  0.00528129\n",
      " 0.0027555  0.0027555  0.01612936 0.0027555  0.0027555  0.01612936\n",
      " 0.0027555  0.0027555  0.00528129 0.00528129 0.00528129 0.00528129\n",
      " 0.00528129 0.00528129 0.00841545 0.0027555  0.00528129 0.00841545\n",
      " 0.0027555  0.00528129 0.00841545 0.00528129 0.00841545 0.00841545\n",
      " 0.0027555  0.00841545 0.00841545 0.0027555  0.00528129 0.00528129\n",
      " 0.00841545 0.0027555  0.00528129 0.00841545 0.01612936 0.00528129\n",
      " 0.00528129 0.0027555  0.00528129 0.00528129 0.0027555  0.0027555\n",
      " 0.01612936 0.00841545 0.00528129 0.0027555  0.00841545 0.0027555\n",
      " 0.00841545 0.0027555  0.00528129 0.00528129 0.00528129 0.0027555\n",
      " 0.00528129 0.00528129 0.0027555  0.0027555  0.00528129 0.00528129\n",
      " 0.00841545 0.0027555  0.01612936 0.00528129 0.0027555  0.0027555\n",
      " 0.00528129 0.0027555  0.0027555  0.00841545 0.0027555  0.0027555\n",
      " 0.0027555  0.0027555  0.00841545 0.0027555  0.00528129 0.0027555\n",
      " 0.00841545 0.0027555  0.0027555  0.00528129 0.0027555  0.00528129]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.30341811197229424\n",
      "Alpha : 0.4155367976240785\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[49 32]\n",
      " [22 47]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.64\n",
      "Misclassification rate : 0.26\n",
      "True positives : 0.681\n",
      "False positives : 0.395\n",
      "Specificity : 0.605\n",
      "Precision : 0.6463469424139775\n",
      "Prevalence : 0.332\n",
      "Recall : 0.681\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[6 2]\n",
      " [2 6]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.75\n",
      "Misclassification rate : 0.019\n",
      "True positives : 0.75\n",
      "False positives : 0.25\n",
      "Specificity : 0.75\n",
      "Precision : 0.75\n",
      "Prevalence : 0.038\n",
      "Recall : 0.75\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00181859 0.00348558 0.01064515 0.00417509 0.00181859 0.00555408\n",
      " 0.00348558 0.00348558 0.00181859 0.00417509 0.00181859 0.00800213\n",
      " 0.00800213 0.00348558 0.01275095 0.01064515 0.00417509 0.00181859\n",
      " 0.00555408 0.01064515 0.00348558 0.00348558 0.00181859 0.00181859\n",
      " 0.00348558 0.00555408 0.00181859 0.00348558 0.00348558 0.00417509\n",
      " 0.00181859 0.00800213 0.00348558 0.00417509 0.00555408 0.00348558\n",
      " 0.00181859 0.00181859 0.00417509 0.00181859 0.00181859 0.00348558\n",
      " 0.00555408 0.00181859 0.00181859 0.00348558 0.00181859 0.01275095\n",
      " 0.00181859 0.00555408 0.01275095 0.01064515 0.00417509 0.00555408\n",
      " 0.00417509 0.00800213 0.00800213 0.00181859 0.00417509 0.01275095\n",
      " 0.00348558 0.00181859 0.00555408 0.00348558 0.00181859 0.00800213\n",
      " 0.00181859 0.00181859 0.01064515 0.00417509 0.00181859 0.01064515\n",
      " 0.00417509 0.00417509 0.00800213 0.00348558 0.00348558 0.00348558\n",
      " 0.00348558 0.00800213 0.01275095 0.00181859 0.00348558 0.00555408\n",
      " 0.00181859 0.00800213 0.01275095 0.00348558 0.00555408 0.00555408\n",
      " 0.00417509 0.00555408 0.00555408 0.00417509 0.00800213 0.00348558\n",
      " 0.00555408 0.00417509 0.00800213 0.00555408 0.01064515 0.00800213\n",
      " 0.00348558 0.00417509 0.00800213 0.00348558 0.00417509 0.00417509\n",
      " 0.01064515 0.00555408 0.00348558 0.00417509 0.01275095 0.00417509\n",
      " 0.00555408 0.00181859 0.00348558 0.00800213 0.00348558 0.00181859\n",
      " 0.00800213 0.00348558 0.00181859 0.00181859 0.00348558 0.00348558\n",
      " 0.01275095 0.00417509 0.01064515 0.00348558 0.00181859 0.00417509\n",
      " 0.00800213 0.00181859 0.00181859 0.01275095 0.00181859 0.00181859\n",
      " 0.00417509 0.00181859 0.01275095 0.00417509 0.00800213 0.00181859\n",
      " 0.00555408 0.00417509 0.00417509 0.00348558 0.00417509 0.00348558]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2787511217829959\n",
      "Alpha : 0.47533245769477067\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[74  7]\n",
      " [51 18]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6133333333333333\n",
      "Misclassification rate : 0.279\n",
      "True positives : 0.261\n",
      "False positives : 0.086\n",
      "Specificity : 0.914\n",
      "Precision : 0.65088\n",
      "Prevalence : 0.332\n",
      "Recall : 0.261\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 0]\n",
      " [7 1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5625\n",
      "Misclassification rate : 0.034\n",
      "True positives : 0.125\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 0.7666666666666666\n",
      "Prevalence : 0.038\n",
      "Recall : 0.125\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00292529 0.00216691 0.00661786 0.00259556 0.00292529 0.00345285\n",
      " 0.00216691 0.00216691 0.00292529 0.00259556 0.00292529 0.00497475\n",
      " 0.00497475 0.00216691 0.02051052 0.00661786 0.00671583 0.00113058\n",
      " 0.00345285 0.00661786 0.00216691 0.00216691 0.00292529 0.00292529\n",
      " 0.00560673 0.00345285 0.00292529 0.00216691 0.00216691 0.00259556\n",
      " 0.00292529 0.00497475 0.00216691 0.00671583 0.008934   0.00216691\n",
      " 0.00113058 0.00292529 0.00671583 0.00292529 0.00292529 0.00216691\n",
      " 0.008934   0.00292529 0.00292529 0.00560673 0.00292529 0.00792699\n",
      " 0.00292529 0.00345285 0.02051052 0.00661786 0.00671583 0.00345285\n",
      " 0.00259556 0.00497475 0.00497475 0.00292529 0.00259556 0.00792699\n",
      " 0.00560673 0.00113058 0.008934   0.00560673 0.00292529 0.00497475\n",
      " 0.00113058 0.00113058 0.00661786 0.00259556 0.00292529 0.00661786\n",
      " 0.00671583 0.00259556 0.00497475 0.00560673 0.00216691 0.00216691\n",
      " 0.00216691 0.00497475 0.00792699 0.00292529 0.00216691 0.008934\n",
      " 0.00113058 0.00497475 0.00792699 0.00216691 0.00345285 0.008934\n",
      " 0.00259556 0.00345285 0.008934   0.00259556 0.00497475 0.00216691\n",
      " 0.008934   0.00259556 0.00497475 0.00345285 0.00661786 0.00497475\n",
      " 0.00560673 0.00259556 0.00497475 0.00216691 0.00671583 0.00671583\n",
      " 0.00661786 0.008934   0.00216691 0.00259556 0.00792699 0.00671583\n",
      " 0.00345285 0.00292529 0.00216691 0.00497475 0.00216691 0.00292529\n",
      " 0.00497475 0.00216691 0.00113058 0.00292529 0.00216691 0.00560673\n",
      " 0.00792699 0.00671583 0.00661786 0.00216691 0.00113058 0.00259556\n",
      " 0.00497475 0.00292529 0.00292529 0.02051052 0.00292529 0.00113058\n",
      " 0.00671583 0.00292529 0.00792699 0.00259556 0.00497475 0.00292529\n",
      " 0.00345285 0.00259556 0.00671583 0.00216691 0.00671583 0.00560673]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2780420355047956\n",
      "Alpha : 0.47709730358266844\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[57 24]\n",
      " [20 49]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7066666666666667\n",
      "Misclassification rate : 0.212\n",
      "True positives : 0.71\n",
      "False positives : 0.296\n",
      "Specificity : 0.704\n",
      "Precision : 0.708507383027931\n",
      "Prevalence : 0.332\n",
      "Recall : 0.71\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[5 3]\n",
      " [3 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.625\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.625\n",
      "False positives : 0.375\n",
      "Specificity : 0.625\n",
      "Precision : 0.625\n",
      "Prevalence : 0.038\n",
      "Recall : 0.625\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00471379 0.00349174 0.00410693 0.00161076 0.00471379 0.00556389\n",
      " 0.00134475 0.00349174 0.00471379 0.00161076 0.00181538 0.00308724\n",
      " 0.00308724 0.00134475 0.01272846 0.01066395 0.00416773 0.00070162\n",
      " 0.00556389 0.01066395 0.00349174 0.00134475 0.00181538 0.00181538\n",
      " 0.00347943 0.00556389 0.00181538 0.00349174 0.00349174 0.00161076\n",
      " 0.00181538 0.00308724 0.00349174 0.00416773 0.00554428 0.00134475\n",
      " 0.00070162 0.00181538 0.01082183 0.00181538 0.00181538 0.00134475\n",
      " 0.00554428 0.00181538 0.00181538 0.00347943 0.00181538 0.00491935\n",
      " 0.00181538 0.00556389 0.01272846 0.00410693 0.00416773 0.00556389\n",
      " 0.00161076 0.00308724 0.00801627 0.00181538 0.00161076 0.01277347\n",
      " 0.00903462 0.0018218  0.01439616 0.00903462 0.00471379 0.00308724\n",
      " 0.00070162 0.0018218  0.00410693 0.00161076 0.00181538 0.00410693\n",
      " 0.00416773 0.00161076 0.00308724 0.00347943 0.00134475 0.00349174\n",
      " 0.00349174 0.00801627 0.01277347 0.00181538 0.00134475 0.00554428\n",
      " 0.00070162 0.00308724 0.00491935 0.00349174 0.00214278 0.01439616\n",
      " 0.00161076 0.00556389 0.00554428 0.00161076 0.00308724 0.00134475\n",
      " 0.00554428 0.00161076 0.00308724 0.00214278 0.01066395 0.00308724\n",
      " 0.00903462 0.00161076 0.00308724 0.00134475 0.01082183 0.00416773\n",
      " 0.01066395 0.00554428 0.00134475 0.00161076 0.00491935 0.00416773\n",
      " 0.00214278 0.00181538 0.00134475 0.00308724 0.00134475 0.00181538\n",
      " 0.00308724 0.00349174 0.0018218  0.00471379 0.00134475 0.00903462\n",
      " 0.00491935 0.01082183 0.01066395 0.00134475 0.00070162 0.00161076\n",
      " 0.00308724 0.00181538 0.00471379 0.01272846 0.00181538 0.00070162\n",
      " 0.00416773 0.00181538 0.00491935 0.00161076 0.00801627 0.00181538\n",
      " 0.00214278 0.00161076 0.00416773 0.00134475 0.00416773 0.00347943]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 8\n",
      "################################################\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.23333333333333273\n",
      "Alpha : 0.5947920334369199\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[67 13]\n",
      " [22 48]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7666666666666667\n",
      "Misclassification rate : 0.168\n",
      "True positives : 0.686\n",
      "False positives : 0.163\n",
      "Specificity : 0.838\n",
      "Precision : 0.7687112420949223\n",
      "Prevalence : 0.337\n",
      "Recall : 0.686\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 2]\n",
      " [3 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6875\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.571\n",
      "False positives : 0.222\n",
      "Specificity : 0.778\n",
      "Precision : 0.6854166666666666\n",
      "Prevalence : 0.034\n",
      "Recall : 0.571\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00367785 0.01208436 0.01208436 0.00367785 0.00367785 0.01208436\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.01208436 0.01208436 0.00367785 0.00367785\n",
      " 0.01208436 0.01208436 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.01208436 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.01208436 0.00367785\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.01208436 0.00367785 0.00367785 0.00367785 0.00367785 0.01208436\n",
      " 0.00367785 0.01208436 0.01208436 0.01208436 0.00367785 0.01208436\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.01208436\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.01208436 0.00367785 0.00367785 0.01208436\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.01208436 0.00367785 0.00367785 0.01208436\n",
      " 0.00367785 0.01208436 0.01208436 0.00367785 0.01208436 0.00367785\n",
      " 0.00367785 0.01208436 0.01208436 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.00367785 0.01208436 0.01208436 0.00367785\n",
      " 0.00367785 0.01208436 0.00367785 0.01208436 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.01208436\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785\n",
      " 0.01208436 0.00367785 0.01208436 0.00367785 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.00367785 0.01208436 0.00367785 0.00367785\n",
      " 0.00367785 0.00367785 0.01208436 0.00367785 0.00367785 0.00367785\n",
      " 0.01208436 0.00367785 0.00367785 0.00367785 0.00367785 0.00367785]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3459627329192547\n",
      "Alpha : 0.3184166361033456\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[74  6]\n",
      " [53 17]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6066666666666667\n",
      "Misclassification rate : 0.284\n",
      "True positives : 0.243\n",
      "False positives : 0.075\n",
      "Specificity : 0.925\n",
      "Precision : 0.655688691087527\n",
      "Prevalence : 0.337\n",
      "Recall : 0.243\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 1]\n",
      " [5 2]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.625\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.286\n",
      "False positives : 0.111\n",
      "Specificity : 0.889\n",
      "Precision : 0.6378205128205128\n",
      "Prevalence : 0.034\n",
      "Recall : 0.286\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00505685 0.00878895 0.00878895 0.0026749  0.00505685 0.00878895\n",
      " 0.0026749  0.0026749  0.00505685 0.0026749  0.00505685 0.0026749\n",
      " 0.0026749  0.0026749  0.01661538 0.00878895 0.00505685 0.0026749\n",
      " 0.00878895 0.00878895 0.0026749  0.0026749  0.00505685 0.00505685\n",
      " 0.00505685 0.00878895 0.00505685 0.0026749  0.0026749  0.0026749\n",
      " 0.00505685 0.0026749  0.0026749  0.00505685 0.01661538 0.0026749\n",
      " 0.0026749  0.00505685 0.00505685 0.00505685 0.00505685 0.0026749\n",
      " 0.01661538 0.00505685 0.00505685 0.00505685 0.00505685 0.00878895\n",
      " 0.00505685 0.00878895 0.01661538 0.00878895 0.00505685 0.00878895\n",
      " 0.0026749  0.0026749  0.0026749  0.00505685 0.0026749  0.00878895\n",
      " 0.00505685 0.0026749  0.00505685 0.00505685 0.00505685 0.0026749\n",
      " 0.0026749  0.0026749  0.00878895 0.0026749  0.00505685 0.00878895\n",
      " 0.00505685 0.0026749  0.0026749  0.00505685 0.0026749  0.0026749\n",
      " 0.0026749  0.0026749  0.00878895 0.00505685 0.0026749  0.01661538\n",
      " 0.0026749  0.00878895 0.00878895 0.0026749  0.00878895 0.00505685\n",
      " 0.0026749  0.00878895 0.01661538 0.0026749  0.0026749  0.0026749\n",
      " 0.00505685 0.0026749  0.0026749  0.00878895 0.00878895 0.0026749\n",
      " 0.0026749  0.00878895 0.0026749  0.01661538 0.0026749  0.00505685\n",
      " 0.00505685 0.00505685 0.0026749  0.00505685 0.0026749  0.01661538\n",
      " 0.00505685 0.0026749  0.0026749  0.0026749  0.0026749  0.00505685\n",
      " 0.0026749  0.0026749  0.0026749  0.00505685 0.0026749  0.00505685\n",
      " 0.00878895 0.00505685 0.00878895 0.0026749  0.0026749  0.0026749\n",
      " 0.0026749  0.00505685 0.00505685 0.01661538 0.00505685 0.0026749\n",
      " 0.00505685 0.00505685 0.00878895 0.0026749  0.0026749  0.00505685\n",
      " 0.00878895 0.0026749  0.00505685 0.0026749  0.00505685 0.00505685]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3022526047660693\n",
      "Alpha : 0.41829701596945545\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[50 30]\n",
      " [19 51]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6733333333333333\n",
      "Misclassification rate : 0.236\n",
      "True positives : 0.729\n",
      "False positives : 0.375\n",
      "Specificity : 0.625\n",
      "Precision : 0.680300590445518\n",
      "Prevalence : 0.337\n",
      "Recall : 0.729\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 5]\n",
      " [4 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.4375\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.429\n",
      "False positives : 0.556\n",
      "Specificity : 0.444\n",
      "Precision : 0.4453125\n",
      "Prevalence : 0.034\n",
      "Recall : 0.429\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00332825 0.0057846  0.0057846  0.00406417 0.00332825 0.0057846\n",
      " 0.00176053 0.00176053 0.00332825 0.00406417 0.00332825 0.00406417\n",
      " 0.00406417 0.00176053 0.02524494 0.0057846  0.00768324 0.00176053\n",
      " 0.0057846  0.0057846  0.00176053 0.00176053 0.00332825 0.00332825\n",
      " 0.00332825 0.0057846  0.00332825 0.00176053 0.00176053 0.00406417\n",
      " 0.00332825 0.00406417 0.00176053 0.00768324 0.01093569 0.00176053\n",
      " 0.00176053 0.00332825 0.00332825 0.00332825 0.00332825 0.00176053\n",
      " 0.01093569 0.00332825 0.00332825 0.00332825 0.00332825 0.01335369\n",
      " 0.00332825 0.0057846  0.02524494 0.0057846  0.00768324 0.0057846\n",
      " 0.00406417 0.00406417 0.00406417 0.00332825 0.00406417 0.01335369\n",
      " 0.00332825 0.00176053 0.00332825 0.00332825 0.00332825 0.00406417\n",
      " 0.00176053 0.00176053 0.0057846  0.00406417 0.00332825 0.0057846\n",
      " 0.00768324 0.00406417 0.00406417 0.00332825 0.00176053 0.00176053\n",
      " 0.00176053 0.00406417 0.01335369 0.00332825 0.00176053 0.01093569\n",
      " 0.00176053 0.01335369 0.01335369 0.00176053 0.0057846  0.00332825\n",
      " 0.00406417 0.0057846  0.01093569 0.00406417 0.00406417 0.00176053\n",
      " 0.00332825 0.00406417 0.00406417 0.0057846  0.0057846  0.00406417\n",
      " 0.00176053 0.01335369 0.00176053 0.01093569 0.00176053 0.00332825\n",
      " 0.00768324 0.00332825 0.00406417 0.00332825 0.00406417 0.01093569\n",
      " 0.00332825 0.00176053 0.00176053 0.00176053 0.00176053 0.00332825\n",
      " 0.00406417 0.00176053 0.00176053 0.00332825 0.00176053 0.00332825\n",
      " 0.01335369 0.00768324 0.0057846  0.00176053 0.00176053 0.00406417\n",
      " 0.00406417 0.00332825 0.00332825 0.02524494 0.00332825 0.00176053\n",
      " 0.00768324 0.00332825 0.01335369 0.00406417 0.00406417 0.00332825\n",
      " 0.0057846  0.00406417 0.00768324 0.00176053 0.00768324 0.00332825]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.27183414232751985\n",
      "Alpha : 0.4926683696329648\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[55 25]\n",
      " [22 48]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6866666666666666\n",
      "Misclassification rate : 0.226\n",
      "True positives : 0.686\n",
      "False positives : 0.312\n",
      "Specificity : 0.688\n",
      "Precision : 0.687801696020874\n",
      "Prevalence : 0.337\n",
      "Recall : 0.686\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 2]\n",
      " [1 6]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8125\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.857\n",
      "False positives : 0.222\n",
      "Specificity : 0.778\n",
      "Precision : 0.8203125\n",
      "Prevalence : 0.034\n",
      "Recall : 0.857\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00544728 0.00946752 0.00353435 0.00248318 0.00544728 0.00946752\n",
      " 0.00107567 0.00288142 0.00544728 0.00248318 0.00203354 0.00248318\n",
      " 0.00248318 0.00107567 0.0154245  0.00946752 0.00469441 0.00107567\n",
      " 0.00946752 0.00946752 0.00288142 0.00107567 0.00203354 0.00203354\n",
      " 0.00203354 0.00946752 0.00203354 0.00288142 0.00288142 0.00248318\n",
      " 0.00203354 0.00248318 0.00288142 0.00469441 0.00668164 0.00107567\n",
      " 0.00107567 0.00203354 0.00544728 0.00203354 0.00203354 0.00107567\n",
      " 0.00668164 0.00203354 0.00203354 0.00203354 0.00203354 0.00815902\n",
      " 0.00203354 0.00946752 0.0154245  0.00353435 0.00469441 0.00946752\n",
      " 0.00248318 0.00248318 0.00665173 0.00203354 0.00248318 0.02185568\n",
      " 0.00544728 0.00288142 0.00544728 0.00544728 0.00544728 0.00248318\n",
      " 0.00107567 0.00288142 0.00353435 0.00248318 0.00203354 0.00353435\n",
      " 0.00469441 0.00248318 0.00248318 0.00203354 0.00107567 0.00288142\n",
      " 0.00288142 0.00665173 0.02185568 0.00203354 0.00107567 0.00668164\n",
      " 0.00107567 0.00815902 0.00815902 0.00288142 0.00353435 0.00544728\n",
      " 0.00248318 0.00946752 0.00668164 0.00248318 0.00248318 0.00107567\n",
      " 0.00203354 0.00248318 0.00248318 0.00353435 0.00946752 0.00248318\n",
      " 0.00288142 0.02185568 0.00288142 0.00668164 0.00107567 0.00203354\n",
      " 0.01257499 0.00544728 0.00248318 0.00203354 0.00248318 0.00668164\n",
      " 0.00203354 0.00107567 0.00107567 0.00288142 0.00107567 0.00203354\n",
      " 0.00248318 0.00288142 0.00288142 0.00544728 0.00107567 0.00544728\n",
      " 0.00815902 0.01257499 0.00946752 0.00107567 0.00107567 0.00248318\n",
      " 0.00248318 0.00203354 0.00544728 0.0154245  0.00203354 0.00107567\n",
      " 0.00469441 0.00203354 0.00815902 0.00248318 0.00665173 0.00203354\n",
      " 0.00353435 0.00248318 0.00469441 0.00107567 0.00469441 0.00203354]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.32892808716672517\n",
      "Alpha : 0.3565185785120065\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[63 17]\n",
      " [36 34]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6466666666666666\n",
      "Misclassification rate : 0.255\n",
      "True positives : 0.486\n",
      "False positives : 0.212\n",
      "Specificity : 0.787\n",
      "Precision : 0.6505050505050505\n",
      "Prevalence : 0.337\n",
      "Recall : 0.486\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 2]\n",
      " [6 1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.143\n",
      "False positives : 0.222\n",
      "Specificity : 0.778\n",
      "Precision : 0.4487179487179487\n",
      "Prevalence : 0.034\n",
      "Recall : 0.143\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00381369 0.0066283  0.00504828 0.00354685 0.00381369 0.0066283\n",
      " 0.00075309 0.00201731 0.00381369 0.00354685 0.0014237  0.0017385\n",
      " 0.0017385  0.00075309 0.02203156 0.0066283  0.00670526 0.00075309\n",
      " 0.0066283  0.0066283  0.00201731 0.00075309 0.0014237  0.0014237\n",
      " 0.0014237  0.01352291 0.0014237  0.00201731 0.00201731 0.00354685\n",
      " 0.00290461 0.0017385  0.00201731 0.00670526 0.00954371 0.00075309\n",
      " 0.00153643 0.0014237  0.00778061 0.00290461 0.0014237  0.00153643\n",
      " 0.00467788 0.0014237  0.0014237  0.0014237  0.0014237  0.00571221\n",
      " 0.00290461 0.01352291 0.01079884 0.00247443 0.0032866  0.01352291\n",
      " 0.0017385  0.0017385  0.00465694 0.00290461 0.00354685 0.01530137\n",
      " 0.00381369 0.00201731 0.00381369 0.00381369 0.00778061 0.0017385\n",
      " 0.00153643 0.00411567 0.00247443 0.0017385  0.00290461 0.00247443\n",
      " 0.00670526 0.00354685 0.0017385  0.0014237  0.00075309 0.00201731\n",
      " 0.00411567 0.00465694 0.01530137 0.00290461 0.00075309 0.00467788\n",
      " 0.00153643 0.00571221 0.00571221 0.00201731 0.00247443 0.00381369\n",
      " 0.0017385  0.01352291 0.00467788 0.00354685 0.0017385  0.00075309\n",
      " 0.00290461 0.00354685 0.0017385  0.00247443 0.0066283  0.0017385\n",
      " 0.00201731 0.01530137 0.00201731 0.00467788 0.00075309 0.00290461\n",
      " 0.00880387 0.00381369 0.0017385  0.00290461 0.0017385  0.00954371\n",
      " 0.00290461 0.00153643 0.00153643 0.00201731 0.00075309 0.00290461\n",
      " 0.0017385  0.00411567 0.00411567 0.00381369 0.00075309 0.00381369\n",
      " 0.01165392 0.01796146 0.0066283  0.00075309 0.00075309 0.0017385\n",
      " 0.0017385  0.00290461 0.00381369 0.02203156 0.0014237  0.00153643\n",
      " 0.00670526 0.00290461 0.00571221 0.0017385  0.00465694 0.00290461\n",
      " 0.00504828 0.00354685 0.00670526 0.00075309 0.00670526 0.0014237 ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 9\n",
      "################################################\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2533333333333327\n",
      "Alpha : 0.540456355784356\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[67 11]\n",
      " [27 45]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7466666666666667\n",
      "Misclassification rate : 0.183\n",
      "True positives : 0.625\n",
      "False positives : 0.141\n",
      "Specificity : 0.859\n",
      "Precision : 0.7563525835866262\n",
      "Prevalence : 0.346\n",
      "Recall : 0.625\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[10  1]\n",
      " [ 1  4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.875\n",
      "Misclassification rate : 0.01\n",
      "True positives : 0.8\n",
      "False positives : 0.091\n",
      "Specificity : 0.909\n",
      "Precision : 0.875\n",
      "Prevalence : 0.024\n",
      "Recall : 0.8\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00388322 0.00388322 0.01144527 0.00388322 0.00388322 0.01144527\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322\n",
      " 0.00388322 0.00388322 0.01144527 0.01144527 0.00388322 0.00388322\n",
      " 0.01144527 0.01144527 0.00388322 0.00388322 0.00388322 0.00388322\n",
      " 0.00388322 0.01144527 0.00388322 0.00388322 0.00388322 0.00388322\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.01144527 0.00388322\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322\n",
      " 0.01144527 0.00388322 0.00388322 0.00388322 0.00388322 0.01144527\n",
      " 0.00388322 0.01144527 0.01144527 0.01144527 0.00388322 0.01144527\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322 0.01144527\n",
      " 0.00388322 0.00388322 0.01144527 0.00388322 0.00388322 0.00388322\n",
      " 0.00388322 0.00388322 0.01144527 0.00388322 0.00388322 0.01144527\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322\n",
      " 0.00388322 0.00388322 0.01144527 0.00388322 0.00388322 0.01144527\n",
      " 0.00388322 0.00388322 0.01144527 0.00388322 0.01144527 0.01144527\n",
      " 0.00388322 0.01144527 0.01144527 0.00388322 0.00388322 0.00388322\n",
      " 0.01144527 0.00388322 0.00388322 0.01144527 0.01144527 0.00388322\n",
      " 0.00388322 0.01144527 0.00388322 0.01144527 0.00388322 0.00388322\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322 0.01144527\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322\n",
      " 0.00388322 0.00388322 0.00388322 0.00388322 0.01144527 0.01144527\n",
      " 0.00388322 0.00388322 0.01144527 0.00388322 0.01144527 0.00388322\n",
      " 0.00388322 0.00388322 0.00388322 0.01144527 0.00388322 0.00388322\n",
      " 0.00388322 0.00388322 0.01144527 0.00388322 0.00388322 0.00388322\n",
      " 0.01144527 0.00388322 0.00388322 0.00388322 0.00388322 0.00388322]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.32401315789473656\n",
      "Alpha : 0.3676947428791238\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[23 55]\n",
      " [ 2 70]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.62\n",
      "Misclassification rate : 0.274\n",
      "True positives : 0.972\n",
      "False positives : 0.705\n",
      "Specificity : 0.295\n",
      "Precision : 0.7472000000000001\n",
      "Prevalence : 0.346\n",
      "Recall : 0.972\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 8]\n",
      " [1 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.4375\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.8\n",
      "False positives : 0.727\n",
      "Specificity : 0.273\n",
      "Precision : 0.6197916666666666\n",
      "Prevalence : 0.024\n",
      "Recall : 0.8\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00268846 0.00560892 0.01653156 0.00268846 0.00268846 0.00792388\n",
      " 0.00560892 0.00268846 0.00268846 0.00268846 0.00268846 0.00560892\n",
      " 0.00560892 0.00560892 0.00792388 0.01653156 0.00268846 0.00268846\n",
      " 0.00792388 0.01653156 0.00560892 0.00560892 0.00268846 0.00268846\n",
      " 0.00560892 0.00792388 0.00268846 0.00560892 0.00560892 0.00268846\n",
      " 0.00268846 0.00560892 0.00560892 0.00268846 0.00792388 0.00560892\n",
      " 0.00268846 0.00268846 0.00268846 0.00268846 0.00268846 0.00560892\n",
      " 0.00792388 0.00268846 0.00268846 0.00560892 0.00268846 0.00792388\n",
      " 0.00268846 0.00792388 0.00792388 0.01653156 0.00268846 0.00792388\n",
      " 0.00268846 0.00560892 0.00560892 0.00268846 0.00268846 0.00792388\n",
      " 0.00560892 0.00268846 0.00792388 0.00560892 0.00268846 0.00560892\n",
      " 0.00268846 0.00268846 0.01653156 0.00268846 0.00268846 0.01653156\n",
      " 0.00268846 0.00268846 0.00560892 0.00560892 0.00560892 0.00560892\n",
      " 0.00560892 0.00560892 0.00792388 0.00268846 0.00560892 0.00792388\n",
      " 0.00268846 0.00560892 0.00792388 0.00560892 0.00792388 0.00792388\n",
      " 0.00268846 0.00792388 0.00792388 0.00268846 0.00560892 0.00268846\n",
      " 0.00792388 0.00268846 0.00560892 0.00792388 0.01653156 0.00560892\n",
      " 0.00560892 0.00792388 0.00560892 0.00792388 0.00560892 0.00268846\n",
      " 0.00268846 0.00560892 0.00560892 0.00268846 0.00560892 0.00792388\n",
      " 0.00268846 0.00268846 0.00560892 0.00560892 0.00560892 0.00268846\n",
      " 0.00560892 0.00560892 0.00268846 0.00268846 0.01653156 0.00792388\n",
      " 0.00560892 0.00268846 0.00792388 0.00268846 0.00792388 0.00268846\n",
      " 0.00560892 0.00560892 0.00268846 0.00792388 0.00268846 0.00268846\n",
      " 0.00268846 0.00268846 0.00792388 0.00268846 0.00560892 0.00268846\n",
      " 0.00792388 0.00268846 0.00268846 0.00560892 0.00268846 0.00560892]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3002907710195865\n",
      "Alpha : 0.4229568097969481\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[47 31]\n",
      " [22 50]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6466666666666666\n",
      "Misclassification rate : 0.255\n",
      "True positives : 0.694\n",
      "False positives : 0.397\n",
      "Specificity : 0.603\n",
      "Precision : 0.650499194847021\n",
      "Prevalence : 0.346\n",
      "Recall : 0.694\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 3]\n",
      " [2 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6875\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.6\n",
      "False positives : 0.273\n",
      "Specificity : 0.727\n",
      "Precision : 0.70625\n",
      "Prevalence : 0.024\n",
      "Recall : 0.6\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00176123 0.00367444 0.01082994 0.00410385 0.00176123 0.00519099\n",
      " 0.00367444 0.00176123 0.00176123 0.00410385 0.00176123 0.00856184\n",
      " 0.00856184 0.00367444 0.01209556 0.01082994 0.00410385 0.00176123\n",
      " 0.00519099 0.01082994 0.00367444 0.00367444 0.00176123 0.00176123\n",
      " 0.00367444 0.00519099 0.00176123 0.00367444 0.00367444 0.00410385\n",
      " 0.00176123 0.00856184 0.00367444 0.00410385 0.00519099 0.00367444\n",
      " 0.00176123 0.00176123 0.00410385 0.00176123 0.00176123 0.00367444\n",
      " 0.00519099 0.00176123 0.00176123 0.00367444 0.00176123 0.01209556\n",
      " 0.00176123 0.00519099 0.01209556 0.01082994 0.00410385 0.00519099\n",
      " 0.00410385 0.00856184 0.00856184 0.00176123 0.00410385 0.01209556\n",
      " 0.00367444 0.00176123 0.00519099 0.00367444 0.00176123 0.00856184\n",
      " 0.00176123 0.00176123 0.01082994 0.00410385 0.00176123 0.01082994\n",
      " 0.00410385 0.00410385 0.00856184 0.00367444 0.00367444 0.00367444\n",
      " 0.00367444 0.00856184 0.01209556 0.00176123 0.00367444 0.00519099\n",
      " 0.00176123 0.00856184 0.01209556 0.00367444 0.00519099 0.00519099\n",
      " 0.00410385 0.00519099 0.00519099 0.00410385 0.00856184 0.00176123\n",
      " 0.00519099 0.00410385 0.00856184 0.00519099 0.01082994 0.00856184\n",
      " 0.00367444 0.01209556 0.00367444 0.00519099 0.00367444 0.00176123\n",
      " 0.00410385 0.00367444 0.00856184 0.00176123 0.00856184 0.00519099\n",
      " 0.00176123 0.00176123 0.00367444 0.00367444 0.00367444 0.00410385\n",
      " 0.00856184 0.00367444 0.00410385 0.00410385 0.01082994 0.00519099\n",
      " 0.00367444 0.00410385 0.01209556 0.00410385 0.00519099 0.00176123\n",
      " 0.00367444 0.00856184 0.00176123 0.01209556 0.00176123 0.00176123\n",
      " 0.00410385 0.00176123 0.01209556 0.00410385 0.00856184 0.00176123\n",
      " 0.00519099 0.00410385 0.00410385 0.00367444 0.00410385 0.00367444]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.28926050513361046\n",
      "Alpha : 0.4494891430659648\n",
      "\n",
      ":: Treinamento :: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[73  5]\n",
      " [55 17]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6\n",
      "Misclassification rate : 0.288\n",
      "True positives : 0.236\n",
      "False positives : 0.064\n",
      "Specificity : 0.936\n",
      "Precision : 0.6674715909090908\n",
      "Prevalence : 0.346\n",
      "Recall : 0.236\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[10  1]\n",
      " [ 4  1]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6875\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.2\n",
      "False positives : 0.091\n",
      "Specificity : 0.909\n",
      "Precision : 0.6473214285714286\n",
      "Prevalence : 0.024\n",
      "Recall : 0.2\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00276075 0.00234413 0.006909   0.00261807 0.00276075 0.00331161\n",
      " 0.00234413 0.00112358 0.00276075 0.00261807 0.00276075 0.00546206\n",
      " 0.00546206 0.00234413 0.01895993 0.006909   0.00643283 0.00112358\n",
      " 0.00813694 0.006909   0.00234413 0.00234413 0.00276075 0.00276075\n",
      " 0.00575973 0.00331161 0.00276075 0.00234413 0.00234413 0.00261807\n",
      " 0.00276075 0.00546206 0.00234413 0.00643283 0.00813694 0.00234413\n",
      " 0.00112358 0.00276075 0.00643283 0.00276075 0.00276075 0.00234413\n",
      " 0.00813694 0.00276075 0.00276075 0.00575973 0.00276075 0.00771641\n",
      " 0.00276075 0.00331161 0.01895993 0.006909   0.00643283 0.00331161\n",
      " 0.00261807 0.00546206 0.00546206 0.00276075 0.00261807 0.00771641\n",
      " 0.00575973 0.00112358 0.00813694 0.00575973 0.00276075 0.00546206\n",
      " 0.00112358 0.00112358 0.006909   0.00261807 0.00276075 0.006909\n",
      " 0.00643283 0.00261807 0.00546206 0.00234413 0.00234413 0.00234413\n",
      " 0.00234413 0.00546206 0.00771641 0.00276075 0.00234413 0.00813694\n",
      " 0.00112358 0.00546206 0.00771641 0.00234413 0.00331161 0.00813694\n",
      " 0.00261807 0.00331161 0.00813694 0.00261807 0.00546206 0.00112358\n",
      " 0.00813694 0.00261807 0.00546206 0.00331161 0.006909   0.00546206\n",
      " 0.00234413 0.00771641 0.00234413 0.00813694 0.00234413 0.00276075\n",
      " 0.00643283 0.00575973 0.00546206 0.00276075 0.00546206 0.00813694\n",
      " 0.00276075 0.00112358 0.00234413 0.00234413 0.00575973 0.00261807\n",
      " 0.00546206 0.00234413 0.00643283 0.00643283 0.006909   0.00813694\n",
      " 0.00234413 0.00261807 0.00771641 0.00643283 0.00331161 0.00276075\n",
      " 0.00234413 0.00546206 0.00276075 0.01895993 0.00276075 0.00112358\n",
      " 0.00643283 0.00276075 0.00771641 0.00261807 0.00546206 0.00276075\n",
      " 0.00331161 0.00261807 0.00643283 0.00234413 0.00643283 0.00575973]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.28577964344618695\n",
      "Alpha : 0.4579852504805733\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[55 23]\n",
      " [21 51]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7066666666666667\n",
      "Misclassification rate : 0.212\n",
      "True positives : 0.708\n",
      "False positives : 0.295\n",
      "Specificity : 0.705\n",
      "Precision : 0.707126600284495\n",
      "Prevalence : 0.346\n",
      "Recall : 0.708\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 4]\n",
      " [2 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.625\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.6\n",
      "False positives : 0.364\n",
      "Specificity : 0.636\n",
      "Precision : 0.6686507936507936\n",
      "Prevalence : 0.024\n",
      "Recall : 0.6\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00436443 0.00370579 0.00437034 0.00165608 0.00436443 0.00523528\n",
      " 0.00148279 0.00177626 0.00436443 0.00165608 0.00174633 0.00345506\n",
      " 0.00345506 0.00148279 0.01199323 0.01092234 0.00406913 0.00071073\n",
      " 0.01286357 0.01092234 0.00370579 0.00148279 0.00174633 0.00174633\n",
      " 0.00364336 0.00523528 0.00174633 0.00370579 0.00370579 0.00165608\n",
      " 0.00174633 0.00345506 0.00370579 0.00406913 0.00514708 0.00148279\n",
      " 0.00071073 0.00174633 0.01016957 0.00174633 0.00174633 0.00148279\n",
      " 0.00514708 0.00174633 0.00174633 0.00364336 0.00174633 0.00488107\n",
      " 0.00174633 0.00523528 0.01199323 0.00437034 0.00406913 0.00523528\n",
      " 0.00165608 0.00345506 0.00863489 0.00174633 0.00165608 0.01219876\n",
      " 0.00910548 0.00177626 0.01286357 0.00910548 0.00436443 0.00345506\n",
      " 0.00071073 0.00177626 0.00437034 0.00165608 0.00174633 0.00437034\n",
      " 0.00406913 0.00165608 0.00345506 0.00148279 0.00148279 0.00370579\n",
      " 0.00370579 0.00863489 0.01219876 0.00174633 0.00148279 0.00514708\n",
      " 0.00071073 0.00345506 0.00488107 0.00370579 0.00209478 0.01286357\n",
      " 0.00165608 0.00523528 0.00514708 0.00165608 0.00345506 0.00071073\n",
      " 0.00514708 0.00165608 0.00345506 0.00209478 0.01092234 0.00345506\n",
      " 0.00370579 0.01219876 0.00370579 0.00514708 0.00148279 0.00174633\n",
      " 0.01016957 0.00910548 0.00345506 0.00174633 0.00345506 0.00514708\n",
      " 0.00174633 0.00071073 0.00148279 0.00370579 0.00910548 0.00165608\n",
      " 0.00345506 0.00148279 0.01016957 0.00406913 0.01092234 0.00514708\n",
      " 0.00148279 0.00165608 0.00488107 0.00406913 0.00209478 0.00174633\n",
      " 0.00148279 0.00345506 0.00436443 0.01199323 0.00174633 0.00071073\n",
      " 0.00406913 0.00174633 0.00488107 0.00165608 0.00863489 0.00174633\n",
      " 0.00209478 0.00165608 0.00406913 0.00148279 0.00406913 0.00364336]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "################################################\n",
      "K-fold : 10\n",
      "################################################\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2399999999999994\n",
      "Alpha : 0.5763397549691943\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[68 16]\n",
      " [20 46]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.76\n",
      "Misclassification rate : 0.173\n",
      "True positives : 0.697\n",
      "False positives : 0.19\n",
      "Specificity : 0.81\n",
      "Precision : 0.7591788856304985\n",
      "Prevalence : 0.317\n",
      "Recall : 0.697\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[2 3]\n",
      " [3 8]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.625\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.727\n",
      "False positives : 0.6\n",
      "Specificity : 0.4\n",
      "Precision : 0.625\n",
      "Prevalence : 0.053\n",
      "Recall : 0.727\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00374634 0.01186342 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.01186342 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.01186342 0.00374634 0.00374634\n",
      " 0.00374634 0.01186342 0.00374634 0.01186342 0.00374634 0.00374634\n",
      " 0.00374634 0.01186342 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.01186342 0.00374634\n",
      " 0.01186342 0.01186342 0.01186342 0.01186342 0.00374634 0.00374634\n",
      " 0.01186342 0.00374634 0.00374634 0.00374634 0.00374634 0.01186342\n",
      " 0.00374634 0.01186342 0.01186342 0.01186342 0.00374634 0.01186342\n",
      " 0.00374634 0.01186342 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.01186342 0.00374634 0.00374634 0.01186342\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634 0.01186342\n",
      " 0.01186342 0.00374634 0.00374634 0.00374634 0.01186342 0.01186342\n",
      " 0.00374634 0.01186342 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.01186342 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634 0.01186342\n",
      " 0.00374634 0.00374634 0.01186342 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.01186342 0.01186342\n",
      " 0.00374634 0.00374634 0.01186342 0.00374634 0.01186342 0.00374634\n",
      " 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634 0.00374634\n",
      " 0.00374634 0.00374634 0.01186342 0.00374634 0.01186342 0.00374634\n",
      " 0.01186342 0.00374634 0.00374634 0.01186342 0.00374634 0.00374634]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2858187134502929\n",
      "Alpha : 0.4578895460287072\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[51 33]\n",
      " [17 49]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6666666666666666\n",
      "Misclassification rate : 0.24\n",
      "True positives : 0.742\n",
      "False positives : 0.393\n",
      "Specificity : 0.607\n",
      "Precision : 0.6829268292682926\n",
      "Prevalence : 0.317\n",
      "Recall : 0.742\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3 2]\n",
      " [6 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.455\n",
      "False positives : 0.4\n",
      "Specificity : 0.6\n",
      "Precision : 0.5952380952380952\n",
      "Prevalence : 0.053\n",
      "Recall : 0.455\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00237    0.00750501 0.00237    0.00592197 0.00237    0.00237\n",
      " 0.00237    0.00237    0.00750501 0.00592197 0.00237    0.00592197\n",
      " 0.00592197 0.00237    0.00592197 0.00750501 0.00592197 0.00237\n",
      " 0.00237    0.00750501 0.00237    0.00750501 0.00237    0.00237\n",
      " 0.00237    0.00750501 0.00237    0.00237    0.00237    0.00592197\n",
      " 0.00237    0.00592197 0.00237    0.00592197 0.00750501 0.00237\n",
      " 0.00750501 0.00750501 0.00750501 0.00750501 0.00237    0.00237\n",
      " 0.00750501 0.00237    0.00237    0.00237    0.00237    0.01875292\n",
      " 0.00237    0.00750501 0.01875292 0.00750501 0.00592197 0.00750501\n",
      " 0.00592197 0.01875292 0.00592197 0.00237    0.00592197 0.00592197\n",
      " 0.00237    0.00237    0.00237    0.00237    0.00237    0.00592197\n",
      " 0.00237    0.00237    0.00750501 0.00592197 0.00237    0.00750501\n",
      " 0.00592197 0.00592197 0.00592197 0.00237    0.00237    0.00237\n",
      " 0.00237    0.00592197 0.00592197 0.00237    0.00237    0.00750501\n",
      " 0.00750501 0.00592197 0.00592197 0.00237    0.00750501 0.00750501\n",
      " 0.00592197 0.00750501 0.00237    0.00592197 0.00592197 0.00237\n",
      " 0.00237    0.00592197 0.00592197 0.00237    0.00237    0.00592197\n",
      " 0.00237    0.00592197 0.00237    0.00750501 0.00237    0.00237\n",
      " 0.00592197 0.00237    0.00592197 0.00237    0.00592197 0.00750501\n",
      " 0.00237    0.00237    0.00750501 0.00237    0.00237    0.00592197\n",
      " 0.00592197 0.00237    0.00592197 0.00592197 0.01875292 0.00750501\n",
      " 0.00237    0.00592197 0.01875292 0.00592197 0.00750501 0.00237\n",
      " 0.00237    0.00592197 0.00237    0.00237    0.00592197 0.00237\n",
      " 0.00237    0.00237    0.00750501 0.00237    0.01875292 0.00592197\n",
      " 0.00750501 0.00237    0.00237    0.01875292 0.00592197 0.00237   ]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2737659257552875\n",
      "Alpha : 0.48779946173064825\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[59 25]\n",
      " [24 42]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6733333333333333\n",
      "Misclassification rate : 0.236\n",
      "True positives : 0.636\n",
      "False positives : 0.298\n",
      "Specificity : 0.702\n",
      "Precision : 0.6738931846790145\n",
      "Prevalence : 0.317\n",
      "Recall : 0.636\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[ 4  1]\n",
      " [ 1 10]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.875\n",
      "Misclassification rate : 0.01\n",
      "True positives : 0.909\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.875\n",
      "Prevalence : 0.053\n",
      "Recall : 0.909\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00386009 0.01222361 0.00145512 0.00363595 0.00386009 0.00386009\n",
      " 0.00145512 0.00386009 0.01222361 0.00363595 0.00145512 0.00363595\n",
      " 0.00363595 0.00145512 0.00363595 0.01222361 0.00363595 0.00145512\n",
      " 0.00386009 0.01222361 0.00386009 0.00460789 0.00145512 0.00145512\n",
      " 0.00145512 0.01222361 0.00145512 0.00386009 0.00386009 0.00363595\n",
      " 0.00145512 0.00363595 0.00386009 0.00363595 0.00460789 0.00145512\n",
      " 0.00460789 0.01222361 0.01222361 0.00460789 0.00145512 0.00145512\n",
      " 0.00460789 0.00145512 0.00145512 0.00145512 0.00145512 0.01151384\n",
      " 0.00145512 0.01222361 0.01151384 0.00460789 0.00363595 0.01222361\n",
      " 0.00363595 0.01151384 0.00964529 0.00145512 0.00363595 0.00964529\n",
      " 0.00386009 0.00386009 0.00386009 0.00386009 0.00386009 0.00363595\n",
      " 0.00145512 0.00386009 0.00460789 0.00363595 0.00145512 0.00460789\n",
      " 0.00363595 0.00363595 0.00363595 0.00145512 0.00145512 0.00386009\n",
      " 0.00386009 0.00964529 0.00964529 0.00145512 0.00145512 0.01222361\n",
      " 0.00460789 0.00363595 0.00363595 0.00386009 0.00460789 0.01222361\n",
      " 0.00363595 0.01222361 0.00145512 0.00363595 0.00363595 0.00145512\n",
      " 0.00145512 0.00363595 0.00363595 0.00145512 0.00386009 0.00363595\n",
      " 0.00386009 0.00964529 0.00386009 0.00460789 0.00145512 0.00145512\n",
      " 0.00964529 0.00386009 0.00363595 0.00145512 0.00363595 0.00460789\n",
      " 0.00145512 0.00145512 0.00460789 0.00386009 0.00386009 0.00363595\n",
      " 0.00363595 0.00145512 0.00964529 0.00363595 0.01151384 0.00460789\n",
      " 0.00145512 0.00363595 0.01151384 0.00363595 0.00460789 0.00145512\n",
      " 0.00145512 0.00363595 0.00145512 0.00145512 0.00363595 0.00386009\n",
      " 0.00386009 0.00386009 0.00460789 0.00386009 0.01151384 0.00964529\n",
      " 0.01222361 0.00145512 0.00145512 0.01151384 0.00363595 0.00145512]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.33152619510633213\n",
      "Alpha : 0.35064519222030915\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[78  6]\n",
      " [50 16]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6266666666666667\n",
      "Misclassification rate : 0.269\n",
      "True positives : 0.242\n",
      "False positives : 0.071\n",
      "Specificity : 0.929\n",
      "Precision : 0.66125\n",
      "Prevalence : 0.317\n",
      "Recall : 0.242\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 1]\n",
      " [8 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.4375\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.273\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.6197916666666666\n",
      "Prevalence : 0.053\n",
      "Recall : 0.273\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00548126 0.00860828 0.00102475 0.00256056 0.00548126 0.0027184\n",
      " 0.00102475 0.0027184  0.01735733 0.00256056 0.00206625 0.00256056\n",
      " 0.00256056 0.00102475 0.00516299 0.00860828 0.00516299 0.00102475\n",
      " 0.0027184  0.00860828 0.0027184  0.00324503 0.00206625 0.00206625\n",
      " 0.00206625 0.00860828 0.00206625 0.0027184  0.0027184  0.00256056\n",
      " 0.00206625 0.00256056 0.0027184  0.00516299 0.00654313 0.00102475\n",
      " 0.00324503 0.01735733 0.01735733 0.00654313 0.00206625 0.00102475\n",
      " 0.00654313 0.00206625 0.00206625 0.00206625 0.00206625 0.00810843\n",
      " 0.00206625 0.00860828 0.01634946 0.00324503 0.00516299 0.00860828\n",
      " 0.00256056 0.00810843 0.00679253 0.00206625 0.00256056 0.00679253\n",
      " 0.00548126 0.0027184  0.00548126 0.00548126 0.00548126 0.00256056\n",
      " 0.00102475 0.0027184  0.00324503 0.00256056 0.00206625 0.00324503\n",
      " 0.00516299 0.00256056 0.00256056 0.00206625 0.00102475 0.0027184\n",
      " 0.0027184  0.00679253 0.00679253 0.00206625 0.00102475 0.01735733\n",
      " 0.00324503 0.00256056 0.00256056 0.0027184  0.00324503 0.01735733\n",
      " 0.00256056 0.00860828 0.00206625 0.00256056 0.00256056 0.00102475\n",
      " 0.00206625 0.00256056 0.00256056 0.00102475 0.0027184  0.00256056\n",
      " 0.0027184  0.00679253 0.0027184  0.00654313 0.00102475 0.00206625\n",
      " 0.01369615 0.00548126 0.00256056 0.00206625 0.00256056 0.00654313\n",
      " 0.00206625 0.00102475 0.00324503 0.0027184  0.00548126 0.00256056\n",
      " 0.00256056 0.00102475 0.01369615 0.00516299 0.00810843 0.00654313\n",
      " 0.00102475 0.00256056 0.00810843 0.00516299 0.00324503 0.00206625\n",
      " 0.00102475 0.00256056 0.00102475 0.00206625 0.00256056 0.0027184\n",
      " 0.0027184  0.00548126 0.00324503 0.00548126 0.00810843 0.01369615\n",
      " 0.00860828 0.00102475 0.00102475 0.00810843 0.00256056 0.00206625]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.3135240781357535\n",
      "Alpha : 0.3918474947245899\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[63 21]\n",
      " [30 36]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.66\n",
      "Misclassification rate : 0.245\n",
      "True positives : 0.545\n",
      "False positives : 0.25\n",
      "Specificity : 0.75\n",
      "Precision : 0.6572495755517826\n",
      "Prevalence : 0.317\n",
      "Recall : 0.545\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4 1]\n",
      " [7 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.364\n",
      "False positives : 0.2\n",
      "Specificity : 0.8\n",
      "Precision : 0.6636363636363637\n",
      "Prevalence : 0.053\n",
      "Recall : 0.364\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00370428 0.00581754 0.00151633 0.00378889 0.00370428 0.00183712\n",
      " 0.00069253 0.00183712 0.01173021 0.00378889 0.00305746 0.00173044\n",
      " 0.00173044 0.00069253 0.00763974 0.00581754 0.00763974 0.00069253\n",
      " 0.00183712 0.00581754 0.00183712 0.00219302 0.00139639 0.00139639\n",
      " 0.00139639 0.01273777 0.00139639 0.00183712 0.00183712 0.00378889\n",
      " 0.00305746 0.00173044 0.00183712 0.00763974 0.00968195 0.00069253\n",
      " 0.00480171 0.01173021 0.01173021 0.0044219  0.00139639 0.00151633\n",
      " 0.0044219  0.00139639 0.00139639 0.00139639 0.00139639 0.00547974\n",
      " 0.00305746 0.01273777 0.01104908 0.00219302 0.00763974 0.01273777\n",
      " 0.00173044 0.00547974 0.00459044 0.00305746 0.00378889 0.00459044\n",
      " 0.00370428 0.00183712 0.00370428 0.00370428 0.00811069 0.00173044\n",
      " 0.00151633 0.00402246 0.00480171 0.00378889 0.00139639 0.00480171\n",
      " 0.00763974 0.00378889 0.00173044 0.00139639 0.00069253 0.00183712\n",
      " 0.00402246 0.00459044 0.00459044 0.00305746 0.00069253 0.01173021\n",
      " 0.00480171 0.00173044 0.00173044 0.00183712 0.00480171 0.01173021\n",
      " 0.00173044 0.01273777 0.00139639 0.00378889 0.00173044 0.00069253\n",
      " 0.00305746 0.00378889 0.00173044 0.00069253 0.00183712 0.00378889\n",
      " 0.00183712 0.00459044 0.00183712 0.0044219  0.00069253 0.00139639\n",
      " 0.00925595 0.00811069 0.00173044 0.00305746 0.00173044 0.00968195\n",
      " 0.00305746 0.00151633 0.00480171 0.00183712 0.00370428 0.00378889\n",
      " 0.00173044 0.00069253 0.00925595 0.00763974 0.00547974 0.0044219\n",
      " 0.00069253 0.00173044 0.01199815 0.00763974 0.00219302 0.00139639\n",
      " 0.00069253 0.00173044 0.00069253 0.00139639 0.00173044 0.00402246\n",
      " 0.00402246 0.00370428 0.00219302 0.00370428 0.01199815 0.02026635\n",
      " 0.00581754 0.00069253 0.00069253 0.00547974 0.00173044 0.00305746]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "scores_test = []\n",
    "\n",
    "error_train = []\n",
    "error_test = []\n",
    "\n",
    "n_modelos = 5\n",
    "alpha = 0.5\n",
    "\n",
    "print()\n",
    "print(\"....Iniciando treinamento com 10 K-folds....\" )\n",
    "print()\n",
    "\n",
    "# Define quantos folds\n",
    "kf = KFold(n_splits=10)\n",
    "kfold = 0    \n",
    "for train_index, test_index in kf.split(trainData):\n",
    "    \n",
    "    print(\"################################################\")\n",
    "    print(\"K-fold : \"+str(kfold+1))    \n",
    "    print(\"################################################\")\n",
    "    #print(train_index, test_index)\n",
    "    #print()\n",
    "\n",
    "    # Obten os subdados de treinamento e teste no n fold\n",
    "    #---------------------------------------------------------------------\n",
    "    X_train, X_test = trainData.iloc[train_index,:], trainData.iloc[test_index,:]\n",
    "    #print(len(X_train), len(X_test))\n",
    "\n",
    "    y_train, y_test = trainLabels.iloc[train_index], trainLabels.iloc[test_index]\n",
    "    #print(len(y_train), len(y_test))\n",
    "    \n",
    "    print(\"....Inicializando vetor de pesos....\")\n",
    "    print()\n",
    "\n",
    "\n",
    "    n_train, n_test = len(X_train), len(X_test)\n",
    "    #pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)]\n",
    "\n",
    "    # Initialize weights\n",
    "    w = np.ones(n_train) / n_train\n",
    "    print(w)\n",
    "    \n",
    "    pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)]\n",
    "    #print(pred_train)\n",
    "    \n",
    "    # Fit um classificador\n",
    "    model = DecisionTreeClassifier(max_depth = 1, random_state = 1)\n",
    "    \n",
    "    model_index = 0\n",
    "    for i in range(n_modelos):\n",
    "        print()\n",
    "        # Treina o modelo de classificação\n",
    "        #---------------------------------------------------------------------\n",
    "        print(\"Treinando o modelo....\")\n",
    "\n",
    "        # Treina o classificador com os pesos de treinamento\n",
    "        model.fit(X=X_train, y=y_train, sample_weight=w)\n",
    "        print(model)\n",
    "\n",
    "        # Classifica o treino\n",
    "        pred_train_i = model.predict(X_train)\n",
    "        #print(pred_train_i)\n",
    "\n",
    "        # Classifica o teste\n",
    "        pred_test_i = model.predict(X_test)\n",
    "        #print(pred_test_i)        \n",
    "\n",
    "        print()\n",
    "        print(\"...:::: Avaliação ::::....  \")\n",
    "        print()\n",
    "\n",
    "        # Obtem o index dos erros da classificação de treino e teste\n",
    "        #---------------------------------------------------------------------\n",
    "        missTrain = [int(x) for x in (pred_train_i != y_train)]\n",
    "        #print(\"Training Miss : \"+str(missTrain))\n",
    "        missTest = [int(x) for x in (pred_test_i != y_test)]\n",
    "        #print(\"Testing Miss : \"+str(missTest))\n",
    "\n",
    "        # Equivale os valores entre 1/-1 para atualização dos pesos\n",
    "        #---------------------------------------------------------------------\n",
    "        miss2Train = [x if x==1 else -1 for x in missTrain]\n",
    "        #print(\"Training Miss2 : \"+str(miss2))\n",
    "        miss2Test = [x if x==1 else -1 for x in missTest]\n",
    "        #print(\"Testing Miss2 : \"+str(miss2Test))\n",
    "\n",
    "\n",
    "        # Calcula o erro\n",
    "        #---------------------------------------------------------------------\n",
    "        err_m = np.dot(w, missTrain) / sum(w)\n",
    "        print(\"Error : \"+str(err_m))\n",
    "\n",
    "        # Calcula o Alpha \n",
    "        #---------------------------------------------------------------------\n",
    "        alpha_m = alpha * np.log( (1 - err_m) / float(err_m))\n",
    "        print(\"Alpha : \"+str(alpha_m))\n",
    "\n",
    "\n",
    "        # Mostra a Matriz de Confusão para treino e teste\n",
    "        #---------------------------------------------------------------------\n",
    "        print()\n",
    "        print(\":: Treinamento :: \")\n",
    "        print(\"\")\n",
    "        train_acc_score, train_precision_score, train_recall_score = printCM(y_train, pred_train_i)\n",
    "\n",
    "        print()\n",
    "        print(\":: Teste ::\")\n",
    "        print()\n",
    "        test_acc_score, test_precision_score, test_recall_score = printCM(y_test, pred_test_i)\n",
    "        print\n",
    "\n",
    "\n",
    "        # Atualiza os valores dos pesos\n",
    "        #---------------------------------------------------------------------\n",
    "        w = np.multiply(w, np.exp([float(x) * alpha_m for x in miss2Train]))\n",
    "        print()\n",
    "        print(\"Novos pesos atualizados : \")\n",
    "        print(w)\n",
    "        print()\n",
    "        print(\"---------------------------------------------------------------------------\")\n",
    "        print()\n",
    "\n",
    "\n",
    "        scores.append([kfold, model_index, train_acc_score, train_precision_score, train_recall_score, err_m, alpha_m, model])\n",
    "        scores_test.append([kfold, model_index, test_acc_score, test_precision_score, test_recall_score, err_m, alpha_m, model])\n",
    "        error_train.append([kfold, model_index, err_m, alpha_m])\n",
    "    \n",
    "        model_index += 1\n",
    "        # Add to prediction\n",
    "        pred_train = [sum(x) for x in zip(pred_train, [x * alpha_m for x in pred_train_i])]\n",
    "        pred_test = [sum(x) for x in zip(pred_test, [x * alpha_m for x in pred_test_i])]\n",
    "        \n",
    "    pred_train, pred_test = np.sign(pred_train), np.sign(pred_test)\n",
    "    #print(pred_train)\n",
    "    print()\n",
    "    print()\n",
    "    kfold += 1 \n",
    "    print\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Apresentação dos Resultados</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-fold</th>\n",
       "      <th>Model Idx</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Error</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.691275</td>\n",
       "      <td>0.730376</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.354966</td>\n",
       "      <td>0.298641</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.655689</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.345963</td>\n",
       "      <td>0.318417</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.711409</td>\n",
       "      <td>0.714398</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.343233</td>\n",
       "      <td>0.324460</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.765754</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.342861</td>\n",
       "      <td>0.325286</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.661250</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.331526</td>\n",
       "      <td>0.350645</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630872</td>\n",
       "      <td>0.741690</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.330326</td>\n",
       "      <td>0.353356</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.604027</td>\n",
       "      <td>0.654423</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.329606</td>\n",
       "      <td>0.354983</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.650505</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.328928</td>\n",
       "      <td>0.356519</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.747200</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.324013</td>\n",
       "      <td>0.367695</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.624161</td>\n",
       "      <td>0.713117</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.322394</td>\n",
       "      <td>0.371396</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.617450</td>\n",
       "      <td>0.728226</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.318461</td>\n",
       "      <td>0.380426</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.610738</td>\n",
       "      <td>0.671962</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.314399</td>\n",
       "      <td>0.389816</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.657250</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.313524</td>\n",
       "      <td>0.391847</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.604027</td>\n",
       "      <td>0.644513</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.305511</td>\n",
       "      <td>0.410595</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.646347</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.303418</td>\n",
       "      <td>0.415537</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.680301</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.302253</td>\n",
       "      <td>0.418297</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.651007</td>\n",
       "      <td>0.654022</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.301149</td>\n",
       "      <td>0.420916</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.671141</td>\n",
       "      <td>0.736375</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.300335</td>\n",
       "      <td>0.422851</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.650499</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.300291</td>\n",
       "      <td>0.422957</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671141</td>\n",
       "      <td>0.686894</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.300214</td>\n",
       "      <td>0.423140</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.617450</td>\n",
       "      <td>0.673821</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.300109</td>\n",
       "      <td>0.423390</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.664430</td>\n",
       "      <td>0.664971</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.298093</td>\n",
       "      <td>0.428197</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671141</td>\n",
       "      <td>0.676598</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.297936</td>\n",
       "      <td>0.428572</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.657718</td>\n",
       "      <td>0.664493</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.294963</td>\n",
       "      <td>0.435699</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.657718</td>\n",
       "      <td>0.663634</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.292291</td>\n",
       "      <td>0.442141</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.590604</td>\n",
       "      <td>0.630589</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.290152</td>\n",
       "      <td>0.447324</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.691275</td>\n",
       "      <td>0.691275</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.289923</td>\n",
       "      <td>0.447878</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.667472</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.289261</td>\n",
       "      <td>0.449489</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.597315</td>\n",
       "      <td>0.655946</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.288480</td>\n",
       "      <td>0.451389</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.644295</td>\n",
       "      <td>0.678966</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.286149</td>\n",
       "      <td>0.457081</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.285819</td>\n",
       "      <td>0.457890</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.707127</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.285780</td>\n",
       "      <td>0.457985</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.597315</td>\n",
       "      <td>0.743044</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.284101</td>\n",
       "      <td>0.462104</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.650880</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.278751</td>\n",
       "      <td>0.475332</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.708507</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.278042</td>\n",
       "      <td>0.477097</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.630872</td>\n",
       "      <td>0.640680</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.277014</td>\n",
       "      <td>0.479660</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.673893</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.273766</td>\n",
       "      <td>0.487799</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.687802</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.271834</td>\n",
       "      <td>0.492668</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.657718</td>\n",
       "      <td>0.665312</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.269164</td>\n",
       "      <td>0.499434</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.644295</td>\n",
       "      <td>0.688609</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.268821</td>\n",
       "      <td>0.500306</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.756353</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.540456</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.759389</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.248322</td>\n",
       "      <td>0.553790</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.558235</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758389</td>\n",
       "      <td>0.769235</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.241611</td>\n",
       "      <td>0.571934</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758389</td>\n",
       "      <td>0.763976</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.241611</td>\n",
       "      <td>0.571934</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.759179</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.576340</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.768952</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.234899</td>\n",
       "      <td>0.590425</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.768711</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.594792</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>0.778958</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.221477</td>\n",
       "      <td>0.628541</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.785235</td>\n",
       "      <td>0.791271</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.214765</td>\n",
       "      <td>0.648219</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n-fold  Model Idx       Acc  Precision  Recall     Error     Alpha  \\\n",
       "0        3          1  0.691275   0.730376   0.412  0.354966  0.298641   \n",
       "1        7          1  0.606667   0.655689   0.243  0.345963  0.318417   \n",
       "2        2          4  0.711409   0.714398   0.538  0.343233  0.324460   \n",
       "3        6          1  0.606667   0.765754   0.986  0.342861  0.325286   \n",
       "4        9          3  0.626667   0.661250   0.242  0.331526  0.350645   \n",
       "5        0          1  0.630872   0.741690   0.957  0.330326  0.353356   \n",
       "6        0          3  0.604027   0.654423   0.243  0.329606  0.354983   \n",
       "7        7          4  0.646667   0.650505   0.486  0.328928  0.356519   \n",
       "8        8          1  0.620000   0.747200   0.972  0.324013  0.367695   \n",
       "9        1          1  0.624161   0.713117   0.929  0.322394  0.371396   \n",
       "10       4          1  0.617450   0.728226   0.958  0.318461  0.380426   \n",
       "11       1          4  0.610738   0.671962   0.243  0.314399  0.389816   \n",
       "12       9          4  0.660000   0.657250   0.545  0.313524  0.391847   \n",
       "13       3          4  0.604027   0.644513   0.221  0.305511  0.410595   \n",
       "14       6          2  0.640000   0.646347   0.681  0.303418  0.415537   \n",
       "15       7          2  0.673333   0.680301   0.729  0.302253  0.418297   \n",
       "16       4          2  0.651007   0.654022   0.694  0.301149  0.420916   \n",
       "17       1          2  0.671141   0.736375   0.357  0.300335  0.422851   \n",
       "18       8          2  0.646667   0.650499   0.694  0.300291  0.422957   \n",
       "19       5          1  0.671141   0.686894   0.789  0.300214  0.423140   \n",
       "20       1          3  0.617450   0.673821   0.871  0.300109  0.423390   \n",
       "21       5          4  0.664430   0.664971   0.662  0.298093  0.428197   \n",
       "22       2          1  0.671141   0.676598   0.677  0.297936  0.428572   \n",
       "23       5          2  0.657718   0.664493   0.507  0.294963  0.435699   \n",
       "24       3          3  0.657718   0.663634   0.691  0.292291  0.442141   \n",
       "25       5          3  0.590604   0.630589   0.831  0.290152  0.447324   \n",
       "26       4          4  0.691275   0.691275   0.681  0.289923  0.447878   \n",
       "27       8          3  0.600000   0.667472   0.236  0.289261  0.449489   \n",
       "28       4          3  0.597315   0.655946   0.250  0.288480  0.451389   \n",
       "29       2          3  0.644295   0.678966   0.277  0.286149  0.457081   \n",
       "30       9          1  0.666667   0.682927   0.742  0.285819  0.457890   \n",
       "31       8          4  0.706667   0.707127   0.708  0.285780  0.457985   \n",
       "32       3          2  0.597315   0.743044   0.971  0.284101  0.462104   \n",
       "33       6          3  0.613333   0.650880   0.261  0.278751  0.475332   \n",
       "34       6          4  0.706667   0.708507   0.710  0.278042  0.477097   \n",
       "35       2          2  0.630872   0.640680   0.662  0.277014  0.479660   \n",
       "36       9          2  0.673333   0.673893   0.636  0.273766  0.487799   \n",
       "37       7          3  0.686667   0.687802   0.686  0.271834  0.492668   \n",
       "38       0          2  0.657718   0.665312   0.486  0.269164  0.499434   \n",
       "39       0          4  0.644295   0.688609   0.857  0.268821  0.500306   \n",
       "40       8          0  0.746667   0.756353   0.625  0.253333  0.540456   \n",
       "41       1          0  0.751678   0.759389   0.629  0.248322  0.553790   \n",
       "42       6          0  0.753333   0.757812   0.638  0.246667  0.558235   \n",
       "43       4          0  0.758389   0.769235   0.639  0.241611  0.571934   \n",
       "44       3          0  0.758389   0.763976   0.632  0.241611  0.571934   \n",
       "45       9          0  0.760000   0.759179   0.697  0.240000  0.576340   \n",
       "46       0          0  0.765101   0.768952   0.671  0.234899  0.590425   \n",
       "47       7          0  0.766667   0.768711   0.686  0.233333  0.594792   \n",
       "48       2          0  0.778523   0.778958   0.754  0.221477  0.628541   \n",
       "49       5          0  0.785235   0.791271   0.690  0.214765  0.648219   \n",
       "\n",
       "                                                Model  \n",
       "0   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "1   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "2   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "3   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "4   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "5   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "6   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "7   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "8   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "9   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "10  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "11  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "12  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "13  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "14  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "15  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "16  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "17  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "18  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "19  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "20  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "21  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "22  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "23  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "24  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "25  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "26  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "27  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "28  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "29  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "30  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "31  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "32  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "33  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "34  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "35  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "36  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "37  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "38  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "39  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "40  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "41  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "42  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "43  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "44  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "45  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "46  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "47  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "48  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "49  DecisionTreeClassifier(class_weight=None, crit...  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresDF = pd.DataFrame(scores, columns=[\"n-fold\", \n",
    "                                         \"Model Idx\",\n",
    "                                         \"Acc\", \n",
    "                                         \"Precision\", \n",
    "                                         \"Recall\",\n",
    "                                         \"Error\", \n",
    "                                         \"Alpha\", \n",
    "                                         \"Model\"])\n",
    "\n",
    "scoresDF = scoresDF.sort_values([\"Error\"], ascending=False)\n",
    "scoresDF = scoresDF.reset_index(drop=True)\n",
    "scoresDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_error = scoresDF.copy()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plot1 = plt.plot(df_error.index.values, df_error[\"Error\"])\n",
    "#plot1.set_xlabel('Number of iterations', fontsize = 12)\n",
    "#plot1.set_xticklabels(range(0,450,50))\n",
    "#plot1.set_ylabel('Error rate', fontsize = 12)\n",
    "#plot1.set_title('Error rate vs number of iterations', fontsize = 16)\n",
    "#plt.axhline(y=error_test[0], linewidth=1, color = 'red', ls = 'dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-fold</th>\n",
       "      <th>Model Idx</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Error</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.691275</td>\n",
       "      <td>0.730376</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.354966</td>\n",
       "      <td>0.298641</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.655689</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.345963</td>\n",
       "      <td>0.318417</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.711409</td>\n",
       "      <td>0.714398</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.343233</td>\n",
       "      <td>0.324460</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.765754</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.342861</td>\n",
       "      <td>0.325286</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.661250</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.331526</td>\n",
       "      <td>0.350645</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630872</td>\n",
       "      <td>0.741690</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.330326</td>\n",
       "      <td>0.353356</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.604027</td>\n",
       "      <td>0.654423</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.329606</td>\n",
       "      <td>0.354983</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.650505</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.328928</td>\n",
       "      <td>0.356519</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.747200</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.324013</td>\n",
       "      <td>0.367695</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.624161</td>\n",
       "      <td>0.713117</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.322394</td>\n",
       "      <td>0.371396</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n-fold  Model Idx       Acc  Precision  Recall     Error     Alpha  \\\n",
       "0       3          1  0.691275   0.730376   0.412  0.354966  0.298641   \n",
       "1       7          1  0.606667   0.655689   0.243  0.345963  0.318417   \n",
       "2       2          4  0.711409   0.714398   0.538  0.343233  0.324460   \n",
       "3       6          1  0.606667   0.765754   0.986  0.342861  0.325286   \n",
       "4       9          3  0.626667   0.661250   0.242  0.331526  0.350645   \n",
       "5       0          1  0.630872   0.741690   0.957  0.330326  0.353356   \n",
       "6       0          3  0.604027   0.654423   0.243  0.329606  0.354983   \n",
       "7       7          4  0.646667   0.650505   0.486  0.328928  0.356519   \n",
       "8       8          1  0.620000   0.747200   0.972  0.324013  0.367695   \n",
       "9       1          1  0.624161   0.713117   0.929  0.322394  0.371396   \n",
       "\n",
       "                                               Model  \n",
       "0  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "1  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "2  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "3  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "4  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "5  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "6  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "7  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "8  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "9  DecisionTreeClassifier(class_weight=None, crit...  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_error.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = scoresDF.iloc[0, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_validation = bestModel.predict(validationData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[11 11]\n",
      " [ 5 15]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6190476190476191\n",
      "Misclassification rate : 0.077\n",
      "True positives : 0.75\n",
      "False positives : 0.5\n",
      "Specificity : 0.5\n",
      "Precision : 0.6348443223443223\n",
      "Prevalence : 0.096\n",
      "Recall : 0.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6190476190476191, 0.6348443223443223, 0.75)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printCM(validationLabels, pred_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-fold</th>\n",
       "      <th>Model Idx</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Error</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.284386</td>\n",
       "      <td>0.461404</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.824421</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.292199</td>\n",
       "      <td>0.442364</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.824421</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.234899</td>\n",
       "      <td>0.590425</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.272401</td>\n",
       "      <td>0.491237</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.823413</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.594792</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.783193</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.228188</td>\n",
       "      <td>0.609286</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.228188</td>\n",
       "      <td>0.609286</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.297824</td>\n",
       "      <td>0.428841</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.576340</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.613615</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.330460</td>\n",
       "      <td>0.353053</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.740642</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.313838</td>\n",
       "      <td>0.391119</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.716063</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.303256</td>\n",
       "      <td>0.415921</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.724599</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.221477</td>\n",
       "      <td>0.628541</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.346349</td>\n",
       "      <td>0.317564</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.312135</td>\n",
       "      <td>0.395080</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.679545</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.293168</td>\n",
       "      <td>0.440024</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.660504</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.322634</td>\n",
       "      <td>0.370846</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.748366</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.294620</td>\n",
       "      <td>0.436524</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.290704</td>\n",
       "      <td>0.445984</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.679739</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.288810</td>\n",
       "      <td>0.450586</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.221477</td>\n",
       "      <td>0.628541</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.400762</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.637821</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.299245</td>\n",
       "      <td>0.425449</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.275973</td>\n",
       "      <td>0.482263</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.620455</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.594792</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.307928</td>\n",
       "      <td>0.404911</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.306868</td>\n",
       "      <td>0.407402</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.592320</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.296351</td>\n",
       "      <td>0.432367</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.592320</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.255644</td>\n",
       "      <td>0.534366</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.659314</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.255102</td>\n",
       "      <td>0.535792</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.254514</td>\n",
       "      <td>0.537339</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.642157</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.249083</td>\n",
       "      <td>0.551754</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.572727</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.300834</td>\n",
       "      <td>0.421665</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.572727</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.265735</td>\n",
       "      <td>0.508186</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.550654</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.325932</td>\n",
       "      <td>0.363321</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.603361</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.324114</td>\n",
       "      <td>0.367464</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.579323</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.311132</td>\n",
       "      <td>0.397415</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.579323</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.307393</td>\n",
       "      <td>0.406167</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.486425</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.270961</td>\n",
       "      <td>0.494877</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.563725</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.268816</td>\n",
       "      <td>0.500319</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.798319</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.201342</td>\n",
       "      <td>0.688963</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.524510</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.317268</td>\n",
       "      <td>0.383179</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.325351</td>\n",
       "      <td>0.364645</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.668182</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.292650</td>\n",
       "      <td>0.441274</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.463542</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.277019</td>\n",
       "      <td>0.479649</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.302656</td>\n",
       "      <td>0.417340</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.308496</td>\n",
       "      <td>0.403580</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.300187</td>\n",
       "      <td>0.423204</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.432127</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.284734</td>\n",
       "      <td>0.460550</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n-fold  Model Idx       Acc  Precision  Recall     Error     Alpha  \\\n",
       "42       8          2  0.875000   0.875000   0.833  0.284386  0.461404   \n",
       "27       5          2  0.823529   0.824421   0.714  0.292199  0.442364   \n",
       "15       3          0  0.823529   0.824421   0.714  0.234899  0.590425   \n",
       "37       7          2  0.812500   0.892857   1.000  0.272401  0.491237   \n",
       "40       8          0  0.812500   0.823413   0.833  0.233333  0.594792   \n",
       "5        1          0  0.764706   0.783193   0.667  0.228188  0.609286   \n",
       "20       4          0  0.764706   0.764706   0.667  0.228188  0.609286   \n",
       "48       9          3  0.750000   0.750000   0.750  0.297824  0.428841   \n",
       "45       9          0  0.750000   0.766667   0.625  0.240000  0.576340   \n",
       "35       7          0  0.750000   0.800000   0.750  0.226667  0.613615   \n",
       "1        0          1  0.705882   0.774510   0.667  0.330460  0.353053   \n",
       "8        1          3  0.705882   0.740642   0.556  0.313838  0.391119   \n",
       "17       3          2  0.705882   0.716063   0.429  0.303256  0.415921   \n",
       "0        0          0  0.705882   0.724599   0.750  0.221477  0.628541   \n",
       "36       7          1  0.687500   0.550000   0.000  0.346349  0.317564   \n",
       "46       9          1  0.687500   0.690476   0.750  0.312135  0.395080   \n",
       "41       8          1  0.687500   0.679545   0.500  0.293168  0.440024   \n",
       "6        1          1  0.647059   0.660504   0.556  0.322634  0.370846   \n",
       "3        0          3  0.647059   0.748366   0.583  0.294620  0.436524   \n",
       "28       5          3  0.647059   0.647059   0.571  0.290704  0.445984   \n",
       "23       4          3  0.647059   0.679739   0.667  0.288810  0.450586   \n",
       "25       5          0  0.647059   0.647059   0.571  0.221477  0.628541   \n",
       "34       6          4  0.625000   0.625000   0.571  0.309700  0.400762   \n",
       "32       6          2  0.625000   0.637821   0.286  0.299245  0.425449   \n",
       "43       8          3  0.625000   0.708333   0.833  0.275973  0.482263   \n",
       "30       6          0  0.625000   0.620455   0.429  0.233333  0.594792   \n",
       "21       4          1  0.588235   0.572549   0.333  0.307928  0.404911   \n",
       "24       4          4  0.588235   0.809955   1.000  0.306868  0.407402   \n",
       "9        1          4  0.588235   0.592320   0.556  0.296351  0.432367   \n",
       "7        1          2  0.588235   0.592320   0.556  0.255644  0.534366   \n",
       "2        0          2  0.588235   0.659314   0.583  0.255102  0.535792   \n",
       "18       3          3  0.588235   0.676471   0.857  0.254514  0.537339   \n",
       "22       4          2  0.588235   0.642157   0.667  0.249083  0.551754   \n",
       "49       9          4  0.562500   0.572727   0.750  0.300834  0.421665   \n",
       "47       9          2  0.562500   0.572727   0.375  0.265735  0.508186   \n",
       "19       3          4  0.529412   0.550654   0.571  0.325932  0.363321   \n",
       "12       2          2  0.529412   0.603361   0.455  0.324114  0.367464   \n",
       "29       5          4  0.529412   0.579323   0.714  0.311132  0.397415   \n",
       "16       3          1  0.529412   0.579323   0.714  0.307393  0.406167   \n",
       "13       2          3  0.529412   0.486425   0.727  0.270961  0.494877   \n",
       "14       2          4  0.529412   0.563725   0.545  0.268816  0.500319   \n",
       "10       2          0  0.529412   0.798319   0.273  0.201342  0.688963   \n",
       "26       5          1  0.470588   0.524510   0.714  0.317268  0.383179   \n",
       "44       8          4  0.437500   0.775000   1.000  0.325351  0.364645   \n",
       "39       7          4  0.437500   0.668182   0.750  0.292650  0.441274   \n",
       "31       6          1  0.437500   0.463542   0.714  0.277019  0.479649   \n",
       "4        0          4  0.411765   0.411765   0.583  0.302656  0.417340   \n",
       "38       7          3  0.375000   0.500000   0.250  0.308496  0.403580   \n",
       "33       6          3  0.375000   0.175000   0.857  0.300187  0.423204   \n",
       "11       2          1  0.352941   0.432127   0.182  0.284734  0.460550   \n",
       "\n",
       "                                                Model  \n",
       "42  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "27  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "15  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "37  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "40  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "5   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "20  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "48  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "45  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "35  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "1   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "8   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "17  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "0   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "36  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "46  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "41  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "6   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "3   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "28  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "23  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "25  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "34  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "32  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "43  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "30  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "21  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "24  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "9   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "7   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "2   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "18  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "22  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "49  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "47  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "19  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "12  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "29  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "16  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "13  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "14  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "10  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "26  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "44  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "39  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "31  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "4   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "38  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "33  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "11  DecisionTreeClassifier(class_weight=None, crit...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresDF = pd.DataFrame(scores_test, columns=[\"n-fold\", \n",
    "                                         \"Model Idx\",\n",
    "                                         \"Acc\", \n",
    "                                         \"Precision\", \n",
    "                                         \"Recall\",\n",
    "                                         \"Error\", \n",
    "                                         \"Alpha\", \n",
    "                                         \"Model\"])\n",
    "\n",
    "scoresDF.sort_values([\"Acc\",\"Error\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
