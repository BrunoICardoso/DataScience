{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 1 - Machine Learning II \n",
    "Prof: Carlos Padilha\n",
    "\n",
    "#### Alunos:  \n",
    "\n",
    "Roberto A. Coutinho  \n",
    "Thais Galho\n",
    "\n",
    "\n",
    "## Sistemas com Multi-classificadores ou Ensembles\n",
    "\n",
    "#### Este trabalho visa avaliar o entendimento em relaçãao á construção de sistemas com multi-classificadores ou ensembles. Para tal, os alunos deverão fazer o seguinte:\n",
    "\n",
    "\n",
    "* Implementar o algoritmo AdaBoost (nos mesmos moldes que fizemos com o algoritmo Bagging).\n",
    "    – Podem escolher qualquer tipo de classificador (MLP, SVM, etc).\n",
    "* Processar os dados presente no arquivo sonar.all-data.\n",
    "* Realizar treinamento e teste usando validação cruzada com 10 folds.\n",
    "* Avaliar os resultados em termos de acurácia, recall e precisão.\n",
    "\n",
    "Obs: O trabalho pode ser feito em dupla e deve ser enviado por email (carlos.engcomp@gmail.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modelos\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# K-fold CrossValidation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9  ...      51      52      53      54      55      56      57      58  \\\n",
       "0  0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090   \n",
       "1  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
       "2  0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
       "3  0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
       "4  0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
       "\n",
       "       59  60  \n",
       "0  0.0032   R  \n",
       "1  0.0044   R  \n",
       "2  0.0078   R  \n",
       "3  0.0117   R  \n",
       "4  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_data = pd.read_csv('sonar.all-data.csv', header=None)\n",
    "imported_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 208)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separação entre dados e labels\n",
    "\n",
    "labels = imported_data.iloc[:,-1]\n",
    "data = imported_data.iloc[:,:-1]\n",
    "len(data), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def getAccuracy(testset, predictions):\n",
    "    correct = 0\n",
    "    for id_test, test in enumerate(testset):\n",
    "        if test == predictions[id_test]:\n",
    "            correct += 1\n",
    "    return (correct / float(len(testset))) * 100.0\n",
    "\n",
    "def printCM(Y_test, predictions):\n",
    "    cm = confusion_matrix(Y_test, predictions)\n",
    "    print ('Confusion Matrix : ')\n",
    "    print (cm)\n",
    "    print\n",
    "    tn = float(cm[0][0])\n",
    "    fp = float(cm[0][1])\n",
    "    fn = float(cm[1][0])\n",
    "    tp = float(cm[1][1])\n",
    "\n",
    "    actual_yes = fn+tp\n",
    "    actual_no = tn+fp\n",
    "    predicted_yes = fp+tp\n",
    "    predicted_no = tn+fn\n",
    "\n",
    "    total = float(len(imported_data))\n",
    "    print ('Total : '+ str(total))\n",
    "\n",
    "    acc = getAccuracy(Y_test, predictions) /100\n",
    "    print ('Acurácia : ' + str(acc))\n",
    "\n",
    "    misclassification_rate = round((fp+fn)/total,3) # Overall, how often is it wrong?\n",
    "    print ('Misclassification rate : ' +str(misclassification_rate))\n",
    "\n",
    "    true_positive = round(tp/actual_yes,3) # When it's actually yes, how often does it predict yes?\n",
    "    print ('True positives : ' +str(true_positive))\n",
    "\n",
    "    false_positive = round(fp/actual_no,3) # When it's actually no, how often does it predict yes?\n",
    "    print ('False positives : ' +str(false_positive))\n",
    "\n",
    "    specificity = round(tn/actual_no,3) # When it's actually no, how often does it predict no?\n",
    "    print ('Specificity : ' +str(specificity))\n",
    "\n",
    "    precision = round(tp/predicted_yes,3) # When it predicts yes, how often is it correct?\n",
    "    print ('Precision : ' +str(precision))\n",
    "\n",
    "    prevalence = round(actual_yes/total,3) # How often does the yes condition actually occur in our sample?\n",
    "    print ('Prevalence : ' +str(prevalence))\n",
    "    \n",
    "    recall = round(tp / (tp + fn), 3)\n",
    "    print ('Recall : ' +str(recall))\n",
    "\n",
    "    #f1 = round(2 * ((precision * true_positive) / (precision + true_positive)),3)\n",
    "    #print ('F1 Score : ' +str(f1))\n",
    "    \n",
    "    return acc, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Separação entre treino e teste</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 187\n",
      "21 21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# utiliza 25% do dataset para teste\n",
    "trainData, validationData, trainLabels, validationLabels = train_test_split(data, labels, \n",
    "                                                    train_size=0.90, \n",
    "                                                    test_size=0.10, \n",
    "                                                    stratify=labels)\n",
    "\n",
    "print(len(trainData), len(trainLabels))\n",
    "print(len(validationData), len(validationLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....Iniciando treinamento com 10 K-folds....\n",
      "\n",
      "################################################\n",
      "K-fold : 1\n",
      "################################################\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.24404761904761962\n",
      "Alpha : 0.011306150197542804\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[81 12]\n",
      " [29 46]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7559523809523809\n",
      "Misclassification rate : 0.197\n",
      "True positives : 0.613\n",
      "False positives : 0.129\n",
      "Specificity : 0.871\n",
      "Precision : 0.793\n",
      "Prevalence : 0.361\n",
      "Recall : 0.613\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 0]\n",
      " [3 9]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8421052631578947\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.75\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 1.0\n",
      "Prevalence : 0.058\n",
      "Recall : 0.75\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00588546 0.00588546 0.00588546 0.00602006 0.00588546 0.00588546\n",
      " 0.00588546 0.00602006 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00602006 0.00588546 0.00588546 0.00588546\n",
      " 0.00602006 0.00588546 0.00602006 0.00588546 0.00602006 0.00588546\n",
      " 0.00588546 0.00602006 0.00602006 0.00588546 0.00588546 0.00602006\n",
      " 0.00588546 0.00602006 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00602006 0.00588546 0.00588546 0.00588546\n",
      " 0.00602006 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00602006 0.00588546\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00602006 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00602006 0.00588546 0.00602006 0.00588546 0.00602006 0.00602006\n",
      " 0.00588546 0.00602006 0.00588546 0.00602006 0.00588546 0.00588546\n",
      " 0.00588546 0.00602006 0.00588546 0.00602006 0.00588546 0.00602006\n",
      " 0.00602006 0.00588546 0.00588546 0.00588546 0.00602006 0.00602006\n",
      " 0.00602006 0.00588546 0.00588546 0.00602006 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00602006 0.00588546 0.00588546 0.00588546\n",
      " 0.00602006 0.00588546 0.00602006 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00602006 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00602006 0.00602006 0.00588546 0.00602006 0.00588546 0.00588546\n",
      " 0.00588546 0.00602006 0.00588546 0.00588546 0.00588546 0.00602006\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00602006 0.00588546\n",
      " 0.00602006 0.00588546 0.00588546 0.00588546 0.00602006 0.00588546\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546 0.00602006]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2482434308884095\n",
      "Alpha : 0.011080027193591958\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[81 12]\n",
      " [29 46]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7559523809523809\n",
      "Misclassification rate : 0.197\n",
      "True positives : 0.613\n",
      "False positives : 0.129\n",
      "Specificity : 0.871\n",
      "Precision : 0.793\n",
      "Prevalence : 0.361\n",
      "Recall : 0.613\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 0]\n",
      " [3 9]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8421052631578947\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.75\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 1.0\n",
      "Prevalence : 0.058\n",
      "Recall : 0.75\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00582061 0.00582061 0.00582061 0.00608713 0.00582061 0.00582061\n",
      " 0.00582061 0.00608713 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00608713 0.00582061 0.00582061 0.00582061\n",
      " 0.00608713 0.00582061 0.00608713 0.00582061 0.00608713 0.00582061\n",
      " 0.00582061 0.00608713 0.00608713 0.00582061 0.00582061 0.00608713\n",
      " 0.00582061 0.00608713 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00608713 0.00582061 0.00582061 0.00582061\n",
      " 0.00608713 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00608713 0.00582061\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00608713 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00608713 0.00582061 0.00608713 0.00582061 0.00608713 0.00608713\n",
      " 0.00582061 0.00608713 0.00582061 0.00608713 0.00582061 0.00582061\n",
      " 0.00582061 0.00608713 0.00582061 0.00608713 0.00582061 0.00608713\n",
      " 0.00608713 0.00582061 0.00582061 0.00582061 0.00608713 0.00608713\n",
      " 0.00608713 0.00582061 0.00582061 0.00608713 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00608713 0.00582061 0.00582061 0.00582061\n",
      " 0.00608713 0.00582061 0.00608713 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00608713 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00608713 0.00608713 0.00582061 0.00608713 0.00582061 0.00582061\n",
      " 0.00582061 0.00608713 0.00582061 0.00582061 0.00582061 0.00608713\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00608713 0.00582061\n",
      " 0.00608713 0.00582061 0.00582061 0.00582061 0.00608713 0.00582061\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061 0.00608713]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "################################################\n",
      "K-fold : 2\n",
      "################################################\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2380952380952387\n",
      "Alpha : 0.011631508098056775\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[77 16]\n",
      " [24 51]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7619047619047619\n",
      "Misclassification rate : 0.192\n",
      "True positives : 0.68\n",
      "False positives : 0.172\n",
      "Specificity : 0.828\n",
      "Precision : 0.761\n",
      "Prevalence : 0.361\n",
      "Recall : 0.68\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[ 5  2]\n",
      " [ 1 11]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8421052631578947\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.917\n",
      "False positives : 0.286\n",
      "Specificity : 0.714\n",
      "Precision : 0.846\n",
      "Prevalence : 0.058\n",
      "Recall : 0.917\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00588355 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00602202 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355 0.00602202\n",
      " 0.00588355 0.00588355 0.00602202 0.00588355 0.00588355 0.00588355\n",
      " 0.00602202 0.00602202 0.00588355 0.00588355 0.00602202 0.00588355\n",
      " 0.00588355 0.00602202 0.00602202 0.00588355 0.00588355 0.00602202\n",
      " 0.00602202 0.00602202 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00602202 0.00588355 0.00588355 0.00588355\n",
      " 0.00602202 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00588355 0.00602202 0.00588355\n",
      " 0.00588355 0.00588355 0.00602202 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00602202 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00602202 0.00588355 0.00602202 0.00588355 0.00588355 0.00602202\n",
      " 0.00588355 0.00602202 0.00588355 0.00602202 0.00588355 0.00588355\n",
      " 0.00588355 0.00602202 0.00588355 0.00602202 0.00588355 0.00602202\n",
      " 0.00602202 0.00588355 0.00588355 0.00588355 0.00602202 0.00602202\n",
      " 0.00602202 0.00588355 0.00588355 0.00602202 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00602202 0.00588355 0.00602202 0.00588355\n",
      " 0.00602202 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00602202 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00602202 0.00602202 0.00588355 0.00602202 0.00588355 0.00588355\n",
      " 0.00588355 0.00602202 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00588355 0.00602202 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00602202 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355 0.00602202]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.24234096282028092\n",
      "Alpha : 0.011398877936095632\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[77 16]\n",
      " [24 51]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7619047619047619\n",
      "Misclassification rate : 0.192\n",
      "True positives : 0.68\n",
      "False positives : 0.172\n",
      "Specificity : 0.828\n",
      "Precision : 0.761\n",
      "Prevalence : 0.361\n",
      "Recall : 0.68\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[ 5  2]\n",
      " [ 1 11]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8421052631578947\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.917\n",
      "False positives : 0.286\n",
      "Specificity : 0.714\n",
      "Precision : 0.846\n",
      "Prevalence : 0.058\n",
      "Recall : 0.917\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00581686 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00609106 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686 0.00609106\n",
      " 0.00581686 0.00581686 0.00609106 0.00581686 0.00581686 0.00581686\n",
      " 0.00609106 0.00609106 0.00581686 0.00581686 0.00609106 0.00581686\n",
      " 0.00581686 0.00609106 0.00609106 0.00581686 0.00581686 0.00609106\n",
      " 0.00609106 0.00609106 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00609106 0.00581686 0.00581686 0.00581686\n",
      " 0.00609106 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00581686 0.00609106 0.00581686\n",
      " 0.00581686 0.00581686 0.00609106 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00609106 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00609106 0.00581686 0.00609106 0.00581686 0.00581686 0.00609106\n",
      " 0.00581686 0.00609106 0.00581686 0.00609106 0.00581686 0.00581686\n",
      " 0.00581686 0.00609106 0.00581686 0.00609106 0.00581686 0.00609106\n",
      " 0.00609106 0.00581686 0.00581686 0.00581686 0.00609106 0.00609106\n",
      " 0.00609106 0.00581686 0.00581686 0.00609106 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00609106 0.00581686 0.00609106 0.00581686\n",
      " 0.00609106 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00609106 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00609106 0.00609106 0.00581686 0.00609106 0.00581686 0.00581686\n",
      " 0.00581686 0.00609106 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00581686 0.00609106 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00609106 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686 0.00609106]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "################################################\n",
      "K-fold : 3\n",
      "################################################\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.20238095238095288\n",
      "Alpha : 0.01371479275334747\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[74 12]\n",
      " [22 60]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7976190476190478\n",
      "Misclassification rate : 0.163\n",
      "True positives : 0.732\n",
      "False positives : 0.14\n",
      "Specificity : 0.86\n",
      "Precision : 0.833\n",
      "Prevalence : 0.394\n",
      "Recall : 0.732\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 6]\n",
      " [3 2]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5263157894736842\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.4\n",
      "False positives : 0.429\n",
      "Specificity : 0.571\n",
      "Precision : 0.25\n",
      "Prevalence : 0.024\n",
      "Recall : 0.4\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0058713  0.0058713  0.0058713  0.0058713  0.0058713  0.0058713\n",
      " 0.0058713  0.0058713  0.00603458 0.0058713  0.0058713  0.0058713\n",
      " 0.0058713  0.0058713  0.0058713  0.0058713  0.0058713  0.00603458\n",
      " 0.0058713  0.0058713  0.0058713  0.0058713  0.00603458 0.0058713\n",
      " 0.0058713  0.00603458 0.00603458 0.0058713  0.0058713  0.0058713\n",
      " 0.0058713  0.0058713  0.0058713  0.0058713  0.0058713  0.0058713\n",
      " 0.0058713  0.0058713  0.0058713  0.0058713  0.0058713  0.0058713\n",
      " 0.0058713  0.0058713  0.00603458 0.0058713  0.0058713  0.0058713\n",
      " 0.00603458 0.0058713  0.0058713  0.0058713  0.0058713  0.0058713\n",
      " 0.0058713  0.0058713  0.0058713  0.0058713  0.00603458 0.0058713\n",
      " 0.0058713  0.0058713  0.00603458 0.0058713  0.0058713  0.0058713\n",
      " 0.0058713  0.00603458 0.0058713  0.0058713  0.0058713  0.0058713\n",
      " 0.0058713  0.0058713  0.0058713  0.0058713  0.0058713  0.0058713\n",
      " 0.00603458 0.0058713  0.00603458 0.0058713  0.0058713  0.00603458\n",
      " 0.0058713  0.00603458 0.0058713  0.00603458 0.0058713  0.0058713\n",
      " 0.0058713  0.00603458 0.0058713  0.00603458 0.0058713  0.00603458\n",
      " 0.00603458 0.0058713  0.0058713  0.0058713  0.00603458 0.00603458\n",
      " 0.00603458 0.0058713  0.0058713  0.00603458 0.0058713  0.0058713\n",
      " 0.0058713  0.0058713  0.00603458 0.0058713  0.00603458 0.0058713\n",
      " 0.00603458 0.0058713  0.0058713  0.0058713  0.0058713  0.0058713\n",
      " 0.0058713  0.00603458 0.0058713  0.0058713  0.0058713  0.0058713\n",
      " 0.00603458 0.00603458 0.0058713  0.00603458 0.0058713  0.0058713\n",
      " 0.0058713  0.00603458 0.0058713  0.0058713  0.0058713  0.0058713\n",
      " 0.0058713  0.0058713  0.0058713  0.0058713  0.00603458 0.0058713\n",
      " 0.0058713  0.0058713  0.0058713  0.0058713  0.0058713  0.0058713\n",
      " 0.0058713  0.0058713  0.00603458 0.0058713  0.0058713  0.0058713\n",
      " 0.0058713  0.0058713  0.0058713  0.0058713  0.0058713  0.0058713\n",
      " 0.0058713  0.0058713  0.0058713  0.0058713  0.0058713  0.00603458]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2068448773608795\n",
      "Alpha : 0.01344049689828053\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[74 12]\n",
      " [22 60]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7976190476190478\n",
      "Misclassification rate : 0.163\n",
      "True positives : 0.732\n",
      "False positives : 0.14\n",
      "Specificity : 0.86\n",
      "Precision : 0.833\n",
      "Prevalence : 0.394\n",
      "Recall : 0.732\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 6]\n",
      " [3 2]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5263157894736842\n",
      "Misclassification rate : 0.043\n",
      "True positives : 0.4\n",
      "False positives : 0.429\n",
      "Specificity : 0.571\n",
      "Precision : 0.25\n",
      "Prevalence : 0.024\n",
      "Recall : 0.4\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00579292 0.00579292 0.00579292 0.00579292 0.00579292 0.00579292\n",
      " 0.00579292 0.00579292 0.00611623 0.00579292 0.00579292 0.00579292\n",
      " 0.00579292 0.00579292 0.00579292 0.00579292 0.00579292 0.00611623\n",
      " 0.00579292 0.00579292 0.00579292 0.00579292 0.00611623 0.00579292\n",
      " 0.00579292 0.00611623 0.00611623 0.00579292 0.00579292 0.00579292\n",
      " 0.00579292 0.00579292 0.00579292 0.00579292 0.00579292 0.00579292\n",
      " 0.00579292 0.00579292 0.00579292 0.00579292 0.00579292 0.00579292\n",
      " 0.00579292 0.00579292 0.00611623 0.00579292 0.00579292 0.00579292\n",
      " 0.00611623 0.00579292 0.00579292 0.00579292 0.00579292 0.00579292\n",
      " 0.00579292 0.00579292 0.00579292 0.00579292 0.00611623 0.00579292\n",
      " 0.00579292 0.00579292 0.00611623 0.00579292 0.00579292 0.00579292\n",
      " 0.00579292 0.00611623 0.00579292 0.00579292 0.00579292 0.00579292\n",
      " 0.00579292 0.00579292 0.00579292 0.00579292 0.00579292 0.00579292\n",
      " 0.00611623 0.00579292 0.00611623 0.00579292 0.00579292 0.00611623\n",
      " 0.00579292 0.00611623 0.00579292 0.00611623 0.00579292 0.00579292\n",
      " 0.00579292 0.00611623 0.00579292 0.00611623 0.00579292 0.00611623\n",
      " 0.00611623 0.00579292 0.00579292 0.00579292 0.00611623 0.00611623\n",
      " 0.00611623 0.00579292 0.00579292 0.00611623 0.00579292 0.00579292\n",
      " 0.00579292 0.00579292 0.00611623 0.00579292 0.00611623 0.00579292\n",
      " 0.00611623 0.00579292 0.00579292 0.00579292 0.00579292 0.00579292\n",
      " 0.00579292 0.00611623 0.00579292 0.00579292 0.00579292 0.00579292\n",
      " 0.00611623 0.00611623 0.00579292 0.00611623 0.00579292 0.00579292\n",
      " 0.00579292 0.00611623 0.00579292 0.00579292 0.00579292 0.00579292\n",
      " 0.00579292 0.00579292 0.00579292 0.00579292 0.00611623 0.00579292\n",
      " 0.00579292 0.00579292 0.00579292 0.00579292 0.00579292 0.00579292\n",
      " 0.00579292 0.00579292 0.00611623 0.00579292 0.00579292 0.00579292\n",
      " 0.00579292 0.00579292 0.00579292 0.00579292 0.00579292 0.00579292\n",
      " 0.00579292 0.00579292 0.00579292 0.00579292 0.00579292 0.00611623]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "################################################\n",
      "K-fold : 4\n",
      "################################################\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.24404761904761962\n",
      "Alpha : 0.011306150197542804\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[70 18]\n",
      " [23 57]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7559523809523809\n",
      "Misclassification rate : 0.197\n",
      "True positives : 0.713\n",
      "False positives : 0.205\n",
      "Specificity : 0.795\n",
      "Precision : 0.76\n",
      "Prevalence : 0.385\n",
      "Recall : 0.713\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[12  0]\n",
      " [ 2  5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8947368421052632\n",
      "Misclassification rate : 0.01\n",
      "True positives : 0.714\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 1.0\n",
      "Prevalence : 0.034\n",
      "Recall : 0.714\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00588546 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00602006 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546 0.00602006\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00602006 0.00588546\n",
      " 0.00588546 0.00602006 0.00602006 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00588546 0.00602006 0.00588546 0.00588546\n",
      " 0.00588546 0.00602006 0.00602006 0.00588546 0.00588546 0.00602006\n",
      " 0.00588546 0.00588546 0.00602006 0.00602006 0.00588546 0.00588546\n",
      " 0.00602006 0.00602006 0.00602006 0.00588546 0.00602006 0.00588546\n",
      " 0.00588546 0.00588546 0.00602006 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00602006 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00602006 0.00588546 0.00602006 0.00588546 0.00588546 0.00602006\n",
      " 0.00588546 0.00602006 0.00588546 0.00602006 0.00588546 0.00588546\n",
      " 0.00588546 0.00602006 0.00588546 0.00602006 0.00588546 0.00602006\n",
      " 0.00602006 0.00588546 0.00588546 0.00588546 0.00602006 0.00602006\n",
      " 0.00602006 0.00588546 0.00588546 0.00602006 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00602006 0.00588546 0.00602006 0.00588546\n",
      " 0.00602006 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00602006 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00602006 0.00602006 0.00588546 0.00602006 0.00588546 0.00588546\n",
      " 0.00588546 0.00602006 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00602006 0.00588546\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00602006 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546\n",
      " 0.00588546 0.00588546 0.00588546 0.00588546 0.00588546 0.00602006]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.24824343088840956\n",
      "Alpha : 0.011080027193591952\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[70 18]\n",
      " [23 57]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7559523809523809\n",
      "Misclassification rate : 0.197\n",
      "True positives : 0.713\n",
      "False positives : 0.205\n",
      "Specificity : 0.795\n",
      "Precision : 0.76\n",
      "Prevalence : 0.385\n",
      "Recall : 0.713\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[12  0]\n",
      " [ 2  5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8947368421052632\n",
      "Misclassification rate : 0.01\n",
      "True positives : 0.714\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 1.0\n",
      "Prevalence : 0.034\n",
      "Recall : 0.714\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00582061 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00608713 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061 0.00608713\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00608713 0.00582061\n",
      " 0.00582061 0.00608713 0.00608713 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00582061 0.00608713 0.00582061 0.00582061\n",
      " 0.00582061 0.00608713 0.00608713 0.00582061 0.00582061 0.00608713\n",
      " 0.00582061 0.00582061 0.00608713 0.00608713 0.00582061 0.00582061\n",
      " 0.00608713 0.00608713 0.00608713 0.00582061 0.00608713 0.00582061\n",
      " 0.00582061 0.00582061 0.00608713 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00608713 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00608713 0.00582061 0.00608713 0.00582061 0.00582061 0.00608713\n",
      " 0.00582061 0.00608713 0.00582061 0.00608713 0.00582061 0.00582061\n",
      " 0.00582061 0.00608713 0.00582061 0.00608713 0.00582061 0.00608713\n",
      " 0.00608713 0.00582061 0.00582061 0.00582061 0.00608713 0.00608713\n",
      " 0.00608713 0.00582061 0.00582061 0.00608713 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00608713 0.00582061 0.00608713 0.00582061\n",
      " 0.00608713 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00608713 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00608713 0.00608713 0.00582061 0.00608713 0.00582061 0.00582061\n",
      " 0.00582061 0.00608713 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00608713 0.00582061\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00608713 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061\n",
      " 0.00582061 0.00582061 0.00582061 0.00582061 0.00582061 0.00608713]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "################################################\n",
      "K-fold : 5\n",
      "################################################\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2380952380952387\n",
      "Alpha : 0.011631508098056775\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[71 16]\n",
      " [24 57]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7619047619047619\n",
      "Misclassification rate : 0.192\n",
      "True positives : 0.704\n",
      "False positives : 0.184\n",
      "Specificity : 0.816\n",
      "Precision : 0.781\n",
      "Prevalence : 0.389\n",
      "Recall : 0.704\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[11  2]\n",
      " [ 1  5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8421052631578947\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.833\n",
      "False positives : 0.154\n",
      "Specificity : 0.846\n",
      "Precision : 0.714\n",
      "Prevalence : 0.029\n",
      "Recall : 0.833\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00588355 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00602202 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355 0.00602202\n",
      " 0.00588355 0.00588355 0.00588355 0.00588355 0.00602202 0.00588355\n",
      " 0.00588355 0.00602202 0.00602202 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00602202 0.00588355 0.00588355\n",
      " 0.00588355 0.00602202 0.00602202 0.00588355 0.00588355 0.00602202\n",
      " 0.00588355 0.00588355 0.00602202 0.00602202 0.00588355 0.00588355\n",
      " 0.00602202 0.00602202 0.00602202 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00602202 0.00588355 0.00588355\n",
      " 0.00588355 0.00602202 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00602202 0.00588355 0.00602202 0.00588355 0.00588355 0.00602202\n",
      " 0.00588355 0.00602202 0.00588355 0.00602202 0.00588355 0.00588355\n",
      " 0.00588355 0.00602202 0.00588355 0.00602202 0.00588355 0.00602202\n",
      " 0.00602202 0.00588355 0.00588355 0.00588355 0.00602202 0.00602202\n",
      " 0.00602202 0.00588355 0.00588355 0.00602202 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00602202 0.00588355 0.00602202 0.00588355\n",
      " 0.00602202 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00602202 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00602202 0.00602202 0.00588355 0.00602202 0.00588355 0.00588355\n",
      " 0.00588355 0.00602202 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00588355 0.00602202 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00602202 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355\n",
      " 0.00588355 0.00588355 0.00588355 0.00588355 0.00588355 0.00602202]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.24234096282028092\n",
      "Alpha : 0.011398877936095632\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[71 16]\n",
      " [24 57]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7619047619047619\n",
      "Misclassification rate : 0.192\n",
      "True positives : 0.704\n",
      "False positives : 0.184\n",
      "Specificity : 0.816\n",
      "Precision : 0.781\n",
      "Prevalence : 0.389\n",
      "Recall : 0.704\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[11  2]\n",
      " [ 1  5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8421052631578947\n",
      "Misclassification rate : 0.014\n",
      "True positives : 0.833\n",
      "False positives : 0.154\n",
      "Specificity : 0.846\n",
      "Precision : 0.714\n",
      "Prevalence : 0.029\n",
      "Recall : 0.833\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00581686 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00609106 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686 0.00609106\n",
      " 0.00581686 0.00581686 0.00581686 0.00581686 0.00609106 0.00581686\n",
      " 0.00581686 0.00609106 0.00609106 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00609106 0.00581686 0.00581686\n",
      " 0.00581686 0.00609106 0.00609106 0.00581686 0.00581686 0.00609106\n",
      " 0.00581686 0.00581686 0.00609106 0.00609106 0.00581686 0.00581686\n",
      " 0.00609106 0.00609106 0.00609106 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00609106 0.00581686 0.00581686\n",
      " 0.00581686 0.00609106 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00609106 0.00581686 0.00609106 0.00581686 0.00581686 0.00609106\n",
      " 0.00581686 0.00609106 0.00581686 0.00609106 0.00581686 0.00581686\n",
      " 0.00581686 0.00609106 0.00581686 0.00609106 0.00581686 0.00609106\n",
      " 0.00609106 0.00581686 0.00581686 0.00581686 0.00609106 0.00609106\n",
      " 0.00609106 0.00581686 0.00581686 0.00609106 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00609106 0.00581686 0.00609106 0.00581686\n",
      " 0.00609106 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00609106 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00609106 0.00609106 0.00581686 0.00609106 0.00581686 0.00581686\n",
      " 0.00581686 0.00609106 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00581686 0.00609106 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00609106 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686\n",
      " 0.00581686 0.00581686 0.00581686 0.00581686 0.00581686 0.00609106]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "################################################\n",
      "K-fold : 6\n",
      "################################################\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2142857142857148\n",
      "Alpha : 0.012992829841302575\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[81  9]\n",
      " [27 51]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7857142857142857\n",
      "Misclassification rate : 0.173\n",
      "True positives : 0.654\n",
      "False positives : 0.1\n",
      "Specificity : 0.9\n",
      "Precision : 0.85\n",
      "Prevalence : 0.375\n",
      "Recall : 0.654\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 3]\n",
      " [5 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5789473684210527\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.444\n",
      "False positives : 0.3\n",
      "Specificity : 0.7\n",
      "Precision : 0.571\n",
      "Prevalence : 0.043\n",
      "Recall : 0.444\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00587554 0.00587554 0.00587554 0.00587554 0.00587554 0.00587554\n",
      " 0.00587554 0.00603022 0.00603022 0.00587554 0.00587554 0.00587554\n",
      " 0.00587554 0.00587554 0.00587554 0.00587554 0.00587554 0.00603022\n",
      " 0.00587554 0.00587554 0.00587554 0.00587554 0.00603022 0.00587554\n",
      " 0.00587554 0.00587554 0.00603022 0.00587554 0.00587554 0.00587554\n",
      " 0.00587554 0.00587554 0.00587554 0.00587554 0.00587554 0.00587554\n",
      " 0.00587554 0.00587554 0.00587554 0.00603022 0.00587554 0.00587554\n",
      " 0.00587554 0.00603022 0.00587554 0.00603022 0.00587554 0.00603022\n",
      " 0.00587554 0.00587554 0.00603022 0.00603022 0.00587554 0.00587554\n",
      " 0.00603022 0.00587554 0.00603022 0.00587554 0.00587554 0.00587554\n",
      " 0.00587554 0.00587554 0.00587554 0.00603022 0.00587554 0.00587554\n",
      " 0.00587554 0.00603022 0.00587554 0.00587554 0.00587554 0.00587554\n",
      " 0.00587554 0.00587554 0.00587554 0.00587554 0.00587554 0.00603022\n",
      " 0.00587554 0.00587554 0.00587554 0.00587554 0.00587554 0.00587554\n",
      " 0.00587554 0.00587554 0.00603022 0.00587554 0.00587554 0.00587554\n",
      " 0.00587554 0.00587554 0.00587554 0.00587554 0.00587554 0.00603022\n",
      " 0.00603022 0.00587554 0.00587554 0.00587554 0.00603022 0.00603022\n",
      " 0.00603022 0.00587554 0.00587554 0.00603022 0.00587554 0.00587554\n",
      " 0.00587554 0.00587554 0.00603022 0.00587554 0.00587554 0.00587554\n",
      " 0.00603022 0.00587554 0.00603022 0.00587554 0.00587554 0.00587554\n",
      " 0.00587554 0.00603022 0.00587554 0.00587554 0.00587554 0.00587554\n",
      " 0.00603022 0.00603022 0.00587554 0.00603022 0.00587554 0.00587554\n",
      " 0.00587554 0.00603022 0.00587554 0.00587554 0.00587554 0.00603022\n",
      " 0.00587554 0.00587554 0.00587554 0.00587554 0.00603022 0.00587554\n",
      " 0.00603022 0.00587554 0.00587554 0.00587554 0.00603022 0.00587554\n",
      " 0.00587554 0.00587554 0.00587554 0.00587554 0.00587554 0.00587554\n",
      " 0.00587554 0.00587554 0.00587554 0.00587554 0.00587554 0.00587554\n",
      " 0.00587554 0.00587554 0.00587554 0.00587554 0.00587554 0.00603022]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.21869332705327416\n",
      "Alpha : 0.012732973244476576\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[81  9]\n",
      " [27 51]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7857142857142857\n",
      "Misclassification rate : 0.173\n",
      "True positives : 0.654\n",
      "False positives : 0.1\n",
      "Specificity : 0.9\n",
      "Precision : 0.85\n",
      "Prevalence : 0.375\n",
      "Recall : 0.654\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 3]\n",
      " [5 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5789473684210527\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.444\n",
      "False positives : 0.3\n",
      "Specificity : 0.7\n",
      "Precision : 0.571\n",
      "Prevalence : 0.043\n",
      "Recall : 0.444\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0058012 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012\n",
      " 0.0061075 0.0061075 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012\n",
      " 0.0058012 0.0058012 0.0058012 0.0061075 0.0058012 0.0058012 0.0058012\n",
      " 0.0058012 0.0061075 0.0058012 0.0058012 0.0058012 0.0061075 0.0058012\n",
      " 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012\n",
      " 0.0058012 0.0058012 0.0058012 0.0058012 0.0061075 0.0058012 0.0058012\n",
      " 0.0058012 0.0061075 0.0058012 0.0061075 0.0058012 0.0061075 0.0058012\n",
      " 0.0058012 0.0061075 0.0061075 0.0058012 0.0058012 0.0061075 0.0058012\n",
      " 0.0061075 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012\n",
      " 0.0061075 0.0058012 0.0058012 0.0058012 0.0061075 0.0058012 0.0058012\n",
      " 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012\n",
      " 0.0061075 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012\n",
      " 0.0058012 0.0058012 0.0061075 0.0058012 0.0058012 0.0058012 0.0058012\n",
      " 0.0058012 0.0058012 0.0058012 0.0058012 0.0061075 0.0061075 0.0058012\n",
      " 0.0058012 0.0058012 0.0061075 0.0061075 0.0061075 0.0058012 0.0058012\n",
      " 0.0061075 0.0058012 0.0058012 0.0058012 0.0058012 0.0061075 0.0058012\n",
      " 0.0058012 0.0058012 0.0061075 0.0058012 0.0061075 0.0058012 0.0058012\n",
      " 0.0058012 0.0058012 0.0061075 0.0058012 0.0058012 0.0058012 0.0058012\n",
      " 0.0061075 0.0061075 0.0058012 0.0061075 0.0058012 0.0058012 0.0058012\n",
      " 0.0061075 0.0058012 0.0058012 0.0058012 0.0061075 0.0058012 0.0058012\n",
      " 0.0058012 0.0058012 0.0061075 0.0058012 0.0061075 0.0058012 0.0058012\n",
      " 0.0058012 0.0061075 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012\n",
      " 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012\n",
      " 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012 0.0058012 0.0061075]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "################################################\n",
      "K-fold : 7\n",
      "################################################\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238\n",
      " 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238 0.00595238]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.20833333333333381\n",
      "Alpha : 0.013350010667323371\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[74 14]\n",
      " [21 59]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7916666666666665\n",
      "Misclassification rate : 0.168\n",
      "True positives : 0.738\n",
      "False positives : 0.159\n",
      "Specificity : 0.841\n",
      "Precision : 0.808\n",
      "Prevalence : 0.385\n",
      "Recall : 0.738\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 4]\n",
      " [4 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5789473684210527\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.429\n",
      "False positives : 0.333\n",
      "Specificity : 0.667\n",
      "Precision : 0.429\n",
      "Prevalence : 0.034\n",
      "Recall : 0.429\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00587344 0.00587344 0.00587344 0.00587344 0.00587344 0.00587344\n",
      " 0.00587344 0.00587344 0.00603238 0.00587344 0.00587344 0.00587344\n",
      " 0.00587344 0.00587344 0.00587344 0.00587344 0.00587344 0.00603238\n",
      " 0.00587344 0.00587344 0.00587344 0.00587344 0.00603238 0.00587344\n",
      " 0.00587344 0.00603238 0.00603238 0.00587344 0.00587344 0.00587344\n",
      " 0.00587344 0.00587344 0.00587344 0.00587344 0.00587344 0.00587344\n",
      " 0.00587344 0.00587344 0.00587344 0.00603238 0.00587344 0.00587344\n",
      " 0.00587344 0.00603238 0.00603238 0.00587344 0.00587344 0.00603238\n",
      " 0.00587344 0.00587344 0.00603238 0.00603238 0.00587344 0.00587344\n",
      " 0.00603238 0.00603238 0.00603238 0.00587344 0.00587344 0.00587344\n",
      " 0.00587344 0.00587344 0.00587344 0.00603238 0.00587344 0.00587344\n",
      " 0.00587344 0.00603238 0.00587344 0.00587344 0.00587344 0.00587344\n",
      " 0.00587344 0.00587344 0.00587344 0.00587344 0.00587344 0.00603238\n",
      " 0.00587344 0.00587344 0.00587344 0.00603238 0.00587344 0.00587344\n",
      " 0.00587344 0.00587344 0.00603238 0.00587344 0.00587344 0.00587344\n",
      " 0.00587344 0.00587344 0.00587344 0.00587344 0.00587344 0.00587344\n",
      " 0.00587344 0.00603238 0.00587344 0.00603238 0.00587344 0.00587344\n",
      " 0.00603238 0.00587344 0.00603238 0.00587344 0.00603238 0.00587344\n",
      " 0.00587344 0.00587344 0.00603238 0.00587344 0.00603238 0.00587344\n",
      " 0.00603238 0.00587344 0.00587344 0.00587344 0.00587344 0.00587344\n",
      " 0.00587344 0.00603238 0.00587344 0.00587344 0.00587344 0.00587344\n",
      " 0.00603238 0.00603238 0.00587344 0.00603238 0.00587344 0.00587344\n",
      " 0.00587344 0.00603238 0.00587344 0.00587344 0.00587344 0.00587344\n",
      " 0.00587344 0.00587344 0.00587344 0.00587344 0.00603238 0.00587344\n",
      " 0.00587344 0.00587344 0.00587344 0.00587344 0.00587344 0.00587344\n",
      " 0.00587344 0.00587344 0.00603238 0.00587344 0.00587344 0.00587344\n",
      " 0.00587344 0.00587344 0.00587344 0.00587344 0.00587344 0.00587344\n",
      " 0.00587344 0.00587344 0.00587344 0.00587344 0.00587344 0.00603238]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.21277127957479308\n",
      "Alpha : 0.013083010453976902\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[74 14]\n",
      " [21 59]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7916666666666665\n",
      "Misclassification rate : 0.168\n",
      "True positives : 0.738\n",
      "False positives : 0.159\n",
      "Specificity : 0.841\n",
      "Precision : 0.808\n",
      "Prevalence : 0.385\n",
      "Recall : 0.738\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 4]\n",
      " [4 3]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.5789473684210527\n",
      "Misclassification rate : 0.038\n",
      "True positives : 0.429\n",
      "False positives : 0.333\n",
      "Specificity : 0.667\n",
      "Precision : 0.429\n",
      "Prevalence : 0.034\n",
      "Recall : 0.429\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.0057971  0.0057971  0.0057971  0.0057971  0.0057971  0.0057971\n",
      " 0.0057971  0.0057971  0.00611182 0.0057971  0.0057971  0.0057971\n",
      " 0.0057971  0.0057971  0.0057971  0.0057971  0.0057971  0.00611182\n",
      " 0.0057971  0.0057971  0.0057971  0.0057971  0.00611182 0.0057971\n",
      " 0.0057971  0.00611182 0.00611182 0.0057971  0.0057971  0.0057971\n",
      " 0.0057971  0.0057971  0.0057971  0.0057971  0.0057971  0.0057971\n",
      " 0.0057971  0.0057971  0.0057971  0.00611182 0.0057971  0.0057971\n",
      " 0.0057971  0.00611182 0.00611182 0.0057971  0.0057971  0.00611182\n",
      " 0.0057971  0.0057971  0.00611182 0.00611182 0.0057971  0.0057971\n",
      " 0.00611182 0.00611182 0.00611182 0.0057971  0.0057971  0.0057971\n",
      " 0.0057971  0.0057971  0.0057971  0.00611182 0.0057971  0.0057971\n",
      " 0.0057971  0.00611182 0.0057971  0.0057971  0.0057971  0.0057971\n",
      " 0.0057971  0.0057971  0.0057971  0.0057971  0.0057971  0.00611182\n",
      " 0.0057971  0.0057971  0.0057971  0.00611182 0.0057971  0.0057971\n",
      " 0.0057971  0.0057971  0.00611182 0.0057971  0.0057971  0.0057971\n",
      " 0.0057971  0.0057971  0.0057971  0.0057971  0.0057971  0.0057971\n",
      " 0.0057971  0.00611182 0.0057971  0.00611182 0.0057971  0.0057971\n",
      " 0.00611182 0.0057971  0.00611182 0.0057971  0.00611182 0.0057971\n",
      " 0.0057971  0.0057971  0.00611182 0.0057971  0.00611182 0.0057971\n",
      " 0.00611182 0.0057971  0.0057971  0.0057971  0.0057971  0.0057971\n",
      " 0.0057971  0.00611182 0.0057971  0.0057971  0.0057971  0.0057971\n",
      " 0.00611182 0.00611182 0.0057971  0.00611182 0.0057971  0.0057971\n",
      " 0.0057971  0.00611182 0.0057971  0.0057971  0.0057971  0.0057971\n",
      " 0.0057971  0.0057971  0.0057971  0.0057971  0.00611182 0.0057971\n",
      " 0.0057971  0.0057971  0.0057971  0.0057971  0.0057971  0.0057971\n",
      " 0.0057971  0.0057971  0.00611182 0.0057971  0.0057971  0.0057971\n",
      " 0.0057971  0.0057971  0.0057971  0.0057971  0.0057971  0.0057971\n",
      " 0.0057971  0.0057971  0.0057971  0.0057971  0.0057971  0.00611182]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "################################################\n",
      "K-fold : 8\n",
      "################################################\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.22485207100591678\n",
      "Alpha : 0.01237611163474768\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[81 12]\n",
      " [26 50]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7751479289940828\n",
      "Misclassification rate : 0.183\n",
      "True positives : 0.658\n",
      "False positives : 0.129\n",
      "Specificity : 0.871\n",
      "Precision : 0.806\n",
      "Prevalence : 0.365\n",
      "Recall : 0.658\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 0]\n",
      " [6 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6666666666666665\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.455\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 1.0\n",
      "Prevalence : 0.053\n",
      "Recall : 0.455\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00584438 0.00584438 0.00584438 0.00584438 0.00584438 0.00584438\n",
      " 0.00584438 0.00599085 0.00599085 0.00584438 0.00584438 0.00584438\n",
      " 0.00584438 0.00584438 0.00584438 0.00584438 0.00584438 0.00599085\n",
      " 0.00584438 0.00584438 0.00584438 0.00584438 0.00599085 0.00584438\n",
      " 0.00584438 0.00584438 0.00599085 0.00584438 0.00584438 0.00584438\n",
      " 0.00584438 0.00584438 0.00584438 0.00584438 0.00584438 0.00584438\n",
      " 0.00584438 0.00584438 0.00584438 0.00599085 0.00584438 0.00584438\n",
      " 0.00584438 0.00599085 0.00584438 0.00599085 0.00584438 0.00599085\n",
      " 0.00584438 0.00584438 0.00599085 0.00599085 0.00584438 0.00584438\n",
      " 0.00599085 0.00584438 0.00599085 0.00584438 0.00584438 0.00584438\n",
      " 0.00584438 0.00584438 0.00584438 0.00599085 0.00584438 0.00584438\n",
      " 0.00584438 0.00599085 0.00584438 0.00584438 0.00584438 0.00584438\n",
      " 0.00584438 0.00584438 0.00584438 0.00584438 0.00584438 0.00599085\n",
      " 0.00584438 0.00584438 0.00584438 0.00584438 0.00584438 0.00584438\n",
      " 0.00584438 0.00584438 0.00599085 0.00584438 0.00584438 0.00584438\n",
      " 0.00584438 0.00584438 0.00584438 0.00584438 0.00584438 0.00584438\n",
      " 0.00584438 0.00599085 0.00584438 0.00599085 0.00584438 0.00599085\n",
      " 0.00599085 0.00584438 0.00599085 0.00584438 0.00599085 0.00584438\n",
      " 0.00584438 0.00584438 0.00599085 0.00584438 0.00599085 0.00584438\n",
      " 0.00599085 0.00599085 0.00584438 0.00584438 0.00584438 0.00599085\n",
      " 0.00599085 0.00599085 0.00584438 0.00584438 0.00599085 0.00584438\n",
      " 0.00584438 0.00584438 0.00584438 0.00599085 0.00584438 0.00584438\n",
      " 0.00584438 0.00584438 0.00599085 0.00584438 0.00584438 0.00584438\n",
      " 0.00599085 0.00584438 0.00584438 0.00584438 0.00584438 0.00599085\n",
      " 0.00584438 0.00599085 0.00584438 0.00584438 0.00584438 0.00599085\n",
      " 0.00584438 0.00584438 0.00584438 0.00584438 0.00584438 0.00584438\n",
      " 0.00584438 0.00584438 0.00584438 0.00584438 0.00584438 0.00584438\n",
      " 0.00584438 0.00584438 0.00584438 0.00584438 0.00584438 0.00584438\n",
      " 0.00599085]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.22919558537655021\n",
      "Alpha : 0.012128589402052754\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[81 12]\n",
      " [26 50]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7751479289940828\n",
      "Misclassification rate : 0.183\n",
      "True positives : 0.658\n",
      "False positives : 0.129\n",
      "Specificity : 0.871\n",
      "Precision : 0.806\n",
      "Prevalence : 0.365\n",
      "Recall : 0.658\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[7 0]\n",
      " [6 5]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.6666666666666665\n",
      "Misclassification rate : 0.029\n",
      "True positives : 0.455\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 1.0\n",
      "Prevalence : 0.053\n",
      "Recall : 0.455\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00577392 0.00577392 0.00577392 0.00577392 0.00577392 0.00577392\n",
      " 0.00577392 0.00606395 0.00606395 0.00577392 0.00577392 0.00577392\n",
      " 0.00577392 0.00577392 0.00577392 0.00577392 0.00577392 0.00606395\n",
      " 0.00577392 0.00577392 0.00577392 0.00577392 0.00606395 0.00577392\n",
      " 0.00577392 0.00577392 0.00606395 0.00577392 0.00577392 0.00577392\n",
      " 0.00577392 0.00577392 0.00577392 0.00577392 0.00577392 0.00577392\n",
      " 0.00577392 0.00577392 0.00577392 0.00606395 0.00577392 0.00577392\n",
      " 0.00577392 0.00606395 0.00577392 0.00606395 0.00577392 0.00606395\n",
      " 0.00577392 0.00577392 0.00606395 0.00606395 0.00577392 0.00577392\n",
      " 0.00606395 0.00577392 0.00606395 0.00577392 0.00577392 0.00577392\n",
      " 0.00577392 0.00577392 0.00577392 0.00606395 0.00577392 0.00577392\n",
      " 0.00577392 0.00606395 0.00577392 0.00577392 0.00577392 0.00577392\n",
      " 0.00577392 0.00577392 0.00577392 0.00577392 0.00577392 0.00606395\n",
      " 0.00577392 0.00577392 0.00577392 0.00577392 0.00577392 0.00577392\n",
      " 0.00577392 0.00577392 0.00606395 0.00577392 0.00577392 0.00577392\n",
      " 0.00577392 0.00577392 0.00577392 0.00577392 0.00577392 0.00577392\n",
      " 0.00577392 0.00606395 0.00577392 0.00606395 0.00577392 0.00606395\n",
      " 0.00606395 0.00577392 0.00606395 0.00577392 0.00606395 0.00577392\n",
      " 0.00577392 0.00577392 0.00606395 0.00577392 0.00606395 0.00577392\n",
      " 0.00606395 0.00606395 0.00577392 0.00577392 0.00577392 0.00606395\n",
      " 0.00606395 0.00606395 0.00577392 0.00577392 0.00606395 0.00577392\n",
      " 0.00577392 0.00577392 0.00577392 0.00606395 0.00577392 0.00577392\n",
      " 0.00577392 0.00577392 0.00606395 0.00577392 0.00577392 0.00577392\n",
      " 0.00606395 0.00577392 0.00577392 0.00577392 0.00577392 0.00606395\n",
      " 0.00577392 0.00606395 0.00577392 0.00577392 0.00577392 0.00606395\n",
      " 0.00577392 0.00577392 0.00577392 0.00577392 0.00577392 0.00577392\n",
      " 0.00577392 0.00577392 0.00577392 0.00577392 0.00577392 0.00577392\n",
      " 0.00577392 0.00577392 0.00577392 0.00577392 0.00577392 0.00577392\n",
      " 0.00606395]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "################################################\n",
      "K-fold : 9\n",
      "################################################\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716]\n",
      "\n",
      "Treinando o modelo....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.23076923076923042\n",
      "Alpha : 0.012039728043259382\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[79 12]\n",
      " [27 51]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7692307692307694\n",
      "Misclassification rate : 0.188\n",
      "True positives : 0.654\n",
      "False positives : 0.132\n",
      "Specificity : 0.868\n",
      "Precision : 0.81\n",
      "Prevalence : 0.375\n",
      "Recall : 0.654\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 0]\n",
      " [5 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7222222222222221\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.444\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 1.0\n",
      "Prevalence : 0.043\n",
      "Recall : 0.444\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00584635 0.00584635 0.00584635 0.00584635 0.00584635 0.00584635\n",
      " 0.00584635 0.00598883 0.00598883 0.00584635 0.00584635 0.00584635\n",
      " 0.00584635 0.00584635 0.00584635 0.00584635 0.00584635 0.00598883\n",
      " 0.00584635 0.00584635 0.00584635 0.00584635 0.00598883 0.00584635\n",
      " 0.00584635 0.00584635 0.00598883 0.00584635 0.00584635 0.00584635\n",
      " 0.00584635 0.00584635 0.00584635 0.00584635 0.00584635 0.00584635\n",
      " 0.00584635 0.00584635 0.00584635 0.00598883 0.00584635 0.00584635\n",
      " 0.00584635 0.00598883 0.00584635 0.00598883 0.00584635 0.00598883\n",
      " 0.00584635 0.00584635 0.00598883 0.00598883 0.00584635 0.00584635\n",
      " 0.00598883 0.00584635 0.00598883 0.00584635 0.00584635 0.00584635\n",
      " 0.00584635 0.00584635 0.00584635 0.00598883 0.00584635 0.00584635\n",
      " 0.00584635 0.00598883 0.00584635 0.00584635 0.00584635 0.00584635\n",
      " 0.00584635 0.00584635 0.00584635 0.00584635 0.00584635 0.00598883\n",
      " 0.00584635 0.00584635 0.00584635 0.00584635 0.00584635 0.00584635\n",
      " 0.00584635 0.00584635 0.00598883 0.00584635 0.00584635 0.00584635\n",
      " 0.00584635 0.00584635 0.00584635 0.00584635 0.00584635 0.00584635\n",
      " 0.00584635 0.00598883 0.00584635 0.00598883 0.00584635 0.00598883\n",
      " 0.00598883 0.00584635 0.00598883 0.00584635 0.00598883 0.00584635\n",
      " 0.00584635 0.00584635 0.00598883 0.00584635 0.00598883 0.00584635\n",
      " 0.00598883 0.00598883 0.00584635 0.00584635 0.00584635 0.00598883\n",
      " 0.00598883 0.00598883 0.00584635 0.00584635 0.00598883 0.00584635\n",
      " 0.00584635 0.00584635 0.00584635 0.00598883 0.00584635 0.00584635\n",
      " 0.00584635 0.00598883 0.00584635 0.00598883 0.00584635 0.00584635\n",
      " 0.00584635 0.00584635 0.00598883 0.00584635 0.00584635 0.00584635\n",
      " 0.00584635 0.00598883 0.00598883 0.00584635 0.00598883 0.00584635\n",
      " 0.00584635 0.00584635 0.00584635 0.00584635 0.00584635 0.00584635\n",
      " 0.00584635 0.00584635 0.00584635 0.00584635 0.00584635 0.00584635\n",
      " 0.00584635 0.00584635 0.00584635 0.00584635 0.00584635 0.00584635\n",
      " 0.00598883]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.23507137304848244\n",
      "Alpha : 0.01179893348239416\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[79 12]\n",
      " [27 51]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7692307692307694\n",
      "Misclassification rate : 0.188\n",
      "True positives : 0.654\n",
      "False positives : 0.132\n",
      "Specificity : 0.868\n",
      "Precision : 0.81\n",
      "Prevalence : 0.375\n",
      "Recall : 0.654\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[9 0]\n",
      " [5 4]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.7222222222222221\n",
      "Misclassification rate : 0.024\n",
      "True positives : 0.444\n",
      "False positives : 0.0\n",
      "Specificity : 1.0\n",
      "Precision : 1.0\n",
      "Prevalence : 0.043\n",
      "Recall : 0.444\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00577777 0.00577777 0.00577777 0.00577777 0.00577777 0.00577777\n",
      " 0.00577777 0.00605991 0.00605991 0.00577777 0.00577777 0.00577777\n",
      " 0.00577777 0.00577777 0.00577777 0.00577777 0.00577777 0.00605991\n",
      " 0.00577777 0.00577777 0.00577777 0.00577777 0.00605991 0.00577777\n",
      " 0.00577777 0.00577777 0.00605991 0.00577777 0.00577777 0.00577777\n",
      " 0.00577777 0.00577777 0.00577777 0.00577777 0.00577777 0.00577777\n",
      " 0.00577777 0.00577777 0.00577777 0.00605991 0.00577777 0.00577777\n",
      " 0.00577777 0.00605991 0.00577777 0.00605991 0.00577777 0.00605991\n",
      " 0.00577777 0.00577777 0.00605991 0.00605991 0.00577777 0.00577777\n",
      " 0.00605991 0.00577777 0.00605991 0.00577777 0.00577777 0.00577777\n",
      " 0.00577777 0.00577777 0.00577777 0.00605991 0.00577777 0.00577777\n",
      " 0.00577777 0.00605991 0.00577777 0.00577777 0.00577777 0.00577777\n",
      " 0.00577777 0.00577777 0.00577777 0.00577777 0.00577777 0.00605991\n",
      " 0.00577777 0.00577777 0.00577777 0.00577777 0.00577777 0.00577777\n",
      " 0.00577777 0.00577777 0.00605991 0.00577777 0.00577777 0.00577777\n",
      " 0.00577777 0.00577777 0.00577777 0.00577777 0.00577777 0.00577777\n",
      " 0.00577777 0.00605991 0.00577777 0.00605991 0.00577777 0.00605991\n",
      " 0.00605991 0.00577777 0.00605991 0.00577777 0.00605991 0.00577777\n",
      " 0.00577777 0.00577777 0.00605991 0.00577777 0.00605991 0.00577777\n",
      " 0.00605991 0.00605991 0.00577777 0.00577777 0.00577777 0.00605991\n",
      " 0.00605991 0.00605991 0.00577777 0.00577777 0.00605991 0.00577777\n",
      " 0.00577777 0.00577777 0.00577777 0.00605991 0.00577777 0.00577777\n",
      " 0.00577777 0.00605991 0.00577777 0.00605991 0.00577777 0.00577777\n",
      " 0.00577777 0.00577777 0.00605991 0.00577777 0.00577777 0.00577777\n",
      " 0.00577777 0.00605991 0.00605991 0.00577777 0.00605991 0.00577777\n",
      " 0.00577777 0.00577777 0.00577777 0.00577777 0.00577777 0.00577777\n",
      " 0.00577777 0.00577777 0.00577777 0.00577777 0.00577777 0.00577777\n",
      " 0.00577777 0.00577777 0.00577777 0.00577777 0.00577777 0.00577777\n",
      " 0.00605991]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "################################################\n",
      "K-fold : 10\n",
      "################################################\n",
      "\n",
      "....Inicializando vetor de pesos....\n",
      "\n",
      "[0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716 0.00591716\n",
      " 0.00591716]\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.2426035502958576\n",
      "Alpha : 0.011384581972153116\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[74 17]\n",
      " [24 54]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.757396449704142\n",
      "Misclassification rate : 0.197\n",
      "True positives : 0.692\n",
      "False positives : 0.187\n",
      "Specificity : 0.813\n",
      "Precision : 0.761\n",
      "Prevalence : 0.375\n",
      "Recall : 0.692\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 1]\n",
      " [1 8]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8888888888888888\n",
      "Misclassification rate : 0.01\n",
      "True positives : 0.889\n",
      "False positives : 0.111\n",
      "Specificity : 0.889\n",
      "Precision : 0.889\n",
      "Prevalence : 0.043\n",
      "Recall : 0.889\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00585018 0.00585018 0.00585018 0.00585018 0.00585018 0.00585018\n",
      " 0.00585018 0.00585018 0.00598491 0.00585018 0.00585018 0.00585018\n",
      " 0.00585018 0.00585018 0.00585018 0.00585018 0.00585018 0.00598491\n",
      " 0.00585018 0.00585018 0.00585018 0.00585018 0.00598491 0.00585018\n",
      " 0.00585018 0.00598491 0.00598491 0.00585018 0.00585018 0.00585018\n",
      " 0.00585018 0.00585018 0.00585018 0.00585018 0.00585018 0.00585018\n",
      " 0.00585018 0.00585018 0.00585018 0.00598491 0.00585018 0.00585018\n",
      " 0.00585018 0.00598491 0.00598491 0.00585018 0.00585018 0.00598491\n",
      " 0.00585018 0.00585018 0.00598491 0.00598491 0.00585018 0.00585018\n",
      " 0.00598491 0.00598491 0.00598491 0.00585018 0.00585018 0.00585018\n",
      " 0.00585018 0.00585018 0.00585018 0.00598491 0.00585018 0.00585018\n",
      " 0.00585018 0.00598491 0.00585018 0.00585018 0.00585018 0.00585018\n",
      " 0.00585018 0.00585018 0.00585018 0.00585018 0.00585018 0.00598491\n",
      " 0.00585018 0.00585018 0.00585018 0.00598491 0.00585018 0.00585018\n",
      " 0.00585018 0.00585018 0.00598491 0.00585018 0.00585018 0.00585018\n",
      " 0.00585018 0.00585018 0.00585018 0.00585018 0.00585018 0.00585018\n",
      " 0.00585018 0.00598491 0.00585018 0.00598491 0.00585018 0.00585018\n",
      " 0.00598491 0.00585018 0.00598491 0.00585018 0.00598491 0.00585018\n",
      " 0.00585018 0.00585018 0.00598491 0.00585018 0.00598491 0.00585018\n",
      " 0.00598491 0.00598491 0.00585018 0.00585018 0.00585018 0.00598491\n",
      " 0.00598491 0.00598491 0.00585018 0.00585018 0.00598491 0.00585018\n",
      " 0.00585018 0.00585018 0.00585018 0.00598491 0.00585018 0.00598491\n",
      " 0.00585018 0.00598491 0.00585018 0.00585018 0.00585018 0.00585018\n",
      " 0.00585018 0.00585018 0.00598491 0.00585018 0.00585018 0.00585018\n",
      " 0.00585018 0.00598491 0.00598491 0.00585018 0.00598491 0.00585018\n",
      " 0.00585018 0.00585018 0.00598491 0.00585018 0.00585018 0.00585018\n",
      " 0.00585018 0.00585018 0.00585018 0.00585018 0.00585018 0.00598491\n",
      " 0.00585018 0.00585018 0.00585018 0.00585018 0.00585018 0.00585018\n",
      " 0.00585018]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Treinando o modelo....\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n",
      "\n",
      "...:::: Avaliação ::::....  \n",
      "\n",
      "Error : 0.24681179888794086\n",
      "Alpha : 0.011156890332710057\n",
      "\n",
      ":: Treinamento :: \n",
      "\n",
      "Confusion Matrix : \n",
      "[[74 17]\n",
      " [24 54]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.757396449704142\n",
      "Misclassification rate : 0.197\n",
      "True positives : 0.692\n",
      "False positives : 0.187\n",
      "Specificity : 0.813\n",
      "Precision : 0.761\n",
      "Prevalence : 0.375\n",
      "Recall : 0.692\n",
      "\n",
      ":: Teste ::\n",
      "\n",
      "Confusion Matrix : \n",
      "[[8 1]\n",
      " [1 8]]\n",
      "Total : 208.0\n",
      "Acurácia : 0.8888888888888888\n",
      "Misclassification rate : 0.01\n",
      "True positives : 0.889\n",
      "False positives : 0.111\n",
      "Specificity : 0.889\n",
      "Precision : 0.889\n",
      "Prevalence : 0.043\n",
      "Recall : 0.889\n",
      "\n",
      "Novos pesos atualizados : \n",
      "[0.00578527 0.00578527 0.00578527 0.00578527 0.00578527 0.00578527\n",
      " 0.00578527 0.00578527 0.00605206 0.00578527 0.00578527 0.00578527\n",
      " 0.00578527 0.00578527 0.00578527 0.00578527 0.00578527 0.00605206\n",
      " 0.00578527 0.00578527 0.00578527 0.00578527 0.00605206 0.00578527\n",
      " 0.00578527 0.00605206 0.00605206 0.00578527 0.00578527 0.00578527\n",
      " 0.00578527 0.00578527 0.00578527 0.00578527 0.00578527 0.00578527\n",
      " 0.00578527 0.00578527 0.00578527 0.00605206 0.00578527 0.00578527\n",
      " 0.00578527 0.00605206 0.00605206 0.00578527 0.00578527 0.00605206\n",
      " 0.00578527 0.00578527 0.00605206 0.00605206 0.00578527 0.00578527\n",
      " 0.00605206 0.00605206 0.00605206 0.00578527 0.00578527 0.00578527\n",
      " 0.00578527 0.00578527 0.00578527 0.00605206 0.00578527 0.00578527\n",
      " 0.00578527 0.00605206 0.00578527 0.00578527 0.00578527 0.00578527\n",
      " 0.00578527 0.00578527 0.00578527 0.00578527 0.00578527 0.00605206\n",
      " 0.00578527 0.00578527 0.00578527 0.00605206 0.00578527 0.00578527\n",
      " 0.00578527 0.00578527 0.00605206 0.00578527 0.00578527 0.00578527\n",
      " 0.00578527 0.00578527 0.00578527 0.00578527 0.00578527 0.00578527\n",
      " 0.00578527 0.00605206 0.00578527 0.00605206 0.00578527 0.00578527\n",
      " 0.00605206 0.00578527 0.00605206 0.00578527 0.00605206 0.00578527\n",
      " 0.00578527 0.00578527 0.00605206 0.00578527 0.00605206 0.00578527\n",
      " 0.00605206 0.00605206 0.00578527 0.00578527 0.00578527 0.00605206\n",
      " 0.00605206 0.00605206 0.00578527 0.00578527 0.00605206 0.00578527\n",
      " 0.00578527 0.00578527 0.00578527 0.00605206 0.00578527 0.00605206\n",
      " 0.00578527 0.00605206 0.00578527 0.00578527 0.00578527 0.00578527\n",
      " 0.00578527 0.00578527 0.00605206 0.00578527 0.00578527 0.00578527\n",
      " 0.00578527 0.00605206 0.00605206 0.00578527 0.00605206 0.00578527\n",
      " 0.00578527 0.00578527 0.00605206 0.00578527 0.00578527 0.00578527\n",
      " 0.00578527 0.00578527 0.00578527 0.00578527 0.00578527 0.00605206\n",
      " 0.00578527 0.00578527 0.00578527 0.00578527 0.00578527 0.00578527\n",
      " 0.00578527]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "\n",
    "\n",
    "# Define quantos folds\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "print()\n",
    "print(\"....Iniciando treinamento com 10 K-folds....\" )\n",
    "print()\n",
    "\n",
    "kfold = 0    \n",
    "for train_index, test_index in kf.split(trainData):\n",
    "    \n",
    "    print(\"################################################\")\n",
    "    print(\"K-fold : \"+str(kfold+1))    \n",
    "    print(\"################################################\")\n",
    "    #print(train_index, test_index)\n",
    "    print()\n",
    "\n",
    "    # Obten os subdados de treinamento e teste no n fold\n",
    "    #---------------------------------------------------------------------\n",
    "    X_train, X_test = trainData.iloc[train_index,:], trainData.iloc[test_index,:]\n",
    "    #print(len(X_train), len(X_test))\n",
    "\n",
    "    y_train, y_test = trainLabels.iloc[train_index], trainLabels.iloc[test_index]\n",
    "    #print(len(y_train), len(y_test))\n",
    "    \n",
    "    print(\"....Inicializando vetor de pesos....\")\n",
    "    print()\n",
    "\n",
    "\n",
    "    n_train, n_test = len(X_train), len(y_test)\n",
    "    #pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)]\n",
    "\n",
    "    # Initialize weights\n",
    "    w = np.ones(n_train) / n_train\n",
    "    print(w)\n",
    "        \n",
    "    # Fit um classificador\n",
    "    clf_tree = DecisionTreeClassifier(max_depth = 1, random_state = 1)\n",
    "    # Fit um classificador\n",
    "    clf_tree2 = DecisionTreeClassifier(max_depth = 1, random_state = 1)\n",
    "\n",
    "    models = [clf_tree, clf_tree2]\n",
    "\n",
    "    for model in models:\n",
    "        print()\n",
    "        # Treina o modelo de classificação\n",
    "        #---------------------------------------------------------------------\n",
    "        print(\"Treinando o modelo....\")\n",
    "\n",
    "        # Treina o classificador com os pesos de treinamento\n",
    "        model.fit(X_train, y_train, sample_weight=w)\n",
    "        print(clf_tree)\n",
    "\n",
    "        # Classifica o treino\n",
    "        pred_train_i = clf_tree.predict(X_train)\n",
    "        #print(pred_train_i)\n",
    "\n",
    "        # Classifica o teste\n",
    "        pred_test_i = clf_tree.predict(X_test)\n",
    "        #print(pred_test_i)        \n",
    "\n",
    "        print()\n",
    "        print(\"...:::: Avaliação ::::....  \")\n",
    "        print()\n",
    "\n",
    "        # Obtem o index dos erros da classificação de treino e teste\n",
    "        #---------------------------------------------------------------------\n",
    "        miss = [int(x) for x in (pred_train_i != y_train)]\n",
    "        #print(\"Training Miss : \"+str(miss))\n",
    "        missTest = [int(x) for x in (pred_test_i != y_test)]\n",
    "        #print(\"Testing Miss : \"+str(missTest))\n",
    "\n",
    "        # Equivale os valores entre 1/-1 para atualização dos pesos\n",
    "        #---------------------------------------------------------------------\n",
    "        miss2 = [x if x==1 else -1 for x in miss]\n",
    "        #print(\"Training Miss2 : \"+str(miss2))\n",
    "        miss2Test = [x if x==1 else -1 for x in missTest]\n",
    "        #print(\"Testing Miss2 : \"+str(miss2Test))\n",
    "\n",
    "\n",
    "        # Calcula o erro\n",
    "        #---------------------------------------------------------------------\n",
    "        err_m = np.dot(w,miss) / sum(w)\n",
    "        print(\"Error : \"+str(err_m))\n",
    "\n",
    "        # Calcula o Alpha \n",
    "        #---------------------------------------------------------------------\n",
    "        alpha_m = alpha * np.log( (1 - err_m) / float(err_m))\n",
    "        print(\"Alpha : \"+str(alpha_m))\n",
    "\n",
    "\n",
    "        # Mostra a Matriz de Confusão para treino e teste\n",
    "        #---------------------------------------------------------------------\n",
    "        print()\n",
    "        print(\":: Treinamento :: \")\n",
    "        print(\"\")\n",
    "        train_acc_score, train_precision_score, train_recall_score = printCM(y_train, pred_train_i)\n",
    "\n",
    "        print()\n",
    "        print(\":: Teste ::\")\n",
    "        print()\n",
    "        test_acc_score, test_precision_score, test_recall_score = printCM(y_test, pred_test_i)\n",
    "        print\n",
    "\n",
    "\n",
    "        # Atualiza os valores dos pesos\n",
    "        #---------------------------------------------------------------------\n",
    "        w = np.multiply(w, np.exp([float(x) * alpha_m for x in miss2]))\n",
    "        print()\n",
    "        print(\"Novos pesos atualizados : \")\n",
    "        print(w)\n",
    "        print()\n",
    "        print(\"---------------------------------------------------------------------------\")\n",
    "        print()\n",
    "\n",
    "\n",
    "        scores.append([kfold, train_acc_score, train_precision_score, train_recall_score, err_m, alpha_m, clf_tree])\n",
    "\n",
    "    kfold += 1 \n",
    "    print\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  0.7559523809523809,\n",
       "  0.793,\n",
       "  0.613,\n",
       "  0.24404761904761962,\n",
       "  0.011306150197542804,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [0,\n",
       "  0.7559523809523809,\n",
       "  0.793,\n",
       "  0.613,\n",
       "  0.2482434308884095,\n",
       "  0.011080027193591958,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [1,\n",
       "  0.7619047619047619,\n",
       "  0.761,\n",
       "  0.68,\n",
       "  0.2380952380952387,\n",
       "  0.011631508098056775,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [1,\n",
       "  0.7619047619047619,\n",
       "  0.761,\n",
       "  0.68,\n",
       "  0.24234096282028092,\n",
       "  0.011398877936095632,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [2,\n",
       "  0.7976190476190478,\n",
       "  0.833,\n",
       "  0.732,\n",
       "  0.20238095238095288,\n",
       "  0.01371479275334747,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [2,\n",
       "  0.7976190476190478,\n",
       "  0.833,\n",
       "  0.732,\n",
       "  0.2068448773608795,\n",
       "  0.01344049689828053,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [3,\n",
       "  0.7559523809523809,\n",
       "  0.76,\n",
       "  0.713,\n",
       "  0.24404761904761962,\n",
       "  0.011306150197542804,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [3,\n",
       "  0.7559523809523809,\n",
       "  0.76,\n",
       "  0.713,\n",
       "  0.24824343088840956,\n",
       "  0.011080027193591952,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [4,\n",
       "  0.7619047619047619,\n",
       "  0.781,\n",
       "  0.704,\n",
       "  0.2380952380952387,\n",
       "  0.011631508098056775,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [4,\n",
       "  0.7619047619047619,\n",
       "  0.781,\n",
       "  0.704,\n",
       "  0.24234096282028092,\n",
       "  0.011398877936095632,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [5,\n",
       "  0.7857142857142857,\n",
       "  0.85,\n",
       "  0.654,\n",
       "  0.2142857142857148,\n",
       "  0.012992829841302575,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [5,\n",
       "  0.7857142857142857,\n",
       "  0.85,\n",
       "  0.654,\n",
       "  0.21869332705327416,\n",
       "  0.012732973244476576,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [6,\n",
       "  0.7916666666666665,\n",
       "  0.808,\n",
       "  0.738,\n",
       "  0.20833333333333381,\n",
       "  0.013350010667323371,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [6,\n",
       "  0.7916666666666665,\n",
       "  0.808,\n",
       "  0.738,\n",
       "  0.21277127957479308,\n",
       "  0.013083010453976902,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [7,\n",
       "  0.7751479289940828,\n",
       "  0.806,\n",
       "  0.658,\n",
       "  0.22485207100591678,\n",
       "  0.01237611163474768,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [7,\n",
       "  0.7751479289940828,\n",
       "  0.806,\n",
       "  0.658,\n",
       "  0.22919558537655021,\n",
       "  0.012128589402052754,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [8,\n",
       "  0.7692307692307694,\n",
       "  0.81,\n",
       "  0.654,\n",
       "  0.23076923076923042,\n",
       "  0.012039728043259382,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [8,\n",
       "  0.7692307692307694,\n",
       "  0.81,\n",
       "  0.654,\n",
       "  0.23507137304848244,\n",
       "  0.01179893348239416,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [9,\n",
       "  0.757396449704142,\n",
       "  0.761,\n",
       "  0.692,\n",
       "  0.2426035502958576,\n",
       "  0.011384581972153116,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')],\n",
       " [9,\n",
       "  0.757396449704142,\n",
       "  0.761,\n",
       "  0.692,\n",
       "  0.24681179888794086,\n",
       "  0.011156890332710057,\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "              splitter='best')]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Apresentação dos Resultados</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-fold</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Error</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.206845</td>\n",
       "      <td>0.013440</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.202381</td>\n",
       "      <td>0.013715</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.212771</td>\n",
       "      <td>0.013083</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.218693</td>\n",
       "      <td>0.012733</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.012993</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>0.775148</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.229196</td>\n",
       "      <td>0.012129</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>0.775148</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.224852</td>\n",
       "      <td>0.012376</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.235071</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.012040</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.242341</td>\n",
       "      <td>0.011399</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.242341</td>\n",
       "      <td>0.011399</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.011632</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.011632</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>0.757396</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.246812</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>0.757396</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.242604</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.755952</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.248243</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.755952</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.248243</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.755952</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.244048</td>\n",
       "      <td>0.011306</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0.755952</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.244048</td>\n",
       "      <td>0.011306</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n-fold       Acc  Precision  Recall     Error     Alpha  \\\n",
       "5        2  0.797619      0.833   0.732  0.206845  0.013440   \n",
       "4        2  0.797619      0.833   0.732  0.202381  0.013715   \n",
       "13       6  0.791667      0.808   0.738  0.212771  0.013083   \n",
       "12       6  0.791667      0.808   0.738  0.208333  0.013350   \n",
       "11       5  0.785714      0.850   0.654  0.218693  0.012733   \n",
       "10       5  0.785714      0.850   0.654  0.214286  0.012993   \n",
       "15       7  0.775148      0.806   0.658  0.229196  0.012129   \n",
       "14       7  0.775148      0.806   0.658  0.224852  0.012376   \n",
       "17       8  0.769231      0.810   0.654  0.235071  0.011799   \n",
       "16       8  0.769231      0.810   0.654  0.230769  0.012040   \n",
       "3        1  0.761905      0.761   0.680  0.242341  0.011399   \n",
       "9        4  0.761905      0.781   0.704  0.242341  0.011399   \n",
       "2        1  0.761905      0.761   0.680  0.238095  0.011632   \n",
       "8        4  0.761905      0.781   0.704  0.238095  0.011632   \n",
       "19       9  0.757396      0.761   0.692  0.246812  0.011157   \n",
       "18       9  0.757396      0.761   0.692  0.242604  0.011385   \n",
       "7        3  0.755952      0.760   0.713  0.248243  0.011080   \n",
       "1        0  0.755952      0.793   0.613  0.248243  0.011080   \n",
       "0        0  0.755952      0.793   0.613  0.244048  0.011306   \n",
       "6        3  0.755952      0.760   0.713  0.244048  0.011306   \n",
       "\n",
       "                                                Model  \n",
       "5   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "4   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "13  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "12  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "11  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "10  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "15  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "14  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "17  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "16  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "3   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "9   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "2   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "8   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "19  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "18  DecisionTreeClassifier(class_weight=None, crit...  \n",
       "7   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "1   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "0   DecisionTreeClassifier(class_weight=None, crit...  \n",
       "6   DecisionTreeClassifier(class_weight=None, crit...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresDF = pd.DataFrame(scores, columns=[\"n-fold\", \n",
    "                                         \"Acc\", \n",
    "                                         \"Precision\", \n",
    "                                         \"Recall\",\n",
    "                                         \"Error\", \n",
    "                                         \"Alpha\", \n",
    "                                         \"Model\"])\n",
    "\n",
    "scoresDF.sort_values([\"Acc\",\"Error\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = scoresDF.iloc[0, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_validation = bestModel.predict(validationData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[19  9]\n",
      " [13 11]]\n",
      "\n",
      "Total : 208.0\n",
      "Acurácia : 0.576923076923\n",
      "Misclassification rate : 0.106\n",
      "True positives : 0.458\n",
      "False positives : 0.321\n",
      "Specificity : 0.679\n",
      "Precision : 0.55\n",
      "Prevalence : 0.115\n",
      "Recall : 0.458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5769230769230769, 0.55, 0.458)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printCM(validationLabels, pred_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
